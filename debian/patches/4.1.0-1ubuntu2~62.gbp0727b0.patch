Description: <short summary of the patch>
 TODO: Put a short summary on the line above and replace this paragraph
 with a longer explanation of this change. Complete the meta-information
 with other relevant fields (see below for details). To make it easier, the
 information below has been extracted from the changelog. Adjust it or drop
 it.
 .
 gtsam (4.1.0-1ubuntu2~62.gbp0727b0) UNRELEASED; urgency=medium
 .
   ** SNAPSHOT build @0727b0f21b6de6482f962ff424761f29b6c682b1 **
 .
   [ Borglab Builder ]
   ** SNAPSHOT build @c3472a71d772c04bdf6ca9a4464897ca3c7ba707 **
 .
   * modified changelog for distro focal
 .
   [ Varun Agrawal ]
   * Make Values::at return as const
   * FIx indentation for Values-inl.h
 .
   [ jingwuOUO ]
   * Added test for subgraph preconditioner in shonan
   * Refined error message in subgraphbuilder
 .
   [ Varun Agrawal ]
   * Assign pointer to prevent errors
   * fixes to plot code
   * suppress warnings from clang as well
 .
   [ Borglab Builder ]
   * commit of final snapshot version number update
 .
   [ Varun Agrawal ]
   * Deprecate SimpleCamera properly
   * deprecate SimpleCamera tests
 .
   [ jingwuOUO ]
   * Fixed typo
 .
   [ Varun Agrawal ]
   * update Python test
   * Revert "FIx indentation for Values-inl.h"
 .
   [ jingwuOUO ]
   * Added more description to the toyExample.g2o
Author: Borglab Builder <borglab.launchpad@gmail.com>

---
The information above should follow the Patch Tagging Guidelines, please
checkout http://dep.debian.net/deps/dep3/ to learn about the format. Here
are templates for supplementary fields that you might want to add:

Origin: <vendor|upstream|other>, <url of original patch>
Bug: <url in upstream bugtracker>
Bug-Debian: https://bugs.debian.org/<bugnumber>
Bug-Ubuntu: https://launchpad.net/bugs/<bugnumber>
Forwarded: <no|not-needed|url proving that it has been forwarded>
Reviewed-By: <name and email of someone who approved the patch>
Last-Update: 2020-12-01

--- gtsam-4.1.0.orig/.github/scripts/python.sh
+++ gtsam-4.1.0/.github/scripts/python.sh
@@ -43,11 +43,6 @@ if [ -z ${PYTHON_VERSION+x} ]; then
     exit 127
 fi
 
-if [ -z ${WRAPPER+x} ]; then
-    echo "Please provide the wrapper to build!"
-    exit 126
-fi
-
 PYTHON="python${PYTHON_VERSION}"
 
 if [[ $(uname) == "Darwin" ]]; then
@@ -61,25 +56,11 @@ PATH=$PATH:$($PYTHON -c "import site; pr
 
 [ "${GTSAM_WITH_TBB:-OFF}" = "ON" ] && install_tbb
 
-case $WRAPPER in
-"cython")
-    BUILD_CYTHON="ON"
-    BUILD_PYBIND="OFF"
-    TYPEDEF_POINTS_TO_VECTORS="OFF"
-
-    sudo $PYTHON -m pip install -r $GITHUB_WORKSPACE/cython/requirements.txt
-    ;;
-"pybind")
-    BUILD_CYTHON="OFF"
-    BUILD_PYBIND="ON"
-    TYPEDEF_POINTS_TO_VECTORS="ON"
-
-    sudo $PYTHON -m pip install -r $GITHUB_WORKSPACE/python/requirements.txt
-    ;;
-*)
-    exit 126
-    ;;
-esac
+
+BUILD_PYBIND="ON"
+TYPEDEF_POINTS_TO_VECTORS="ON"
+
+sudo $PYTHON -m pip install -r $GITHUB_WORKSPACE/python/requirements.txt
 
 mkdir $GITHUB_WORKSPACE/build
 cd $GITHUB_WORKSPACE/build
@@ -90,7 +71,6 @@ cmake $GITHUB_WORKSPACE -DCMAKE_BUILD_TY
     -DGTSAM_WITH_TBB=${GTSAM_WITH_TBB:-OFF} \
     -DGTSAM_BUILD_EXAMPLES_ALWAYS=OFF \
     -DGTSAM_BUILD_WITH_MARCH_NATIVE=OFF \
-    -DGTSAM_INSTALL_CYTHON_TOOLBOX=${BUILD_CYTHON} \
     -DGTSAM_BUILD_PYTHON=${BUILD_PYBIND} \
     -DGTSAM_TYPEDEF_POINTS_TO_VECTORS=${TYPEDEF_POINTS_TO_VECTORS} \
     -DGTSAM_PYTHON_VERSION=$PYTHON_VERSION \
@@ -98,30 +78,10 @@ cmake $GITHUB_WORKSPACE -DCMAKE_BUILD_TY
     -DGTSAM_ALLOW_DEPRECATED_SINCE_V41=OFF \
     -DCMAKE_INSTALL_PREFIX=$GITHUB_WORKSPACE/gtsam_install
 
-make -j$(nproc) install &
+make -j$(nproc) install
+
 
-while ps -p $! > /dev/null
-do
-  sleep 60
-  now=$(date +%s)
-  printf "%d seconds have elapsed\n" $(( (now - start) ))
-done
-
-case $WRAPPER in
-"cython")
-    cd $GITHUB_WORKSPACE/build/cython
-    $PYTHON setup.py install --user --prefix=
-    cd $GITHUB_WORKSPACE/build/cython/gtsam/tests
-    $PYTHON -m unittest discover
-    ;;
-"pybind")
-    cd $GITHUB_WORKSPACE/build/python
-    $PYTHON setup.py install --user --prefix=
-    cd $GITHUB_WORKSPACE/python/gtsam/tests
-    $PYTHON -m unittest discover
-    ;;
-*)
-    echo "THIS SHOULD NEVER HAPPEN!"
-    exit 125
-    ;;
-esac
\ No newline at end of file
+cd $GITHUB_WORKSPACE/build/python
+$PYTHON setup.py install --user --prefix=
+cd $GITHUB_WORKSPACE/python/gtsam/tests
+$PYTHON -m unittest discover
--- gtsam-4.1.0.orig/.github/scripts/unix.sh
+++ gtsam-4.1.0/.github/scripts/unix.sh
@@ -66,6 +66,8 @@ function configure()
       -DGTSAM_BUILD_EXAMPLES_ALWAYS=${GTSAM_BUILD_EXAMPLES_ALWAYS:-ON} \
       -DGTSAM_ALLOW_DEPRECATED_SINCE_V41=${GTSAM_ALLOW_DEPRECATED_SINCE_V41:-OFF} \
       -DGTSAM_USE_QUATERNIONS=${GTSAM_USE_QUATERNIONS:-OFF} \
+      -DGTSAM_ROT3_EXPMAP=${GTSAM_ROT3_EXPMAP:-ON} \
+      -DGTSAM_POSE3_EXPMAP=${GTSAM_POSE3_EXPMAP:-ON} \
       -DGTSAM_BUILD_WITH_MARCH_NATIVE=OFF \
       -DBOOST_ROOT=$BOOST_ROOT \
       -DBoost_NO_SYSTEM_PATHS=ON \
--- gtsam-4.1.0.orig/.github/workflows/build-linux.yml
+++ gtsam-4.1.0/.github/workflows/build-linux.yml
@@ -48,25 +48,32 @@ jobs:
       - name: Install (Linux)
         if: runner.os == 'Linux'
         run: |
-          # LLVM 9 is not in Bionic's repositories so we add the official LLVM repository.
+          # LLVM (clang) 9 is not in Bionic's repositories so we add the official LLVM repository.
           if [ "${{ matrix.compiler }}" = "clang" ] && [ "${{ matrix.version }}" = "9" ]; then
+            # (ipv4|ha).pool.sks-keyservers.net is the SKS GPG global keyserver pool
+            # ipv4 avoids potential timeouts because of crappy IPv6 infrastructure
+            # 15CF4D18AF4F7421 is the GPG key for the LLVM apt repository
+            # This key is not in the keystore by default for Ubuntu so we need to add it.
+            LLVM_KEY=15CF4D18AF4F7421
+            gpg --keyserver ipv4.pool.sks-keyservers.net --recv-key $LLVM_KEY || gpg --keyserver ha.pool.sks-keyservers.net --recv-key $LLVM_KEY
+            gpg -a --export $LLVM_KEY | sudo apt-key add -
             sudo add-apt-repository "deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main"
           fi
           sudo apt-get -y update
 
           sudo apt install cmake build-essential pkg-config libpython-dev python-numpy
           
-          echo "::set-env name=BOOST_ROOT::$(echo $BOOST_ROOT_1_69_0)"
-          echo "::set-env name=LD_LIBRARY_PATH::$(echo $BOOST_ROOT_1_69_0/lib)"
+          echo "BOOST_ROOT=$(echo $BOOST_ROOT_1_72_0)" >> $GITHUB_ENV
+          echo "LD_LIBRARY_PATH=$(echo $BOOST_ROOT_1_72_0/lib)" >> $GITHUB_ENV
           
           if [ "${{ matrix.compiler }}" = "gcc" ]; then
             sudo apt-get install -y g++-${{ matrix.version }} g++-${{ matrix.version }}-multilib
-            echo "::set-env name=CC::gcc-${{ matrix.version }}"
-            echo "::set-env name=CXX::g++-${{ matrix.version }}"
+            echo "CC=gcc-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=g++-${{ matrix.version }}" >> $GITHUB_ENV
           else
             sudo apt-get install -y clang-${{ matrix.version }} g++-multilib
-            echo "::set-env name=CC::clang-${{ matrix.version }}"
-            echo "::set-env name=CXX::clang++-${{ matrix.version }}"
+            echo "CC=clang-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=clang++-${{ matrix.version }}" >> $GITHUB_ENV
           fi
       - name: Check Boost version
         if: runner.os == 'Linux'
@@ -75,4 +82,10 @@ jobs:
       - name: Build and Test (Linux)
         if: runner.os == 'Linux'
         run: |
-          bash .github/scripts/unix.sh -t
\ No newline at end of file
+          bash .github/scripts/unix.sh -t
+      - name: Upload build directory
+        uses: actions/upload-artifact@v2
+        if: matrix.build_type  == 'Release'
+        with:
+          name: gtsam-${{ matrix.name }}-${{ matrix.build_type }}
+          path: ${{ github.workspace }}/build/
--- gtsam-4.1.0.orig/.github/workflows/build-macos.yml
+++ gtsam-4.1.0/.github/workflows/build-macos.yml
@@ -35,17 +35,25 @@ jobs:
       - name: Install (macOS)
         if: runner.os == 'macOS'
         run: |
-          brew install cmake ninja boost
+          brew tap ProfFan/robotics
+          brew install cmake ninja
+          brew install ProfFan/robotics/boost
           if [ "${{ matrix.compiler }}" = "gcc" ]; then
             brew install gcc@${{ matrix.version }}
-            echo "::set-env name=CC::gcc-${{ matrix.version }}"
-            echo "::set-env name=CXX::g++-${{ matrix.version }}"
+            echo "CC=gcc-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=g++-${{ matrix.version }}" >> $GITHUB_ENV
           else
             sudo xcode-select -switch /Applications/Xcode_${{ matrix.version }}.app
-            echo "::set-env name=CC::clang"
-            echo "::set-env name=CXX::clang++"
+            echo "CC=clang" >> $GITHUB_ENV
+            echo "CXX=clang++" >> $GITHUB_ENV
           fi
       - name: Build and Test (macOS)
         if: runner.os == 'macOS'
         run: |
-          bash .github/scripts/unix.sh -t
\ No newline at end of file
+          bash .github/scripts/unix.sh -t
+      - name: Upload build directory
+        uses: actions/upload-artifact@v2
+        if: matrix.build_type == 'Release'
+        with:
+          name: gtsam-${{ matrix.name }}-${{ matrix.build_type }}
+          path: ${{ github.workspace }}/build/
--- gtsam-4.1.0.orig/.github/workflows/build-python.yml
+++ gtsam-4.1.0/.github/workflows/build-python.yml
@@ -12,7 +12,6 @@ jobs:
       CTEST_PARALLEL_LEVEL: 2
       CMAKE_BUILD_TYPE: ${{ matrix.build_type }}
       PYTHON_VERSION: ${{ matrix.python_version }}
-      WRAPPER: ${{ matrix.wrapper }}
     strategy:
       fail-fast: false
       matrix:
@@ -20,7 +19,7 @@ jobs:
         # See https://help.github.com/en/articles/workflow-syntax-for-github-actions.
         name: [
           ubuntu-18.04-gcc-5,
-          # ubuntu-18.04-gcc-9,  # TODO Disabled for now because of timeouts
+          ubuntu-18.04-gcc-9,
           ubuntu-18.04-clang-9,
           macOS-10.15-xcode-11.3.1,
           ubuntu-18.04-gcc-5-tbb,
@@ -28,18 +27,16 @@ jobs:
 
         build_type: [Debug, Release]
         python_version: [3]
-        wrapper: [pybind]
         include:
           - name: ubuntu-18.04-gcc-5
             os: ubuntu-18.04
             compiler: gcc
             version: "5"
 
-          # TODO Disabled for now because of timeouts
-          # - name: ubuntu-18.04-gcc-9
-          #   os: ubuntu-18.04
-          #   compiler: gcc
-          #   version: "9"
+          - name: ubuntu-18.04-gcc-9
+            os: ubuntu-18.04
+            compiler: gcc
+            version: "9"
 
           - name: ubuntu-18.04-clang-9
             os: ubuntu-18.04
@@ -63,8 +60,14 @@ jobs:
       - name: Install (Linux)
         if: runner.os == 'Linux'
         run: |
-          # LLVM 9 is not in Bionic's repositories so we add the official LLVM repository.
           if [ "${{ matrix.compiler }}" = "clang" ] && [ "${{ matrix.version }}" = "9" ]; then
+            # (ipv4|ha).pool.sks-keyservers.net is the SKS GPG global keyserver pool
+            # ipv4 avoids potential timeouts because of crappy IPv6 infrastructure
+            # 15CF4D18AF4F7421 is the GPG key for the LLVM apt repository
+            # This key is not in the keystore by default for Ubuntu so we need to add it.
+            LLVM_KEY=15CF4D18AF4F7421
+            gpg --keyserver ipv4.pool.sks-keyservers.net --recv-key $LLVM_KEY || gpg --keyserver ha.pool.sks-keyservers.net --recv-key $LLVM_KEY
+            gpg -a --export $LLVM_KEY | sudo apt-key add -
             sudo add-apt-repository "deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main"
           fi
           sudo apt-get -y update
@@ -73,30 +76,32 @@ jobs:
           
           if [ "${{ matrix.compiler }}" = "gcc" ]; then
             sudo apt-get install -y g++-${{ matrix.version }} g++-${{ matrix.version }}-multilib
-            echo "::set-env name=CC::gcc-${{ matrix.version }}"
-            echo "::set-env name=CXX::g++-${{ matrix.version }}"
+            echo "CC=gcc-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=g++-${{ matrix.version }}" >> $GITHUB_ENV
           else
             sudo apt-get install -y clang-${{ matrix.version }} g++-multilib
-            echo "::set-env name=CC::clang-${{ matrix.version }}"
-            echo "::set-env name=CXX::clang++-${{ matrix.version }}"
+            echo "CC=clang-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=clang++-${{ matrix.version }}" >> $GITHUB_ENV
           fi
       - name: Install (macOS)
         if: runner.os == 'macOS'
         run: |
-          brew install cmake ninja boost
+          brew tap ProfFan/robotics
+          brew install cmake ninja
+          brew install ProfFan/robotics/boost
           if [ "${{ matrix.compiler }}" = "gcc" ]; then
             brew install gcc@${{ matrix.version }}
-            echo "::set-env name=CC::gcc-${{ matrix.version }}"
-            echo "::set-env name=CXX::g++-${{ matrix.version }}"
+            echo "CC=gcc-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=g++-${{ matrix.version }}" >> $GITHUB_ENV
           else
             sudo xcode-select -switch /Applications/Xcode_${{ matrix.version }}.app
-            echo "::set-env name=CC::clang"
-            echo "::set-env name=CXX::clang++"
+            echo "CC=clang" >> $GITHUB_ENV
+            echo "CXX=clang++" >> $GITHUB_ENV
           fi
       - name: Set GTSAM_WITH_TBB Flag
         if: matrix.flag == 'tbb'
         run: |
-          echo "::set-env name=GTSAM_WITH_TBB::ON"
+          echo "GTSAM_WITH_TBB=ON" >> $GITHUB_ENV
           echo "GTSAM Uses TBB"
       - name: Build (Linux)
         if: runner.os == 'Linux'
@@ -105,4 +110,4 @@ jobs:
       - name: Build (macOS)
         if: runner.os == 'macOS'
         run: |
-          bash .github/scripts/python.sh
\ No newline at end of file
+          bash .github/scripts/python.sh
--- gtsam-4.1.0.orig/.github/workflows/build-special.yml
+++ gtsam-4.1.0/.github/workflows/build-special.yml
@@ -24,6 +24,7 @@ jobs:
             ubuntu-gcc-deprecated,
             ubuntu-gcc-quaternions,
             ubuntu-gcc-tbb,
+            ubuntu-cayleymap,
           ]
 
         build_type: [Debug, Release]
@@ -47,6 +48,12 @@ jobs:
             version: "9"
             flag: tbb
 
+          - name: ubuntu-cayleymap
+            os: ubuntu-18.04
+            compiler: gcc
+            version: "9"
+            flag: cayley
+
     steps:
       - name: Checkout
         uses: actions/checkout@master
@@ -56,23 +63,25 @@ jobs:
         run: |
           # LLVM 9 is not in Bionic's repositories so we add the official LLVM repository.
           if [ "${{ matrix.compiler }}" = "clang" ] && [ "${{ matrix.version }}" = "9" ]; then
+            gpg --keyserver pool.sks-keyservers.net --recv-key 15CF4D18AF4F7421
+            gpg -a --export 15CF4D18AF4F7421 | sudo apt-key add -
             sudo add-apt-repository "deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main"
           fi
           sudo apt-get -y update
 
           sudo apt install cmake build-essential pkg-config libpython-dev python-numpy
 
-          echo "::set-env name=BOOST_ROOT::$(echo $BOOST_ROOT_1_69_0)"
-          echo "::set-env name=LD_LIBRARY_PATH::$(echo $BOOST_ROOT_1_69_0/lib)"
+          echo "BOOST_ROOT=$(echo $BOOST_ROOT_1_72_0)" >> $GITHUB_ENV
+          echo "LD_LIBRARY_PATH=$(echo $BOOST_ROOT_1_72_0/lib)" >> $GITHUB_ENV
 
           if [ "${{ matrix.compiler }}" = "gcc" ]; then
             sudo apt-get install -y g++-${{ matrix.version }} g++-${{ matrix.version }}-multilib
-            echo "::set-env name=CC::gcc-${{ matrix.version }}"
-            echo "::set-env name=CXX::g++-${{ matrix.version }}"
+            echo "CC=gcc-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=g++-${{ matrix.version }}" >> $GITHUB_ENV
           else
             sudo apt-get install -y clang-${{ matrix.version }} g++-multilib
-            echo "::set-env name=CC::clang-${{ matrix.version }}"
-            echo "::set-env name=CXX::clang++-${{ matrix.version }}"
+            echo "CC=clang-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=clang++-${{ matrix.version }}" >> $GITHUB_ENV
           fi
 
       - name: Install (macOS)
@@ -81,32 +90,39 @@ jobs:
           brew install cmake ninja boost
           if [ "${{ matrix.compiler }}" = "gcc" ]; then
             brew install gcc@${{ matrix.version }}
-            echo "::set-env name=CC::gcc-${{ matrix.version }}"
-            echo "::set-env name=CXX::g++-${{ matrix.version }}"
+            echo "CC=gcc-${{ matrix.version }}" >> $GITHUB_ENV
+            echo "CXX=g++-${{ matrix.version }}" >> $GITHUB_ENV
           else
             sudo xcode-select -switch /Applications/Xcode_${{ matrix.version }}.app
-            echo "::set-env name=CC::clang"
-            echo "::set-env name=CXX::clang++"
+            echo "CC=clang" >> $GITHUB_ENV
+            echo "CXX=clang++" >> $GITHUB_ENV
             fi
 
       - name: Set Allow Deprecated Flag
         if: matrix.flag == 'deprecated'
         run: |
-          echo "::set-env name=GTSAM_ALLOW_DEPRECATED_SINCE_V41::ON"
+          echo "GTSAM_ALLOW_DEPRECATED_SINCE_V41=ON" >> $GITHUB_ENV
           echo "Allow deprecated since version 4.1"
 
       - name: Set Use Quaternions Flag
         if: matrix.flag == 'quaternions'
         run: |
-          echo "::set-env name=GTSAM_USE_QUATERNIONS::ON"
+          echo "GTSAM_USE_QUATERNIONS=ON" >> $GITHUB_ENV
           echo "Use Quaternions for rotations"
 
       - name: Set GTSAM_WITH_TBB Flag
         if: matrix.flag == 'tbb'
         run: |
-          echo "::set-env name=GTSAM_WITH_TBB::ON"
+          echo "GTSAM_WITH_TBB=ON" >> $GITHUB_ENV
           echo "GTSAM Uses TBB"
 
+      - name: Use Cayley Transform for Rot3
+        if: matrix.flag == 'cayley'
+        run: |
+          echo "GTSAM_POSE3_EXPMAP=OFF" >> $GITHUB_ENV
+          echo "GTSAM_ROT3_EXPMAP=OFF" >> $GITHUB_ENV
+          echo "GTSAM Uses Cayley map for Rot3"
+
       - name: Build & Test
         run: |
           bash .github/scripts/unix.sh -t
--- gtsam-4.1.0.orig/.github/workflows/build-windows.yml
+++ gtsam-4.1.0/.github/workflows/build-windows.yml
@@ -18,16 +18,19 @@ jobs:
         # Github Actions requires a single row to be added to the build matrix.
         # See https://help.github.com/en/articles/workflow-syntax-for-github-actions.
         name: [
-          windows-2016-cl,
+          #TODO This build keeps timing out, need to understand why.
+          # windows-2016-cl,
           windows-2019-cl,
         ]
 
         build_type: [Debug, Release]
         build_unstable: [ON]
         include:
-          - name: windows-2016-cl
-            os: windows-2016
-            compiler: cl
+
+          #TODO This build keeps timing out, need to understand why.
+          # - name: windows-2016-cl
+          #   os: windows-2016
+          #   compiler: cl
 
           - name: windows-2019-cl
             os: windows-2019
@@ -50,17 +53,17 @@ jobs:
             # See: https://github.com/DaanDeMeyer/doctest/runs/231595515
             # See: https://github.community/t5/GitHub-Actions/Something-is-wrong-with-the-chocolatey-installed-version-of-gcc/td-p/32413
             scoop install gcc --global
-            echo "::set-env name=CC::gcc"
-            echo "::set-env name=CXX::g++"
+            echo "CC=gcc" >> $GITHUB_ENV
+            echo "CXX=g++" >> $GITHUB_ENV
           } elseif ("${{ matrix.compiler }}" -eq "clang") {
-            echo "::set-env name=CC::clang"
-            echo "::set-env name=CXX::clang++"
+            echo "CC=clang" >> $GITHUB_ENV
+            echo "CXX=clang++" >> $GITHUB_ENV
           } else {
-            echo "::set-env name=CC::${{ matrix.compiler }}"
-            echo "::set-env name=CXX::${{ matrix.compiler }}"
+            echo "CC=${{ matrix.compiler }}" >> $GITHUB_ENV
+            echo "CXX=${{ matrix.compiler }}" >> $GITHUB_ENV
           }
           # Scoop modifies the PATH so we make the modified PATH global.
-          echo "::set-env name=PATH::$env:PATH"
+          echo "$env:PATH" >> $GITHUB_PATH
       - name: Build (Windows)
         if: runner.os == 'Windows'
         run: |
@@ -72,4 +75,10 @@ jobs:
           cmake --build build --config ${{ matrix.build_type }} --target wrap
           cmake --build build --config ${{ matrix.build_type }} --target check.base
           cmake --build build --config ${{ matrix.build_type }} --target check.base_unstable
-          cmake --build build --config ${{ matrix.build_type }} --target check.linear
\ No newline at end of file
+          cmake --build build --config ${{ matrix.build_type }} --target check.linear
+      - name: Upload build directory
+        uses: actions/upload-artifact@v2
+        if: matrix.build_type == 'Release'
+        with:
+          name: gtsam-${{ matrix.name }}-${{ matrix.build_type }}
+          path: ${{ github.workspace }}/build/
--- gtsam-4.1.0.orig/.github/workflows/trigger-python.yml
+++ gtsam-4.1.0/.github/workflows/trigger-python.yml
@@ -1,11 +1,11 @@
-# This triggers Cython builds on `gtsam-manylinux-build`
+# This triggers Python builds on `gtsam-manylinux-build`
 name: Trigger Python Builds
 on:
   push:
     branches:
       - develop
 jobs:
-  triggerCython:
+  triggerPython:
     runs-on: ubuntu-latest
     steps:
       - name: Repository Dispatch
@@ -13,5 +13,5 @@ jobs:
         with:
           token: ${{ secrets.PYTHON_CI_REPO_ACCESS_TOKEN }}
           repository: borglab/gtsam-manylinux-build
-          event-type: cython-wrapper
+          event-type: python-wrapper
           client-payload: '{"ref": "${{ github.ref }}", "sha": "${{ github.sha }}"}'
--- gtsam-4.1.0.orig/CMakeLists.txt
+++ gtsam-4.1.0/CMakeLists.txt
@@ -14,20 +14,18 @@ set (GTSAM_VERSION_PATCH 0)
 math (EXPR GTSAM_VERSION_NUMERIC "10000 * ${GTSAM_VERSION_MAJOR} + 100 * ${GTSAM_VERSION_MINOR} + ${GTSAM_VERSION_PATCH}")
 set (GTSAM_VERSION_STRING "${GTSAM_VERSION_MAJOR}.${GTSAM_VERSION_MINOR}.${GTSAM_VERSION_PATCH}")
 
+set (CMAKE_PROJECT_VERSION ${GTSAM_VERSION_STRING})
+set (CMAKE_PROJECT_VERSION_MAJOR ${GTSAM_VERSION_MAJOR})
+set (CMAKE_PROJECT_VERSION_MINOR ${GTSAM_VERSION_MINOR})
+set (CMAKE_PROJECT_VERSION_PATCH ${GTSAM_VERSION_PATCH})
+
 ###############################################################################
 # Gather information, perform checks, set defaults
 
-# Set the default install path to home
-#set (CMAKE_INSTALL_PREFIX ${HOME} CACHE PATH "Install prefix for library")
-
 set(CMAKE_MODULE_PATH "${CMAKE_MODULE_PATH}" "${CMAKE_CURRENT_SOURCE_DIR}/cmake")
 include(GtsamMakeConfigFile)
 include(GNUInstallDirs)
 
-# Record the root dir for gtsam - needed during external builds, e.g., ROS
-set(GTSAM_SOURCE_ROOT_DIR ${CMAKE_CURRENT_SOURCE_DIR})
-message(STATUS "GTSAM_SOURCE_ROOT_DIR: [${GTSAM_SOURCE_ROOT_DIR}]")
-
 # Load build type flags and default to Debug mode
 include(GtsamBuildTypes)
 
@@ -40,383 +38,21 @@ if(${CMAKE_SOURCE_DIR} STREQUAL ${CMAKE_
   message(FATAL_ERROR "In-source builds not allowed. Please make a new directory (called a build directory) and run CMake from there. You may need to remove CMakeCache.txt. ")
 endif()
 
-# See whether gtsam_unstable is available (it will be present only if we're using a git checkout)
-if(EXISTS "${PROJECT_SOURCE_DIR}/gtsam_unstable" AND IS_DIRECTORY "${PROJECT_SOURCE_DIR}/gtsam_unstable")
-    set(GTSAM_UNSTABLE_AVAILABLE 1)
-else()
-    set(GTSAM_UNSTABLE_AVAILABLE 0)
-endif()
-
-# ----------------------------------------------------------------------------
-#   Uninstall target, for "make uninstall"
-# ----------------------------------------------------------------------------
-configure_file(
-  "${CMAKE_CURRENT_SOURCE_DIR}/cmake/cmake_uninstall.cmake.in"
-  "${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake"
-  IMMEDIATE @ONLY)
-
-add_custom_target(uninstall
-  "${CMAKE_COMMAND}" -P "${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake")
-
-
-###############################################################################
-# Set up options
-
-# Configurable Options
-if(GTSAM_UNSTABLE_AVAILABLE)
-    option(GTSAM_BUILD_UNSTABLE              "Enable/Disable libgtsam_unstable"          ON)
-    option(GTSAM_UNSTABLE_BUILD_PYTHON       "Enable/Disable Python wrapper for libgtsam_unstable" ON)
-    option(GTSAM_UNSTABLE_INSTALL_MATLAB_TOOLBOX "Enable/Disable MATLAB wrapper for libgtsam_unstable" OFF)
-endif()
-option(BUILD_SHARED_LIBS                 "Build shared gtsam library, instead of static" ON)
-option(GTSAM_USE_QUATERNIONS             "Enable/Disable using an internal Quaternion representation for rotations instead of rotation matrices. If enable, Rot3::EXPMAP is enforced by default." OFF)
-option(GTSAM_POSE3_EXPMAP                "Enable/Disable using Pose3::EXPMAP as the default mode. If disabled, Pose3::FIRST_ORDER will be used." ON)
-option(GTSAM_ROT3_EXPMAP                 "Ignore if GTSAM_USE_QUATERNIONS is OFF (Rot3::EXPMAP by default). Otherwise, enable Rot3::EXPMAP, or if disabled, use Rot3::CAYLEY." ON)
-option(GTSAM_ENABLE_CONSISTENCY_CHECKS   "Enable/Disable expensive consistency checks"       OFF)
-option(GTSAM_WITH_TBB                    "Use Intel Threaded Building Blocks (TBB) if available" ON)
-option(GTSAM_WITH_EIGEN_MKL              "Eigen will use Intel MKL if available" OFF)
-option(GTSAM_WITH_EIGEN_MKL_OPENMP       "Eigen, when using Intel MKL, will also use OpenMP for multithreading if available" OFF)
-option(GTSAM_THROW_CHEIRALITY_EXCEPTION  "Throw exception when a triangulated point is behind a camera" ON)
-option(GTSAM_BUILD_PYTHON                "Enable/Disable building & installation of Python module with pybind11" OFF)
-option(GTSAM_ALLOW_DEPRECATED_SINCE_V41  "Allow use of methods/functions deprecated in GTSAM 4.1" ON)
-option(GTSAM_SUPPORT_NESTED_DISSECTION   "Support Metis-based nested dissection" ON)
-option(GTSAM_TANGENT_PREINTEGRATION      "Use new ImuFactor with integration on tangent space" ON)
-if(NOT MSVC AND NOT XCODE_VERSION)
-    option(GTSAM_BUILD_WITH_CCACHE           "Use ccache compiler cache" ON)
-endif()
-
-if(NOT MSVC AND NOT XCODE_VERSION)
-  # Set the build type to upper case for downstream use
-  string(TOUPPER "${CMAKE_BUILD_TYPE}" CMAKE_BUILD_TYPE_UPPER)
-
-  # Set the GTSAM_BUILD_TAG variable.
-  # If build type is Release, set to blank (""), else set to the build type.
-  if(${CMAKE_BUILD_TYPE_UPPER} STREQUAL "RELEASE")
-   set(GTSAM_BUILD_TAG "") # Don't create release mode tag on installed directory
-  else()
-   set(GTSAM_BUILD_TAG "${CMAKE_BUILD_TYPE}")
-  endif()
-endif()
-
-# Options relating to MATLAB wrapper
-# TODO: Check for matlab mex binary before handling building of binaries
-option(GTSAM_INSTALL_MATLAB_TOOLBOX      "Enable/Disable installation of matlab toolbox"  OFF)
-set(GTSAM_PYTHON_VERSION "Default" CACHE STRING "The version of Python to build the wrappers against.")
-
-# Check / set dependent variables for MATLAB wrapper
-if(GTSAM_INSTALL_MATLAB_TOOLBOX AND GTSAM_BUILD_TYPE_POSTFIXES)
-    set(CURRENT_POSTFIX ${CMAKE_${CMAKE_BUILD_TYPE_UPPER}_POSTFIX})
-endif()
-
-if(GTSAM_INSTALL_MATLAB_TOOLBOX AND NOT BUILD_SHARED_LIBS)
-    message(FATAL_ERROR "GTSAM_INSTALL_MATLAB_TOOLBOX and BUILD_SHARED_LIBS=OFF. The MATLAB wrapper cannot be compiled with a static GTSAM library because mex modules are themselves shared libraries.  If you want a self-contained mex module, enable GTSAM_MEX_BUILD_STATIC_MODULE instead of BUILD_SHARED_LIBS=OFF.")
-endif()
-
-if(GTSAM_BUILD_PYTHON)
-    if(GTSAM_UNSTABLE_BUILD_PYTHON)
-        if (NOT GTSAM_BUILD_UNSTABLE)
-            message(WARNING "GTSAM_UNSTABLE_BUILD_PYTHON requires the unstable module to be enabled.")
-            set(GTSAM_UNSTABLE_BUILD_PYTHON OFF)
-        endif()
-    endif()
-
-    set(GTSAM_PY_INSTALL_PATH "${CMAKE_INSTALL_PREFIX}/python")
-endif()
-
-# Flags for choosing default packaging tools
-set(CPACK_SOURCE_GENERATOR "TGZ" CACHE STRING "CPack Default Source Generator")
-set(CPACK_GENERATOR        "TGZ" CACHE STRING "CPack Default Binary Generator")
-
-if (CMAKE_GENERATOR STREQUAL "Ninja" AND
-    ((CMAKE_CXX_COMPILER_ID STREQUAL "GNU" AND NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.9) OR
-     (CMAKE_CXX_COMPILER_ID STREQUAL "Clang" AND NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 3.5)))
-    # Force colored warnings in Ninja's output, if the compiler has -fdiagnostics-color support.
-    # Rationale in https://github.com/ninja-build/ninja/issues/814
-    add_compile_options(-fdiagnostics-color=always)
-endif()
-
-###############################################################################
-# Find boost
-
-# To change the path for boost, you will need to set:
-# BOOST_ROOT: path to install prefix for boost
-# Boost_NO_SYSTEM_PATHS: set to true to keep the find script from ignoring BOOST_ROOT
-
-if(MSVC)
-    # By default, boost only builds static libraries on windows
-    set(Boost_USE_STATIC_LIBS ON)  # only find static libs
-    # If we ever reset above on windows and, ...
-    # If we use Boost shared libs, disable auto linking.
-    # Some libraries, at least Boost Program Options, rely on this to export DLL symbols.
-    if(NOT Boost_USE_STATIC_LIBS)
-        list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC BOOST_ALL_NO_LIB BOOST_ALL_DYN_LINK)
-    endif()
-    # Virtual memory range for PCH exceeded on VS2015
-    if(MSVC_VERSION LESS 1910) # older than VS2017
-      list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE -Zm295)
-    endif()
-endif()
-
-# If building DLLs in MSVC, we need to avoid EIGEN_STATIC_ASSERT()
-# or explicit instantiation will generate build errors.
-# See: https://bitbucket.org/gtborg/gtsam/issues/417/fail-to-build-on-msvc-2017
-#
-if(MSVC AND BUILD_SHARED_LIBS)
-    list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC EIGEN_NO_STATIC_ASSERT)
-endif()
-
-# Store these in variables so they are automatically replicated in GTSAMConfig.cmake and such.
-set(BOOST_FIND_MINIMUM_VERSION 1.43)
-set(BOOST_FIND_MINIMUM_COMPONENTS serialization system filesystem thread program_options date_time timer chrono regex)
-
-find_package(Boost ${BOOST_FIND_MINIMUM_VERSION} COMPONENTS ${BOOST_FIND_MINIMUM_COMPONENTS})
-
-# Required components
-if(NOT Boost_SERIALIZATION_LIBRARY OR NOT Boost_SYSTEM_LIBRARY OR NOT Boost_FILESYSTEM_LIBRARY OR
-    NOT Boost_THREAD_LIBRARY OR NOT Boost_DATE_TIME_LIBRARY)
-  message(FATAL_ERROR "Missing required Boost components >= v1.43, please install/upgrade Boost or configure your search paths.")
-endif()
-
-option(GTSAM_DISABLE_NEW_TIMERS "Disables using Boost.chrono for timing" OFF)
-# Allow for not using the timer libraries on boost < 1.48 (GTSAM timing code falls back to old timer library)
-set(GTSAM_BOOST_LIBRARIES
-  Boost::serialization
-  Boost::system
-  Boost::filesystem
-  Boost::thread
-  Boost::date_time
-  Boost::regex
-)
-if (GTSAM_DISABLE_NEW_TIMERS)
-    message("WARNING:  GTSAM timing instrumentation manually disabled")
-    list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC DGTSAM_DISABLE_NEW_TIMERS)
-else()
-    if(Boost_TIMER_LIBRARY)
-      list(APPEND GTSAM_BOOST_LIBRARIES Boost::timer Boost::chrono)
-    else()
-      list(APPEND GTSAM_BOOST_LIBRARIES rt) # When using the header-only boost timer library, need -lrt
-      message("WARNING:  GTSAM timing instrumentation will use the older, less accurate, Boost timer library because boost older than 1.48 was found.")
-    endif()
-endif()
-
-###############################################################################
-# Find TBB
-find_package(TBB 4.4 COMPONENTS tbb tbbmalloc)
-
-# Set up variables if we're using TBB
-if(TBB_FOUND AND GTSAM_WITH_TBB)
-    set(GTSAM_USE_TBB 1)  # This will go into config.h
-    if ((${TBB_VERSION_MAJOR} GREATER 2020) OR (${TBB_VERSION_MAJOR} EQUAL 2020))
-        set(TBB_GREATER_EQUAL_2020 1)
-    else()
-        set(TBB_GREATER_EQUAL_2020 0)
-    endif()
-    # all definitions and link requisites will go via imported targets:
-    # tbb & tbbmalloc
-    list(APPEND GTSAM_ADDITIONAL_LIBRARIES tbb tbbmalloc)
-else()
-    set(GTSAM_USE_TBB 0)  # This will go into config.h
-endif()
-
-###############################################################################
-# Prohibit Timing build mode in combination with TBB
-if(GTSAM_USE_TBB AND (CMAKE_BUILD_TYPE  STREQUAL "Timing"))
-      message(FATAL_ERROR "Timing build mode cannot be used together with TBB. Use a sampling profiler such as Instruments or Intel VTune Amplifier instead.")
-endif()
-
-
-###############################################################################
-# Find Google perftools
-find_package(GooglePerfTools)
-
-###############################################################################
-# Support ccache, if installed
-if(NOT MSVC AND NOT XCODE_VERSION)
-    find_program(CCACHE_FOUND ccache)
-    if(CCACHE_FOUND)
-        if(GTSAM_BUILD_WITH_CCACHE)
-            set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE ccache)
-            set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK ccache)
-        else()
-            set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "")
-            set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK "")
-        endif()
-    endif(CCACHE_FOUND)
-endif()
-
-###############################################################################
-# Find MKL
-find_package(MKL)
-
-if(MKL_FOUND AND GTSAM_WITH_EIGEN_MKL)
-    set(GTSAM_USE_EIGEN_MKL 1) # This will go into config.h
-    set(EIGEN_USE_MKL_ALL 1) # This will go into config.h - it makes Eigen use MKL
-    list(APPEND GTSAM_ADDITIONAL_LIBRARIES ${MKL_LIBRARIES})
-
-    # --no-as-needed is required with gcc according to the MKL link advisor
-    if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
-        set(CMAKE_EXE_LINKER_FLAGS "${CMAKE_EXE_LINKER_FLAGS} -Wl,--no-as-needed")
-    endif()
-else()
-    set(GTSAM_USE_EIGEN_MKL 0)
-    set(EIGEN_USE_MKL_ALL 0)
-endif()
-
-###############################################################################
-# Find OpenMP (if we're also using MKL)
-find_package(OpenMP)  # do this here to generate correct message if disabled
-
-if(GTSAM_WITH_EIGEN_MKL AND GTSAM_WITH_EIGEN_MKL_OPENMP AND GTSAM_USE_EIGEN_MKL)
-    if(OPENMP_FOUND AND GTSAM_USE_EIGEN_MKL AND GTSAM_WITH_EIGEN_MKL_OPENMP)
-        set(GTSAM_USE_EIGEN_MKL_OPENMP 1) # This will go into config.h
-        list_append_cache(GTSAM_COMPILE_OPTIONS_PUBLIC ${OpenMP_CXX_FLAGS})
-    endif()
-endif()
-
-
-###############################################################################
-# Option for using system Eigen or GTSAM-bundled Eigen
-### These patches only affect usage of MKL. If you want to enable MKL, you *must*
-### use our patched version of Eigen
-### See:  http://eigen.tuxfamily.org/bz/show_bug.cgi?id=704 (Householder QR MKL selection)
-###       http://eigen.tuxfamily.org/bz/show_bug.cgi?id=705 (Fix MKL LLT return code)
-option(GTSAM_USE_SYSTEM_EIGEN "Find and use system-installed Eigen. If 'off', use the one bundled with GTSAM" OFF)
-option(GTSAM_WITH_EIGEN_UNSUPPORTED "Install Eigen's unsupported modules" OFF)
-
-# Switch for using system Eigen or GTSAM-bundled Eigen
-if(GTSAM_USE_SYSTEM_EIGEN)
-    find_package(Eigen3 REQUIRED)
-
-    # Use generic Eigen include paths e.g. <Eigen/Core>
-    set(GTSAM_EIGEN_INCLUDE_FOR_INSTALL "${EIGEN3_INCLUDE_DIR}")
-
-    # check if MKL is also enabled - can have one or the other, but not both!
-    # Note: Eigen >= v3.2.5 includes our patches
-    if(EIGEN_USE_MKL_ALL AND (EIGEN3_VERSION VERSION_LESS 3.2.5))
-      message(FATAL_ERROR "MKL requires at least Eigen 3.2.5, and your system appears to have an older version. Disable GTSAM_USE_SYSTEM_EIGEN to use GTSAM's copy of Eigen, or disable GTSAM_WITH_EIGEN_MKL")
-    endif()
-
-    # Check for Eigen version which doesn't work with MKL
-    # See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1527 for details.
-    if(EIGEN_USE_MKL_ALL AND (EIGEN3_VERSION VERSION_EQUAL 3.3.4))
-        message(FATAL_ERROR "MKL does not work with Eigen 3.3.4 because of a bug in Eigen. See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1527. Disable GTSAM_USE_SYSTEM_EIGEN to use GTSAM's copy of Eigen, disable GTSAM_WITH_EIGEN_MKL, or upgrade/patch your installation of Eigen.")
-    endif()
-
-    # The actual include directory (for BUILD cmake target interface):
-    set(GTSAM_EIGEN_INCLUDE_FOR_BUILD "${EIGEN3_INCLUDE_DIR}")
-else()
-    # Use bundled Eigen include path.
-    # Clear any variables set by FindEigen3
-    if(EIGEN3_INCLUDE_DIR)
-        set(EIGEN3_INCLUDE_DIR NOTFOUND CACHE STRING "" FORCE)
-    endif()
-
-    # set full path to be used by external projects
-    # this will be added to GTSAM_INCLUDE_DIR by gtsam_extra.cmake.in
-    set(GTSAM_EIGEN_INCLUDE_FOR_INSTALL "include/gtsam/3rdparty/Eigen/")
+include(cmake/HandleBoost.cmake)            # Boost
+include(cmake/HandleCCache.cmake)           # ccache
+include(cmake/HandleCPack.cmake)            # CPack
+include(cmake/HandleEigen.cmake)            # Eigen3
+include(cmake/HandleGeneralOptions.cmake)  # CMake build options
+include(cmake/HandleMKL.cmake)              # MKL
+include(cmake/HandleOpenMP.cmake)           # OpenMP
+include(cmake/HandlePerfTools.cmake)        # Google perftools
+include(cmake/HandlePython.cmake)           # Python options and commands
+include(cmake/HandleTBB.cmake)              # TBB
+include(cmake/HandleUninstall.cmake)        # for "make uninstall"
 
-    # The actual include directory (for BUILD cmake target interface):
-    set(GTSAM_EIGEN_INCLUDE_FOR_BUILD "${CMAKE_SOURCE_DIR}/gtsam/3rdparty/Eigen/")
-endif()
-
-# Detect Eigen version:
-set(EIGEN_VER_H "${GTSAM_EIGEN_INCLUDE_FOR_BUILD}/Eigen/src/Core/util/Macros.h")
-if (EXISTS ${EIGEN_VER_H})
-    file(READ "${EIGEN_VER_H}" STR_EIGEN_VERSION)
-
-    # Extract the Eigen version from the Macros.h file, lines "#define EIGEN_WORLD_VERSION  XX", etc...
-
-    string(REGEX MATCH "EIGEN_WORLD_VERSION[ ]+[0-9]+" GTSAM_EIGEN_VERSION_WORLD "${STR_EIGEN_VERSION}")
-    string(REGEX MATCH "[0-9]+" GTSAM_EIGEN_VERSION_WORLD "${GTSAM_EIGEN_VERSION_WORLD}")
-
-    string(REGEX MATCH "EIGEN_MAJOR_VERSION[ ]+[0-9]+" GTSAM_EIGEN_VERSION_MAJOR "${STR_EIGEN_VERSION}")
-    string(REGEX MATCH "[0-9]+" GTSAM_EIGEN_VERSION_MAJOR "${GTSAM_EIGEN_VERSION_MAJOR}")
-
-    string(REGEX MATCH "EIGEN_MINOR_VERSION[ ]+[0-9]+" GTSAM_EIGEN_VERSION_MINOR "${STR_EIGEN_VERSION}")
-    string(REGEX MATCH "[0-9]+" GTSAM_EIGEN_VERSION_MINOR "${GTSAM_EIGEN_VERSION_MINOR}")
-
-    set(GTSAM_EIGEN_VERSION "${GTSAM_EIGEN_VERSION_WORLD}.${GTSAM_EIGEN_VERSION_MAJOR}.${GTSAM_EIGEN_VERSION_MINOR}")
-
-    message(STATUS "Found Eigen version: ${GTSAM_EIGEN_VERSION}")
-else()
-    message(WARNING "Cannot determine Eigen version, missing file: `${EIGEN_VER_H}`")
-endif ()
-
-if (MSVC)
-    if (BUILD_SHARED_LIBS)
-        # mute eigen static assert to avoid errors in shared lib
-        list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC EIGEN_NO_STATIC_ASSERT)
-    endif()
-    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE "/wd4244") # Disable loss of precision which is thrown all over our Eigen
-endif()
+include(cmake/HandleAllocators.cmake)       # Must be after tbb, pertools
 
-if (APPLE AND BUILD_SHARED_LIBS)
-    # Set the default install directory on macOS
-    set(CMAKE_INSTALL_NAME_DIR "${CMAKE_INSTALL_PREFIX}/lib")
-endif()
-
-###############################################################################
-# Global compile options
-
-# Build list of possible allocators
-set(possible_allocators "")
-if(GTSAM_USE_TBB)
-    list(APPEND possible_allocators TBB)
-    set(preferred_allocator TBB)
-else()
-    list(APPEND possible_allocators BoostPool STL)
-    set(preferred_allocator STL)
-endif()
-if(GOOGLE_PERFTOOLS_FOUND)
-    list(APPEND possible_allocators tcmalloc)
-endif()
-
-# Check if current allocator choice is valid and set cache option
-list(FIND possible_allocators "${GTSAM_DEFAULT_ALLOCATOR}" allocator_valid)
-if(allocator_valid EQUAL -1)
-    set(GTSAM_DEFAULT_ALLOCATOR ${preferred_allocator} CACHE STRING "Default allocator" FORCE)
-else()
-    set(GTSAM_DEFAULT_ALLOCATOR ${preferred_allocator} CACHE STRING "Default allocator")
-endif()
-set_property(CACHE GTSAM_DEFAULT_ALLOCATOR PROPERTY STRINGS ${possible_allocators})
-mark_as_advanced(GTSAM_DEFAULT_ALLOCATOR)
-
-# Define compile flags depending on allocator
-if("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "BoostPool")
-    set(GTSAM_ALLOCATOR_BOOSTPOOL 1)
-elseif("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "STL")
-    set(GTSAM_ALLOCATOR_STL 1)
-elseif("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "TBB")
-    set(GTSAM_ALLOCATOR_TBB 1)
-elseif("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "tcmalloc")
-    set(GTSAM_ALLOCATOR_STL 1) # tcmalloc replaces malloc, so to use it we use the STL allocator
-    list(APPEND GTSAM_ADDITIONAL_LIBRARIES "tcmalloc")
-endif()
-
-if(MSVC)
-    list_append_cache(GTSAM_COMPILE_DEFINITIONS_PRIVATE _CRT_SECURE_NO_WARNINGS _SCL_SECURE_NO_WARNINGS)
-    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE /wd4251 /wd4275 /wd4251 /wd4661 /wd4344 /wd4503) # Disable non-DLL-exported base class and other warnings
-    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE /bigobj) # Allow large object files for template-based code
-endif()
-
-# GCC 4.8+ complains about local typedefs which we use for shared_ptr etc.
-if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
-  if (NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.8)
-    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE -Wno-unused-local-typedefs)
-  endif()
-endif()
-
-# As of XCode 7, clang also complains about this
-if(CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
-  if (NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 7.0)
-    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE -Wno-unused-local-typedefs)
-  endif()
-endif()
-
-if(GTSAM_ENABLE_CONSISTENCY_CHECKS)
-  # This should be made PUBLIC if GTSAM_EXTRA_CONSISTENCY_CHECKS is someday used in a public .h
-  list_append_cache(GTSAM_COMPILE_DEFINITIONS_PRIVATE GTSAM_EXTRA_CONSISTENCY_CHECKS)
-endif()
+include(cmake/HandleGlobalBuildFlags.cmake) # Build flags
 
 ###############################################################################
 # Add components
@@ -456,7 +92,6 @@ endif()
 GtsamMakeConfigFile(GTSAM "${CMAKE_CURRENT_SOURCE_DIR}/gtsam_extra.cmake.in")
 export(TARGETS ${GTSAM_EXPORTED_TARGETS} FILE GTSAM-exports.cmake)
 
-
 # Check for doxygen availability - optional dependency
 find_package(Doxygen)
 
@@ -468,146 +103,11 @@ endif()
 # CMake Tools
 add_subdirectory(cmake)
 
-
-###############################################################################
-# Set up CPack
-set(CPACK_PACKAGE_DESCRIPTION_SUMMARY "GTSAM")
-set(CPACK_PACKAGE_VENDOR "Frank Dellaert, Georgia Institute of Technology")
-set(CPACK_PACKAGE_CONTACT "Frank Dellaert, dellaert@cc.gatech.edu")
-set(CPACK_PACKAGE_DESCRIPTION_FILE "${CMAKE_CURRENT_SOURCE_DIR}/README.md")
-set(CPACK_RESOURCE_FILE_LICENSE "${CMAKE_CURRENT_SOURCE_DIR}/LICENSE")
-set(CPACK_PACKAGE_VERSION_MAJOR ${GTSAM_VERSION_MAJOR})
-set(CPACK_PACKAGE_VERSION_MINOR ${GTSAM_VERSION_MINOR})
-set(CPACK_PACKAGE_VERSION_PATCH ${GTSAM_VERSION_PATCH})
-set(CPACK_PACKAGE_INSTALL_DIRECTORY "CMake ${CMake_VERSION_MAJOR}.${CMake_VERSION_MINOR}")
-#set(CPACK_INSTALLED_DIRECTORIES "doc;.") # Include doc directory
-#set(CPACK_INSTALLED_DIRECTORIES ".") # FIXME: throws error
-set(CPACK_SOURCE_IGNORE_FILES "/build*;/\\\\.;/makestats.sh$")
-set(CPACK_SOURCE_IGNORE_FILES "${CPACK_SOURCE_IGNORE_FILES}" "/gtsam_unstable/")
-set(CPACK_SOURCE_IGNORE_FILES "${CPACK_SOURCE_IGNORE_FILES}" "/package_scripts/")
-set(CPACK_SOURCE_PACKAGE_FILE_NAME "gtsam-${GTSAM_VERSION_MAJOR}.${GTSAM_VERSION_MINOR}.${GTSAM_VERSION_PATCH}")
-#set(CPACK_SOURCE_PACKAGE_FILE_NAME "gtsam-aspn${GTSAM_VERSION_PATCH}") # Used for creating ASPN tarballs
-
-# Deb-package specific cpack
-set(CPACK_DEBIAN_PACKAGE_NAME "libgtsam-dev")
-set(CPACK_DEBIAN_PACKAGE_DEPENDS "libboost-dev (>= 1.43)") #Example: "libc6 (>= 2.3.1-6), libgcc1 (>= 1:3.4.2-12)")
-
-
-###############################################################################
 # Print configuration variables
-message(STATUS "===============================================================")
-message(STATUS "================  Configuration Options  ======================")
-print_config("CMAKE_CXX_COMPILER_ID type" "${CMAKE_CXX_COMPILER_ID}")
-print_config("CMAKE_CXX_COMPILER_VERSION" "${CMAKE_CXX_COMPILER_VERSION}")
-print_config("CMake version"    "${CMAKE_VERSION}")
-print_config("CMake generator"  "${CMAKE_GENERATOR}")
-print_config("CMake build tool" "${CMAKE_BUILD_TOOL}")
-message(STATUS "Build flags                                               ")
-print_enabled_config(${GTSAM_BUILD_TESTS}                 "Build Tests")
-print_enabled_config(${GTSAM_BUILD_EXAMPLES_ALWAYS}       "Build examples with 'make all'")
-print_enabled_config(${GTSAM_BUILD_TIMING_ALWAYS}         "Build timing scripts with 'make all'")
-if (DOXYGEN_FOUND)
-    print_enabled_config(${GTSAM_BUILD_DOCS}              "Build Docs")
-endif()
-print_enabled_config(${BUILD_SHARED_LIBS}                 "Build shared GTSAM libraries")
-print_enabled_config(${GTSAM_BUILD_TYPE_POSTFIXES}        "Put build type in library name")
-if(GTSAM_UNSTABLE_AVAILABLE)
-    print_enabled_config(${GTSAM_BUILD_UNSTABLE}          "Build libgtsam_unstable        ")
-    print_enabled_config(${GTSAM_UNSTABLE_BUILD_PYTHON}   "Build GTSAM unstable Python    ")
-    print_enabled_config(${GTSAM_UNSTABLE_INSTALL_MATLAB_TOOLBOX} "Build MATLAB Toolbox for unstable")
-endif()
-
-if(NOT MSVC AND NOT XCODE_VERSION)
-    print_enabled_config(${GTSAM_BUILD_WITH_MARCH_NATIVE}     "Build for native architecture  ")
-    print_config("Build type" "${CMAKE_BUILD_TYPE}")
-    print_config("C compilation flags" "${CMAKE_C_FLAGS} ${CMAKE_C_FLAGS_${CMAKE_BUILD_TYPE_UPPER}}")
-    print_config("C++ compilation flags" "${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE_UPPER}}")
-endif()
-
-print_build_options_for_target(gtsam)
-
-print_config("Use System Eigen" "${GTSAM_USE_SYSTEM_EIGEN} (Using version: ${GTSAM_EIGEN_VERSION})")
-
-if(GTSAM_USE_TBB)
-    print_config("Use Intel TBB" "Yes")
-elseif(TBB_FOUND)
-    print_config("Use Intel TBB" "TBB found but GTSAM_WITH_TBB is disabled")
-else()
-    print_config("Use Intel TBB" "TBB not found")
-endif()
-if(GTSAM_USE_EIGEN_MKL)
-    print_config("Eigen will use MKL" "Yes")
-elseif(MKL_FOUND)
-    print_config("Eigen will use MKL" "MKL found but GTSAM_WITH_EIGEN_MKL is disabled")
-else()
-    print_config("Eigen will use MKL" "MKL not found")
-endif()
-if(GTSAM_USE_EIGEN_MKL_OPENMP)
-    print_config("Eigen will use MKL and OpenMP" "Yes")
-elseif(OPENMP_FOUND AND NOT GTSAM_WITH_EIGEN_MKL)
-    print_config("Eigen will use MKL and OpenMP" "OpenMP found but GTSAM_WITH_EIGEN_MKL is disabled")
-elseif(OPENMP_FOUND AND NOT MKL_FOUND)
-    print_config("Eigen will use MKL and OpenMP" "OpenMP found but MKL not found")
-elseif(OPENMP_FOUND)
-    print_config("Eigen will use MKL and OpenMP" "OpenMP found but GTSAM_WITH_EIGEN_MKL_OPENMP is disabled")
-else()
-    print_config("Eigen will use MKL and OpenMP" "OpenMP not found")
-endif()
-print_config("Default allocator" "${GTSAM_DEFAULT_ALLOCATOR}")
-
-if(GTSAM_THROW_CHEIRALITY_EXCEPTION)
-    print_config("Cheirality exceptions enabled" "YES")
-else()
-    print_config("Cheirality exceptions enabled" "NO")
-endif()
-
-if(NOT MSVC AND NOT XCODE_VERSION)
-    if(CCACHE_FOUND AND GTSAM_BUILD_WITH_CCACHE)
-        print_config("Build with ccache" "Yes")
-    elseif(CCACHE_FOUND)
-        print_config("Build with ccache" "ccache found but GTSAM_BUILD_WITH_CCACHE is disabled")
-    else()
-        print_config("Build with ccache" "No")
-    endif()
-endif()
-
-message(STATUS "Packaging flags")
-print_config("CPack Source Generator" "${CPACK_SOURCE_GENERATOR}")
-print_config("CPack Generator" "${CPACK_GENERATOR}")
-
-message(STATUS "GTSAM flags                                               ")
-print_enabled_config(${GTSAM_USE_QUATERNIONS}             "Quaternions as default Rot3     ")
-print_enabled_config(${GTSAM_ENABLE_CONSISTENCY_CHECKS}   "Runtime consistency checking    ")
-print_enabled_config(${GTSAM_ROT3_EXPMAP}                 "Rot3 retract is full ExpMap     ")
-print_enabled_config(${GTSAM_POSE3_EXPMAP}                "Pose3 retract is full ExpMap    ")
-print_enabled_config(${GTSAM_ALLOW_DEPRECATED_SINCE_V41}  "Allow features deprecated in GTSAM 4.1")
-print_enabled_config(${GTSAM_SUPPORT_NESTED_DISSECTION}   "Metis-based Nested Dissection   ")
-print_enabled_config(${GTSAM_TANGENT_PREINTEGRATION}      "Use tangent-space preintegration")
-
-message(STATUS "MATLAB toolbox flags")
-print_enabled_config(${GTSAM_INSTALL_MATLAB_TOOLBOX}      "Install MATLAB toolbox          ")
-if (${GTSAM_INSTALL_MATLAB_TOOLBOX})
-    print_config("MATLAB root" "${MATLAB_ROOT}")
-    print_config("MEX binary" "${MEX_COMMAND}")
-endif()
-message(STATUS "Python toolbox flags                                      ")
-print_enabled_config(${GTSAM_BUILD_PYTHON}                "Build Python module with pybind ")
-if(GTSAM_BUILD_PYTHON)
-    print_config("Python version" ${GTSAM_PYTHON_VERSION})
-endif()
-
-message(STATUS "===============================================================")
+include(cmake/HandlePrintConfiguration.cmake)
 
 # Print warnings at the end
-if(GTSAM_WITH_TBB AND NOT TBB_FOUND)
-    message(WARNING "TBB 4.4 or newer was not found - this is ok, but note that GTSAM parallelization will be disabled.  Set GTSAM_WITH_TBB to 'Off' to avoid this warning.")
-endif()
-if(GTSAM_WITH_EIGEN_MKL AND NOT MKL_FOUND)
-    message(WARNING "MKL was not found - this is ok, but note that MKL will be disabled.  Set GTSAM_WITH_EIGEN_MKL to 'Off' to disable this warning.  See INSTALL.md for notes on performance.")
-endif()
-if(GTSAM_WITH_EIGEN_MKL_OPENMP AND NOT OPENMP_FOUND AND MKL_FOUND)
-    message(WARNING "Your compiler does not support OpenMP.  Set GTSAM_WITH_EIGEN_MKL_OPENMP to 'Off' to avoid this warning. See INSTALL.md for notes on performance.")
-endif()
+include(cmake/HandleFinalChecks.cmake)
 
 # Include CPack *after* all flags
 include(CPack)
--- gtsam-4.1.0.orig/INSTALL.md
+++ gtsam-4.1.0/INSTALL.md
@@ -13,7 +13,7 @@ $ make install
 ## Important Installation Notes
 
 1. GTSAM requires the following libraries to be installed on your system:
-    - BOOST version 1.43 or greater (install through Linux repositories or MacPorts)
+    - BOOST version 1.58 or greater (install through Linux repositories or MacPorts)
     - Cmake version 3.0 or higher
     - Support for XCode 4.3 command line tools on Mac requires CMake 2.8.8 or higher
 
@@ -173,7 +173,7 @@ NOTE:  If _GLIBCXX_DEBUG is used to comp
 Intel has a guide for installing MKL on Linux through APT repositories at <https://software.intel.com/en-us/articles/installing-intel-free-libs-and-python-apt-repo>.
 
 After following the instructions, add the following to your `~/.bashrc` (and afterwards, open a new terminal before compiling GTSAM):
-`LD_PRELOAD` need only be set if you are building the cython wrapper to use GTSAM from python.
+`LD_PRELOAD` need only be set if you are building the python wrapper to use GTSAM from python.
 ```sh
 source /opt/intel/mkl/bin/mklvars.sh intel64
 export LD_PRELOAD="$LD_PRELOAD:/opt/intel/mkl/lib/intel64/libmkl_core.so:/opt/intel/mkl/lib/intel64/libmkl_sequential.so"
@@ -190,6 +190,6 @@ Failing to specify `LD_PRELOAD` may lead
 `ImportError: /opt/intel/mkl/lib/intel64/libmkl_vml_avx2.so: undefined symbol: mkl_serv_getenv`
 or
 `Intel MKL FATAL ERROR: Cannot load libmkl_avx2.so or libmkl_def.so.`
-when importing GTSAM using the cython wrapper in python.
+when importing GTSAM using the python wrapper.
 
 
--- gtsam-4.1.0.orig/README.md
+++ gtsam-4.1.0/README.md
@@ -40,7 +40,7 @@ $ make install
 
 Prerequisites:
 
-- [Boost](http://www.boost.org/users/download/) >= 1.43 (Ubuntu: `sudo apt-get install libboost-all-dev`)
+- [Boost](http://www.boost.org/users/download/) >= 1.58 (Ubuntu: `sudo apt-get install libboost-all-dev`)
 - [CMake](http://www.cmake.org/cmake/resources/software.html) >= 3.0 (Ubuntu: `sudo apt-get install cmake`)
 - A modern compiler, i.e., at least gcc 4.7.3 on Linux.
 
@@ -62,7 +62,7 @@ GTSAM 4.1 added a new pybind wrapper, an
 
 ## Wrappers
 
-We provide support for [MATLAB](matlab/README.md) and [Python](cython/README.md) wrappers for GTSAM. Please refer to the linked documents for more details.
+We provide support for [MATLAB](matlab/README.md) and [Python](python/README.md) wrappers for GTSAM. Please refer to the linked documents for more details.
 
 ## The Preintegrated IMU Factor
 
--- gtsam-4.1.0.orig/cmake/CMakeLists.txt
+++ gtsam-4.1.0/cmake/CMakeLists.txt
@@ -19,7 +19,6 @@ install(FILES
   GtsamMatlabWrap.cmake
   GtsamTesting.cmake
   GtsamPrinting.cmake
-  FindCython.cmake
   FindNumPy.cmake
   README.html
   DESTINATION "${SCRIPT_INSTALL_DIR}/GTSAMCMakeTools")
--- gtsam-4.1.0.orig/cmake/FindNumPy.cmake
+++ gtsam-4.1.0/cmake/FindNumPy.cmake
@@ -40,17 +40,9 @@
 
 # Finding NumPy involves calling the Python interpreter
 if(NumPy_FIND_REQUIRED)
-  if(GTSAM_PYTHON_VERSION STREQUAL "Default")
-    find_package(PythonInterp REQUIRED)
-  else()
-      find_package(PythonInterp ${GTSAM_PYTHON_VERSION} EXACT REQUIRED)
-  endif()
+  find_package(PythonInterp ${GTSAM_PYTHON_VERSION} EXACT REQUIRED)
 else()
-  if(GTSAM_PYTHON_VERSION STREQUAL "Default")
-    find_package(PythonInterp)
-  else()
-    find_package(PythonInterp ${GTSAM_PYTHON_VERSION} EXACT)
-  endif()
+  find_package(PythonInterp ${GTSAM_PYTHON_VERSION} EXACT)
 endif()
 
 if(NOT PYTHONINTERP_FOUND)
--- gtsam-4.1.0.orig/cmake/GtsamBuildTypes.cmake
+++ gtsam-4.1.0/cmake/GtsamBuildTypes.cmake
@@ -1,3 +1,5 @@
+include(CheckCXXCompilerFlag) # for check_cxx_compiler_flag()
+
 # Set cmake policy to recognize the AppleClang compiler
 # independently from the Clang compiler.
 if(POLICY CMP0025)
@@ -105,11 +107,14 @@ if(MSVC)
 else()
   # Common to all configurations, next for each configuration:
 
-  if (
-      ((CMAKE_CXX_COMPILER_ID MATCHES "Clang") AND (NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 12.0.0)) OR
-      (CMAKE_CXX_COMPILER_ID MATCHES "GNU")
-     )
-    set(flag_override_ -Wsuggest-override) # -Werror=suggest-override: Add again someday
+  if (NOT MSVC)
+    check_cxx_compiler_flag(-Wsuggest-override COMPILER_HAS_WSUGGEST_OVERRIDE)
+    check_cxx_compiler_flag(-Wmissing COMPILER_HAS_WMISSING_OVERRIDE)
+    if (COMPILER_HAS_WSUGGEST_OVERRIDE)
+      set(flag_override_ -Wsuggest-override) # -Werror=suggest-override: Add again someday
+    elseif(COMPILER_HAS_WMISSING_OVERRIDE)
+      set(flag_override_ -Wmissing-override) # -Werror=missing-override: Add again someday
+    endif()
   endif()
 
   set(GTSAM_COMPILE_OPTIONS_PRIVATE_COMMON
@@ -263,3 +268,17 @@ function(gtsam_apply_build_flags target_
   target_compile_options(${target_name_} PRIVATE ${GTSAM_COMPILE_OPTIONS_PRIVATE})
 
 endfunction(gtsam_apply_build_flags)
+
+
+if(NOT MSVC AND NOT XCODE_VERSION)
+  # Set the build type to upper case for downstream use
+  string(TOUPPER "${CMAKE_BUILD_TYPE}" CMAKE_BUILD_TYPE_UPPER)
+
+  # Set the GTSAM_BUILD_TAG variable.
+  # If build type is Release, set to blank (""), else set to the build type.
+  if(${CMAKE_BUILD_TYPE_UPPER} STREQUAL "RELEASE")
+   set(GTSAM_BUILD_TAG "") # Don't create release mode tag on installed directory
+  else()
+   set(GTSAM_BUILD_TAG "${CMAKE_BUILD_TYPE}")
+  endif()
+endif()
--- gtsam-4.1.0.orig/cmake/GtsamMatlabWrap.cmake
+++ gtsam-4.1.0/cmake/GtsamMatlabWrap.cmake
@@ -1,51 +1,64 @@
+# Check / set dependent variables for MATLAB wrapper
+if(GTSAM_INSTALL_MATLAB_TOOLBOX)
+    find_package(Matlab COMPONENTS MEX_COMPILER REQUIRED)
+    if(NOT Matlab_MEX_COMPILER)
+        message(FATAL_ERROR "Cannot find MEX compiler binary. Please check your Matlab installation and ensure MEX in installed as well.")
+        endif()
+
+    if(GTSAM_BUILD_TYPE_POSTFIXES)
+        set(CURRENT_POSTFIX ${CMAKE_${CMAKE_BUILD_TYPE_UPPER}_POSTFIX})
+    endif()
+
+    if(NOT BUILD_SHARED_LIBS)
+        message(FATAL_ERROR "GTSAM_INSTALL_MATLAB_TOOLBOX and BUILD_SHARED_LIBS=OFF. The MATLAB wrapper cannot be compiled with a static GTSAM library because mex modules are themselves shared libraries.  If you want a self-contained mex module, enable GTSAM_MEX_BUILD_STATIC_MODULE instead of BUILD_SHARED_LIBS=OFF.")
+    endif()
+endif()
+
 # Set up cache options
 option(GTSAM_MEX_BUILD_STATIC_MODULE "Build MATLAB wrapper statically (increases build time)" OFF)
 set(GTSAM_BUILD_MEX_BINARY_FLAGS "" CACHE STRING "Extra flags for running Matlab MEX compilation")
 set(GTSAM_TOOLBOX_INSTALL_PATH "" CACHE PATH "Matlab toolbox destination, blank defaults to CMAKE_INSTALL_PREFIX/gtsam_toolbox")
 if(NOT GTSAM_TOOLBOX_INSTALL_PATH)
-	set(GTSAM_TOOLBOX_INSTALL_PATH "${CMAKE_INSTALL_PREFIX}/gtsam_toolbox")
+    set(GTSAM_TOOLBOX_INSTALL_PATH "${CMAKE_INSTALL_PREFIX}/gtsam_toolbox")
 endif()
 
 # GTSAM_MEX_BUILD_STATIC_MODULE is not for Windows - on Windows any static
 # are already compiled into the library by the linker
 if(GTSAM_MEX_BUILD_STATIC_MODULE AND WIN32)
-	message(FATAL_ERROR "GTSAM_MEX_BUILD_STATIC_MODULE should not be set on Windows - the linker already automatically compiles in any dependent static libraries.  To create a standalone toolbox pacakge, simply ensure that CMake finds the static versions of all dependent libraries (Boost, etc).")
+    message(FATAL_ERROR "GTSAM_MEX_BUILD_STATIC_MODULE should not be set on Windows - the linker already automatically compiles in any dependent static libraries. To create a standalone toolbox pacakge, simply ensure that CMake finds the static versions of all dependent libraries (Boost, etc).")
 endif()
 
-# Try to automatically configure mex path
-if(APPLE)
-	file(GLOB matlab_bin_directories "/Applications/MATLAB*/bin")
-	set(mex_program_name "mex")
-elseif(WIN32)
-	file(GLOB matlab_bin_directories "C:/Program Files*/MATLAB/*/bin")
-	set(mex_program_name "mex.bat")
-else()
-	file(GLOB matlab_bin_directories "/usr/local/MATLAB/*/bin")
-	set(mex_program_name "mex")
-endif()
+set(MEX_COMMAND ${Matlab_MEX_COMPILER} CACHE PATH "Path to MATLAB MEX compiler")
+set(MATLAB_ROOT ${Matlab_ROOT_DIR} CACHE PATH "Path to MATLAB installation root (e.g. /usr/local/MATLAB/R2012a)")
 
+# Try to automatically configure mex path from provided custom `bin` path.
 if(GTSAM_CUSTOM_MATLAB_PATH)
-	set(matlab_bin_directories ${GTSAM_CUSTOM_MATLAB_PATH})
-endif()
+    set(matlab_bin_directory ${GTSAM_CUSTOM_MATLAB_PATH})
+
+    if(WIN32)
+        set(mex_program_name "mex.bat")
+    else()
+        set(mex_program_name "mex")
+    endif()
 
-# Run find_program explicitly putting $PATH after our predefined program
-# directories using 'ENV PATH' and 'NO_SYSTEM_ENVIRONMENT_PATH' - this prevents
-# finding the LaTeX mex program (totally unrelated to MATLAB Mex) when LaTeX is
-# on the system path.
-list(REVERSE matlab_bin_directories) # Reverse list so the highest version (sorted alphabetically) is preferred
-find_program(MEX_COMMAND ${mex_program_name}
-	PATHS ${matlab_bin_directories} ENV PATH
-	NO_DEFAULT_PATH)
-mark_as_advanced(FORCE MEX_COMMAND)
-# Now that we have mex, trace back to find the Matlab installation root
-get_filename_component(MEX_COMMAND "${MEX_COMMAND}" REALPATH)
-get_filename_component(mex_path "${MEX_COMMAND}" PATH)
-if(mex_path MATCHES ".*/win64$")
-	get_filename_component(MATLAB_ROOT "${mex_path}/../.." ABSOLUTE)
-else()
-	get_filename_component(MATLAB_ROOT "${mex_path}/.." ABSOLUTE)
+    # Run find_program explicitly putting $PATH after our predefined program
+    # directories using 'ENV PATH' and 'NO_SYSTEM_ENVIRONMENT_PATH' - this prevents
+    # finding the LaTeX mex program (totally unrelated to MATLAB Mex) when LaTeX is
+    # on the system path.
+    find_program(MEX_COMMAND ${mex_program_name}
+       PATHS ${matlab_bin_directory} ENV PATH
+       NO_DEFAULT_PATH)
+
+    mark_as_advanced(FORCE MEX_COMMAND)
+    # Now that we have mex, trace back to find the Matlab installation root
+    get_filename_component(MEX_COMMAND "${MEX_COMMAND}" REALPATH)
+    get_filename_component(mex_path "${MEX_COMMAND}" PATH)
+    if(mex_path MATCHES ".*/win64$")
+       get_filename_component(MATLAB_ROOT "${mex_path}/../.." ABSOLUTE)
+    else()
+       get_filename_component(MATLAB_ROOT "${mex_path}/.." ABSOLUTE)
+    endif()
 endif()
-set(MATLAB_ROOT "${MATLAB_ROOT}" CACHE PATH "Path to MATLAB installation root (e.g. /usr/local/MATLAB/R2012a)")
 
 
 # User-friendly wrapping function.  Builds a mex module from the provided
@@ -215,19 +228,15 @@ function(wrap_library_internal interface
 	# Set up generation of module source file
 	file(MAKE_DIRECTORY "${generated_files_path}")
 
-	if(GTSAM_PYTHON_VERSION STREQUAL "Default")
-		find_package(PythonInterp REQUIRED)
-		find_package(PythonLibs REQUIRED)
-	else()
-		find_package(PythonInterp
-				${GTSAM_PYTHON_VERSION}
-				EXACT
-				REQUIRED)
-		find_package(PythonLibs
-				${GTSAM_PYTHON_VERSION}
-				EXACT
-				REQUIRED)
-	endif()
+    find_package(PythonInterp
+            ${GTSAM_PYTHON_VERSION}
+            EXACT
+            REQUIRED)
+    find_package(PythonLibs
+            ${GTSAM_PYTHON_VERSION}
+            EXACT
+            REQUIRED)
+
 
 	set(_ignore gtsam::Point2
 			gtsam::Point3)
--- gtsam-4.1.0.orig/cmake/GtsamPrinting.cmake
+++ gtsam-4.1.0/cmake/GtsamPrinting.cmake
@@ -46,16 +46,16 @@ endfunction()
 # Prints all the relevant CMake build options for a given target:
 function(print_build_options_for_target target_name_)
   print_padded(GTSAM_COMPILE_FEATURES_PUBLIC)
-  print_padded(GTSAM_COMPILE_OPTIONS_PRIVATE)
+  # print_padded(GTSAM_COMPILE_OPTIONS_PRIVATE)
   print_padded(GTSAM_COMPILE_OPTIONS_PUBLIC)
-  print_padded(GTSAM_COMPILE_DEFINITIONS_PRIVATE)
+  # print_padded(GTSAM_COMPILE_DEFINITIONS_PRIVATE)
   print_padded(GTSAM_COMPILE_DEFINITIONS_PUBLIC)
 
   foreach(build_type ${GTSAM_CMAKE_CONFIGURATION_TYPES})
     string(TOUPPER "${build_type}" build_type_toupper)
-    print_padded(GTSAM_COMPILE_OPTIONS_PRIVATE_${build_type_toupper})
+    # print_padded(GTSAM_COMPILE_OPTIONS_PRIVATE_${build_type_toupper})
     print_padded(GTSAM_COMPILE_OPTIONS_PUBLIC_${build_type_toupper})
-    print_padded(GTSAM_COMPILE_DEFINITIONS_PRIVATE_${build_type_toupper})
+    # print_padded(GTSAM_COMPILE_DEFINITIONS_PRIVATE_${build_type_toupper})
     print_padded(GTSAM_COMPILE_DEFINITIONS_PUBLIC_${build_type_toupper})
   endforeach()
 endfunction()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleAllocators.cmake
@@ -0,0 +1,34 @@
+# Build list of possible allocators
+set(possible_allocators "")
+if(GTSAM_USE_TBB)
+    list(APPEND possible_allocators TBB)
+    set(preferred_allocator TBB)
+else()
+    list(APPEND possible_allocators BoostPool STL)
+    set(preferred_allocator STL)
+endif()
+if(GOOGLE_PERFTOOLS_FOUND)
+    list(APPEND possible_allocators tcmalloc)
+endif()
+
+# Check if current allocator choice is valid and set cache option
+list(FIND possible_allocators "${GTSAM_DEFAULT_ALLOCATOR}" allocator_valid)
+if(allocator_valid EQUAL -1)
+    set(GTSAM_DEFAULT_ALLOCATOR ${preferred_allocator} CACHE STRING "Default allocator" FORCE)
+else()
+    set(GTSAM_DEFAULT_ALLOCATOR ${preferred_allocator} CACHE STRING "Default allocator")
+endif()
+set_property(CACHE GTSAM_DEFAULT_ALLOCATOR PROPERTY STRINGS ${possible_allocators})
+mark_as_advanced(GTSAM_DEFAULT_ALLOCATOR)
+
+# Define compile flags depending on allocator
+if("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "BoostPool")
+    set(GTSAM_ALLOCATOR_BOOSTPOOL 1)
+elseif("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "STL")
+    set(GTSAM_ALLOCATOR_STL 1)
+elseif("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "TBB")
+    set(GTSAM_ALLOCATOR_TBB 1)
+elseif("${GTSAM_DEFAULT_ALLOCATOR}" STREQUAL "tcmalloc")
+    set(GTSAM_ALLOCATOR_STL 1) # tcmalloc replaces malloc, so to use it we use the STL allocator
+    list(APPEND GTSAM_ADDITIONAL_LIBRARIES "tcmalloc")
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleBoost.cmake
@@ -0,0 +1,56 @@
+###############################################################################
+# Find boost
+
+# To change the path for boost, you will need to set:
+# BOOST_ROOT: path to install prefix for boost
+# Boost_NO_SYSTEM_PATHS: set to true to keep the find script from ignoring BOOST_ROOT
+
+if(MSVC)
+    # By default, boost only builds static libraries on windows
+    set(Boost_USE_STATIC_LIBS ON)  # only find static libs
+    # If we ever reset above on windows and, ...
+    # If we use Boost shared libs, disable auto linking.
+    # Some libraries, at least Boost Program Options, rely on this to export DLL symbols.
+    if(NOT Boost_USE_STATIC_LIBS)
+        list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC BOOST_ALL_NO_LIB BOOST_ALL_DYN_LINK)
+    endif()
+    # Virtual memory range for PCH exceeded on VS2015
+    if(MSVC_VERSION LESS 1910) # older than VS2017
+      list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE -Zm295)
+    endif()
+endif()
+
+
+# Store these in variables so they are automatically replicated in GTSAMConfig.cmake and such.
+set(BOOST_FIND_MINIMUM_VERSION 1.58)
+set(BOOST_FIND_MINIMUM_COMPONENTS serialization system filesystem thread program_options date_time timer chrono regex)
+
+find_package(Boost ${BOOST_FIND_MINIMUM_VERSION} COMPONENTS ${BOOST_FIND_MINIMUM_COMPONENTS})
+
+# Required components
+if(NOT Boost_SERIALIZATION_LIBRARY OR NOT Boost_SYSTEM_LIBRARY OR NOT Boost_FILESYSTEM_LIBRARY OR
+    NOT Boost_THREAD_LIBRARY OR NOT Boost_DATE_TIME_LIBRARY)
+  message(FATAL_ERROR "Missing required Boost components >= v1.58, please install/upgrade Boost or configure your search paths.")
+endif()
+
+option(GTSAM_DISABLE_NEW_TIMERS "Disables using Boost.chrono for timing" OFF)
+# Allow for not using the timer libraries on boost < 1.48 (GTSAM timing code falls back to old timer library)
+set(GTSAM_BOOST_LIBRARIES
+  Boost::serialization
+  Boost::system
+  Boost::filesystem
+  Boost::thread
+  Boost::date_time
+  Boost::regex
+)
+if (GTSAM_DISABLE_NEW_TIMERS)
+    message("WARNING:  GTSAM timing instrumentation manually disabled")
+    list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC DGTSAM_DISABLE_NEW_TIMERS)
+else()
+    if(Boost_TIMER_LIBRARY)
+      list(APPEND GTSAM_BOOST_LIBRARIES Boost::timer Boost::chrono)
+    else()
+      list(APPEND GTSAM_BOOST_LIBRARIES rt) # When using the header-only boost timer library, need -lrt
+      message("WARNING:  GTSAM timing instrumentation will use the older, less accurate, Boost timer library because boost older than 1.48 was found.")
+    endif()
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleCCache.cmake
@@ -0,0 +1,14 @@
+###############################################################################
+# Support ccache, if installed
+if(NOT MSVC AND NOT XCODE_VERSION)
+    find_program(CCACHE_FOUND ccache)
+    if(CCACHE_FOUND)
+        if(GTSAM_BUILD_WITH_CCACHE)
+            set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE ccache)
+            set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK ccache)
+        else()
+            set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "")
+            set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK "")
+        endif()
+    endif(CCACHE_FOUND)
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleCPack.cmake
@@ -0,0 +1,28 @@
+#JLBC: is all this actually used by someone? could it be removed?
+
+# Flags for choosing default packaging tools
+set(CPACK_SOURCE_GENERATOR "TGZ" CACHE STRING "CPack Default Source Generator")
+set(CPACK_GENERATOR        "TGZ" CACHE STRING "CPack Default Binary Generator")
+
+###############################################################################
+# Set up CPack
+set(CPACK_PACKAGE_DESCRIPTION_SUMMARY "GTSAM")
+set(CPACK_PACKAGE_VENDOR "Frank Dellaert, Georgia Institute of Technology")
+set(CPACK_PACKAGE_CONTACT "Frank Dellaert, dellaert@cc.gatech.edu")
+set(CPACK_PACKAGE_DESCRIPTION_FILE "${CMAKE_CURRENT_SOURCE_DIR}/README.md")
+set(CPACK_RESOURCE_FILE_LICENSE "${CMAKE_CURRENT_SOURCE_DIR}/LICENSE")
+set(CPACK_PACKAGE_VERSION_MAJOR ${GTSAM_VERSION_MAJOR})
+set(CPACK_PACKAGE_VERSION_MINOR ${GTSAM_VERSION_MINOR})
+set(CPACK_PACKAGE_VERSION_PATCH ${GTSAM_VERSION_PATCH})
+set(CPACK_PACKAGE_INSTALL_DIRECTORY "CMake ${CMake_VERSION_MAJOR}.${CMake_VERSION_MINOR}")
+#set(CPACK_INSTALLED_DIRECTORIES "doc;.") # Include doc directory
+#set(CPACK_INSTALLED_DIRECTORIES ".") # FIXME: throws error
+set(CPACK_SOURCE_IGNORE_FILES "/build*;/\\\\.;/makestats.sh$")
+set(CPACK_SOURCE_IGNORE_FILES "${CPACK_SOURCE_IGNORE_FILES}" "/gtsam_unstable/")
+set(CPACK_SOURCE_IGNORE_FILES "${CPACK_SOURCE_IGNORE_FILES}" "/package_scripts/")
+set(CPACK_SOURCE_PACKAGE_FILE_NAME "gtsam-${GTSAM_VERSION_MAJOR}.${GTSAM_VERSION_MINOR}.${GTSAM_VERSION_PATCH}")
+#set(CPACK_SOURCE_PACKAGE_FILE_NAME "gtsam-aspn${GTSAM_VERSION_PATCH}") # Used for creating ASPN tarballs
+
+# Deb-package specific cpack
+set(CPACK_DEBIAN_PACKAGE_NAME "libgtsam-dev")
+set(CPACK_DEBIAN_PACKAGE_DEPENDS "libboost-dev (>= 1.58)") #Example: "libc6 (>= 2.3.1-6), libgcc1 (>= 1:3.4.2-12)")
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleEigen.cmake
@@ -0,0 +1,77 @@
+###############################################################################
+# Option for using system Eigen or GTSAM-bundled Eigen
+
+option(GTSAM_USE_SYSTEM_EIGEN "Find and use system-installed Eigen. If 'off', use the one bundled with GTSAM" OFF)
+
+if(NOT GTSAM_USE_SYSTEM_EIGEN)
+  # This option only makes sense if using the embedded copy of Eigen, it is
+  # used to decide whether to *install* the "unsupported" module:
+  option(GTSAM_WITH_EIGEN_UNSUPPORTED "Install Eigen's unsupported modules" OFF)
+endif()
+
+# Switch for using system Eigen or GTSAM-bundled Eigen
+if(GTSAM_USE_SYSTEM_EIGEN)
+    find_package(Eigen3 REQUIRED)
+
+    # Use generic Eigen include paths e.g. <Eigen/Core>
+    set(GTSAM_EIGEN_INCLUDE_FOR_INSTALL "${EIGEN3_INCLUDE_DIR}")
+
+    # check if MKL is also enabled - can have one or the other, but not both!
+    # Note: Eigen >= v3.2.5 includes our patches
+    if(EIGEN_USE_MKL_ALL AND (EIGEN3_VERSION VERSION_LESS 3.2.5))
+      message(FATAL_ERROR "MKL requires at least Eigen 3.2.5, and your system appears to have an older version. Disable GTSAM_USE_SYSTEM_EIGEN to use GTSAM's copy of Eigen, or disable GTSAM_WITH_EIGEN_MKL")
+    endif()
+
+    # Check for Eigen version which doesn't work with MKL
+    # See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1527 for details.
+    if(EIGEN_USE_MKL_ALL AND (EIGEN3_VERSION VERSION_EQUAL 3.3.4))
+        message(FATAL_ERROR "MKL does not work with Eigen 3.3.4 because of a bug in Eigen. See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1527. Disable GTSAM_USE_SYSTEM_EIGEN to use GTSAM's copy of Eigen, disable GTSAM_WITH_EIGEN_MKL, or upgrade/patch your installation of Eigen.")
+    endif()
+
+    # The actual include directory (for BUILD cmake target interface):
+    set(GTSAM_EIGEN_INCLUDE_FOR_BUILD "${EIGEN3_INCLUDE_DIR}")
+else()
+    # Use bundled Eigen include path.
+    # Clear any variables set by FindEigen3
+    if(EIGEN3_INCLUDE_DIR)
+        set(EIGEN3_INCLUDE_DIR NOTFOUND CACHE STRING "" FORCE)
+    endif()
+
+    # set full path to be used by external projects
+    # this will be added to GTSAM_INCLUDE_DIR by gtsam_extra.cmake.in
+    set(GTSAM_EIGEN_INCLUDE_FOR_INSTALL "include/gtsam/3rdparty/Eigen/")
+
+    # The actual include directory (for BUILD cmake target interface):
+    set(GTSAM_EIGEN_INCLUDE_FOR_BUILD "${CMAKE_SOURCE_DIR}/gtsam/3rdparty/Eigen/")
+endif()
+
+# Detect Eigen version:
+set(EIGEN_VER_H "${GTSAM_EIGEN_INCLUDE_FOR_BUILD}/Eigen/src/Core/util/Macros.h")
+if (EXISTS ${EIGEN_VER_H})
+    file(READ "${EIGEN_VER_H}" STR_EIGEN_VERSION)
+
+    # Extract the Eigen version from the Macros.h file, lines "#define EIGEN_WORLD_VERSION  XX", etc...
+
+    string(REGEX MATCH "EIGEN_WORLD_VERSION[ ]+[0-9]+" GTSAM_EIGEN_VERSION_WORLD "${STR_EIGEN_VERSION}")
+    string(REGEX MATCH "[0-9]+" GTSAM_EIGEN_VERSION_WORLD "${GTSAM_EIGEN_VERSION_WORLD}")
+
+    string(REGEX MATCH "EIGEN_MAJOR_VERSION[ ]+[0-9]+" GTSAM_EIGEN_VERSION_MAJOR "${STR_EIGEN_VERSION}")
+    string(REGEX MATCH "[0-9]+" GTSAM_EIGEN_VERSION_MAJOR "${GTSAM_EIGEN_VERSION_MAJOR}")
+
+    string(REGEX MATCH "EIGEN_MINOR_VERSION[ ]+[0-9]+" GTSAM_EIGEN_VERSION_MINOR "${STR_EIGEN_VERSION}")
+    string(REGEX MATCH "[0-9]+" GTSAM_EIGEN_VERSION_MINOR "${GTSAM_EIGEN_VERSION_MINOR}")
+
+    set(GTSAM_EIGEN_VERSION "${GTSAM_EIGEN_VERSION_WORLD}.${GTSAM_EIGEN_VERSION_MAJOR}.${GTSAM_EIGEN_VERSION_MINOR}")
+
+    message(STATUS "Found Eigen version: ${GTSAM_EIGEN_VERSION}")
+else()
+    message(WARNING "Cannot determine Eigen version, missing file: `${EIGEN_VER_H}`")
+endif ()
+
+if (MSVC)
+    if (BUILD_SHARED_LIBS)
+        # mute eigen static assert to avoid errors in shared lib
+        list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC EIGEN_NO_STATIC_ASSERT)
+    endif()
+    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE "/wd4244") # Disable loss of precision which is thrown all over our Eigen
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleFinalChecks.cmake
@@ -0,0 +1,10 @@
+# Print warnings at the end
+if(GTSAM_WITH_TBB AND NOT TBB_FOUND)
+    message(WARNING "TBB 4.4 or newer was not found - this is ok, but note that GTSAM parallelization will be disabled.  Set GTSAM_WITH_TBB to 'Off' to avoid this warning.")
+endif()
+if(GTSAM_WITH_EIGEN_MKL AND NOT MKL_FOUND)
+    message(WARNING "MKL was not found - this is ok, but note that MKL will be disabled.  Set GTSAM_WITH_EIGEN_MKL to 'Off' to disable this warning.  See INSTALL.md for notes on performance.")
+endif()
+if(GTSAM_WITH_EIGEN_MKL_OPENMP AND NOT OPENMP_FOUND AND MKL_FOUND)
+    message(WARNING "Your compiler does not support OpenMP.  Set GTSAM_WITH_EIGEN_MKL_OPENMP to 'Off' to avoid this warning. See INSTALL.md for notes on performance.")
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleGeneralOptions.cmake
@@ -0,0 +1,45 @@
+###############################################################################
+# Set up options
+
+# See whether gtsam_unstable is available (it will be present only if we're using a git checkout)
+if(EXISTS "${PROJECT_SOURCE_DIR}/gtsam_unstable" AND IS_DIRECTORY "${PROJECT_SOURCE_DIR}/gtsam_unstable")
+    set(GTSAM_UNSTABLE_AVAILABLE 1)
+else()
+    set(GTSAM_UNSTABLE_AVAILABLE 0)
+endif()
+
+# Configurable Options
+if(GTSAM_UNSTABLE_AVAILABLE)
+    option(GTSAM_BUILD_UNSTABLE              "Enable/Disable libgtsam_unstable"          ON)
+    option(GTSAM_UNSTABLE_BUILD_PYTHON       "Enable/Disable Python wrapper for libgtsam_unstable" ON)
+    option(GTSAM_UNSTABLE_INSTALL_MATLAB_TOOLBOX "Enable/Disable MATLAB wrapper for libgtsam_unstable" OFF)
+endif()
+option(BUILD_SHARED_LIBS                 "Build shared gtsam library, instead of static" ON)
+option(GTSAM_USE_QUATERNIONS             "Enable/Disable using an internal Quaternion representation for rotations instead of rotation matrices. If enable, Rot3::EXPMAP is enforced by default." OFF)
+option(GTSAM_POSE3_EXPMAP                "Enable/Disable using Pose3::EXPMAP as the default mode. If disabled, Pose3::FIRST_ORDER will be used." ON)
+option(GTSAM_ROT3_EXPMAP                 "Ignore if GTSAM_USE_QUATERNIONS is OFF (Rot3::EXPMAP by default). Otherwise, enable Rot3::EXPMAP, or if disabled, use Rot3::CAYLEY." ON)
+option(GTSAM_ENABLE_CONSISTENCY_CHECKS   "Enable/Disable expensive consistency checks"       OFF)
+option(GTSAM_WITH_TBB                    "Use Intel Threaded Building Blocks (TBB) if available" ON)
+option(GTSAM_WITH_EIGEN_MKL              "Eigen will use Intel MKL if available" OFF)
+option(GTSAM_WITH_EIGEN_MKL_OPENMP       "Eigen, when using Intel MKL, will also use OpenMP for multithreading if available" OFF)
+option(GTSAM_THROW_CHEIRALITY_EXCEPTION  "Throw exception when a triangulated point is behind a camera" ON)
+option(GTSAM_BUILD_PYTHON                "Enable/Disable building & installation of Python module with pybind11" OFF)
+option(GTSAM_INSTALL_MATLAB_TOOLBOX      "Enable/Disable installation of matlab toolbox"  OFF)
+option(GTSAM_ALLOW_DEPRECATED_SINCE_V41  "Allow use of methods/functions deprecated in GTSAM 4.1" ON)
+option(GTSAM_SUPPORT_NESTED_DISSECTION   "Support Metis-based nested dissection" ON)
+option(GTSAM_TANGENT_PREINTEGRATION      "Use new ImuFactor with integration on tangent space" ON)
+if(NOT MSVC AND NOT XCODE_VERSION)
+    option(GTSAM_BUILD_WITH_CCACHE           "Use ccache compiler cache" ON)
+endif()
+
+# Enable GTSAM_ROT3_EXPMAP if GTSAM_POSE3_EXPMAP is enabled, and vice versa.
+if(GTSAM_POSE3_EXPMAP)
+    message(STATUS "GTSAM_POSE3_EXPMAP=ON, enabling GTSAM_ROT3_EXPMAP as well")
+    set(GTSAM_ROT3_EXPMAP 1 CACHE BOOL "" FORCE)
+elseif(GTSAM_ROT3_EXPMAP)
+    message(STATUS "GTSAM_ROT3_EXPMAP=ON, enabling GTSAM_POSE3_EXPMAP as well")
+    set(GTSAM_POSE3_EXPMAP 1 CACHE BOOL "" FORCE)
+endif()
+
+# Set the default Python version. This is later updated in HandlePython.cmake.
+set(GTSAM_PYTHON_VERSION "Default" CACHE STRING "The version of Python to build the wrappers against.")
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleGlobalBuildFlags.cmake
@@ -0,0 +1,52 @@
+# JLBC: These should ideally be ported to "modern cmake" via target properties.
+#
+
+if (CMAKE_GENERATOR STREQUAL "Ninja" AND
+    ((CMAKE_CXX_COMPILER_ID STREQUAL "GNU" AND NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.9) OR
+     (CMAKE_CXX_COMPILER_ID STREQUAL "Clang" AND NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 3.5)))
+    # Force colored warnings in Ninja's output, if the compiler has -fdiagnostics-color support.
+    # Rationale in https://github.com/ninja-build/ninja/issues/814
+    add_compile_options(-fdiagnostics-color=always)
+endif()
+
+
+# If building DLLs in MSVC, we need to avoid EIGEN_STATIC_ASSERT()
+# or explicit instantiation will generate build errors.
+# See: https://bitbucket.org/gtborg/gtsam/issues/417/fail-to-build-on-msvc-2017
+#
+if(MSVC AND BUILD_SHARED_LIBS)
+    list_append_cache(GTSAM_COMPILE_DEFINITIONS_PUBLIC EIGEN_NO_STATIC_ASSERT)
+endif()
+
+if (APPLE AND BUILD_SHARED_LIBS)
+    # Set the default install directory on macOS
+    set(CMAKE_INSTALL_NAME_DIR "${CMAKE_INSTALL_PREFIX}/lib")
+endif()
+
+###############################################################################
+# Global compile options
+
+if(MSVC)
+    list_append_cache(GTSAM_COMPILE_DEFINITIONS_PRIVATE _CRT_SECURE_NO_WARNINGS _SCL_SECURE_NO_WARNINGS)
+    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE /wd4251 /wd4275 /wd4251 /wd4661 /wd4344 /wd4503) # Disable non-DLL-exported base class and other warnings
+    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE /bigobj) # Allow large object files for template-based code
+endif()
+
+# GCC 4.8+ complains about local typedefs which we use for shared_ptr etc.
+if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
+  if (NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.8)
+    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE -Wno-unused-local-typedefs)
+  endif()
+endif()
+
+# As of XCode 7, clang also complains about this
+if(CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
+  if (NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 7.0)
+    list_append_cache(GTSAM_COMPILE_OPTIONS_PRIVATE -Wno-unused-local-typedefs)
+  endif()
+endif()
+
+if(GTSAM_ENABLE_CONSISTENCY_CHECKS)
+  # This should be made PUBLIC if GTSAM_EXTRA_CONSISTENCY_CHECKS is someday used in a public .h
+  list_append_cache(GTSAM_COMPILE_DEFINITIONS_PRIVATE GTSAM_EXTRA_CONSISTENCY_CHECKS)
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleMKL.cmake
@@ -0,0 +1,17 @@
+###############################################################################
+# Find MKL
+find_package(MKL)
+
+if(MKL_FOUND AND GTSAM_WITH_EIGEN_MKL)
+    set(GTSAM_USE_EIGEN_MKL 1) # This will go into config.h
+    set(EIGEN_USE_MKL_ALL 1) # This will go into config.h - it makes Eigen use MKL
+    list(APPEND GTSAM_ADDITIONAL_LIBRARIES ${MKL_LIBRARIES})
+
+    # --no-as-needed is required with gcc according to the MKL link advisor
+    if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
+        set(CMAKE_EXE_LINKER_FLAGS "${CMAKE_EXE_LINKER_FLAGS} -Wl,--no-as-needed")
+    endif()
+else()
+    set(GTSAM_USE_EIGEN_MKL 0)
+    set(EIGEN_USE_MKL_ALL 0)
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleOpenMP.cmake
@@ -0,0 +1,11 @@
+
+###############################################################################
+# Find OpenMP (if we're also using MKL)
+find_package(OpenMP)  # do this here to generate correct message if disabled
+
+if(GTSAM_WITH_EIGEN_MKL AND GTSAM_WITH_EIGEN_MKL_OPENMP AND GTSAM_USE_EIGEN_MKL)
+    if(OPENMP_FOUND AND GTSAM_USE_EIGEN_MKL AND GTSAM_WITH_EIGEN_MKL_OPENMP)
+        set(GTSAM_USE_EIGEN_MKL_OPENMP 1) # This will go into config.h
+        list_append_cache(GTSAM_COMPILE_OPTIONS_PUBLIC ${OpenMP_CXX_FLAGS})
+    endif()
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandlePerfTools.cmake
@@ -0,0 +1,4 @@
+
+###############################################################################
+# Find Google perftools
+find_package(GooglePerfTools)
--- /dev/null
+++ gtsam-4.1.0/cmake/HandlePrintConfiguration.cmake
@@ -0,0 +1,104 @@
+###############################################################################
+# Print configuration variables
+message(STATUS "===============================================================")
+message(STATUS "================  Configuration Options  ======================")
+print_config("CMAKE_CXX_COMPILER_ID type" "${CMAKE_CXX_COMPILER_ID}")
+print_config("CMAKE_CXX_COMPILER_VERSION" "${CMAKE_CXX_COMPILER_VERSION}")
+print_config("CMake version"    "${CMAKE_VERSION}")
+print_config("CMake generator"  "${CMAKE_GENERATOR}")
+print_config("CMake build tool" "${CMAKE_BUILD_TOOL}")
+message(STATUS "Build flags                                               ")
+print_enabled_config(${GTSAM_BUILD_TESTS}                 "Build Tests")
+print_enabled_config(${GTSAM_BUILD_EXAMPLES_ALWAYS}       "Build examples with 'make all'")
+print_enabled_config(${GTSAM_BUILD_TIMING_ALWAYS}         "Build timing scripts with 'make all'")
+if (DOXYGEN_FOUND)
+    print_enabled_config(${GTSAM_BUILD_DOCS}              "Build Docs")
+endif()
+print_enabled_config(${BUILD_SHARED_LIBS}                 "Build shared GTSAM libraries")
+print_enabled_config(${GTSAM_BUILD_TYPE_POSTFIXES}        "Put build type in library name")
+if(GTSAM_UNSTABLE_AVAILABLE)
+    print_enabled_config(${GTSAM_BUILD_UNSTABLE}          "Build libgtsam_unstable        ")
+    print_enabled_config(${GTSAM_UNSTABLE_BUILD_PYTHON}   "Build GTSAM unstable Python    ")
+    print_enabled_config(${GTSAM_UNSTABLE_INSTALL_MATLAB_TOOLBOX} "Build MATLAB Toolbox for unstable")
+endif()
+
+if(NOT MSVC AND NOT XCODE_VERSION)
+    print_enabled_config(${GTSAM_BUILD_WITH_MARCH_NATIVE}     "Build for native architecture  ")
+    print_config("Build type" "${CMAKE_BUILD_TYPE}")
+    print_config("C compilation flags" "${CMAKE_C_FLAGS} ${CMAKE_C_FLAGS_${CMAKE_BUILD_TYPE_UPPER}}")
+    print_config("C++ compilation flags" "${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE_UPPER}}")
+endif()
+
+print_build_options_for_target(gtsam)
+
+print_config("Use System Eigen" "${GTSAM_USE_SYSTEM_EIGEN} (Using version: ${GTSAM_EIGEN_VERSION})")
+
+if(GTSAM_USE_TBB)
+    print_config("Use Intel TBB" "Yes (Version: ${TBB_VERSION})")
+elseif(TBB_FOUND)
+    print_config("Use Intel TBB" "TBB (Version: ${TBB_VERSION}) found but GTSAM_WITH_TBB is disabled")
+else()
+    print_config("Use Intel TBB" "TBB not found")
+endif()
+if(GTSAM_USE_EIGEN_MKL)
+    print_config("Eigen will use MKL" "Yes")
+elseif(MKL_FOUND)
+    print_config("Eigen will use MKL" "MKL found but GTSAM_WITH_EIGEN_MKL is disabled")
+else()
+    print_config("Eigen will use MKL" "MKL not found")
+endif()
+if(GTSAM_USE_EIGEN_MKL_OPENMP)
+    print_config("Eigen will use MKL and OpenMP" "Yes")
+elseif(OPENMP_FOUND AND NOT GTSAM_WITH_EIGEN_MKL)
+    print_config("Eigen will use MKL and OpenMP" "OpenMP found but GTSAM_WITH_EIGEN_MKL is disabled")
+elseif(OPENMP_FOUND AND NOT MKL_FOUND)
+    print_config("Eigen will use MKL and OpenMP" "OpenMP found but MKL not found")
+elseif(OPENMP_FOUND)
+    print_config("Eigen will use MKL and OpenMP" "OpenMP found but GTSAM_WITH_EIGEN_MKL_OPENMP is disabled")
+else()
+    print_config("Eigen will use MKL and OpenMP" "OpenMP not found")
+endif()
+print_config("Default allocator" "${GTSAM_DEFAULT_ALLOCATOR}")
+
+if(GTSAM_THROW_CHEIRALITY_EXCEPTION)
+    print_config("Cheirality exceptions enabled" "YES")
+else()
+    print_config("Cheirality exceptions enabled" "NO")
+endif()
+
+if(NOT MSVC AND NOT XCODE_VERSION)
+    if(CCACHE_FOUND AND GTSAM_BUILD_WITH_CCACHE)
+        print_config("Build with ccache" "Yes")
+    elseif(CCACHE_FOUND)
+        print_config("Build with ccache" "ccache found but GTSAM_BUILD_WITH_CCACHE is disabled")
+    else()
+        print_config("Build with ccache" "No")
+    endif()
+endif()
+
+message(STATUS "Packaging flags")
+print_config("CPack Source Generator" "${CPACK_SOURCE_GENERATOR}")
+print_config("CPack Generator" "${CPACK_GENERATOR}")
+
+message(STATUS "GTSAM flags                                               ")
+print_enabled_config(${GTSAM_USE_QUATERNIONS}             "Quaternions as default Rot3     ")
+print_enabled_config(${GTSAM_ENABLE_CONSISTENCY_CHECKS}   "Runtime consistency checking    ")
+print_enabled_config(${GTSAM_ROT3_EXPMAP}                 "Rot3 retract is full ExpMap     ")
+print_enabled_config(${GTSAM_POSE3_EXPMAP}                "Pose3 retract is full ExpMap    ")
+print_enabled_config(${GTSAM_ALLOW_DEPRECATED_SINCE_V41}  "Allow features deprecated in GTSAM 4.1")
+print_enabled_config(${GTSAM_SUPPORT_NESTED_DISSECTION}   "Metis-based Nested Dissection   ")
+print_enabled_config(${GTSAM_TANGENT_PREINTEGRATION}      "Use tangent-space preintegration")
+
+message(STATUS "MATLAB toolbox flags")
+print_enabled_config(${GTSAM_INSTALL_MATLAB_TOOLBOX}      "Install MATLAB toolbox          ")
+if (${GTSAM_INSTALL_MATLAB_TOOLBOX})
+    print_config("MATLAB root" "${MATLAB_ROOT}")
+    print_config("MEX binary" "${MEX_COMMAND}")
+endif()
+message(STATUS "Python toolbox flags                                      ")
+print_enabled_config(${GTSAM_BUILD_PYTHON}                "Build Python module with pybind ")
+if(GTSAM_BUILD_PYTHON)
+    print_config("Python version" ${GTSAM_PYTHON_VERSION})
+endif()
+
+message(STATUS "===============================================================")
--- /dev/null
+++ gtsam-4.1.0/cmake/HandlePython.cmake
@@ -0,0 +1,29 @@
+# Set Python version if either Python or MATLAB wrapper is requested.
+if(GTSAM_BUILD_PYTHON OR GTSAM_INSTALL_MATLAB_TOOLBOX)
+    if(${GTSAM_PYTHON_VERSION} STREQUAL "Default")
+        # Get info about the Python3 interpreter
+        # https://cmake.org/cmake/help/latest/module/FindPython3.html#module:FindPython3
+        find_package(Python3 COMPONENTS Interpreter Development)
+
+        if(NOT ${Python3_FOUND})
+            message(FATAL_ERROR "Cannot find Python3 interpreter. Please install Python >= 3.6.")
+        endif()
+
+        set(GTSAM_PYTHON_VERSION "${Python3_VERSION_MAJOR}.${Python3_VERSION_MINOR}"
+                CACHE
+                STRING
+                "The version of Python to build the wrappers against."
+                FORCE)
+    endif()
+endif()
+
+if(GTSAM_BUILD_PYTHON)
+    if(GTSAM_UNSTABLE_BUILD_PYTHON)
+        if (NOT GTSAM_BUILD_UNSTABLE)
+            message(WARNING "GTSAM_UNSTABLE_BUILD_PYTHON requires the unstable module to be enabled.")
+            set(GTSAM_UNSTABLE_BUILD_PYTHON OFF)
+        endif()
+    endif()
+
+    set(GTSAM_PY_INSTALL_PATH "${CMAKE_INSTALL_PREFIX}/python")
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleTBB.cmake
@@ -0,0 +1,24 @@
+###############################################################################
+# Find TBB
+find_package(TBB 4.4 COMPONENTS tbb tbbmalloc)
+
+# Set up variables if we're using TBB
+if(TBB_FOUND AND GTSAM_WITH_TBB)
+    set(GTSAM_USE_TBB 1)  # This will go into config.h
+    if ((${TBB_VERSION_MAJOR} GREATER 2020) OR (${TBB_VERSION_MAJOR} EQUAL 2020))
+        set(TBB_GREATER_EQUAL_2020 1)
+    else()
+        set(TBB_GREATER_EQUAL_2020 0)
+    endif()
+    # all definitions and link requisites will go via imported targets:
+    # tbb & tbbmalloc
+    list(APPEND GTSAM_ADDITIONAL_LIBRARIES tbb tbbmalloc)
+else()
+    set(GTSAM_USE_TBB 0)  # This will go into config.h
+endif()
+
+###############################################################################
+# Prohibit Timing build mode in combination with TBB
+if(GTSAM_USE_TBB AND (CMAKE_BUILD_TYPE  STREQUAL "Timing"))
+      message(FATAL_ERROR "Timing build mode cannot be used together with TBB. Use a sampling profiler such as Instruments or Intel VTune Amplifier instead.")
+endif()
--- /dev/null
+++ gtsam-4.1.0/cmake/HandleUninstall.cmake
@@ -0,0 +1,10 @@
+# ----------------------------------------------------------------------------
+#   Uninstall target, for "make uninstall"
+# ----------------------------------------------------------------------------
+configure_file(
+  "${CMAKE_CURRENT_SOURCE_DIR}/cmake/cmake_uninstall.cmake.in"
+  "${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake"
+  IMMEDIATE @ONLY)
+
+add_custom_target(uninstall
+  "${CMAKE_COMMAND}" -P "${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake")
--- gtsam-4.1.0.orig/doc/Doxyfile.in
+++ gtsam-4.1.0/doc/Doxyfile.in
@@ -1188,7 +1188,7 @@ USE_MATHJAX            = YES
 # MathJax, but it is strongly recommended to install a local copy of MathJax 
 # before deployment.
 
-MATHJAX_RELPATH        = http://cdn.mathjax.org/mathjax/latest
+MATHJAX_RELPATH        = https://cdn.mathjax.org/mathjax/latest
 
 # The MATHJAX_EXTENSIONS tag can be used to specify one or MathJax extension 
 # names that should be enabled during MathJax rendering.
--- gtsam-4.1.0.orig/docker/ubuntu-gtsam-python/Dockerfile
+++ gtsam-4.1.0/docker/ubuntu-gtsam-python/Dockerfile
@@ -7,9 +7,9 @@ FROM dellaert/ubuntu-gtsam:bionic
 RUN apt-get install -y python3-pip python3-dev
 
 # Install python wrapper requirements
-RUN python3 -m pip install -U -r /usr/src/gtsam/cython/requirements.txt
+RUN python3 -m pip install -U -r /usr/src/gtsam/python/requirements.txt
 
-# Run cmake again, now with cython toolbox on
+# Run cmake again, now with python toolbox on
 WORKDIR /usr/src/gtsam/build
 RUN cmake \
     -DCMAKE_BUILD_TYPE=Release \
@@ -17,7 +17,7 @@ RUN cmake \
     -DGTSAM_BUILD_EXAMPLES_ALWAYS=OFF \
     -DGTSAM_BUILD_TIMING_ALWAYS=OFF \
     -DGTSAM_BUILD_TESTS=OFF \
-    -DGTSAM_INSTALL_CYTHON_TOOLBOX=ON \
+    -DGTSAM_BUILD_PYTHON=ON \
     -DGTSAM_PYTHON_VERSION=3\
     ..
 
@@ -25,7 +25,7 @@ RUN cmake \
 RUN make -j4 install && make clean
 
 # Needed to run python wrapper:
-RUN echo 'export PYTHONPATH=/usr/local/cython/:$PYTHONPATH' >> /root/.bashrc
+RUN echo 'export PYTHONPATH=/usr/local/python/:$PYTHONPATH' >> /root/.bashrc
 
 # Run bash
 CMD ["bash"]
--- gtsam-4.1.0.orig/docker/ubuntu-gtsam/Dockerfile
+++ gtsam-4.1.0/docker/ubuntu-gtsam/Dockerfile
@@ -23,7 +23,6 @@ RUN cmake \
     -DGTSAM_BUILD_EXAMPLES_ALWAYS=OFF \
     -DGTSAM_BUILD_TIMING_ALWAYS=OFF \
     -DGTSAM_BUILD_TESTS=OFF \
-    -DGTSAM_INSTALL_CYTHON_TOOLBOX=OFF \
     ..
 
 # Build
--- /dev/null
+++ gtsam-4.1.0/examples/CombinedImuFactorsExample.cpp
@@ -0,0 +1,303 @@
+/* ----------------------------------------------------------------------------
+
+ * GTSAM Copyright 2010, Georgia Tech Research Corporation,
+ * Atlanta, Georgia 30332-0415
+ * All Rights Reserved
+ * Authors: Frank Dellaert, et al. (see THANKS for the full author list)
+
+ * See LICENSE for the license information
+
+ * -------------------------------------------------------------------------- */
+
+/**
+ * @file CombinedImuFactorsExample
+ * @brief Test example for using GTSAM ImuCombinedFactor
+ * navigation code.
+ * @author Varun Agrawal
+ */
+
+/**
+ * Example of use of the CombinedImuFactor in
+ * conjunction with GPS
+ *  - we read IMU and GPS data from a CSV file, with the following format:
+ *  A row starting with "i" is the first initial position formatted with
+ *  N, E, D, qx, qY, qZ, qW, velN, velE, velD
+ *  A row starting with "0" is an imu measurement
+ *  linAccN, linAccE, linAccD, angVelN, angVelE, angVelD
+ *  A row starting with "1" is a gps correction formatted with
+ *  N, E, D, qX, qY, qZ, qW
+ * Note that for GPS correction, we're only using the position not the
+ * rotation. The rotation is provided in the file for ground truth comparison.
+ *
+ *  See usage: ./CombinedImuFactorsExample --help
+ */
+
+#include <boost/program_options.hpp>
+
+// GTSAM related includes.
+#include <gtsam/inference/Symbol.h>
+#include <gtsam/navigation/CombinedImuFactor.h>
+#include <gtsam/navigation/GPSFactor.h>
+#include <gtsam/navigation/ImuFactor.h>
+#include <gtsam/nonlinear/LevenbergMarquardtOptimizer.h>
+#include <gtsam/nonlinear/NonlinearFactorGraph.h>
+#include <gtsam/slam/BetweenFactor.h>
+#include <gtsam/slam/dataset.h>
+
+#include <cstring>
+#include <fstream>
+#include <iostream>
+
+using namespace gtsam;
+using namespace std;
+
+using symbol_shorthand::B;  // Bias  (ax,ay,az,gx,gy,gz)
+using symbol_shorthand::V;  // Vel   (xdot,ydot,zdot)
+using symbol_shorthand::X;  // Pose3 (x,y,z,r,p,y)
+
+namespace po = boost::program_options;
+
+po::variables_map parseOptions(int argc, char* argv[]) {
+  po::options_description desc;
+  desc.add_options()("help,h", "produce help message")(
+      "data_csv_path", po::value<string>()->default_value("imuAndGPSdata.csv"),
+      "path to the CSV file with the IMU data")(
+      "output_filename",
+      po::value<string>()->default_value("imuFactorExampleResults.csv"),
+      "path to the result file to use")("use_isam", po::bool_switch(),
+                                        "use ISAM as the optimizer");
+
+  po::variables_map vm;
+  po::store(po::parse_command_line(argc, argv, desc), vm);
+
+  if (vm.count("help")) {
+    cout << desc << "\n";
+    exit(1);
+  }
+
+  return vm;
+}
+
+Vector10 readInitialState(ifstream& file) {
+  string value;
+  // Format is (N,E,D,qX,qY,qZ,qW,velN,velE,velD)
+  Vector10 initial_state;
+  getline(file, value, ',');  // i
+  for (int i = 0; i < 9; i++) {
+    getline(file, value, ',');
+    initial_state(i) = stof(value.c_str());
+  }
+  getline(file, value, '\n');
+  initial_state(9) = stof(value.c_str());
+
+  return initial_state;
+}
+
+boost::shared_ptr<PreintegratedCombinedMeasurements::Params> imuParams() {
+  // We use the sensor specs to build the noise model for the IMU factor.
+  double accel_noise_sigma = 0.0003924;
+  double gyro_noise_sigma = 0.000205689024915;
+  double accel_bias_rw_sigma = 0.004905;
+  double gyro_bias_rw_sigma = 0.000001454441043;
+  Matrix33 measured_acc_cov = I_3x3 * pow(accel_noise_sigma, 2);
+  Matrix33 measured_omega_cov = I_3x3 * pow(gyro_noise_sigma, 2);
+  Matrix33 integration_error_cov =
+      I_3x3 * 1e-8;  // error committed in integrating position from velocities
+  Matrix33 bias_acc_cov = I_3x3 * pow(accel_bias_rw_sigma, 2);
+  Matrix33 bias_omega_cov = I_3x3 * pow(gyro_bias_rw_sigma, 2);
+  Matrix66 bias_acc_omega_int =
+      I_6x6 * 1e-5;  // error in the bias used for preintegration
+
+  auto p = PreintegratedCombinedMeasurements::Params::MakeSharedD(0.0);
+  // PreintegrationBase params:
+  p->accelerometerCovariance =
+      measured_acc_cov;  // acc white noise in continuous
+  p->integrationCovariance =
+      integration_error_cov;  // integration uncertainty continuous
+  // should be using 2nd order integration
+  // PreintegratedRotation params:
+  p->gyroscopeCovariance =
+      measured_omega_cov;  // gyro white noise in continuous
+  // PreintegrationCombinedMeasurements params:
+  p->biasAccCovariance = bias_acc_cov;      // acc bias in continuous
+  p->biasOmegaCovariance = bias_omega_cov;  // gyro bias in continuous
+  p->biasAccOmegaInt = bias_acc_omega_int;
+
+  return p;
+}
+
+int main(int argc, char* argv[]) {
+  string data_filename, output_filename;
+  po::variables_map var_map = parseOptions(argc, argv);
+
+  data_filename = findExampleDataFile(var_map["data_csv_path"].as<string>());
+  output_filename = var_map["output_filename"].as<string>();
+
+  // Set up output file for plotting errors
+  FILE* fp_out = fopen(output_filename.c_str(), "w+");
+  fprintf(fp_out,
+          "#time(s),x(m),y(m),z(m),qx,qy,qz,qw,gt_x(m),gt_y(m),gt_z(m),gt_qx,"
+          "gt_qy,gt_qz,gt_qw\n");
+
+  // Begin parsing the CSV file.  Input the first line for initialization.
+  // From there, we'll iterate through the file and we'll preintegrate the IMU
+  // or add in the GPS given the input.
+  ifstream file(data_filename.c_str());
+
+  Vector10 initial_state = readInitialState(file);
+  cout << "initial state:\n" << initial_state.transpose() << "\n\n";
+
+  // Assemble initial quaternion through GTSAM constructor
+  // ::Quaternion(w,x,y,z);
+  Rot3 prior_rotation = Rot3::Quaternion(initial_state(6), initial_state(3),
+                                         initial_state(4), initial_state(5));
+  Point3 prior_point(initial_state.head<3>());
+  Pose3 prior_pose(prior_rotation, prior_point);
+  Vector3 prior_velocity(initial_state.tail<3>());
+
+  imuBias::ConstantBias prior_imu_bias;  // assume zero initial bias
+
+  int index = 0;
+
+  Values initial_values;
+
+  // insert pose at initialization
+  initial_values.insert(X(index), prior_pose);
+  initial_values.insert(V(index), prior_velocity);
+  initial_values.insert(B(index), prior_imu_bias);
+
+  // Assemble prior noise model and add it the graph.`
+  auto pose_noise_model = noiseModel::Diagonal::Sigmas(
+      (Vector(6) << 0.01, 0.01, 0.01, 0.5, 0.5, 0.5)
+          .finished());  // rad,rad,rad,m, m, m
+  auto velocity_noise_model = noiseModel::Isotropic::Sigma(3, 0.1);  // m/s
+  auto bias_noise_model = noiseModel::Isotropic::Sigma(6, 1e-3);
+
+  // Add all prior factors (pose, velocity, bias) to the graph.
+  NonlinearFactorGraph graph;
+  graph.addPrior<Pose3>(X(index), prior_pose, pose_noise_model);
+  graph.addPrior<Vector3>(V(index), prior_velocity, velocity_noise_model);
+  graph.addPrior<imuBias::ConstantBias>(B(index), prior_imu_bias,
+                                        bias_noise_model);
+
+  auto p = imuParams();
+
+  std::shared_ptr<PreintegrationType> preintegrated =
+      std::make_shared<PreintegratedCombinedMeasurements>(p, prior_imu_bias);
+
+  assert(preintegrated);
+
+  // Store previous state for imu integration and latest predicted outcome.
+  NavState prev_state(prior_pose, prior_velocity);
+  NavState prop_state = prev_state;
+  imuBias::ConstantBias prev_bias = prior_imu_bias;
+
+  // Keep track of total error over the entire run as simple performance metric.
+  double current_position_error = 0.0, current_orientation_error = 0.0;
+
+  double output_time = 0.0;
+  double dt = 0.005;  // The real system has noise, but here, results are nearly
+                      // exactly the same, so keeping this for simplicity.
+
+  // All priors have been set up, now iterate through the data file.
+  while (file.good()) {
+    // Parse out first value
+    string value;
+    getline(file, value, ',');
+    int type = stoi(value.c_str());
+
+    if (type == 0) {  // IMU measurement
+      Vector6 imu;
+      for (int i = 0; i < 5; ++i) {
+        getline(file, value, ',');
+        imu(i) = stof(value.c_str());
+      }
+      getline(file, value, '\n');
+      imu(5) = stof(value.c_str());
+
+      // Adding the IMU preintegration.
+      preintegrated->integrateMeasurement(imu.head<3>(), imu.tail<3>(), dt);
+
+    } else if (type == 1) {  // GPS measurement
+      Vector7 gps;
+      for (int i = 0; i < 6; ++i) {
+        getline(file, value, ',');
+        gps(i) = stof(value.c_str());
+      }
+      getline(file, value, '\n');
+      gps(6) = stof(value.c_str());
+
+      index++;
+
+      // Adding IMU factor and GPS factor and optimizing.
+      auto preint_imu_combined =
+          dynamic_cast<const PreintegratedCombinedMeasurements&>(
+              *preintegrated);
+      CombinedImuFactor imu_factor(X(index - 1), V(index - 1), X(index),
+                                   V(index), B(index - 1), B(index),
+                                   preint_imu_combined);
+      graph.add(imu_factor);
+
+      auto correction_noise = noiseModel::Isotropic::Sigma(3, 1.0);
+      GPSFactor gps_factor(X(index),
+                           Point3(gps(0),   // N,
+                                  gps(1),   // E,
+                                  gps(2)),  // D,
+                           correction_noise);
+      graph.add(gps_factor);
+
+      // Now optimize and compare results.
+      prop_state = preintegrated->predict(prev_state, prev_bias);
+      initial_values.insert(X(index), prop_state.pose());
+      initial_values.insert(V(index), prop_state.v());
+      initial_values.insert(B(index), prev_bias);
+
+      LevenbergMarquardtParams params;
+      params.setVerbosityLM("SUMMARY");
+      LevenbergMarquardtOptimizer optimizer(graph, initial_values, params);
+      Values result = optimizer.optimize();
+
+      // Overwrite the beginning of the preintegration for the next step.
+      prev_state =
+          NavState(result.at<Pose3>(X(index)), result.at<Vector3>(V(index)));
+      prev_bias = result.at<imuBias::ConstantBias>(B(index));
+
+      // Reset the preintegration object.
+      preintegrated->resetIntegrationAndSetBias(prev_bias);
+
+      // Print out the position and orientation error for comparison.
+      Vector3 result_position = prev_state.pose().translation();
+      Vector3 position_error = result_position - gps.head<3>();
+      current_position_error = position_error.norm();
+
+      Quaternion result_quat = prev_state.pose().rotation().toQuaternion();
+      Quaternion gps_quat(gps(6), gps(3), gps(4), gps(5));
+      Quaternion quat_error = result_quat * gps_quat.inverse();
+      quat_error.normalize();
+      Vector3 euler_angle_error(quat_error.x() * 2, quat_error.y() * 2,
+                                quat_error.z() * 2);
+      current_orientation_error = euler_angle_error.norm();
+
+      // display statistics
+      cout << "Position error:" << current_position_error << "\t "
+           << "Angular error:" << current_orientation_error << "\n"
+           << endl;
+
+      fprintf(fp_out, "%f,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f\n",
+              output_time, result_position(0), result_position(1),
+              result_position(2), result_quat.x(), result_quat.y(),
+              result_quat.z(), result_quat.w(), gps(0), gps(1), gps(2),
+              gps_quat.x(), gps_quat.y(), gps_quat.z(), gps_quat.w());
+
+      output_time += 1.0;
+
+    } else {
+      cerr << "ERROR parsing file\n";
+      return 1;
+    }
+  }
+  fclose(fp_out);
+  cout << "Complete, results written to " << output_filename << "\n\n";
+
+  return 0;
+}
--- gtsam-4.1.0.orig/examples/ImuFactorsExample.cpp
+++ gtsam-4.1.0/examples/ImuFactorsExample.cpp
@@ -10,7 +10,7 @@
  * -------------------------------------------------------------------------- */
 
 /**
- * @file imuFactorsExample
+ * @file ImuFactorsExample
  * @brief Test example for using GTSAM ImuFactor and ImuCombinedFactor
  * navigation code.
  * @author Garrett (ghemann@gmail.com), Luca Carlone
@@ -31,32 +31,26 @@
  * Note that for GPS correction, we're only using the position not the
  * rotation. The rotation is provided in the file for ground truth comparison.
  *
- *  Usage: ./ImuFactorsExample [data_csv_path] [-c]
- *  optional arguments:
- *    data_csv_path           path to the CSV file with the IMU data.
- *    -c                      use CombinedImuFactor
- *  Note: Define USE_LM to use Levenberg Marquardt Optimizer
- *        By default ISAM2 is used
+ *  See usage: ./ImuFactorsExample --help
  */
 
+#include <boost/program_options.hpp>
+
 // GTSAM related includes.
+#include <gtsam/inference/Symbol.h>
 #include <gtsam/navigation/CombinedImuFactor.h>
 #include <gtsam/navigation/GPSFactor.h>
 #include <gtsam/navigation/ImuFactor.h>
-#include <gtsam/slam/BetweenFactor.h>
-#include <gtsam/slam/dataset.h>
+#include <gtsam/nonlinear/ISAM2.h>
 #include <gtsam/nonlinear/LevenbergMarquardtOptimizer.h>
 #include <gtsam/nonlinear/NonlinearFactorGraph.h>
-#include <gtsam/nonlinear/ISAM2.h>
-#include <gtsam/inference/Symbol.h>
+#include <gtsam/slam/BetweenFactor.h>
+#include <gtsam/slam/dataset.h>
 
 #include <cstring>
 #include <fstream>
 #include <iostream>
 
-// Uncomment the following to use Levenberg Marquardt Optimizer
-// #define USE_LM
-
 using namespace gtsam;
 using namespace std;
 
@@ -64,45 +58,87 @@ using symbol_shorthand::B;  // Bias  (ax
 using symbol_shorthand::V;  // Vel   (xdot,ydot,zdot)
 using symbol_shorthand::X;  // Pose3 (x,y,z,r,p,y)
 
-static const char output_filename[] = "imuFactorExampleResults.csv";
-static const char use_combined_imu_flag[3] = "-c";
+namespace po = boost::program_options;
+
+po::variables_map parseOptions(int argc, char* argv[]) {
+  po::options_description desc;
+  desc.add_options()("help,h", "produce help message")(
+      "data_csv_path", po::value<string>()->default_value("imuAndGPSdata.csv"),
+      "path to the CSV file with the IMU data")(
+      "output_filename",
+      po::value<string>()->default_value("imuFactorExampleResults.csv"),
+      "path to the result file to use")("use_isam", po::bool_switch(),
+                                        "use ISAM as the optimizer");
+
+  po::variables_map vm;
+  po::store(po::parse_command_line(argc, argv, desc), vm);
+
+  if (vm.count("help")) {
+    cout << desc << "\n";
+    exit(1);
+  }
+
+  return vm;
+}
+
+boost::shared_ptr<PreintegratedCombinedMeasurements::Params> imuParams() {
+  // We use the sensor specs to build the noise model for the IMU factor.
+  double accel_noise_sigma = 0.0003924;
+  double gyro_noise_sigma = 0.000205689024915;
+  double accel_bias_rw_sigma = 0.004905;
+  double gyro_bias_rw_sigma = 0.000001454441043;
+  Matrix33 measured_acc_cov = I_3x3 * pow(accel_noise_sigma, 2);
+  Matrix33 measured_omega_cov = I_3x3 * pow(gyro_noise_sigma, 2);
+  Matrix33 integration_error_cov =
+      I_3x3 * 1e-8;  // error committed in integrating position from velocities
+  Matrix33 bias_acc_cov = I_3x3 * pow(accel_bias_rw_sigma, 2);
+  Matrix33 bias_omega_cov = I_3x3 * pow(gyro_bias_rw_sigma, 2);
+  Matrix66 bias_acc_omega_int =
+      I_6x6 * 1e-5;  // error in the bias used for preintegration
+
+  auto p = PreintegratedCombinedMeasurements::Params::MakeSharedD(0.0);
+  // PreintegrationBase params:
+  p->accelerometerCovariance =
+      measured_acc_cov;  // acc white noise in continuous
+  p->integrationCovariance =
+      integration_error_cov;  // integration uncertainty continuous
+  // should be using 2nd order integration
+  // PreintegratedRotation params:
+  p->gyroscopeCovariance =
+      measured_omega_cov;  // gyro white noise in continuous
+  // PreintegrationCombinedMeasurements params:
+  p->biasAccCovariance = bias_acc_cov;      // acc bias in continuous
+  p->biasOmegaCovariance = bias_omega_cov;  // gyro bias in continuous
+  p->biasAccOmegaInt = bias_acc_omega_int;
+
+  return p;
+}
 
 int main(int argc, char* argv[]) {
-  string data_filename;
-  bool use_combined_imu = false;
+  string data_filename, output_filename;
+
+  bool use_isam = false;
+
+  po::variables_map var_map = parseOptions(argc, argv);
+
+  data_filename = findExampleDataFile(var_map["data_csv_path"].as<string>());
+  output_filename = var_map["output_filename"].as<string>();
+  use_isam = var_map["use_isam"].as<bool>();
+
+  ISAM2* isam2 = 0;
+  if (use_isam) {
+    printf("Using ISAM2\n");
+    ISAM2Params parameters;
+    parameters.relinearizeThreshold = 0.01;
+    parameters.relinearizeSkip = 1;
+    isam2 = new ISAM2(parameters);
 
-#ifndef USE_LM
-  printf("Using ISAM2\n");
-  ISAM2Params parameters;
-  parameters.relinearizeThreshold = 0.01;
-  parameters.relinearizeSkip = 1;
-  ISAM2 isam2(parameters);
-#else
-  printf("Using Levenberg Marquardt Optimizer\n");
-#endif
-
-  if (argc < 2) {
-    printf("using default CSV file\n");
-    data_filename = findExampleDataFile("imuAndGPSdata.csv");
-  } else if (argc < 3) {
-    if (strcmp(argv[1], use_combined_imu_flag) == 0) {
-      printf("using CombinedImuFactor\n");
-      use_combined_imu = true;
-      printf("using default CSV file\n");
-      data_filename = findExampleDataFile("imuAndGPSdata.csv");
-    } else {
-      data_filename = argv[1];
-    }
   } else {
-    data_filename = argv[1];
-    if (strcmp(argv[2], use_combined_imu_flag) == 0) {
-      printf("using CombinedImuFactor\n");
-      use_combined_imu = true;
-    }
+    printf("Using Levenberg Marquardt Optimizer\n");
   }
 
   // Set up output file for plotting errors
-  FILE* fp_out = fopen(output_filename, "w+");
+  FILE* fp_out = fopen(output_filename.c_str(), "w+");
   fprintf(fp_out,
           "#time(s),x(m),y(m),z(m),qx,qy,qz,qw,gt_x(m),gt_y(m),gt_z(m),gt_qx,"
           "gt_qy,gt_qz,gt_qw\n");
@@ -118,10 +154,10 @@ int main(int argc, char* argv[]) {
   getline(file, value, ',');  // i
   for (int i = 0; i < 9; i++) {
     getline(file, value, ',');
-    initial_state(i) = atof(value.c_str());
+    initial_state(i) = stof(value.c_str());
   }
   getline(file, value, '\n');
-  initial_state(9) = atof(value.c_str());
+  initial_state(9) = stof(value.c_str());
   cout << "initial state:\n" << initial_state.transpose() << "\n\n";
 
   // Assemble initial quaternion through GTSAM constructor
@@ -152,43 +188,11 @@ int main(int argc, char* argv[]) {
   graph->addPrior(V(correction_count), prior_velocity, velocity_noise_model);
   graph->addPrior(B(correction_count), prior_imu_bias, bias_noise_model);
 
-  // We use the sensor specs to build the noise model for the IMU factor.
-  double accel_noise_sigma = 0.0003924;
-  double gyro_noise_sigma = 0.000205689024915;
-  double accel_bias_rw_sigma = 0.004905;
-  double gyro_bias_rw_sigma = 0.000001454441043;
-  Matrix33 measured_acc_cov = I_3x3 * pow(accel_noise_sigma, 2);
-  Matrix33 measured_omega_cov = I_3x3 * pow(gyro_noise_sigma, 2);
-  Matrix33 integration_error_cov =
-      I_3x3 * 1e-8;  // error committed in integrating position from velocities
-  Matrix33 bias_acc_cov = I_3x3 * pow(accel_bias_rw_sigma, 2);
-  Matrix33 bias_omega_cov = I_3x3 * pow(gyro_bias_rw_sigma, 2);
-  Matrix66 bias_acc_omega_int =
-      I_6x6 * 1e-5;  // error in the bias used for preintegration
+  auto p = imuParams();
 
-  auto p = PreintegratedCombinedMeasurements::Params::MakeSharedD(0.0);
-  // PreintegrationBase params:
-  p->accelerometerCovariance =
-      measured_acc_cov;  // acc white noise in continuous
-  p->integrationCovariance =
-      integration_error_cov;  // integration uncertainty continuous
-  // should be using 2nd order integration
-  // PreintegratedRotation params:
-  p->gyroscopeCovariance =
-      measured_omega_cov;  // gyro white noise in continuous
-  // PreintegrationCombinedMeasurements params:
-  p->biasAccCovariance = bias_acc_cov;      // acc bias in continuous
-  p->biasOmegaCovariance = bias_omega_cov;  // gyro bias in continuous
-  p->biasAccOmegaInt = bias_acc_omega_int;
+  std::shared_ptr<PreintegrationType> preintegrated =
+      std::make_shared<PreintegratedImuMeasurements>(p, prior_imu_bias);
 
-  std::shared_ptr<PreintegrationType> preintegrated = nullptr;
-  if (use_combined_imu) {
-    preintegrated =
-        std::make_shared<PreintegratedCombinedMeasurements>(p, prior_imu_bias);
-  } else {
-    preintegrated =
-        std::make_shared<PreintegratedImuMeasurements>(p, prior_imu_bias);
-  }
   assert(preintegrated);
 
   // Store previous state for imu integration and latest predicted outcome.
@@ -207,16 +211,16 @@ int main(int argc, char* argv[]) {
   while (file.good()) {
     // Parse out first value
     getline(file, value, ',');
-    int type = atoi(value.c_str());
+    int type = stoi(value.c_str());
 
     if (type == 0) {  // IMU measurement
       Vector6 imu;
       for (int i = 0; i < 5; ++i) {
         getline(file, value, ',');
-        imu(i) = atof(value.c_str());
+        imu(i) = stof(value.c_str());
       }
       getline(file, value, '\n');
-      imu(5) = atof(value.c_str());
+      imu(5) = stof(value.c_str());
 
       // Adding the IMU preintegration.
       preintegrated->integrateMeasurement(imu.head<3>(), imu.tail<3>(), dt);
@@ -225,35 +229,24 @@ int main(int argc, char* argv[]) {
       Vector7 gps;
       for (int i = 0; i < 6; ++i) {
         getline(file, value, ',');
-        gps(i) = atof(value.c_str());
+        gps(i) = stof(value.c_str());
       }
       getline(file, value, '\n');
-      gps(6) = atof(value.c_str());
+      gps(6) = stof(value.c_str());
 
       correction_count++;
 
       // Adding IMU factor and GPS factor and optimizing.
-      if (use_combined_imu) {
-        auto preint_imu_combined =
-            dynamic_cast<const PreintegratedCombinedMeasurements&>(
-                *preintegrated);
-        CombinedImuFactor imu_factor(
-            X(correction_count - 1), V(correction_count - 1),
-            X(correction_count), V(correction_count), B(correction_count - 1),
-            B(correction_count), preint_imu_combined);
-        graph->add(imu_factor);
-      } else {
-        auto preint_imu =
-            dynamic_cast<const PreintegratedImuMeasurements&>(*preintegrated);
-        ImuFactor imu_factor(X(correction_count - 1), V(correction_count - 1),
-                             X(correction_count), V(correction_count),
-                             B(correction_count - 1), preint_imu);
-        graph->add(imu_factor);
-        imuBias::ConstantBias zero_bias(Vector3(0, 0, 0), Vector3(0, 0, 0));
-        graph->add(BetweenFactor<imuBias::ConstantBias>(
-            B(correction_count - 1), B(correction_count), zero_bias,
-            bias_noise_model));
-      }
+      auto preint_imu =
+          dynamic_cast<const PreintegratedImuMeasurements&>(*preintegrated);
+      ImuFactor imu_factor(X(correction_count - 1), V(correction_count - 1),
+                           X(correction_count), V(correction_count),
+                           B(correction_count - 1), preint_imu);
+      graph->add(imu_factor);
+      imuBias::ConstantBias zero_bias(Vector3(0, 0, 0), Vector3(0, 0, 0));
+      graph->add(BetweenFactor<imuBias::ConstantBias>(
+          B(correction_count - 1), B(correction_count), zero_bias,
+          bias_noise_model));
 
       auto correction_noise = noiseModel::Isotropic::Sigma(3, 1.0);
       GPSFactor gps_factor(X(correction_count),
@@ -270,18 +263,21 @@ int main(int argc, char* argv[]) {
       initial_values.insert(B(correction_count), prev_bias);
 
       Values result;
-#ifdef USE_LM
-      LevenbergMarquardtOptimizer optimizer(*graph, initial_values);
-      result = optimizer.optimize();
-#else
-      isam2.update(*graph, initial_values);
-      isam2.update();
-      result = isam2.calculateEstimate();
-
-      // reset the graph
-      graph->resize(0);
-      initial_values.clear();
-#endif
+
+      if (use_isam) {
+        isam2->update(*graph, initial_values);
+        isam2->update();
+        result = isam2->calculateEstimate();
+
+        // reset the graph
+        graph->resize(0);
+        initial_values.clear();
+
+      } else {
+        LevenbergMarquardtOptimizer optimizer(*graph, initial_values);
+        result = optimizer.optimize();
+      }
+
       // Overwrite the beginning of the preintegration for the next step.
       prev_state = NavState(result.at<Pose3>(X(correction_count)),
                             result.at<Vector3>(V(correction_count)));
--- /dev/null
+++ gtsam-4.1.0/examples/ImuFactorsExample2.cpp
@@ -0,0 +1,147 @@
+/* ----------------------------------------------------------------------------
+
+ * GTSAM Copyright 2010, Georgia Tech Research Corporation,
+ * Atlanta, Georgia 30332-0415
+ * All Rights Reserved
+ * Authors: Frank Dellaert, et al. (see THANKS for the full author list)
+
+ * See LICENSE for the license information
+
+ * -------------------------------------------------------------------------- */
+
+/**
+ * @file ImuFactorExample2
+ * @brief Test example for using GTSAM ImuFactor and ImuCombinedFactor with ISAM2.
+ * @author Robert Truax
+ */
+
+#include <gtsam/geometry/PinholeCamera.h>
+#include <gtsam/geometry/Cal3_S2.h>
+#include <gtsam/inference/Symbol.h>
+#include <gtsam/navigation/ImuBias.h>
+#include <gtsam/navigation/ImuFactor.h>
+#include <gtsam/navigation/Scenario.h>
+#include <gtsam/nonlinear/ISAM2.h>
+#include <gtsam/slam/BetweenFactor.h>
+
+#include <vector>
+
+using namespace std;
+using namespace gtsam;
+
+// Shorthand for velocity and pose variables
+using symbol_shorthand::V;
+using symbol_shorthand::X;
+
+const double kGravity = 9.81;
+
+/* ************************************************************************* */
+int main(int argc, char* argv[]) {
+  auto params = PreintegrationParams::MakeSharedU(kGravity);
+  params->setAccelerometerCovariance(I_3x3 * 0.1);
+  params->setGyroscopeCovariance(I_3x3 * 0.1);
+  params->setIntegrationCovariance(I_3x3 * 0.1);
+  params->setUse2ndOrderCoriolis(false);
+  params->setOmegaCoriolis(Vector3(0, 0, 0));
+
+  Pose3 delta(Rot3::Rodrigues(-0.1, 0.2, 0.25), Point3(0.05, -0.10, 0.20));
+
+  // Start with a camera on x-axis looking at origin
+  double radius = 30;
+  const Point3 up(0, 0, 1), target(0, 0, 0);
+  const Point3 position(radius, 0, 0);
+  const auto camera = PinholeCamera<Cal3_S2>::Lookat(position, target, up);
+  const auto pose_0 = camera.pose();
+
+  // Now, create a constant-twist scenario that makes the camera orbit the
+  // origin
+  double angular_velocity = M_PI,  // rad/sec
+      delta_t = 1.0 / 18;          // makes for 10 degrees per step
+  Vector3 angular_velocity_vector(0, -angular_velocity, 0);
+  Vector3 linear_velocity_vector(radius * angular_velocity, 0, 0);
+  auto scenario = ConstantTwistScenario(angular_velocity_vector,
+                                        linear_velocity_vector, pose_0);
+
+  // Create a factor graph
+  NonlinearFactorGraph newgraph;
+
+  // Create (incremental) ISAM2 solver
+  ISAM2 isam;
+
+  // Create the initial estimate to the solution
+  // Intentionally initialize the variables off from the ground truth
+  Values initialEstimate, totalEstimate, result;
+
+  // Add a prior on pose x0. This indirectly specifies where the origin is.
+  // 0.1 rad std on roll, pitch, yaw, 30cm std on x,y,z.
+  auto noise = noiseModel::Diagonal::Sigmas(
+      (Vector(6) << Vector3::Constant(0.1), Vector3::Constant(0.3)).finished());
+  newgraph.addPrior(X(0), pose_0, noise);
+
+  // Add imu priors
+  Key biasKey = Symbol('b', 0);
+  auto biasnoise = noiseModel::Diagonal::Sigmas(Vector6::Constant(0.1));
+  newgraph.addPrior(biasKey, imuBias::ConstantBias(), biasnoise);
+  initialEstimate.insert(biasKey, imuBias::ConstantBias());
+  auto velnoise = noiseModel::Diagonal::Sigmas(Vector3(0.1, 0.1, 0.1));
+
+  Vector n_velocity(3);
+  n_velocity << 0, angular_velocity * radius, 0;
+  newgraph.addPrior(V(0), n_velocity, velnoise);
+
+  initialEstimate.insert(V(0), n_velocity);
+
+  // IMU preintegrator
+  PreintegratedImuMeasurements accum(params);
+
+  // Simulate poses and imu measurements, adding them to the factor graph
+  for (size_t i = 0; i < 36; ++i) {
+    double t = i * delta_t;
+    if (i == 0) {  // First time add two poses
+      auto pose_1 = scenario.pose(delta_t);
+      initialEstimate.insert(X(0), pose_0.compose(delta));
+      initialEstimate.insert(X(1), pose_1.compose(delta));
+    } else if (i >= 2) {  // Add more poses as necessary
+      auto pose_i = scenario.pose(t);
+      initialEstimate.insert(X(i), pose_i.compose(delta));
+    }
+
+    if (i > 0) {
+      // Add Bias variables periodically
+      if (i % 5 == 0) {
+        biasKey++;
+        Symbol b1 = biasKey - 1;
+        Symbol b2 = biasKey;
+        Vector6 covvec;
+        covvec << 0.1, 0.1, 0.1, 0.1, 0.1, 0.1;
+        auto cov = noiseModel::Diagonal::Variances(covvec);
+        auto f = boost::make_shared<BetweenFactor<imuBias::ConstantBias> >(
+            b1, b2, imuBias::ConstantBias(), cov);
+        newgraph.add(f);
+        initialEstimate.insert(biasKey, imuBias::ConstantBias());
+      }
+      // Predict acceleration and gyro measurements in (actual) body frame
+      Vector3 measuredAcc = scenario.acceleration_b(t) -
+                            scenario.rotation(t).transpose() * params->n_gravity;
+      Vector3 measuredOmega = scenario.omega_b(t);
+      accum.integrateMeasurement(measuredAcc, measuredOmega, delta_t);
+
+      // Add Imu Factor
+      ImuFactor imufac(X(i - 1), V(i - 1), X(i), V(i), biasKey, accum);
+      newgraph.add(imufac);
+
+      // insert new velocity, which is wrong
+      initialEstimate.insert(V(i), n_velocity);
+      accum.resetIntegration();
+    }
+
+    // Incremental solution
+    isam.update(newgraph, initialEstimate);
+    result = isam.calculateEstimate();
+    newgraph = NonlinearFactorGraph();
+    initialEstimate.clear();
+  }
+  GTSAM_PRINT(result);
+  return 0;
+}
+/* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/CMakeLists.txt
+++ gtsam-4.1.0/gtsam/CMakeLists.txt
@@ -199,7 +199,7 @@ if(WIN32)
 else()
   if("${CMAKE_BUILD_TYPE}" STREQUAL "Release")
     # Suppress all warnings from 3rd party sources.
-    set_source_files_properties(${3rdparty_srcs} PROPERTIES COMPILE_FLAGS "-w")
+    set_source_files_properties(${3rdparty_srcs} PROPERTIES COMPILE_FLAGS "-w -Wno-everything")
   else()
     set_source_files_properties(${3rdparty_srcs} PROPERTIES COMPILE_FLAGS "-Wno-error")
   endif()
--- gtsam-4.1.0.orig/gtsam/base/DSFMap.h
+++ gtsam-4.1.0/gtsam/base/DSFMap.h
@@ -21,6 +21,7 @@
 #include <cstdlib>  // Provides size_t
 #include <map>
 #include <set>
+#include <vector>
 
 namespace gtsam {
 
@@ -120,4 +121,12 @@ class IndexPair : public std::pair<size_
   inline size_t i() const { return first; };
   inline size_t j() const { return second; };
 };
+
+typedef std::vector<IndexPair> IndexPairVector;
+typedef std::set<IndexPair> IndexPairSet;
+
+inline IndexPairVector IndexPairSetAsArray(IndexPairSet& set) { return IndexPairVector(set.begin(), set.end()); }
+
+typedef std::map<IndexPair, IndexPairSet> IndexPairSetMap;
+typedef DSFMap<IndexPair> DSFMapIndexPair;
 }  // namespace gtsam
--- gtsam-4.1.0.orig/gtsam/base/Matrix.h
+++ gtsam-4.1.0/gtsam/base/Matrix.h
@@ -90,7 +90,7 @@ bool equal_with_abs_tol(const Eigen::Den
 
   for(size_t i=0; i<m1; i++)
     for(size_t j=0; j<n1; j++) {
-      if(!fpEqual(A(i,j), B(i,j), tol)) {
+      if(!fpEqual(A(i,j), B(i,j), tol, false)) {
         return false;
       }
     }
--- gtsam-4.1.0.orig/gtsam/base/OptionalJacobian.h
+++ gtsam-4.1.0/gtsam/base/OptionalJacobian.h
@@ -112,7 +112,7 @@ public:
   //  template <typename Derived, bool InnerPanel>
   //  OptionalJacobian(Eigen::Block<Derived,Rows,Cols,InnerPanel> block) : map_(nullptr) { ?? }
 
-  /// Return true is allocated, false if default constructor was used
+  /// Return true if allocated, false if default constructor was used
   operator bool() const {
     return map_.data() != nullptr;
   }
@@ -197,7 +197,7 @@ public:
 
 #endif
 
-  /// Return true is allocated, false if default constructor was used
+  /// Return true if allocated, false if default constructor was used
   operator bool() const {
     return pointer_!=nullptr;
   }
--- gtsam-4.1.0.orig/gtsam/base/TestableAssertions.h
+++ gtsam-4.1.0/gtsam/base/TestableAssertions.h
@@ -23,6 +23,7 @@
 #include <boost/optional.hpp>
 #include <map>
 #include <iostream>
+#include <sstream>
 #include <vector>
 
 namespace gtsam {
@@ -349,4 +350,44 @@ bool assert_inequal(const V& expected, c
   return false;
 }
 
+/**
+ * Capture std out via cout stream and compare against string.
+ */
+template<class V>
+bool assert_stdout_equal(const std::string& expected, const V& actual) {
+  // Redirect output to buffer so we can compare
+  std::stringstream buffer;
+  // Save the original output stream so we can reset later
+  std::streambuf* old = std::cout.rdbuf(buffer.rdbuf());
+
+  // We test against actual std::cout for faithful reproduction
+  std::cout << actual;
+
+  // Get output string and reset stdout
+  std::string actual_ = buffer.str();
+  std::cout.rdbuf(old);
+
+  return assert_equal(expected, actual_);
+}
+
+/**
+ * Capture print function output and compare against string.
+ */
+template<class V>
+bool assert_print_equal(const std::string& expected, const V& actual) {
+  // Redirect output to buffer so we can compare
+  std::stringstream buffer;
+  // Save the original output stream so we can reset later
+  std::streambuf* old = std::cout.rdbuf(buffer.rdbuf());
+
+  // We test against actual std::cout for faithful reproduction
+  actual.print();
+
+  // Get output string and reset stdout
+  std::string actual_ = buffer.str();
+  std::cout.rdbuf(old);
+
+  return assert_equal(expected, actual_);
+}
+
 } // \namespace gtsam
--- gtsam-4.1.0.orig/gtsam/base/Vector.cpp
+++ gtsam-4.1.0/gtsam/base/Vector.cpp
@@ -39,7 +39,7 @@ namespace gtsam {
  * 1. https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/
  * 2. https://floating-point-gui.de/errors/comparison/
  * ************************************************************************* */
-bool fpEqual(double a, double b, double tol) {
+bool fpEqual(double a, double b, double tol, bool check_relative_also) {
   using std::abs;
   using std::isnan;
   using std::isinf;
@@ -48,7 +48,7 @@ bool fpEqual(double a, double b, double
   double larger = (abs(b) > abs(a)) ? abs(b) : abs(a);
 
   // handle NaNs
-  if(std::isnan(a) || isnan(b)) {
+  if(isnan(a) || isnan(b)) {
     return isnan(a) && isnan(b);
   }
   // handle inf
@@ -60,13 +60,15 @@ bool fpEqual(double a, double b, double
   else if(a == 0 || b == 0 || (abs(a) + abs(b)) < DOUBLE_MIN_NORMAL) {
     return abs(a-b) <= tol * DOUBLE_MIN_NORMAL;
   }
-  // Check if the numbers are really close
-  // Needed when comparing numbers near zero or tol is in vicinity
-  else if(abs(a-b) <= tol) {
+  // Check if the numbers are really close.
+  // Needed when comparing numbers near zero or tol is in vicinity.
+  else if (abs(a - b) <= tol) {
     return true;
   }
-  // Use relative error
-  else if(abs(a-b) <= tol * min(larger, std::numeric_limits<double>::max())) {
+  // Check for relative error
+  else if (abs(a - b) <=
+               tol * min(larger, std::numeric_limits<double>::max()) &&
+           check_relative_also) {
     return true;
   }
 
--- gtsam-4.1.0.orig/gtsam/base/Vector.h
+++ gtsam-4.1.0/gtsam/base/Vector.h
@@ -85,9 +85,15 @@ static_assert(
  * respectively for the comparison to be true.
  * If one is NaN/Inf and the other is not, returns false.
  *
+ * @param check_relative_also is a flag which toggles additional checking for
+ * relative error. This means that if either the absolute error or the relative
+ * error is within the tolerance, the result will be true.
+ * By default, the flag is true.
+ *
  * Return true if two numbers are close wrt tol.
  */
-GTSAM_EXPORT bool fpEqual(double a, double b, double tol);
+GTSAM_EXPORT bool fpEqual(double a, double b, double tol,
+                          bool check_relative_also = true);
 
 /**
  * print without optional string, must specify cout yourself
--- gtsam-4.1.0.orig/gtsam/base/numericalDerivative.h
+++ gtsam-4.1.0/gtsam/base/numericalDerivative.h
@@ -109,7 +109,7 @@ typename Eigen::Matrix<double, N, 1> num
  * @param delta increment for numerical derivative
  * Class Y is the output argument
  * Class X is the input argument
- * int N is the dimension of the X input value if variable dimension type but known at test time
+ * @tparam int N is the dimension of the X input value if variable dimension type but known at test time
  * @return m*n Jacobian computed via central differencing
  */
 
@@ -167,15 +167,16 @@ typename internal::FixedSizeMatrix<Y,X>:
  * @param x2 second argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X1 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2>
+template<class Y, class X1, class X2, int N = traits<X1>::dimension>
 typename internal::FixedSizeMatrix<Y,X1>::type numericalDerivative21(const boost::function<Y(const X1&, const X2&)>& h,
     const X1& x1, const X2& x2, double delta = 1e-5) {
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<Y>::structure_category>::value),
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X1>(boost::bind(h, _1, boost::cref(x2)), x1, delta);
+  return numericalDerivative11<Y, X1, N>(boost::bind(h, _1, boost::cref(x2)), x1, delta);
 }
 
 /** use a raw C++ function pointer */
@@ -192,15 +193,16 @@ typename internal::FixedSizeMatrix<Y,X1>
  * @param x2 n-dimensional second argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X2 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2>
+template<class Y, class X1, class X2, int N = traits<X2>::dimension>
 typename internal::FixedSizeMatrix<Y,X2>::type numericalDerivative22(boost::function<Y(const X1&, const X2&)> h,
     const X1& x1, const X2& x2, double delta = 1e-5) {
 //  BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
 //       "Template argument X1 must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X2>::structure_category>::value),
        "Template argument X2 must be a manifold type.");
-  return numericalDerivative11<Y, X2>(boost::bind(h, boost::cref(x1), _1), x2, delta);
+  return numericalDerivative11<Y, X2, N>(boost::bind(h, boost::cref(x1), _1), x2, delta);
 }
 
 /** use a raw C++ function pointer */
@@ -219,8 +221,9 @@ typename internal::FixedSizeMatrix<Y,X2>
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
  * All classes Y,X1,X2,X3 need dim, expmap, logmap
+ * @tparam int N is the dimension of the X1 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3>
+template<class Y, class X1, class X2, class X3, int N = traits<X1>::dimension>
 typename internal::FixedSizeMatrix<Y,X1>::type numericalDerivative31(
     boost::function<Y(const X1&, const X2&, const X3&)> h, const X1& x1,
     const X2& x2, const X3& x3, double delta = 1e-5) {
@@ -228,7 +231,7 @@ typename internal::FixedSizeMatrix<Y,X1>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X1>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3)), x1, delta);
+  return numericalDerivative11<Y, X1, N>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3)), x1, delta);
 }
 
 template<class Y, class X1, class X2, class X3>
@@ -247,8 +250,9 @@ typename internal::FixedSizeMatrix<Y,X1>
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
  * All classes Y,X1,X2,X3 need dim, expmap, logmap
+ * @tparam int N is the dimension of the X2 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3>
+template<class Y, class X1, class X2, class X3, int N = traits<X2>::dimension>
 typename internal::FixedSizeMatrix<Y,X2>::type numericalDerivative32(
     boost::function<Y(const X1&, const X2&, const X3&)> h, const X1& x1,
     const X2& x2, const X3& x3, double delta = 1e-5) {
@@ -256,7 +260,7 @@ typename internal::FixedSizeMatrix<Y,X2>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X2>::structure_category>::value),
       "Template argument X2 must be a manifold type.");
-  return numericalDerivative11<Y, X2>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3)), x2, delta);
+  return numericalDerivative11<Y, X2, N>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3)), x2, delta);
 }
 
 template<class Y, class X1, class X2, class X3>
@@ -275,8 +279,9 @@ inline typename internal::FixedSizeMatri
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
  * All classes Y,X1,X2,X3 need dim, expmap, logmap
+ * @tparam int N is the dimension of the X3 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3>
+template<class Y, class X1, class X2, class X3, int N = traits<X3>::dimension>
 typename internal::FixedSizeMatrix<Y,X3>::type numericalDerivative33(
     boost::function<Y(const X1&, const X2&, const X3&)> h, const X1& x1,
     const X2& x2, const X3& x3, double delta = 1e-5) {
@@ -284,7 +289,7 @@ typename internal::FixedSizeMatrix<Y,X3>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X3>::structure_category>::value),
       "Template argument X3 must be a manifold type.");
-  return numericalDerivative11<Y, X3>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1), x3, delta);
+  return numericalDerivative11<Y, X3, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1), x3, delta);
 }
 
 template<class Y, class X1, class X2, class X3>
@@ -303,8 +308,9 @@ inline typename internal::FixedSizeMatri
  * @param x4 fourth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X1 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4>
+template<class Y, class X1, class X2, class X3, class X4, int N = traits<X1>::dimension>
 typename internal::FixedSizeMatrix<Y,X1>::type numericalDerivative41(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, double delta = 1e-5) {
@@ -312,7 +318,7 @@ typename internal::FixedSizeMatrix<Y,X1>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X1>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3), boost::cref(x4)), x1, delta);
+  return numericalDerivative11<Y, X1, N>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3), boost::cref(x4)), x1, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4>
@@ -330,8 +336,9 @@ inline typename internal::FixedSizeMatri
  * @param x4 fourth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X2 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4>
+template<class Y, class X1, class X2, class X3, class X4, int N = traits<X2>::dimension>
 typename internal::FixedSizeMatrix<Y,X2>::type numericalDerivative42(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, double delta = 1e-5) {
@@ -339,7 +346,7 @@ typename internal::FixedSizeMatrix<Y,X2>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X2>::structure_category>::value),
       "Template argument X2 must be a manifold type.");
-  return numericalDerivative11<Y, X2>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3), boost::cref(x4)), x2, delta);
+  return numericalDerivative11<Y, X2, N>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3), boost::cref(x4)), x2, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4>
@@ -357,8 +364,9 @@ inline typename internal::FixedSizeMatri
  * @param x4 fourth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X3 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4>
+template<class Y, class X1, class X2, class X3, class X4, int N = traits<X3>::dimension>
 typename internal::FixedSizeMatrix<Y,X3>::type numericalDerivative43(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, double delta = 1e-5) {
@@ -366,7 +374,7 @@ typename internal::FixedSizeMatrix<Y,X3>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X3>::structure_category>::value),
       "Template argument X3 must be a manifold type.");
-  return numericalDerivative11<Y, X3>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1, boost::cref(x4)), x3, delta);
+  return numericalDerivative11<Y, X3, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1, boost::cref(x4)), x3, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4>
@@ -384,8 +392,9 @@ inline typename internal::FixedSizeMatri
  * @param x4 n-dimensional fourth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X4 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4>
+template<class Y, class X1, class X2, class X3, class X4, int N = traits<X4>::dimension>
 typename internal::FixedSizeMatrix<Y,X4>::type numericalDerivative44(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, double delta = 1e-5) {
@@ -393,7 +402,7 @@ typename internal::FixedSizeMatrix<Y,X4>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X4>::structure_category>::value),
       "Template argument X4 must be a manifold type.");
-  return numericalDerivative11<Y, X4>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), _1), x4, delta);
+  return numericalDerivative11<Y, X4, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), _1), x4, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4>
@@ -412,8 +421,9 @@ inline typename internal::FixedSizeMatri
  * @param x5 fifth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X1 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5>
+template<class Y, class X1, class X2, class X3, class X4, class X5, int N = traits<X1>::dimension>
 typename internal::FixedSizeMatrix<Y,X1>::type numericalDerivative51(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, double delta = 1e-5) {
@@ -421,7 +431,7 @@ typename internal::FixedSizeMatrix<Y,X1>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X1>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3), boost::cref(x4), boost::cref(x5)), x1, delta);
+  return numericalDerivative11<Y, X1, N>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3), boost::cref(x4), boost::cref(x5)), x1, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5>
@@ -440,8 +450,9 @@ inline typename internal::FixedSizeMatri
  * @param x5 fifth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X2 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5>
+template<class Y, class X1, class X2, class X3, class X4, class X5, int N = traits<X2>::dimension>
 typename internal::FixedSizeMatrix<Y,X2>::type numericalDerivative52(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, double delta = 1e-5) {
@@ -449,7 +460,7 @@ typename internal::FixedSizeMatrix<Y,X2>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X2>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3), boost::cref(x4), boost::cref(x5)), x2, delta);
+  return numericalDerivative11<Y, X2, N>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3), boost::cref(x4), boost::cref(x5)), x2, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5>
@@ -468,8 +479,9 @@ inline typename internal::FixedSizeMatri
  * @param x5 fifth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X3 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5>
+template<class Y, class X1, class X2, class X3, class X4, class X5, int N = traits<X3>::dimension>
 typename internal::FixedSizeMatrix<Y,X3>::type numericalDerivative53(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, double delta = 1e-5) {
@@ -477,7 +489,7 @@ typename internal::FixedSizeMatrix<Y,X3>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X3>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1, boost::cref(x4), boost::cref(x5)), x3, delta);
+  return numericalDerivative11<Y, X3, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1, boost::cref(x4), boost::cref(x5)), x3, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5>
@@ -496,8 +508,9 @@ inline typename internal::FixedSizeMatri
  * @param x5 fifth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X4 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5>
+template<class Y, class X1, class X2, class X3, class X4, class X5, int N = traits<X4>::dimension>
 typename internal::FixedSizeMatrix<Y,X4>::type numericalDerivative54(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, double delta = 1e-5) {
@@ -505,7 +518,7 @@ typename internal::FixedSizeMatrix<Y,X4>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X4>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), _1, boost::cref(x5)), x4, delta);
+  return numericalDerivative11<Y, X4, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), _1, boost::cref(x5)), x4, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5>
@@ -524,8 +537,9 @@ inline typename internal::FixedSizeMatri
  * @param x5 fifth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X5 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5>
+template<class Y, class X1, class X2, class X3, class X4, class X5, int N = traits<X5>::dimension>
 typename internal::FixedSizeMatrix<Y,X5>::type numericalDerivative55(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, double delta = 1e-5) {
@@ -533,7 +547,7 @@ typename internal::FixedSizeMatrix<Y,X5>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X5>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), boost::cref(x4), _1), x5, delta);
+  return numericalDerivative11<Y, X5, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), boost::cref(x4), _1), x5, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5>
@@ -553,8 +567,9 @@ inline typename internal::FixedSizeMatri
  * @param x6 sixth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X1 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
+template<class Y, class X1, class X2, class X3, class X4, class X5, class X6, int N = traits<X1>::dimension>
 typename internal::FixedSizeMatrix<Y,X1>::type numericalDerivative61(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6, double delta = 1e-5) {
@@ -562,7 +577,7 @@ typename internal::FixedSizeMatrix<Y,X1>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X1>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3), boost::cref(x4), boost::cref(x5), boost::cref(x6)), x1, delta);
+  return numericalDerivative11<Y, X1, N>(boost::bind(h, _1, boost::cref(x2), boost::cref(x3), boost::cref(x4), boost::cref(x5), boost::cref(x6)), x1, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
@@ -582,8 +597,9 @@ inline typename internal::FixedSizeMatri
  * @param x6 sixth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X2 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
+template<class Y, class X1, class X2, class X3, class X4, class X5, class X6, int N = traits<X2>::dimension>
 typename internal::FixedSizeMatrix<Y,X2>::type numericalDerivative62(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6, double delta = 1e-5) {
@@ -591,7 +607,7 @@ typename internal::FixedSizeMatrix<Y,X2>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X2>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3), boost::cref(x4), boost::cref(x5), boost::cref(x6)), x2, delta);
+  return numericalDerivative11<Y, X2, N>(boost::bind(h, boost::cref(x1), _1, boost::cref(x3), boost::cref(x4), boost::cref(x5), boost::cref(x6)), x2, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
@@ -608,11 +624,12 @@ inline typename internal::FixedSizeMatri
  * @param x3 third argument value
  * @param x4 fourth argument value
  * @param x5 fifth argument value
- *  @param x6 sixth argument value
+ * @param x6 sixth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X3 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
+template<class Y, class X1, class X2, class X3, class X4, class X5, class X6, int N = traits<X3>::dimension>
 typename internal::FixedSizeMatrix<Y,X3>::type numericalDerivative63(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6, double delta = 1e-5) {
@@ -620,7 +637,7 @@ typename internal::FixedSizeMatrix<Y,X3>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X3>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1, boost::cref(x4), boost::cref(x5), boost::cref(x6)), x3, delta);
+  return numericalDerivative11<Y, X3, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), _1, boost::cref(x4), boost::cref(x5), boost::cref(x6)), x3, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
@@ -640,8 +657,9 @@ inline typename internal::FixedSizeMatri
  * @param x6 sixth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X4 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
+template<class Y, class X1, class X2, class X3, class X4, class X5, class X6, int N = traits<X4>::dimension>
 typename internal::FixedSizeMatrix<Y,X4>::type numericalDerivative64(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6, double delta = 1e-5) {
@@ -649,7 +667,7 @@ typename internal::FixedSizeMatrix<Y,X4>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X4>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), _1, boost::cref(x5), boost::cref(x6)), x4, delta);
+  return numericalDerivative11<Y, X4, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), _1, boost::cref(x5), boost::cref(x6)), x4, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
@@ -669,8 +687,9 @@ inline typename internal::FixedSizeMatri
  * @param x6 sixth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X5 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
+template<class Y, class X1, class X2, class X3, class X4, class X5, class X6, int N = traits<X5>::dimension>
 typename internal::FixedSizeMatrix<Y,X5>::type numericalDerivative65(
     boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h, const X1& x1,
     const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6, double delta = 1e-5) {
@@ -678,7 +697,7 @@ typename internal::FixedSizeMatrix<Y,X5>
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X5>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), boost::cref(x4), _1, boost::cref(x6)), x5, delta);
+  return numericalDerivative11<Y, X5, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), boost::cref(x4), _1, boost::cref(x6)), x5, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
@@ -698,16 +717,18 @@ inline typename internal::FixedSizeMatri
  * @param x6 sixth argument value
  * @param delta increment for numerical derivative
  * @return m*n Jacobian computed via central differencing
+ * @tparam int N is the dimension of the X6 input value if variable dimension type but known at test time
  */
-template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
-typename internal::FixedSizeMatrix<Y,X5>::type numericalDerivative66(
-    boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h, const X1& x1,
-    const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6, double delta = 1e-5) {
+template<class Y, class X1, class X2, class X3, class X4, class X5, class X6, int N = traits<X6>::dimension>
+typename internal::FixedSizeMatrix<Y, X6>::type numericalDerivative66(
+    boost::function<Y(const X1&, const X2&, const X3&, const X4&, const X5&, const X6&)> h,
+    const X1& x1, const X2& x2, const X3& x3, const X4& x4, const X5& x5, const X6& x6,
+    double delta = 1e-5) {
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<Y>::structure_category>::value),
       "Template argument Y must be a manifold type.");
   BOOST_STATIC_ASSERT_MSG( (boost::is_base_of<gtsam::manifold_tag, typename traits<X1>::structure_category>::value),
       "Template argument X1 must be a manifold type.");
-  return numericalDerivative11<Y, X6>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), boost::cref(x4), boost::cref(x5), _1), x6, delta);
+  return numericalDerivative11<Y, X6, N>(boost::bind(h, boost::cref(x1), boost::cref(x2), boost::cref(x3), boost::cref(x4), boost::cref(x5), _1), x6, delta);
 }
 
 template<class Y, class X1, class X2, class X3, class X4, class X5, class X6>
--- gtsam-4.1.0.orig/gtsam/base/tests/testMatrix.cpp
+++ gtsam-4.1.0/gtsam/base/tests/testMatrix.cpp
@@ -1163,6 +1163,19 @@ TEST(Matrix , IsVectorSpace) {
   BOOST_CONCEPT_ASSERT((IsVectorSpace<Vector5>));
 }
 
+TEST(Matrix, AbsoluteError) {
+  double a = 2000, b = 1997, tol = 1e-1;
+  bool isEqual;
+
+  // Test only absolute error
+  isEqual = fpEqual(a, b, tol, false);
+  EXPECT(!isEqual);
+
+  // Test relative error as well
+  isEqual = fpEqual(a, b, tol);
+  EXPECT(isEqual);
+}
+
 /* ************************************************************************* */
 int main() {
   TestResult tr;
--- gtsam-4.1.0.orig/gtsam/base/tests/testNumericalDerivative.cpp
+++ gtsam-4.1.0/gtsam/base/tests/testNumericalDerivative.cpp
@@ -143,6 +143,13 @@ Vector6 f6(const double x1, const double
   return result;
 }
 
+Vector g6(const double x1, const double x2, const double x3, const double x4,
+          const double x5, const double x6) {
+  Vector result(6);
+  result << sin(x1), cos(x2), x3 * x3, x4 * x4 * x4, sqrt(x5), sin(x6) - cos(x6);
+  return result;
+}
+
 /* ************************************************************************* */
 //
 TEST(testNumericalDerivative, numeriDerivative61) {
@@ -153,6 +160,14 @@ TEST(testNumericalDerivative, numeriDeri
       double, double, double, double>(f6, x1, x2, x3, x4, x5, x6);
   
   EXPECT(assert_equal(expected61, actual61, 1e-5));
+
+  Matrix expected61Dynamic = Matrix::Zero(6, 1);
+  expected61Dynamic(0, 0) = cos(x1);
+  Matrix actual61Dynamic =
+      numericalDerivative61<Vector, double, double, double, double, double,
+                            double, 1>(g6, x1, x2, x3, x4, x5, x6);
+
+  EXPECT(assert_equal(expected61Dynamic, actual61Dynamic, 1e-5));
 }
 
 /* ************************************************************************* */
@@ -165,6 +180,13 @@ TEST(testNumericalDerivative, numeriDeri
      double, double, double>(f6, x1, x2, x3, x4, x5, x6);
   
   EXPECT(assert_equal(expected62, actual62, 1e-5));
+
+  Matrix expected62Dynamic = Matrix::Zero(6, 1);
+  expected62Dynamic(1, 0) = -sin(x2);
+  Matrix61 actual62Dynamic = numericalDerivative62<Vector, double, double,
+      double, double, double, double, 1>(f6, x1, x2, x3, x4, x5, x6);
+
+  EXPECT(assert_equal(expected62Dynamic, actual62Dynamic, 1e-5));
 }
 
 /* ************************************************************************* */
@@ -177,6 +199,14 @@ TEST(testNumericalDerivative, numeriDeri
      double, double, double>(f6, x1, x2, x3, x4, x5, x6);
   
   EXPECT(assert_equal(expected63, actual63, 1e-5));
+
+  Matrix expected63Dynamic = Matrix::Zero(6, 1);
+  expected63Dynamic(2, 0) = 2 * x3;
+  Matrix61 actual63Dynamic =
+      numericalDerivative63<Vector, double, double, double, double, double,
+                            double, 1>(f6, x1, x2, x3, x4, x5, x6);
+
+  EXPECT(assert_equal(expected63Dynamic, actual63Dynamic, 1e-5));
 }
 
 /* ************************************************************************* */
@@ -189,6 +219,14 @@ TEST(testNumericalDerivative, numeriDeri
      double, double, double>(f6, x1, x2, x3, x4, x5, x6);
   
   EXPECT(assert_equal(expected64, actual64, 1e-5));
+
+  Matrix expected64Dynamic = Matrix::Zero(6, 1);
+  expected64Dynamic(3, 0) = 3 * x4 * x4;
+  Matrix61 actual64Dynamic =
+      numericalDerivative64<Vector, double, double, double, double, double,
+                            double, 1>(f6, x1, x2, x3, x4, x5, x6);
+
+  EXPECT(assert_equal(expected64Dynamic, actual64Dynamic, 1e-5));
 }
 
 /* ************************************************************************* */
@@ -201,6 +239,14 @@ TEST(testNumericalDerivative, numeriDeri
      double, double, double>(f6, x1, x2, x3, x4, x5, x6);
   
   EXPECT(assert_equal(expected65, actual65, 1e-5));
+
+  Matrix expected65Dynamic = Matrix::Zero(6, 1);
+  expected65Dynamic(4, 0) = 0.5 / sqrt(x5);
+  Matrix61 actual65Dynamic =
+      numericalDerivative65<Vector, double, double, double, double, double,
+                            double, 1>(f6, x1, x2, x3, x4, x5, x6);
+
+  EXPECT(assert_equal(expected65Dynamic, actual65Dynamic, 1e-5));
 }
 
 /* ************************************************************************* */
@@ -213,6 +259,14 @@ TEST(testNumericalDerivative, numeriDeri
       double, double, double>(f6, x1, x2, x3, x4, x5, x6);
   
   EXPECT(assert_equal(expected66, actual66, 1e-5));
+
+  Matrix expected66Dynamic = Matrix::Zero(6, 1);
+  expected66Dynamic(5, 0) = cos(x6) + sin(x6);
+  Matrix61 actual66Dynamic =
+      numericalDerivative66<Vector, double, double, double, double, double,
+                            double, 1>(f6, x1, x2, x3, x4, x5, x6);
+
+  EXPECT(assert_equal(expected66Dynamic, actual66Dynamic, 1e-5));
 }
 
 /* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/geometry/Cal3Bundler.cpp
+++ gtsam-4.1.0/gtsam/geometry/Cal3Bundler.cpp
@@ -25,13 +25,13 @@ namespace gtsam {
 
 /* ************************************************************************* */
 Cal3Bundler::Cal3Bundler() :
-    f_(1), k1_(0), k2_(0), u0_(0), v0_(0) {
+    f_(1), k1_(0), k2_(0), u0_(0), v0_(0), tol_(1e-5) {
 }
 
 /* ************************************************************************* */
-Cal3Bundler::Cal3Bundler(double f, double k1, double k2, double u0, double v0) :
-    f_(f), k1_(k1), k2_(k2), u0_(u0), v0_(v0) {
-}
+Cal3Bundler::Cal3Bundler(double f, double k1, double k2, double u0, double v0,
+                         double tol)
+    : f_(f), k1_(k1), k2_(k2), u0_(u0), v0_(v0), tol_(tol) {}
 
 /* ************************************************************************* */
 Matrix3 Cal3Bundler::K() const {
@@ -94,21 +94,24 @@ Point2 Cal3Bundler::uncalibrate(const Po
 }
 
 /* ************************************************************************* */
-Point2 Cal3Bundler::calibrate(const Point2& pi, const double tol) const {
+Point2 Cal3Bundler::calibrate(const Point2& pi,
+                              OptionalJacobian<2, 3> Dcal,
+                              OptionalJacobian<2, 2> Dp) const {
   // Copied from Cal3DS2 :-(
   // but specialized with k1,k2 non-zero only and fx=fy and s=0
-  const Point2 invKPi((pi.x() - u0_)/f_, (pi.y() - v0_)/f_);
+  double x = (pi.x() - u0_)/f_, y = (pi.y() - v0_)/f_;
+  const Point2 invKPi(x, y);
 
   // initialize by ignoring the distortion at all, might be problematic for pixels around boundary
-  Point2 pn = invKPi;
+  Point2 pn(x, y);
 
   // iterate until the uncalibrate is close to the actual pixel coordinate
   const int maxIterations = 10;
   int iteration;
   for (iteration = 0; iteration < maxIterations; ++iteration) {
-    if (distance2(uncalibrate(pn), pi) <= tol)
+    if (distance2(uncalibrate(pn), pi) <= tol_)
       break;
-    const double x = pn.x(), y = pn.y(), xx = x * x, yy = y * y;
+    const double px = pn.x(), py = pn.y(), xx = px * px, yy = py * py;
     const double rr = xx + yy;
     const double g = (1 + k1_ * rr + k2_ * rr * rr);
     pn = invKPi / g;
@@ -118,6 +121,25 @@ Point2 Cal3Bundler::calibrate(const Poin
     throw std::runtime_error(
         "Cal3Bundler::calibrate fails to converge. need a better initialization");
 
+  // We make use of the Implicit Function Theorem to compute the Jacobians from uncalibrate
+  // Given f(pi, pn) = uncalibrate(pn) - pi, and g(pi) = calibrate, we can easily compute the Jacobians
+  // df/pi = -I (pn and pi are independent args)
+  // Dcal = -inv(H_uncal_pn) * df/pi = -inv(H_uncal_pn) * (-I) = inv(H_uncal_pn)
+  // Dp = -inv(H_uncal_pn) * df/K = -inv(H_uncal_pn) * H_uncal_K
+  Matrix23 H_uncal_K;
+  Matrix22 H_uncal_pn, H_uncal_pn_inv;
+
+  if (Dcal || Dp) {
+    // Compute uncalibrate Jacobians
+    uncalibrate(pn, Dcal ? &H_uncal_K : nullptr, H_uncal_pn);
+
+    H_uncal_pn_inv = H_uncal_pn.inverse();
+
+    if (Dp) *Dp = H_uncal_pn_inv;
+    if (Dcal) *Dcal = -H_uncal_pn_inv * H_uncal_K;
+
+  }
+
   return pn;
 }
 
--- gtsam-4.1.0.orig/gtsam/geometry/Cal3Bundler.h
+++ gtsam-4.1.0/gtsam/geometry/Cal3Bundler.h
@@ -33,6 +33,7 @@ private:
   double f_; ///< focal length
   double k1_, k2_; ///< radial distortion
   double u0_, v0_; ///< image center, not a parameter to be optimized but a constant
+  double tol_; ///< tolerance value when calibrating
 
 public:
 
@@ -51,8 +52,10 @@ public:
    *  @param k2 second radial distortion coefficient (quartic)
    *  @param u0 optional image center (default 0), considered a constant
    *  @param v0 optional image center (default 0), considered a constant
+   *  @param tol optional calibration tolerance value
    */
-  Cal3Bundler(double f, double k1, double k2, double u0 = 0, double v0 = 0);
+  Cal3Bundler(double f, double k1, double k2, double u0 = 0, double v0 = 0,
+              double tol = 1e-5);
 
   virtual ~Cal3Bundler() {}
 
@@ -95,6 +98,17 @@ public:
     return k2_;
   }
 
+  /// image center in x
+  inline double px() const {
+    return u0_;
+  }
+
+  /// image center in y
+  inline double py() const {
+    return v0_;
+  }
+
+#ifdef GTSAM_ALLOW_DEPRECATED_SINCE_V41
   /// get parameter u0
   inline double u0() const {
     return u0_;
@@ -104,6 +118,7 @@ public:
   inline double v0() const {
     return v0_;
   }
+#endif
 
 
   /**
@@ -117,8 +132,17 @@ public:
   Point2 uncalibrate(const Point2& p, OptionalJacobian<2, 3> Dcal = boost::none,
       OptionalJacobian<2, 2> Dp = boost::none) const;
 
-  /// Convert a pixel coordinate to ideal coordinate
-  Point2 calibrate(const Point2& pi, const double tol = 1e-5) const;
+  /**
+   * Convert a pixel coordinate to ideal coordinate xy
+   * @param p point in image coordinates
+   * @param tol optional tolerance threshold value for iterative minimization
+   * @param Dcal optional 2*3 Jacobian wrpt Cal3Bundler parameters
+   * @param Dp optional 2*2 Jacobian wrpt intrinsic coordinates
+   * @return point in intrinsic coordinates
+   */
+  Point2 calibrate(const Point2& pi,
+                   OptionalJacobian<2, 3> Dcal = boost::none,
+                   OptionalJacobian<2, 2> Dp = boost::none) const;
 
   /// @deprecated might be removed in next release, use uncalibrate
   Matrix2 D2d_intrinsic(const Point2& p) const;
@@ -164,6 +188,7 @@ private:
     ar & BOOST_SERIALIZATION_NVP(k2_);
     ar & BOOST_SERIALIZATION_NVP(u0_);
     ar & BOOST_SERIALIZATION_NVP(v0_);
+    ar & BOOST_SERIALIZATION_NVP(tol_);
   }
 
   /// @}
--- gtsam-4.1.0.orig/gtsam/geometry/Point3.cpp
+++ gtsam-4.1.0/gtsam/geometry/Point3.cpp
@@ -75,6 +75,18 @@ double dot(const Point3 &p, const Point3
   return p.x() * q.x() + p.y() * q.y() + p.z() * q.z();
 }
 
+Point3Pair means(const std::vector<Point3Pair> &abPointPairs) {
+  const size_t n = abPointPairs.size();
+  if (n == 0) throw std::invalid_argument("Point3::mean input Point3Pair vector is empty");
+  Point3 aSum(0, 0, 0), bSum(0, 0, 0);
+  for (const Point3Pair &abPair : abPointPairs) {
+    aSum += abPair.first;
+    bSum += abPair.second;
+  }
+  const double f = 1.0 / n;
+  return {aSum * f, bSum * f};
+}
+
 /* ************************************************************************* */
 ostream &operator<<(ostream &os, const gtsam::Point3Pair &p) {
   os << p.first << " <-> " << p.second;
--- gtsam-4.1.0.orig/gtsam/geometry/Point3.h
+++ gtsam-4.1.0/gtsam/geometry/Point3.h
@@ -26,6 +26,7 @@
 #include <gtsam/base/Vector.h>
 #include <gtsam/dllexport.h>
 #include <boost/serialization/nvp.hpp>
+#include <numeric>
 
 namespace gtsam {
 
@@ -58,6 +59,18 @@ GTSAM_EXPORT double dot(const Point3& p,
                         OptionalJacobian<1, 3> H_p = boost::none,
                         OptionalJacobian<1, 3> H_q = boost::none);
 
+/// mean
+template <class CONTAINER>
+GTSAM_EXPORT Point3 mean(const CONTAINER& points) {
+  if (points.size() == 0) throw std::invalid_argument("Point3::mean input container is empty");
+  Point3 sum(0, 0, 0);
+  sum = std::accumulate(points.begin(), points.end(), sum);
+  return sum / points.size();
+}
+
+/// Calculate the two means of a set of Point3 pairs
+GTSAM_EXPORT Point3Pair means(const std::vector<Point3Pair> &abPointPairs);
+
 template <typename A1, typename A2>
 struct Range;
 
--- gtsam-4.1.0.orig/gtsam/geometry/Pose3.cpp
+++ gtsam-4.1.0/gtsam/geometry/Pose3.cpp
@@ -24,10 +24,11 @@
 #include <limits>
 #include <string>
 
-using namespace std;
-
 namespace gtsam {
 
+using std::vector;
+using Point3Pairs = vector<Point3Pair>;
+
 /** instantiate concept checks */
 GTSAM_CONCEPT_POSE_INST(Pose3);
 
@@ -190,15 +191,7 @@ Vector6 Pose3::ChartAtOrigin::Local(cons
 }
 
 /* ************************************************************************* */
-/**
- * Compute the 3x3 bottom-left block Q of the SE3 Expmap derivative matrix
- *  J(xi) = [J_(w) Z_3x3;
- *             Q   J_(w)]
- *  where J_(w) is the SO3 Expmap derivative.
- *  (see Chirikjian11book2, pg 44, eq 10.95.
- *  The closed-form formula is similar to formula 102 in Barfoot14tro)
- */
-static Matrix3 computeQforExpmapDerivative(const Vector6& xi) {
+Matrix3 Pose3::ComputeQforExpmapDerivative(const Vector6& xi, double nearZeroThreshold) {
   const auto w = xi.head<3>();
   const auto v = xi.tail<3>();
   const Matrix3 V = skewSymmetric(v);
@@ -220,18 +213,20 @@ static Matrix3 computeQforExpmapDerivati
 #else
   // The closed-form formula in Barfoot14tro eq. (102)
   double phi = w.norm();
-  if (std::abs(phi)>1e-5) {
-    const double sinPhi = sin(phi), cosPhi = cos(phi);
-    const double phi2 = phi * phi, phi3 = phi2 * phi, phi4 = phi3 * phi, phi5 = phi4 * phi;
+  const Matrix3 WVW = W * V * W;
+  if (std::abs(phi) > nearZeroThreshold) {
+    const double s = sin(phi), c = cos(phi);
+    const double phi2 = phi * phi, phi3 = phi2 * phi, phi4 = phi3 * phi,
+                 phi5 = phi4 * phi;
     // Invert the sign of odd-order terms to have the right Jacobian
-    Q = -0.5*V + (phi-sinPhi)/phi3*(W*V + V*W - W*V*W)
-            + (1-phi2/2-cosPhi)/phi4*(W*W*V + V*W*W - 3*W*V*W)
-            - 0.5*((1-phi2/2-cosPhi)/phi4 - 3*(phi-sinPhi-phi3/6.)/phi5)*(W*V*W*W + W*W*V*W);
-  }
-  else {
-    Q = -0.5*V + 1./6.*(W*V + V*W - W*V*W)
-        + 1./24.*(W*W*V + V*W*W - 3*W*V*W)
-        - 0.5*(1./24. + 3./120.)*(W*V*W*W + W*W*V*W);
+    Q = -0.5 * V + (phi - s) / phi3 * (W * V + V * W - WVW) +
+        (1 - phi2 / 2 - c) / phi4 * (W * W * V + V * W * W - 3 * WVW) -
+        0.5 * ((1 - phi2 / 2 - c) / phi4 - 3 * (phi - s - phi3 / 6.) / phi5) *
+            (WVW * W + W * WVW);
+  } else {
+    Q = -0.5 * V + 1. / 6. * (W * V + V * W - WVW) -
+        1. / 24. * (W * W * V + V * W * W - 3 * WVW) +
+        1. / 120. * (WVW * W + W * WVW);
   }
 #endif
 
@@ -242,7 +237,7 @@ static Matrix3 computeQforExpmapDerivati
 Matrix6 Pose3::ExpmapDerivative(const Vector6& xi) {
   const Vector3 w = xi.head<3>();
   const Matrix3 Jw = Rot3::ExpmapDerivative(w);
-  const Matrix3 Q = computeQforExpmapDerivative(xi);
+  const Matrix3 Q = ComputeQforExpmapDerivative(xi);
   Matrix6 J;
   J << Jw, Z_3x3, Q, Jw;
   return J;
@@ -253,7 +248,7 @@ Matrix6 Pose3::LogmapDerivative(const Po
   const Vector6 xi = Logmap(pose);
   const Vector3 w = xi.head<3>();
   const Matrix3 Jw = Rot3::LogmapDerivative(w);
-  const Matrix3 Q = computeQforExpmapDerivative(xi);
+  const Matrix3 Q = ComputeQforExpmapDerivative(xi);
   const Matrix3 Q2 = -Jw*Q*Jw;
   Matrix6 J;
   J << Jw, Z_3x3, Q2, Jw;
@@ -389,39 +384,33 @@ Unit3 Pose3::bearing(const Pose3& pose,
 }
 
 /* ************************************************************************* */
-boost::optional<Pose3> Pose3::Align(const std::vector<Point3Pair>& abPointPairs) {
+boost::optional<Pose3> Pose3::Align(const Point3Pairs &abPointPairs) {
   const size_t n = abPointPairs.size();
-  if (n < 3)
-    return boost::none;  // we need at least three pairs
+  if (n < 3) {
+    return boost::none; // we need at least three pairs
+  }
 
   // calculate centroids
-  Point3 aCentroid(0,0,0), bCentroid(0,0,0);
-  for(const Point3Pair& abPair: abPointPairs) {
-    aCentroid += abPair.first;
-    bCentroid += abPair.second;
-  }
-  double f = 1.0 / n;
-  aCentroid *= f;
-  bCentroid *= f;
+  const auto centroids = means(abPointPairs);
 
   // Add to form H matrix
   Matrix3 H = Z_3x3;
-  for(const Point3Pair& abPair: abPointPairs) {
-    Point3 da = abPair.first - aCentroid;
-    Point3 db = abPair.second - bCentroid;
+  for (const Point3Pair &abPair : abPointPairs) {
+    const Point3 da = abPair.first - centroids.first;
+    const Point3 db = abPair.second - centroids.second;
     H += da * db.transpose();
-    }
+  }
 
   // ClosestTo finds rotation matrix closest to H in Frobenius sense
-  Rot3 aRb = Rot3::ClosestTo(H);
-  Point3 aTb = Point3(aCentroid) - aRb * Point3(bCentroid);
+  const Rot3 aRb = Rot3::ClosestTo(H);
+  const Point3 aTb = centroids.first - aRb * centroids.second;
   return Pose3(aRb, aTb);
 }
 
-boost::optional<Pose3> align(const vector<Point3Pair>& baPointPairs) {
-  vector<Point3Pair> abPointPairs;
-  for (const Point3Pair& baPair: baPointPairs) {
-    abPointPairs.push_back(make_pair(baPair.second, baPair.first));
+boost::optional<Pose3> align(const Point3Pairs &baPointPairs) {
+  Point3Pairs abPointPairs;
+  for (const Point3Pair &baPair : baPointPairs) {
+    abPointPairs.emplace_back(baPair.second, baPair.first);
   }
   return Pose3::Align(abPointPairs);
 }
--- gtsam-4.1.0.orig/gtsam/geometry/Pose3.h
+++ gtsam-4.1.0/gtsam/geometry/Pose3.h
@@ -181,6 +181,18 @@ public:
     static Vector6 Local(const Pose3& pose, ChartJacobian Hpose = boost::none);
   };
 
+  /**
+  * Compute the 3x3 bottom-left block Q of SE3 Expmap right derivative matrix
+  *  J_r(xi) = [J_(w) Z_3x3;
+  *             Q_r   J_(w)]
+  *  where J_(w) is the SO3 Expmap right derivative.
+  *  (see Chirikjian11book2, pg 44, eq 10.95.
+  *  The closed-form formula is identical to formula 102 in Barfoot14tro where
+  *  Q_l of the SE3 Expmap left derivative matrix is given.
+  */
+  static Matrix3 ComputeQforExpmapDerivative(
+      const Vector6& xi, double nearZeroThreshold = 1e-5);
+
   using LieGroup<Pose3, 6>::inverse; // version with derivative
 
   /**
@@ -356,6 +368,9 @@ inline Matrix wedge<Pose3>(const Vector&
   return Pose3::wedge(xi(0), xi(1), xi(2), xi(3), xi(4), xi(5));
 }
 
+// Convenience typedef
+using Pose3Pair = std::pair<Pose3, Pose3>;
+
 // For MATLAB wrapper
 typedef std::vector<Pose3> Pose3Vector;
 
--- gtsam-4.1.0.orig/gtsam/geometry/Rot3.cpp
+++ gtsam-4.1.0/gtsam/geometry/Rot3.cpp
@@ -158,21 +158,73 @@ Point3 Rot3::column(int index) const{
 }
 
 /* ************************************************************************* */
-Vector3 Rot3::xyz() const {
+Vector3 Rot3::xyz(OptionalJacobian<3, 3> H) const {
   Matrix3 I;Vector3 q;
-  boost::tie(I,q)=RQ(matrix());
+  if (H) {
+    Matrix93 mH;
+    const auto m = matrix();
+#ifdef GTSAM_USE_QUATERNIONS
+    SO3{m}.vec(mH);
+#else
+    rot_.vec(mH);
+#endif
+
+    Matrix39 qHm;
+    boost::tie(I, q) = RQ(m, qHm);
+
+    // TODO : Explore whether this expression can be optimized as both
+    // qHm and mH are super-sparse
+    *H = qHm * mH;
+  } else
+    boost::tie(I, q) = RQ(matrix());
   return q;
 }
 
 /* ************************************************************************* */
-Vector3 Rot3::ypr() const {
-  Vector3 q = xyz();
+Vector3 Rot3::ypr(OptionalJacobian<3, 3> H) const {
+  Vector3 q = xyz(H);
+  if (H) H->row(0).swap(H->row(2));
+
   return Vector3(q(2),q(1),q(0));
 }
 
 /* ************************************************************************* */
-Vector3 Rot3::rpy() const {
-  return xyz();
+Vector3 Rot3::rpy(OptionalJacobian<3, 3> H) const { return xyz(H); }
+
+/* ************************************************************************* */
+double Rot3::roll(OptionalJacobian<1, 3> H) const {
+  double r;
+  if (H) {
+    Matrix3 xyzH;
+    r = xyz(xyzH)(0);
+    *H = xyzH.row(0);
+  } else
+    r = xyz()(0);
+  return r;
+}
+
+/* ************************************************************************* */
+double Rot3::pitch(OptionalJacobian<1, 3> H) const {
+  double p;
+  if (H) {
+    Matrix3 xyzH;
+    p = xyz(xyzH)(1);
+    *H = xyzH.row(1);
+  } else
+    p = xyz()(1);
+  return p;
+}
+
+/* ************************************************************************* */
+double Rot3::yaw(OptionalJacobian<1, 3> H) const {
+  double y;
+  if (H) {
+    Matrix3 xyzH;
+    y = xyz(xyzH)(2);
+    *H = xyzH.row(2);
+  } else
+    y = xyz()(2);
+  return y;
 }
 
 /* ************************************************************************* */
@@ -203,21 +255,62 @@ Matrix3 Rot3::LogmapDerivative(const Vec
 }
 
 /* ************************************************************************* */
-pair<Matrix3, Vector3> RQ(const Matrix3& A) {
-
-  double x = -atan2(-A(2, 1), A(2, 2));
-  Rot3 Qx = Rot3::Rx(-x);
-  Matrix3 B = A * Qx.matrix();
-
-  double y = -atan2(B(2, 0), B(2, 2));
-  Rot3 Qy = Rot3::Ry(-y);
-  Matrix3 C = B * Qy.matrix();
-
-  double z = -atan2(-C(1, 0), C(1, 1));
-  Rot3 Qz = Rot3::Rz(-z);
-  Matrix3 R = C * Qz.matrix();
+pair<Matrix3, Vector3> RQ(const Matrix3& A, OptionalJacobian<3, 9> H) {
+  const double x = -atan2(-A(2, 1), A(2, 2));
+  const auto Qx = Rot3::Rx(-x).matrix();
+  const Matrix3 B = A * Qx;
+
+  const double y = -atan2(B(2, 0), B(2, 2));
+  const auto Qy = Rot3::Ry(-y).matrix();
+  const Matrix3 C = B * Qy;
+
+  const double z = -atan2(-C(1, 0), C(1, 1));
+  const auto Qz = Rot3::Rz(-z).matrix();
+  const Matrix3 R = C * Qz;
+
+  if (H) {
+    if (std::abs(y - M_PI / 2) < 1e-2)
+      throw std::runtime_error(
+          "Rot3::RQ : Derivative undefined at singularity (gimbal lock)");
+
+    auto atan_d1 = [](double y, double x) { return x / (x * x + y * y); };
+    auto atan_d2 = [](double y, double x) { return -y / (x * x + y * y); };
+
+    const auto sx = -Qx(2, 1), cx = Qx(1, 1);
+    const auto sy = -Qy(0, 2), cy = Qy(0, 0);
+
+    *H = Matrix39::Zero();
+    // First, calculate the derivate of x
+    (*H)(0, 5) = atan_d1(A(2, 1), A(2, 2));
+    (*H)(0, 8) = atan_d2(A(2, 1), A(2, 2));
+
+    // Next, calculate the derivate of y. We have
+    // b20 = a20 and b22 = a21 * sx + a22 * cx
+    (*H)(1, 2) = -atan_d1(B(2, 0), B(2, 2));
+    const auto yHb22 = -atan_d2(B(2, 0), B(2, 2));
+    (*H)(1, 5) = yHb22 * sx;
+    (*H)(1, 8) = yHb22 * cx;
+
+    // Next, calculate the derivate of z. We have
+    // c20 = a10 * cy + a11 * sx * sy + a12 * cx * sy
+    // c22 = a11 * cx - a12 * sx
+    const auto c10Hx = (A(1, 1) * cx - A(1, 2) * sx) * sy;
+    const auto c10Hy = A(1, 2) * cx * cy + A(1, 1) * cy * sx - A(1, 0) * sy;
+    Vector9 c10HA = c10Hx * H->row(0) + c10Hy * H->row(1);
+    c10HA[1] = cy;
+    c10HA[4] = sx * sy;
+    c10HA[7] = cx * sy;
+
+    const auto c11Hx = -A(1, 2) * cx - A(1, 1) * sx;
+    Vector9 c11HA = c11Hx * H->row(0);
+    c11HA[4] = cx;
+    c11HA[7] = -sx;
+
+    H->block<1, 9>(2, 0) =
+        atan_d1(C(1, 0), C(1, 1)) * c10HA + atan_d2(C(1, 0), C(1, 1)) * c11HA;
+  }
 
-  Vector xyz = Vector3(x, y, z);
+  const auto xyz = Vector3(x, y, z);
   return make_pair(R, xyz);
 }
 
--- gtsam-4.1.0.orig/gtsam/geometry/Rot3.h
+++ gtsam-4.1.0/gtsam/geometry/Rot3.h
@@ -154,12 +154,23 @@ namespace gtsam {
     static Rot3 Rz(double t);
 
     /// Rotations around Z, Y, then X axes as in http://en.wikipedia.org/wiki/Rotation_matrix, counterclockwise when looking from unchanging axis.
-    static Rot3 RzRyRx(double x, double y, double z);
+    static Rot3 RzRyRx(double x, double y, double z,
+                       OptionalJacobian<3, 1> Hx = boost::none,
+                       OptionalJacobian<3, 1> Hy = boost::none,
+                       OptionalJacobian<3, 1> Hz = boost::none);
 
     /// Rotations around Z, Y, then X axes as in http://en.wikipedia.org/wiki/Rotation_matrix, counterclockwise when looking from unchanging axis.
-    inline static Rot3 RzRyRx(const Vector& xyz) {
+    inline static Rot3 RzRyRx(const Vector& xyz,
+                              OptionalJacobian<3, 3> H = boost::none) {
       assert(xyz.size() == 3);
-      return RzRyRx(xyz(0), xyz(1), xyz(2));
+      Rot3 out;
+      if (H) {
+        Vector3 Hx, Hy, Hz;
+        out = RzRyRx(xyz(0), xyz(1), xyz(2), Hx, Hy, Hz);
+        (*H) << Hx, Hy, Hz;
+      } else
+        out = RzRyRx(xyz(0), xyz(1), xyz(2));
+      return out;
     }
 
     /// Positive yaw is to right (as in aircraft heading). See ypr
@@ -185,7 +196,12 @@ namespace gtsam {
      * Positive pitch is down (decreasing aircraft altitude).
      * Positive roll is to right (decreasing yaw in aircraft).
      */
-    static Rot3 Ypr(double y, double p, double r) { return RzRyRx(r,p,y);}
+    static Rot3 Ypr(double y, double p, double r,
+                    OptionalJacobian<3, 1> Hy = boost::none,
+                    OptionalJacobian<3, 1> Hp = boost::none,
+                    OptionalJacobian<3, 1> Hr = boost::none) {
+      return RzRyRx(r, p, y, Hr, Hp, Hy);
+    }
 
     /** Create from Quaternion coefficients */
     static Rot3 Quaternion(double w, double x, double y, double z) {
@@ -246,9 +262,29 @@ namespace gtsam {
     static Rot3 AlignTwoPairs(const Unit3& a_p, const Unit3& b_p,  //
                               const Unit3& a_q, const Unit3& b_q);
 
-    /// Static, named constructor that finds Rot3 element closest to M in Frobenius norm.
+    /**
+     * Static, named constructor that finds Rot3 element closest to M in Frobenius norm.
+     * 
+     * Uses Full SVD to compute the orthogonal matrix, thus is highly accurate and robust.
+     * 
+     * N. J. Higham. Matrix nearness problems and applications.
+     * In M. J. C. Gover and S. Barnett, editors, Applications of Matrix Theory, pages 1–27.
+     * Oxford University Press, 1989.
+     */
     static Rot3 ClosestTo(const Matrix3& M) { return Rot3(SO3::ClosestTo(M)); }
 
+    /**
+     * Normalize rotation so that its determinant is 1.
+     * This means either re-orthogonalizing the Matrix representation or
+     * normalizing the quaternion representation.
+     *
+     * This method is akin to `ClosestTo` but uses a computationally cheaper
+     * algorithm.
+     * 
+     * Ref: https://drive.google.com/file/d/0B9rLLz1XQKmaZTlQdV81QjNoZTA/view
+     */
+    Rot3 normalized() const;
+
     /// @}
     /// @name Testable
     /// @{
@@ -425,19 +461,19 @@ namespace gtsam {
      * Use RQ to calculate xyz angle representation
      * @return a vector containing x,y,z s.t. R = Rot3::RzRyRx(x,y,z)
      */
-    Vector3 xyz() const;
+    Vector3 xyz(OptionalJacobian<3, 3> H = boost::none) const;
 
     /**
      * Use RQ to calculate yaw-pitch-roll angle representation
      * @return a vector containing ypr s.t. R = Rot3::Ypr(y,p,r)
      */
-    Vector3 ypr() const;
+    Vector3 ypr(OptionalJacobian<3, 3> H = boost::none) const;
 
     /**
      * Use RQ to calculate roll-pitch-yaw angle representation
      * @return a vector containing rpy s.t. R = Rot3::Ypr(y,p,r)
      */
-    Vector3 rpy() const;
+    Vector3 rpy(OptionalJacobian<3, 3> H = boost::none) const;
 
     /**
      * Accessor to get to component of angle representations
@@ -445,7 +481,7 @@ namespace gtsam {
      * you should instead use xyz() or ypr()
      * TODO: make this more efficient
      */
-    inline double roll() const  { return xyz()(0); }
+    double roll(OptionalJacobian<1, 3> H = boost::none) const;
 
     /**
      * Accessor to get to component of angle representations
@@ -453,7 +489,7 @@ namespace gtsam {
      * you should instead use xyz() or ypr()
      * TODO: make this more efficient
      */
-    inline double pitch() const { return xyz()(1); }
+    double pitch(OptionalJacobian<1, 3> H = boost::none) const;
 
     /**
      * Accessor to get to component of angle representations
@@ -461,7 +497,7 @@ namespace gtsam {
      * you should instead use xyz() or ypr()
      * TODO: make this more efficient
      */
-    inline double yaw() const   { return xyz()(2); }
+    double yaw(OptionalJacobian<1, 3> H = boost::none) const;
 
     /// @}
     /// @name Advanced Interface
@@ -490,7 +526,7 @@ namespace gtsam {
 
     /**
      * @brief Spherical Linear intERPolation between *this and other
-     * @param s a value between 0 and 1
+     * @param t a value between 0 and 1
      * @param other final point of iterpolation geodesic on manifold
      */
     Rot3 slerp(double t, const Rot3& other) const;
@@ -541,7 +577,8 @@ namespace gtsam {
    * @return an upper triangular matrix R
    * @return a vector [thetax, thetay, thetaz] in radians.
    */
-  GTSAM_EXPORT std::pair<Matrix3,Vector3> RQ(const Matrix3& A);
+  GTSAM_EXPORT std::pair<Matrix3, Vector3> RQ(
+      const Matrix3& A, OptionalJacobian<3, 9> H = boost::none);
 
   template<>
   struct traits<Rot3> : public internal::LieGroup<Rot3> {};
--- gtsam-4.1.0.orig/gtsam/geometry/Rot3M.cpp
+++ gtsam-4.1.0/gtsam/geometry/Rot3M.cpp
@@ -82,7 +82,8 @@ Rot3 Rot3::Rz(double t) {
 
 /* ************************************************************************* */
 // Considerably faster than composing matrices above !
-Rot3 Rot3::RzRyRx(double x, double y, double z) {
+Rot3 Rot3::RzRyRx(double x, double y, double z, OptionalJacobian<3, 1> Hx,
+                  OptionalJacobian<3, 1> Hy, OptionalJacobian<3, 1> Hz) {
   double cx=cos(x),sx=sin(x);
   double cy=cos(y),sy=sin(y);
   double cz=cos(z),sz=sin(z);
@@ -97,6 +98,9 @@ Rot3 Rot3::RzRyRx(double x, double y, do
   double s_c = sx * cz;
   double c_c = cx * cz;
   double ssc = ss_ * cz, csc = cs_ * cz, sss = ss_ * sz, css = cs_ * sz;
+  if (Hx) (*Hx) << 1, 0, 0;
+  if (Hy) (*Hy) << 0, cx, -sx;
+  if (Hz) (*Hz) << -sy, sc_, cc_;
   return Rot3(
       _cc,- c_s + ssc,  s_s + csc,
       _cs,  c_c + sss, -s_c + css,
@@ -105,6 +109,33 @@ Rot3 Rot3::RzRyRx(double x, double y, do
 }
 
 /* ************************************************************************* */
+Rot3 Rot3::normalized() const {
+  /// Implementation from here: https://stackoverflow.com/a/23082112/1236990
+
+  /// Essentially, this computes the orthogonalization error, distributes the
+  /// error to the x and y rows, and then performs a Taylor expansion to
+  /// orthogonalize.
+
+  Matrix3 rot = rot_.matrix(), rot_orth;
+
+  // Check if determinant is already 1.
+  // If yes, then return the current Rot3.
+  if (std::fabs(rot.determinant()-1) < 1e-12) return Rot3(rot_);
+
+  Vector3 x = rot.block<1, 3>(0, 0), y = rot.block<1, 3>(1, 0);
+  double error = x.dot(y);
+
+  Vector3 x_ort = x - (error / 2) * y, y_ort = y - (error / 2) * x;
+  Vector3 z_ort = x_ort.cross(y_ort);
+
+  rot_orth.block<1, 3>(0, 0) = 0.5 * (3 - x_ort.dot(x_ort)) * x_ort;
+  rot_orth.block<1, 3>(1, 0) = 0.5 * (3 - y_ort.dot(y_ort)) * y_ort;
+  rot_orth.block<1, 3>(2, 0) = 0.5 * (3 - z_ort.dot(z_ort)) * z_ort;
+
+  return Rot3(rot_orth);
+}
+
+/* ************************************************************************* */
 Rot3 Rot3::operator*(const Rot3& R2) const {
   return Rot3(rot_*R2.rot_);
 }
@@ -145,7 +176,17 @@ Vector3 Rot3::CayleyChart::Local(const R
   if (H) throw std::runtime_error("Rot3::CayleyChart::Local Derivative");
   // Create a fixed-size matrix
   Matrix3 A = R.matrix();
-  // Mathematica closed form optimization (procrastination?) gone wild:
+
+  // Check if (A+I) is invertible. Same as checking for -1 eigenvalue.
+  if ((A + I_3x3).determinant() == 0.0) {
+    throw std::runtime_error("Rot3::CayleyChart::Local Invalid Rotation");
+  }
+
+  // Mathematica closed form optimization.
+  // The following are the essential computations for the following algorithm
+  // 1. Compute the inverse of P = (A+I), using a closed-form formula since P is 3x3 
+  // 2. Compute the Cayley transform C = 2 * P^{-1} * (A-I)
+  // 3. C is skew-symmetric, so we pick out the computations corresponding only to x, y, and z.
   const double a = A(0, 0), b = A(0, 1), c = A(0, 2);
   const double d = A(1, 0), e = A(1, 1), f = A(1, 2);
   const double g = A(2, 0), h = A(2, 1), i = A(2, 2);
--- gtsam-4.1.0.orig/gtsam/geometry/Rot3Q.cpp
+++ gtsam-4.1.0/gtsam/geometry/Rot3Q.cpp
@@ -67,13 +67,30 @@ namespace gtsam {
   }
 
   /* ************************************************************************* */
-  Rot3 Rot3::RzRyRx(double x, double y, double z) { return Rot3(
-      gtsam::Quaternion(Eigen::AngleAxisd(z, Eigen::Vector3d::UnitZ())) *
-      gtsam::Quaternion(Eigen::AngleAxisd(y, Eigen::Vector3d::UnitY())) *
-      gtsam::Quaternion(Eigen::AngleAxisd(x, Eigen::Vector3d::UnitX())));
+  Rot3 Rot3::RzRyRx(double x, double y, double z, OptionalJacobian<3, 1> Hx,
+                    OptionalJacobian<3, 1> Hy, OptionalJacobian<3, 1> Hz) {
+    if (Hx) (*Hx) << 1, 0, 0;
+
+    if (Hy or Hz) {
+      const auto cx = cos(x), sx = sin(x);
+      if (Hy) (*Hy) << 0, cx, -sx;
+      if (Hz) {
+        const auto cy = cos(y), sy = sin(y);
+        (*Hz) << -sy, sx * cy, cx * cy;
+      }
+    }
+
+    return Rot3(
+        gtsam::Quaternion(Eigen::AngleAxisd(z, Eigen::Vector3d::UnitZ())) *
+        gtsam::Quaternion(Eigen::AngleAxisd(y, Eigen::Vector3d::UnitY())) *
+        gtsam::Quaternion(Eigen::AngleAxisd(x, Eigen::Vector3d::UnitX())));
   }
 
   /* ************************************************************************* */
+  Rot3 Rot3::normalized() const {
+    return Rot3(quaternion_.normalized());
+  }
+  /* ************************************************************************* */
   Rot3 Rot3::operator*(const Rot3& R2) const {
     return Rot3(quaternion_ * R2.quaternion_);
   }
--- gtsam-4.1.0.orig/gtsam/geometry/SimpleCamera.cpp
+++ gtsam-4.1.0/gtsam/geometry/SimpleCamera.cpp
@@ -21,6 +21,7 @@
 
 namespace gtsam {
 
+#ifdef GTSAM_ALLOW_DEPRECATED_SINCE_V41
   SimpleCamera simpleCamera(const Matrix34& P) {
 
     // P = [A|a] = s K cRw [I|-T], with s the unknown scale
@@ -45,5 +46,6 @@ namespace gtsam {
     return SimpleCamera(Pose3(wRc, T),
         Cal3_S2(K(0, 0), K(1, 1), K(0, 1), K(0, 2), K(1, 2)));
   }
+#endif
 
 }
--- gtsam-4.1.0.orig/gtsam/geometry/SimpleCamera.h
+++ gtsam-4.1.0/gtsam/geometry/SimpleCamera.h
@@ -19,14 +19,23 @@
 #pragma once
 
 #include <gtsam/geometry/BearingRange.h>
-#include <gtsam/geometry/PinholeCamera.h>
+#include <gtsam/geometry/Cal3Bundler.h>
+#include <gtsam/geometry/Cal3DS2.h>
+#include <gtsam/geometry/Cal3Unified.h>
 #include <gtsam/geometry/Cal3_S2.h>
+#include <gtsam/geometry/PinholeCamera.h>
 
 namespace gtsam {
 
-  /// A simple camera class with a Cal3_S2 calibration
-typedef gtsam::PinholeCamera<gtsam::Cal3_S2> PinholeCameraCal3_S2;
+  /// Convenient aliases for Pinhole camera classes with different calibrations.
+  /// Also needed as forward declarations in the wrapper.
+  using PinholeCameraCal3_S2 = gtsam::PinholeCamera<gtsam::Cal3_S2>;
+  using PinholeCameraCal3Bundler = gtsam::PinholeCamera<gtsam::Cal3Bundler>;
+  //TODO Need to fix issue 621 for this to work with wrapper
+  // using PinholeCameraCal3DS2 = gtsam::PinholeCamera<gtsam::Cal3DS2>;
+  // using PinholeCameraCal3Unified = gtsam::PinholeCamera<gtsam::Cal3Unified>;
 
+#ifdef GTSAM_ALLOW_DEPRECATED_SINCE_V41
 /**
  * @deprecated: SimpleCamera for backwards compatability with GTSAM 3.x
  * Use PinholeCameraCal3_S2 instead
@@ -140,4 +149,6 @@ struct traits<const SimpleCamera> : publ
 template <typename T>
 struct Range<SimpleCamera, T> : HasRange<SimpleCamera, T, double> {};
 
+#endif
+
 }  // namespace gtsam
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testCal3Bundler.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testCal3Bundler.cpp
@@ -52,12 +52,14 @@ TEST( Cal3Bundler, calibrate )
   Point2 pn(0.5, 0.5);
   Point2 pi = K.uncalibrate(pn);
   Point2 pn_hat = K.calibrate(pi);
-  CHECK( traits<Point2>::Equals(pn, pn_hat, 1e-5));
+  CHECK(traits<Point2>::Equals(pn, pn_hat, 1e-5));
 }
 
 /* ************************************************************************* */
 Point2 uncalibrate_(const Cal3Bundler& k, const Point2& pt) { return k.uncalibrate(pt); }
 
+Point2 calibrate_(const Cal3Bundler& k, const Point2& pt) { return k.calibrate(pt); }
+
 /* ************************************************************************* */
 TEST( Cal3Bundler, Duncalibrate)
 {
@@ -69,11 +71,20 @@ TEST( Cal3Bundler, Duncalibrate)
   Matrix numerical2 = numericalDerivative22(uncalibrate_, K, p);
   CHECK(assert_equal(numerical1,Dcal,1e-7));
   CHECK(assert_equal(numerical2,Dp,1e-7));
-  CHECK(assert_equal(numerical1,K.D2d_calibration(p),1e-7));
-  CHECK(assert_equal(numerical2,K.D2d_intrinsic(p),1e-7));
-  Matrix Dcombined(2,5);
-  Dcombined << Dp, Dcal;
-  CHECK(assert_equal(Dcombined,K.D2d_intrinsic_calibration(p),1e-7));
+}
+
+/* ************************************************************************* */
+TEST( Cal3Bundler, Dcalibrate)
+{
+  Matrix Dcal, Dp;
+  Point2 pn(0.5, 0.5);
+  Point2 pi = K.uncalibrate(pn);
+  Point2 actual = K.calibrate(pi, Dcal, Dp);
+  CHECK(assert_equal(pn, actual, 1e-7));
+  Matrix numerical1 = numericalDerivative21(calibrate_, K, pi);
+  Matrix numerical2 = numericalDerivative22(calibrate_, K, pi);
+  CHECK(assert_equal(numerical1,Dcal,1e-5));
+  CHECK(assert_equal(numerical2,Dp,1e-5));
 }
 
 /* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testCal3_S2.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testCal3_S2.cpp
@@ -16,6 +16,7 @@
 
 #include <CppUnitLite/TestHarness.h>
 #include <gtsam/base/Testable.h>
+#include <gtsam/base/TestableAssertions.h>
 #include <gtsam/base/numericalDerivative.h>
 #include <gtsam/geometry/Cal3_S2.h>
 
@@ -128,6 +129,16 @@ TEST(Cal3_S2, between) {
 }
 
 /* ************************************************************************* */
+TEST(Cal3_S2, Print) {
+  Cal3_S2 cal(5, 5, 5, 5, 5);
+  std::stringstream os;
+  os << "{fx: " << cal.fx() << ", fy: " << cal.fy() << ", s:" << cal.skew() << ", px:" << cal.px()
+     << ", py:" << cal.py() << "}";
+
+  EXPECT(assert_stdout_equal(os.str(), cal));
+}
+
+/* ************************************************************************* */
 int main() {
   TestResult tr;
   return TestRegistry::runAllTests(tr);
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testPinholeCamera.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testPinholeCamera.cpp
@@ -337,6 +337,15 @@ TEST( PinholeCamera, range3) {
 }
 
 /* ************************************************************************* */
+TEST( PinholeCamera, Cal3Bundler) {
+  Cal3Bundler calibration;
+  Pose3 wTc;
+  PinholeCamera<Cal3Bundler> camera(wTc, calibration);
+  Point2 p(50, 100);
+  camera.backproject(p, 10);
+}
+
+/* ************************************************************************* */
 int main() { TestResult tr; return TestRegistry::runAllTests(tr); }
 /* ************************************************************************* */
 
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testPoint3.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testPoint3.cpp
@@ -165,6 +165,26 @@ TEST (Point3, normalize) {
 }
 
 //*************************************************************************
+TEST(Point3, mean) {
+  Point3 expected(2, 2, 2);
+  Point3 a1(0, 0, 0), a2(1, 2, 3), a3(5, 4, 3);
+  std::vector<Point3> a_points{a1, a2, a3};
+  Point3 actual = mean(a_points);
+  EXPECT(assert_equal(expected, actual));
+}
+
+TEST(Point3, mean_pair) {
+  Point3 a_mean(2, 2, 2), b_mean(-1, 1, 0);
+  Point3Pair expected = std::make_pair(a_mean, b_mean);
+  Point3 a1(0, 0, 0), a2(1, 2, 3), a3(5, 4, 3);
+  Point3 b1(-1, 0, 0), b2(-2, 4, 0), b3(0, -1, 0);
+  std::vector<Point3Pair> point_pairs{{a1, b1}, {a2, b2}, {a3, b3}};
+  Point3Pair actual = means(point_pairs);
+  EXPECT(assert_equal(expected.first, actual.first));
+  EXPECT(assert_equal(expected.second, actual.second));
+}
+
+//*************************************************************************
 double norm_proxy(const Point3& point) {
   return double(point.norm());
 }
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testPose3.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testPose3.cpp
@@ -18,6 +18,7 @@
 #include <gtsam/geometry/Pose2.h>
 #include <gtsam/base/testLie.h>
 #include <gtsam/base/lieProxies.h>
+#include <gtsam/base/TestableAssertions.h>
 
 #include <boost/assign/std/vector.hpp> // for operator +=
 using namespace boost::assign;
@@ -807,6 +808,17 @@ TEST(Pose3, ExpmapDerivative2) {
   }
 }
 
+TEST( Pose3, ExpmapDerivativeQr) {
+  Vector6 w = Vector6::Random();
+  w.head<3>().normalize();
+  w.head<3>() = w.head<3>() * 0.9e-2;
+  Matrix3 actualQr = Pose3::ComputeQforExpmapDerivative(w, 0.01);
+  Matrix expectedH = numericalDerivative21<Pose3, Vector6,
+      OptionalJacobian<6, 6> >(&Pose3::Expmap, w, boost::none);
+  Matrix3 expectedQr = expectedH.bottomLeftCorner<3, 3>();
+  EXPECT(assert_equal(expectedQr, actualQr, 1e-6));
+}
+
 /* ************************************************************************* */
 TEST( Pose3, LogmapDerivative) {
   Matrix6 actualH;
@@ -895,9 +907,9 @@ TEST(Pose3 , ChartDerivatives) {
   Pose3 id;
   if (ROT3_DEFAULT_COORDINATES_MODE == Rot3::EXPMAP) {
     CHECK_CHART_DERIVATIVES(id,id);
-//    CHECK_CHART_DERIVATIVES(id,T2);
-//    CHECK_CHART_DERIVATIVES(T2,id);
-//    CHECK_CHART_DERIVATIVES(T2,T3);
+    CHECK_CHART_DERIVATIVES(id,T2);
+    CHECK_CHART_DERIVATIVES(T2,id);
+    CHECK_CHART_DERIVATIVES(T2,T3);
   }
 }
 
@@ -1017,32 +1029,13 @@ TEST(Pose3, Create) {
 }
 
 /* ************************************************************************* */
-TEST(Pose3, print) {
-  std::stringstream redirectStream;
-  std::streambuf* ssbuf = redirectStream.rdbuf();
-  std::streambuf* oldbuf  = std::cout.rdbuf();
-  // redirect cout to redirectStream
-  std::cout.rdbuf(ssbuf);
-
+TEST(Pose3, Print) {
   Pose3 pose(Rot3::identity(), Point3(1, 2, 3));
-  // output is captured to redirectStream
-  pose.print();
 
   // Generate the expected output
-  std::stringstream expected;
-  Point3 translation(1, 2, 3);
-
-  // Add expected rotation
-  expected << "R: [\n\t1, 0, 0;\n\t0, 1, 0;\n\t0, 0, 1\n]\n";
-  expected << "t: 1 2 3\n";
-
-  // reset cout to the original stream
-  std::cout.rdbuf(oldbuf);
-
-  // Get substring corresponding to translation part
-  std::string actual = redirectStream.str();
+  std::string expected = "R: [\n\t1, 0, 0;\n\t0, 1, 0;\n\t0, 0, 1\n]\nt: 1 2 3\n";
 
-  CHECK_EQUAL(expected.str(), actual);
+  EXPECT(assert_print_equal(expected, pose));
 }
 
 /* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testRot3.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testRot3.cpp
@@ -744,6 +744,193 @@ TEST(Rot3, axisAngle) {
 }
 
 /* ************************************************************************* */
+Rot3 RzRyRx_proxy(double const& a, double const& b, double const& c) {
+  return Rot3::RzRyRx(a, b, c);
+}
+
+TEST(Rot3, RzRyRx_scalars_derivative) {
+  const auto x = 0.1, y = 0.4, z = 0.2;
+  const auto num_x = numericalDerivative31(RzRyRx_proxy, x, y, z);
+  const auto num_y = numericalDerivative32(RzRyRx_proxy, x, y, z);
+  const auto num_z = numericalDerivative33(RzRyRx_proxy, x, y, z);
+
+  Vector3 act_x, act_y, act_z;
+  Rot3::RzRyRx(x, y, z, act_x, act_y, act_z);
+
+  CHECK(assert_equal(num_x, act_x));
+  CHECK(assert_equal(num_y, act_y));
+  CHECK(assert_equal(num_z, act_z));
+}
+
+/* ************************************************************************* */
+Rot3 RzRyRx_proxy(Vector3 const& xyz) { return Rot3::RzRyRx(xyz); }
+
+TEST(Rot3, RzRyRx_vector_derivative) {
+  const auto xyz = Vector3{-0.3, 0.1, 0.7};
+  const auto num = numericalDerivative11(RzRyRx_proxy, xyz);
+
+  Matrix3 act;
+  Rot3::RzRyRx(xyz, act);
+
+  CHECK(assert_equal(num, act));
+}
+
+/* ************************************************************************* */
+Rot3 Ypr_proxy(double const& y, double const& p, double const& r) {
+  return Rot3::Ypr(y, p, r);
+}
+
+TEST(Rot3, Ypr_derivative) {
+  const auto y = 0.7, p = -0.3, r = 0.1;
+  const auto num_y = numericalDerivative31(Ypr_proxy, y, p, r);
+  const auto num_p = numericalDerivative32(Ypr_proxy, y, p, r);
+  const auto num_r = numericalDerivative33(Ypr_proxy, y, p, r);
+
+  Vector3 act_y, act_p, act_r;
+  Rot3::Ypr(y, p, r, act_y, act_p, act_r);
+
+  CHECK(assert_equal(num_y, act_y));
+  CHECK(assert_equal(num_p, act_p));
+  CHECK(assert_equal(num_r, act_r));
+}
+
+/* ************************************************************************* */
+Vector3 RQ_proxy(Matrix3 const& R) {
+  const auto RQ_ypr = RQ(R);
+  return RQ_ypr.second;
+}
+
+TEST(Rot3, RQ_derivative) {
+  using VecAndErr = std::pair<Vector3, double>;
+  std::vector<VecAndErr> test_xyz;
+  // Test zeros and a couple of random values
+  test_xyz.push_back(VecAndErr{{0, 0, 0}, error});
+  test_xyz.push_back(VecAndErr{{0, 0.5, -0.5}, error});
+  test_xyz.push_back(VecAndErr{{0.3, 0, 0.2}, error});
+  test_xyz.push_back(VecAndErr{{-0.6, 1.3, 0}, 1e-8});
+  test_xyz.push_back(VecAndErr{{1.0, 0.7, 0.8}, error});
+  test_xyz.push_back(VecAndErr{{3.0, 0.7, -0.6}, error});
+  test_xyz.push_back(VecAndErr{{M_PI / 2, 0, 0}, error});
+  test_xyz.push_back(VecAndErr{{0, 0, M_PI / 2}, error});
+
+  // Test close to singularity
+  test_xyz.push_back(VecAndErr{{0, M_PI / 2 - 1e-1, 0}, 1e-7});
+  test_xyz.push_back(VecAndErr{{0, 3 * M_PI / 2 + 1e-1, 0}, 1e-7});
+  test_xyz.push_back(VecAndErr{{0, M_PI / 2 - 1.1e-2, 0}, 1e-4});
+  test_xyz.push_back(VecAndErr{{0, 3 * M_PI / 2 + 1.1e-2, 0}, 1e-4});
+
+  for (auto const& vec_err : test_xyz) {
+    auto const& xyz = vec_err.first;
+
+    const auto R = Rot3::RzRyRx(xyz).matrix();
+    const auto num = numericalDerivative11(RQ_proxy, R);
+    Matrix39 calc;
+    RQ(R, calc).second;
+
+    const auto err = vec_err.second;
+    CHECK(assert_equal(num, calc, err));
+  }
+}
+
+/* ************************************************************************* */
+Vector3 xyz_proxy(Rot3 const& R) { return R.xyz(); }
+
+TEST(Rot3, xyz_derivative) {
+  const auto aa = Vector3{-0.6, 0.3, 0.2};
+  const auto R = Rot3::Expmap(aa);
+  const auto num = numericalDerivative11(xyz_proxy, R);
+  Matrix3 calc;
+  R.xyz(calc);
+
+  CHECK(assert_equal(num, calc));
+}
+
+/* ************************************************************************* */
+Vector3 ypr_proxy(Rot3 const& R) { return R.ypr(); }
+
+TEST(Rot3, ypr_derivative) {
+  const auto aa = Vector3{0.1, -0.3, -0.2};
+  const auto R = Rot3::Expmap(aa);
+  const auto num = numericalDerivative11(ypr_proxy, R);
+  Matrix3 calc;
+  R.ypr(calc);
+
+  CHECK(assert_equal(num, calc));
+}
+
+/* ************************************************************************* */
+Vector3 rpy_proxy(Rot3 const& R) { return R.rpy(); }
+
+TEST(Rot3, rpy_derivative) {
+  const auto aa = Vector3{1.2, 0.3, -0.9};
+  const auto R = Rot3::Expmap(aa);
+  const auto num = numericalDerivative11(rpy_proxy, R);
+  Matrix3 calc;
+  R.rpy(calc);
+
+  CHECK(assert_equal(num, calc));
+}
+
+/* ************************************************************************* */
+double roll_proxy(Rot3 const& R) { return R.roll(); }
+
+TEST(Rot3, roll_derivative) {
+  const auto aa = Vector3{0.8, -0.8, 0.8};
+  const auto R = Rot3::Expmap(aa);
+  const auto num = numericalDerivative11(roll_proxy, R);
+  Matrix13 calc;
+  R.roll(calc);
+
+  CHECK(assert_equal(num, calc));
+}
+
+/* ************************************************************************* */
+double pitch_proxy(Rot3 const& R) { return R.pitch(); }
+
+TEST(Rot3, pitch_derivative) {
+  const auto aa = Vector3{0.01, 0.1, 0.0};
+  const auto R = Rot3::Expmap(aa);
+  const auto num = numericalDerivative11(pitch_proxy, R);
+  Matrix13 calc;
+  R.pitch(calc);
+
+  CHECK(assert_equal(num, calc));
+}
+
+/* ************************************************************************* */
+double yaw_proxy(Rot3 const& R) { return R.yaw(); }
+
+TEST(Rot3, yaw_derivative) {
+  const auto aa = Vector3{0.0, 0.1, 0.6};
+  const auto R = Rot3::Expmap(aa);
+  const auto num = numericalDerivative11(yaw_proxy, R);
+  Matrix13 calc;
+  R.yaw(calc);
+
+  CHECK(assert_equal(num, calc));
+}
+
+/* ************************************************************************* */
+TEST(Rot3, determinant) {
+  size_t degree = 1;
+  Rot3 R_w0;  // Zero rotation
+  Rot3 R_w1 = Rot3::Ry(degree * M_PI / 180);
+
+  Rot3 R_01, R_w2;
+  double actual, expected = 1.0;
+
+  for (size_t i = 2; i < 360; ++i) {
+    R_01 = R_w0.between(R_w1);
+    R_w2 = R_w1 * R_01;
+    R_w0 = R_w1;
+    R_w1 = R_w2.normalized();
+    actual = R_w2.matrix().determinant();
+
+    EXPECT_DOUBLES_EQUAL(expected, actual, 1e-7);
+  }
+}
+
+/* ************************************************************************* */
 int main() {
   TestResult tr;
   return TestRegistry::runAllTests(tr);
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testSerializationGeometry.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testSerializationGeometry.cpp
@@ -57,7 +57,7 @@ static StereoCamera cam2(pose3, cal4ptr)
 static StereoPoint2 spt(1.0, 2.0, 3.0);
 
 /* ************************************************************************* */
-TEST_DISABLED (Serialization, text_geometry) {
+TEST (Serialization, text_geometry) {
   EXPECT(equalsObj<gtsam::Point2>(Point2(1.0, 2.0)));
   EXPECT(equalsObj<gtsam::Pose2>(Pose2(1.0, 2.0, 0.3)));
   EXPECT(equalsObj<gtsam::Rot2>(Rot2::fromDegrees(30.0)));
@@ -82,7 +82,7 @@ TEST_DISABLED (Serialization, text_geome
 }
 
 /* ************************************************************************* */
-TEST_DISABLED (Serialization, xml_geometry) {
+TEST (Serialization, xml_geometry) {
   EXPECT(equalsXML<gtsam::Point2>(Point2(1.0, 2.0)));
   EXPECT(equalsXML<gtsam::Pose2>(Pose2(1.0, 2.0, 0.3)));
   EXPECT(equalsXML<gtsam::Rot2>(Rot2::fromDegrees(30.0)));
@@ -106,7 +106,7 @@ TEST_DISABLED (Serialization, xml_geomet
 }
 
 /* ************************************************************************* */
-TEST_DISABLED (Serialization, binary_geometry) {
+TEST (Serialization, binary_geometry) {
   EXPECT(equalsBinary<gtsam::Point2>(Point2(1.0, 2.0)));
   EXPECT(equalsBinary<gtsam::Pose2>(Pose2(1.0, 2.0, 0.3)));
   EXPECT(equalsBinary<gtsam::Rot2>(Rot2::fromDegrees(30.0)));
--- gtsam-4.1.0.orig/gtsam/geometry/tests/testSimpleCamera.cpp
+++ gtsam-4.1.0/gtsam/geometry/tests/testSimpleCamera.cpp
@@ -26,6 +26,8 @@
 using namespace std;
 using namespace gtsam;
 
+#ifdef GTSAM_ALLOW_DEPRECATED_SINCE_V41
+
 static const Cal3_S2 K(625, 625, 0, 0, 0);
 
 static const Pose3 pose1(Rot3(Vector3(1, -1, -1).asDiagonal()),
@@ -149,6 +151,8 @@ TEST( SimpleCamera, simpleCamera)
   CHECK(assert_equal(expected, actual,1e-1));
 }
 
+#endif
+
 /* ************************************************************************* */
 int main() { TestResult tr; return TestRegistry::runAllTests(tr); }
 /* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/gtsam.i
+++ gtsam-4.1.0/gtsam/gtsam.i
@@ -93,9 +93,9 @@
  *        - Add "void serializable()" to a class if you only want the class to be serialized as a
  *          part of a container (such as noisemodel). This version does not require a publicly
  *          accessible default constructor.
- *   Forward declarations and class definitions for Cython:
- *     - Need to specify the base class (both this forward class and base class are declared in an external cython header)
- *       This is so Cython can generate proper inheritance.
+ *   Forward declarations and class definitions for Pybind:
+ *     - Need to specify the base class (both this forward class and base class are declared in an external Pybind header)
+ *       This is so Pybind can generate proper inheritance.
  *       Example when wrapping a gtsam-based project:
  *          // forward declarations
  *          virtual class gtsam::NonlinearFactor
@@ -104,7 +104,7 @@
  *          #include <MyFactor.h>
  *          virtual class MyFactor : gtsam::NoiseModelFactor {...};
  *    - *DO NOT* re-define overriden function already declared in the external (forward-declared) base class
- *        - This will cause an ambiguity problem in Cython pxd header file
+ *        - This will cause an ambiguity problem in Pybind header file
  */
 
 /**
@@ -259,124 +259,79 @@ class IndexPair {
   size_t j() const;
 };
 
-template<KEY = {gtsam::IndexPair}>
-class DSFMap {
-  DSFMap();
-  KEY find(const KEY& key) const;
-  void merge(const KEY& x, const KEY& y);
-};
-
-#include <gtsam/base/Matrix.h>
-bool linear_independent(Matrix A, Matrix B, double tol);
-
-#include <gtsam/base/Value.h>
-virtual class Value {
-  // No constructors because this is an abstract class
-
-  // Testable
-  void print(string s) const;
+// template<KEY = {gtsam::IndexPair}>
+// class DSFMap {
+//   DSFMap();
+//   KEY find(const KEY& key) const;
+//   void merge(const KEY& x, const KEY& y);
+//   std::map<KEY, Set> sets();
+// };
 
-  // Manifold
-  size_t dim() const;
-};
+class IndexPairSet {
+  IndexPairSet();
+  // common STL methods
+  size_t size() const;
+  bool empty() const;
+  void clear();
 
-#include <gtsam/base/GenericValue.h>
-template<T = {Vector, Matrix, gtsam::Point2, gtsam::Point3, gtsam::Rot2, gtsam::Rot3, gtsam::Pose2, gtsam::Pose3, gtsam::StereoPoint2, gtsam::Cal3_S2, gtsam::Cal3DS2, gtsam::Cal3Bundler, gtsam::EssentialMatrix, gtsam::CalibratedCamera, gtsam::SimpleCamera, gtsam::imuBias::ConstantBias}>
-virtual class GenericValue : gtsam::Value {
-  void serializable() const;
+  // structure specific methods
+  void insert(gtsam::IndexPair key);
+  bool erase(gtsam::IndexPair key); // returns true if value was removed
+  bool count(gtsam::IndexPair key) const; // returns true if value exists
 };
 
-#include <gtsam/base/deprecated/LieScalar.h>
-class LieScalar {
-  // Standard constructors
-  LieScalar();
-  LieScalar(double d);
-
-  // Standard interface
-  double value() const;
-
-  // Testable
-  void print(string s) const;
-  bool equals(const gtsam::LieScalar& expected, double tol) const;
+class IndexPairVector {
+  IndexPairVector();
+  IndexPairVector(const gtsam::IndexPairVector& other);
 
-  // Group
-  static gtsam::LieScalar identity();
-  gtsam::LieScalar inverse() const;
-  gtsam::LieScalar compose(const gtsam::LieScalar& p) const;
-  gtsam::LieScalar between(const gtsam::LieScalar& l2) const;
-
-  // Manifold
-  size_t dim() const;
-  gtsam::LieScalar retract(Vector v) const;
-  Vector localCoordinates(const gtsam::LieScalar& t2) const;
+  // common STL methods
+  size_t size() const;
+  bool empty() const;
+  void clear();
 
-  // Lie group
-  static gtsam::LieScalar Expmap(Vector v);
-  static Vector Logmap(const gtsam::LieScalar& p);
+  // structure specific methods
+  gtsam::IndexPair at(size_t i) const;
+  void push_back(gtsam::IndexPair key) const;
 };
 
-#include <gtsam/base/deprecated/LieVector.h>
-class LieVector {
-  // Standard constructors
-  LieVector();
-  LieVector(Vector v);
-
-  // Standard interface
-  Vector vector() const;
-
-  // Testable
-  void print(string s) const;
-  bool equals(const gtsam::LieVector& expected, double tol) const;
-
-  // Group
-  static gtsam::LieVector identity();
-  gtsam::LieVector inverse() const;
-  gtsam::LieVector compose(const gtsam::LieVector& p) const;
-  gtsam::LieVector between(const gtsam::LieVector& l2) const;
+gtsam::IndexPairVector IndexPairSetAsArray(gtsam::IndexPairSet& set);
 
-  // Manifold
-  size_t dim() const;
-  gtsam::LieVector retract(Vector v) const;
-  Vector localCoordinates(const gtsam::LieVector& t2) const;
+class IndexPairSetMap {
+  IndexPairSetMap();
+  // common STL methods
+  size_t size() const;
+  bool empty() const;
+  void clear();
 
-  // Lie group
-  static gtsam::LieVector Expmap(Vector v);
-  static Vector Logmap(const gtsam::LieVector& p);
+  // structure specific methods
+  gtsam::IndexPairSet at(gtsam::IndexPair& key);
+};
 
-  // enabling serialization functionality
-  void serialize() const;
+class DSFMapIndexPair {
+  DSFMapIndexPair();
+  gtsam::IndexPair find(const gtsam::IndexPair& key) const;
+  void merge(const gtsam::IndexPair& x, const gtsam::IndexPair& y);
+  gtsam::IndexPairSetMap sets();
 };
 
-#include <gtsam/base/deprecated/LieMatrix.h>
-class LieMatrix {
-  // Standard constructors
-  LieMatrix();
-  LieMatrix(Matrix v);
+#include <gtsam/base/Matrix.h>
+bool linear_independent(Matrix A, Matrix B, double tol);
 
-  // Standard interface
-  Matrix matrix() const;
+#include <gtsam/base/Value.h>
+virtual class Value {
+  // No constructors because this is an abstract class
 
   // Testable
   void print(string s) const;
-  bool equals(const gtsam::LieMatrix& expected, double tol) const;
-
-  // Group
-  static gtsam::LieMatrix identity();
-  gtsam::LieMatrix inverse() const;
-  gtsam::LieMatrix compose(const gtsam::LieMatrix& p) const;
-  gtsam::LieMatrix between(const gtsam::LieMatrix& l2) const;
 
   // Manifold
   size_t dim() const;
-  gtsam::LieMatrix retract(Vector v) const;
-  Vector localCoordinates(const gtsam::LieMatrix & t2) const;
-
-  // Lie group
-  static gtsam::LieMatrix Expmap(Vector v);
-  static Vector Logmap(const gtsam::LieMatrix& p);
+};
 
-  // enabling serialization functionality
-  void serialize() const;
+#include <gtsam/base/GenericValue.h>
+template<T = {Vector, Matrix, gtsam::Point2, gtsam::Point3, gtsam::Rot2, gtsam::Rot3, gtsam::Pose2, gtsam::Pose3, gtsam::StereoPoint2, gtsam::Cal3_S2, gtsam::Cal3DS2, gtsam::Cal3Bundler, gtsam::EssentialMatrix, gtsam::CalibratedCamera, gtsam::imuBias::ConstantBias}>
+virtual class GenericValue : gtsam::Value {
+  void serializable() const;
 };
 
 //*************************************************************************
@@ -519,6 +474,7 @@ class Rot2 {
   // Lie Group
   static gtsam::Rot2 Expmap(Vector v);
   static Vector Logmap(const gtsam::Rot2& p);
+  Vector logmap(const gtsam::Rot2& p);
 
   // Group Action on Point2
   gtsam::Point2 rotate(const gtsam::Point2& point) const;
@@ -623,6 +579,15 @@ class SOn {
   void serialize() const;
 };
 
+#include <gtsam/geometry/Quaternion.h>
+class Quaternion {
+  double w() const;
+  double x() const;
+  double y() const;
+  double z() const;
+  Vector coeffs() const;
+};
+
 #include <gtsam/geometry/Rot3.h>
 class Rot3 {
   // Standard Constructors and Named Constructors
@@ -632,6 +597,7 @@ class Rot3 {
   Rot3(double R11, double R12, double R13,
       double R21, double R22, double R23,
       double R31, double R32, double R33);
+  Rot3(double w, double x, double y, double z);
 
   static gtsam::Rot3 Rx(double t);
   static gtsam::Rot3 Ry(double t);
@@ -659,7 +625,7 @@ class Rot3 {
   gtsam::Rot3 between(const gtsam::Rot3& p2) const;
 
   // Manifold
-  //gtsam::Rot3 retractCayley(Vector v) const; // FIXME, does not exist in both Matrix and Quaternion options
+  //gtsam::Rot3 retractCayley(Vector v) const; // TODO, does not exist in both Matrix and Quaternion options
   gtsam::Rot3 retract(Vector v) const;
   Vector localCoordinates(const gtsam::Rot3& p) const;
 
@@ -670,6 +636,7 @@ class Rot3 {
   // Standard Interface
   static gtsam::Rot3 Expmap(Vector v);
   static Vector Logmap(const gtsam::Rot3& p);
+  Vector logmap(const gtsam::Rot3& p);
   Matrix matrix() const;
   Matrix transpose() const;
   gtsam::Point3 column(size_t index) const;
@@ -680,7 +647,7 @@ class Rot3 {
   double pitch() const;
   double yaw() const;
   pair<gtsam::Unit3, double> axisAngle() const;
-//  Vector toQuaternion() const;  // FIXME: Can't cast to Vector properly
+  gtsam::Quaternion toQuaternion() const;
   Vector quaternion() const;
   gtsam::Rot3 slerp(double t, const gtsam::Rot3& other) const;
 
@@ -715,6 +682,7 @@ class Pose2 {
   // Lie Group
   static gtsam::Pose2 Expmap(Vector v);
   static Vector Logmap(const gtsam::Pose2& p);
+  Vector logmap(const gtsam::Pose2& p);
   static Matrix ExpmapDerivative(Vector v);
   static Matrix LogmapDerivative(const gtsam::Pose2& v);
   Matrix AdjointMap() const;
@@ -748,7 +716,7 @@ class Pose3 {
   Pose3();
   Pose3(const gtsam::Pose3& other);
   Pose3(const gtsam::Rot3& r, const gtsam::Point3& t);
-  Pose3(const gtsam::Pose2& pose2); // FIXME: shadows Pose3(Pose3 pose)
+  Pose3(const gtsam::Pose2& pose2);
   Pose3(Matrix mat);
 
   // Testable
@@ -768,6 +736,7 @@ class Pose3 {
   // Lie Group
   static gtsam::Pose3 Expmap(Vector v);
   static Vector Logmap(const gtsam::Pose3& pose);
+  Vector logmap(const gtsam::Pose3& pose);
   Matrix AdjointMap() const;
   Vector Adjoint(Vector xi) const;
   static Matrix adjointMap_(Vector xi);
@@ -991,6 +960,7 @@ class Cal3Bundler {
   // Standard Constructors
   Cal3Bundler();
   Cal3Bundler(double fx, double k1, double k2, double u0, double v0);
+  Cal3Bundler(double fx, double k1, double k2, double u0, double v0, double tol);
 
   // Testable
   void print(string s) const;
@@ -1003,7 +973,7 @@ class Cal3Bundler {
   Vector localCoordinates(const gtsam::Cal3Bundler& c) const;
 
   // Action on Point2
-  gtsam::Point2 calibrate(const gtsam::Point2& p, double tol) const;
+  gtsam::Point2 calibrate(const gtsam::Point2& p) const;
   gtsam::Point2 uncalibrate(const gtsam::Point2& p) const;
 
   // Standard Interface
@@ -1011,11 +981,11 @@ class Cal3Bundler {
   double fy() const;
   double k1() const;
   double k2() const;
-  double u0() const;
-  double v0() const;
+  double px() const;
+  double py() const;
   Vector vector() const;
   Vector k() const;
-  //Matrix K() const; //FIXME: Uppercase
+  Matrix K() const;
 
   // enabling serialization functionality
   void serialize() const;
@@ -1089,55 +1059,15 @@ class PinholeCamera {
   void serialize() const;
 };
 
+// Forward declaration of PinholeCameraCalX is defined here.
 #include <gtsam/geometry/SimpleCamera.h>
-virtual class SimpleCamera {
-  // Standard Constructors and Named Constructors
-  SimpleCamera();
-  SimpleCamera(const gtsam::Pose3& pose);
-  SimpleCamera(const gtsam::Pose3& pose, const gtsam::Cal3_S2& K);
-  static gtsam::SimpleCamera Level(const gtsam::Cal3_S2& K, const gtsam::Pose2& pose, double height);
-  static gtsam::SimpleCamera Level(const gtsam::Pose2& pose, double height);
-  static gtsam::SimpleCamera Lookat(const gtsam::Point3& eye, const gtsam::Point3& target,
-      const gtsam::Point3& upVector, const gtsam::Cal3_S2& K);
-  static gtsam::SimpleCamera Lookat(const gtsam::Point3& eye, const gtsam::Point3& target,
-      const gtsam::Point3& upVector);
-
-  // Testable
-  void print(string s) const;
-  bool equals(const gtsam::SimpleCamera& camera, double tol) const;
-
-  // Standard Interface
-  gtsam::Pose3 pose() const;
-  gtsam::Cal3_S2 calibration() const;
-
-  // Manifold
-  gtsam::SimpleCamera retract(Vector d) const;
-  Vector localCoordinates(const gtsam::SimpleCamera& T2) const;
-  size_t dim() const;
-  static size_t Dim();
-
-  // Transformations and measurement functions
-  static gtsam::Point2 Project(const gtsam::Point3& cameraPoint);
-  pair<gtsam::Point2,bool> projectSafe(const gtsam::Point3& pw) const;
-  gtsam::Point2 project(const gtsam::Point3& point);
-  gtsam::Point3 backproject(const gtsam::Point2& p, double depth) const;
-  double range(const gtsam::Point3& point);
-  double range(const gtsam::Pose3& pose);
-
-  // enabling serialization functionality
-  void serialize() const;
-
-};
-
-gtsam::SimpleCamera simpleCamera(const Matrix& P);
-
 // Some typedefs for common camera types
 // PinholeCameraCal3_S2 is the same as SimpleCamera above
 typedef gtsam::PinholeCamera<gtsam::Cal3_S2> PinholeCameraCal3_S2;
-// due to lack of jacobians of Cal3DS2_Base::calibrate, PinholeCamera does not apply to Cal3DS2/Unified
+//TODO (Issue 621) due to lack of jacobians of Cal3DS2_Base::calibrate, PinholeCamera does not apply to Cal3DS2/Unified
 //typedef gtsam::PinholeCamera<gtsam::Cal3DS2> PinholeCameraCal3DS2;
 //typedef gtsam::PinholeCamera<gtsam::Cal3Unified> PinholeCameraCal3Unified;
-//typedef gtsam::PinholeCamera<gtsam::Cal3Bundler> PinholeCameraCal3Bundler;
+typedef gtsam::PinholeCamera<gtsam::Cal3Bundler> PinholeCameraCal3Bundler;
 
 #include <gtsam/geometry/StereoCamera.h>
 class StereoCamera {
@@ -1180,7 +1110,7 @@ gtsam::Point3 triangulatePoint3(const gt
 gtsam::Point3 triangulatePoint3(const gtsam::Pose3Vector& poses,
     gtsam::Cal3Bundler* sharedCal, const gtsam::Point2Vector& measurements,
     double rank_tol, bool optimize);
-
+    
 //*************************************************************************
 // Symbolic
 //*************************************************************************
@@ -1330,7 +1260,7 @@ class SymbolicBayesTree {
 // //  const std::list<derived_ptr>& children() const { return children_; }
 // //  derived_ptr parent() const { return parent_.lock(); }
 //
-//   // FIXME: need wrapped versions graphs, BayesNet
+//   // TODO: need wrapped versions graphs, BayesNet
 // //  BayesNet<ConditionalType> shortcut(derived_ptr root, Eliminate function) const;
 // //  FactorGraph<FactorType> marginal(derived_ptr root, Eliminate function) const;
 // //  FactorGraph<FactorType> joint(derived_ptr C2, derived_ptr root, Eliminate function) const;
@@ -2099,7 +2029,7 @@ class NonlinearFactorGraph {
   gtsam::KeySet keys() const;
   gtsam::KeyVector keyVector() const;
 
-  template<T = {Vector, gtsam::Point2, gtsam::StereoPoint2, gtsam::Point3, gtsam::Rot2, gtsam::SO3, gtsam::SO4, gtsam::Rot3, gtsam::Pose2, gtsam::Pose3, gtsam::Cal3_S2,gtsam::CalibratedCamera, gtsam::SimpleCamera, gtsam::PinholeCameraCal3_S2, gtsam::imuBias::ConstantBias}>
+  template<T = {Vector, gtsam::Point2, gtsam::StereoPoint2, gtsam::Point3, gtsam::Rot2, gtsam::SO3, gtsam::SO4, gtsam::Rot3, gtsam::Pose2, gtsam::Pose3, gtsam::Cal3_S2,gtsam::CalibratedCamera, gtsam::PinholeCameraCal3_S2, gtsam::PinholeCamera<gtsam::Cal3Bundler>, gtsam::imuBias::ConstantBias}>
   void addPrior(size_t key, const T& prior, const gtsam::noiseModel::Base* noiseModel);
 
   // NonlinearFactorGraph
@@ -2129,7 +2059,7 @@ virtual class NonlinearFactor {
   bool active(const gtsam::Values& c) const;
   gtsam::GaussianFactor* linearize(const gtsam::Values& c) const;
   gtsam::NonlinearFactor* clone() const;
-  // gtsam::NonlinearFactor* rekey(const gtsam::KeyVector& newKeys) const; //FIXME: Conversion from KeyVector to std::vector does not happen
+  // gtsam::NonlinearFactor* rekey(const gtsam::KeyVector& newKeys) const; //TODO: Conversion from KeyVector to std::vector does not happen
 };
 
 #include <gtsam/nonlinear/NonlinearFactor.h>
@@ -2188,11 +2118,13 @@ class Values {
   void insert(size_t j, const gtsam::SOn& P);
   void insert(size_t j, const gtsam::Rot3& rot3);
   void insert(size_t j, const gtsam::Pose3& pose3);
+  void insert(size_t j, const gtsam::Unit3& unit3);
   void insert(size_t j, const gtsam::Cal3_S2& cal3_s2);
   void insert(size_t j, const gtsam::Cal3DS2& cal3ds2);
   void insert(size_t j, const gtsam::Cal3Bundler& cal3bundler);
   void insert(size_t j, const gtsam::EssentialMatrix& essential_matrix);
   void insert(size_t j, const gtsam::PinholeCameraCal3_S2& simple_camera);
+  void insert(size_t j, const gtsam::PinholeCamera<gtsam::Cal3Bundler>& camera);
   void insert(size_t j, const gtsam::imuBias::ConstantBias& constant_bias);
   void insert(size_t j, const gtsam::NavState& nav_state);
 
@@ -2205,16 +2137,19 @@ class Values {
   void update(size_t j, const gtsam::SOn& P);
   void update(size_t j, const gtsam::Rot3& rot3);
   void update(size_t j, const gtsam::Pose3& pose3);
+  void update(size_t j, const gtsam::Unit3& unit3);
   void update(size_t j, const gtsam::Cal3_S2& cal3_s2);
   void update(size_t j, const gtsam::Cal3DS2& cal3ds2);
   void update(size_t j, const gtsam::Cal3Bundler& cal3bundler);
   void update(size_t j, const gtsam::EssentialMatrix& essential_matrix);
+  void update(size_t j, const gtsam::PinholeCameraCal3_S2& simple_camera);
+  void update(size_t j, const gtsam::PinholeCamera<gtsam::Cal3Bundler>& camera);
   void update(size_t j, const gtsam::imuBias::ConstantBias& constant_bias);
   void update(size_t j, const gtsam::NavState& nav_state);
   void update(size_t j, Vector vector);
   void update(size_t j, Matrix matrix);
 
-  template<T = {gtsam::Point2, gtsam::Point3, gtsam::Rot2, gtsam::Pose2, gtsam::SO3, gtsam::SO4, gtsam::SOn, gtsam::Rot3, gtsam::Pose3, gtsam::Cal3_S2, gtsam::Cal3DS2, gtsam::Cal3Bundler, gtsam::EssentialMatrix, gtsam::imuBias::ConstantBias, gtsam::NavState, Vector, Matrix}>
+  template<T = {gtsam::Point2, gtsam::Point3, gtsam::Rot2, gtsam::Pose2, gtsam::SO3, gtsam::SO4, gtsam::SOn, gtsam::Rot3, gtsam::Pose3, gtsam::Unit3, gtsam::Cal3_S2, gtsam::Cal3DS2, gtsam::Cal3Bundler, gtsam::EssentialMatrix, gtsam::PinholeCameraCal3_S2, gtsam::PinholeCamera<gtsam::Cal3Bundler>, gtsam::imuBias::ConstantBias, gtsam::NavState, Vector, Matrix}>
   T at(size_t j);
 
   /// version for double
@@ -2491,6 +2426,8 @@ class ISAM2Result {
   size_t getVariablesRelinearized() const;
   size_t getVariablesReeliminated() const;
   size_t getCliques() const;
+  double getErrorBefore() const;
+  double getErrorAfter() const;
 };
 
 class ISAM2 {
@@ -2507,16 +2444,17 @@ class ISAM2 {
   gtsam::ISAM2Result update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta);
   gtsam::ISAM2Result update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::FactorIndices& removeFactorIndices);
   gtsam::ISAM2Result update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::FactorIndices& removeFactorIndices, const gtsam::KeyGroupMap& constrainedKeys);
-  // TODO: wrap the full version of update
- //void update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::KeyVector& removeFactorIndices, FastMap<Key,int>& constrainedKeys);
-  //void update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::KeyVector& removeFactorIndices, FastMap<Key,int>& constrainedKeys, bool force_relinearize);
+  gtsam::ISAM2Result update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::FactorIndices& removeFactorIndices, gtsam::KeyGroupMap& constrainedKeys, const gtsam::KeyList& noRelinKeys);
+  gtsam::ISAM2Result update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::FactorIndices& removeFactorIndices, gtsam::KeyGroupMap& constrainedKeys, const gtsam::KeyList& noRelinKeys, const gtsam::KeyList& extraReelimKeys);
+  gtsam::ISAM2Result update(const gtsam::NonlinearFactorGraph& newFactors, const gtsam::Values& newTheta, const gtsam::FactorIndices& removeFactorIndices, gtsam::KeyGroupMap& constrainedKeys, const gtsam::KeyList& noRelinKeys, const gtsam::KeyList& extraReelimKeys, bool force_relinearize);
 
   gtsam::Values getLinearizationPoint() const;
   gtsam::Values calculateEstimate() const;
   template <VALUE = {gtsam::Point2, gtsam::Rot2, gtsam::Pose2, gtsam::Point3,
                      gtsam::Rot3, gtsam::Pose3, gtsam::Cal3_S2, gtsam::Cal3DS2,
                      gtsam::Cal3Bundler, gtsam::EssentialMatrix,
-                     gtsam::SimpleCamera, gtsam::PinholeCameraCal3_S2, Vector, Matrix}>
+                     gtsam::PinholeCameraCal3_S2, gtsam::PinholeCamera<gtsam::Cal3Bundler>, 
+                     Vector, Matrix}>
   VALUE calculateEstimate(size_t key) const;
   gtsam::Values calculateBestEstimate() const;
   Matrix marginalCovariance(size_t key) const;
@@ -2549,12 +2487,11 @@ class NonlinearISAM {
 //*************************************************************************
 // Nonlinear factor types
 //*************************************************************************
-#include <gtsam/geometry/SimpleCamera.h>
 #include <gtsam/geometry/CalibratedCamera.h>
 #include <gtsam/geometry/StereoPoint2.h>
 
 #include <gtsam/nonlinear/PriorFactor.h>
-template<T = {Vector, gtsam::Point2, gtsam::StereoPoint2, gtsam::Point3, gtsam::Rot2, gtsam::SO3, gtsam::SO4, gtsam::SOn, gtsam::Rot3, gtsam::Pose2, gtsam::Pose3, gtsam::Cal3_S2,gtsam::CalibratedCamera, gtsam::SimpleCamera, gtsam::PinholeCameraCal3_S2, gtsam::imuBias::ConstantBias}>
+template<T = {Vector, gtsam::Point2, gtsam::StereoPoint2, gtsam::Point3, gtsam::Rot2, gtsam::SO3, gtsam::SO4, gtsam::SOn, gtsam::Rot3, gtsam::Pose2, gtsam::Pose3, gtsam::Unit3, gtsam::Cal3_S2,gtsam::CalibratedCamera, gtsam::PinholeCameraCal3_S2, gtsam::imuBias::ConstantBias, gtsam::PinholeCamera<gtsam::Cal3Bundler>}>
 virtual class PriorFactor : gtsam::NoiseModelFactor {
   PriorFactor(size_t key, const T& prior, const gtsam::noiseModel::Base* noiseModel);
   T prior() const;
@@ -2578,7 +2515,7 @@ virtual class BetweenFactor : gtsam::Noi
 template <T = {gtsam::Point2, gtsam::StereoPoint2, gtsam::Point3, gtsam::Rot2,
                gtsam::SO3, gtsam::SO4, gtsam::SOn, gtsam::Rot3, gtsam::Pose2,
                gtsam::Pose3, gtsam::Cal3_S2, gtsam::CalibratedCamera,
-               gtsam::SimpleCamera, gtsam::PinholeCameraCal3_S2,
+               gtsam::PinholeCameraCal3_S2,
                gtsam::imuBias::ConstantBias}>
 virtual class NonlinearEquality : gtsam::NoiseModelFactor {
   // Constructor - forces exact evaluation
@@ -2641,8 +2578,7 @@ class BearingRange {
   BearingRange(const BEARING& b, const RANGE& r);
   BEARING bearing() const;
   RANGE range() const;
-  // TODO(frank): can't class instance itself?
-  // static gtsam::BearingRange Measure(const POSE& pose, const POINT& point);
+  static This Measure(const POSE& pose, const POINT& point);
   static BEARING MeasureBearing(const POSE& pose, const POINT& point);
   static RANGE MeasureRange(const POSE& pose, const POINT& point);
   void print(string s) const;
@@ -2698,8 +2634,9 @@ virtual class GeneralSFMFactor : gtsam::
   gtsam::Point2 measured() const;
 };
 typedef gtsam::GeneralSFMFactor<gtsam::PinholeCameraCal3_S2, gtsam::Point3> GeneralSFMFactorCal3_S2;
-// due to lack of jacobians of Cal3DS2_Base::calibrate, GeneralSFMFactor does not apply to Cal3DS2
+//TODO (Issue 621) due to lack of jacobians of Cal3DS2_Base::calibrate, GeneralSFMFactor does not apply to Cal3DS2
 //typedef gtsam::GeneralSFMFactor<gtsam::PinholeCameraCal3DS2, gtsam::Point3> GeneralSFMFactorCal3DS2;
+typedef gtsam::GeneralSFMFactor<gtsam::PinholeCamera<gtsam::Cal3Bundler>, gtsam::Point3> GeneralSFMFactorCal3Bundler;
 
 template<CALIBRATION = {gtsam::Cal3_S2}>
 virtual class GeneralSFMFactor2 : gtsam::NoiseModelFactor {
@@ -2786,21 +2723,39 @@ virtual class EssentialMatrixFactor : gt
 };
 
 #include <gtsam/slam/dataset.h>
+
 class SfmTrack {
+  SfmTrack();
+  SfmTrack(const gtsam::Point3& pt);
+  const Point3& point3() const;
+
+  double r;
+  double g;
+  double b;
+  // TODO Need to close wrap#10 to allow this to work.
+  // std::vector<pair<size_t, gtsam::Point2>> measurements;
+
   size_t number_measurements() const;
   pair<size_t, gtsam::Point2> measurement(size_t idx) const;
   pair<size_t, size_t> siftIndex(size_t idx) const;
+  void add_measurement(size_t idx, const gtsam::Point2& m);
 };
 
 class SfmData {
+  SfmData();
   size_t number_cameras() const;
   size_t number_tracks() const;
-  //TODO(Varun) Need to fix issue #237 first before this can work
-  // gtsam::PinholeCamera<gtsam::Cal3Bundler> camera(size_t idx) const;
+  gtsam::PinholeCamera<gtsam::Cal3Bundler> camera(size_t idx) const;
   gtsam::SfmTrack track(size_t idx) const;
+  void add_track(const gtsam::SfmTrack& t) ;
+  void add_camera(const gtsam::SfmCamera& cam);
 };
 
-string findExampleDataFile(string name);
+gtsam::SfmData readBal(string filename);
+bool writeBAL(string filename, gtsam::SfmData& data);
+gtsam::Values initialCamerasEstimate(const gtsam::SfmData& db);
+gtsam::Values initialCamerasAndPointsEstimate(const gtsam::SfmData& db);
+
 pair<gtsam::NonlinearFactorGraph*, gtsam::Values*> load2D(string filename,
     gtsam::noiseModel::Diagonal* model, int maxIndex, bool addNoise, bool smart);
 pair<gtsam::NonlinearFactorGraph*, gtsam::Values*> load2D(string filename,
@@ -2909,11 +2864,19 @@ class BinaryMeasurement {
   size_t key1() const;
   size_t key2() const;
   T measured() const;
+  gtsam::noiseModel::Base* noiseModel() const;
 };
 
 typedef gtsam::BinaryMeasurement<gtsam::Unit3> BinaryMeasurementUnit3;
 typedef gtsam::BinaryMeasurement<gtsam::Rot3> BinaryMeasurementRot3;
 
+class BinaryMeasurementsUnit3 {
+  BinaryMeasurementsUnit3();
+  size_t size() const;
+  gtsam::BinaryMeasurement<gtsam::Unit3> at(size_t idx) const;
+  void push_back(const gtsam::BinaryMeasurement<gtsam::Unit3>& measurement);
+};
+
 #include <gtsam/sfm/ShonanAveraging.h>
 
 // TODO(frank): copy/pasta below until we have integer template paremeters in wrap!
@@ -2925,6 +2888,7 @@ class ShonanAveragingParameters2 {
   void setOptimalityThreshold(double value);
   double getOptimalityThreshold() const;
   void setAnchor(size_t index, const gtsam::Rot2& value);
+  pair<size_t, gtsam::Rot2> getAnchor();
   void setAnchorWeight(double value);
   double getAnchorWeight() const;
   void setKarcherWeight(double value);
@@ -2940,6 +2904,7 @@ class ShonanAveragingParameters3 {
   void setOptimalityThreshold(double value);
   double getOptimalityThreshold() const;
   void setAnchor(size_t index, const gtsam::Rot3& value);
+  pair<size_t, gtsam::Rot3> getAnchor();
   void setAnchorWeight(double value);
   double getAnchorWeight() const;
   void setKarcherWeight(double value);
@@ -3033,6 +2998,36 @@ class ShonanAveraging3 {
   pair<gtsam::Values, double> run(const gtsam::Values& initial, size_t min_p, size_t max_p) const;
 };
 
+#include <gtsam/sfm/MFAS.h>
+
+class KeyPairDoubleMap {
+  KeyPairDoubleMap();
+  KeyPairDoubleMap(const gtsam::KeyPairDoubleMap& other);
+
+  size_t size() const;
+  bool empty() const;
+  void clear();
+  size_t at(const pair<size_t, size_t>& keypair) const;
+};
+
+class MFAS {
+  MFAS(const gtsam::BinaryMeasurementsUnit3& relativeTranslations,
+       const gtsam::Unit3& projectionDirection);
+
+  gtsam::KeyPairDoubleMap computeOutlierWeights() const;
+  gtsam::KeyVector computeOrdering() const;
+};
+
+#include <gtsam/sfm/TranslationRecovery.h>
+class TranslationRecovery {
+  TranslationRecovery(const gtsam::BinaryMeasurementsUnit3 &relativeTranslations,
+                      const gtsam::LevenbergMarquardtParams &lmParams);
+  TranslationRecovery(
+      const gtsam::BinaryMeasurementsUnit3 & relativeTranslations);  // default LevenbergMarquardtParams
+  gtsam::Values run(const double scale) const;
+  gtsam::Values run() const;    // default scale = 1.0
+};
+
 //*************************************************************************
 // Navigation
 //*************************************************************************
--- gtsam-4.1.0.orig/gtsam/inference/Symbol.h
+++ gtsam-4.1.0/gtsam/inference/Symbol.h
@@ -164,8 +164,16 @@ inline Key Y(std::uint64_t j) { return S
 inline Key Z(std::uint64_t j) { return Symbol('z', j); }
 }
 
+/** Generates symbol shorthands with alternative names different than the
+ * one-letter predefined ones. */
+class SymbolGenerator {
+  const char c_;
+public:
+  SymbolGenerator(const char c) : c_(c) {}
+  Symbol operator()(const std::uint64_t j) const { return Symbol(c_, j); }
+};
+
 /// traits
 template<> struct traits<Symbol> : public Testable<Symbol> {};
 
 } // \ namespace gtsam
-
--- gtsam-4.1.0.orig/gtsam/inference/tests/testKey.cpp
+++ gtsam-4.1.0/gtsam/inference/tests/testKey.cpp
@@ -41,6 +41,25 @@ TEST(Key, KeySymbolConversion) {
 }
 
 /* ************************************************************************* */
+TEST(Key, SymbolGenerator) {
+  const auto x1 = gtsam::symbol_shorthand::X(1);
+  const auto v1 = gtsam::symbol_shorthand::V(1);
+  const auto a1 = gtsam::symbol_shorthand::A(1);
+
+  const auto Z = gtsam::SymbolGenerator('x');
+  const auto DZ = gtsam::SymbolGenerator('v');
+  const auto DDZ = gtsam::SymbolGenerator('a');
+
+  const auto z1 = Z(1);
+  const auto dz1 = DZ(1);
+  const auto ddz1 = DDZ(1);
+
+  EXPECT(assert_equal(x1, z1));
+  EXPECT(assert_equal(v1, dz1));
+  EXPECT(assert_equal(a1, ddz1));
+}
+
+/* ************************************************************************* */
 template<int KeySize>
 Key KeyTestValue();
 
@@ -106,4 +125,3 @@ int main() {
   return TestRegistry::runAllTests(tr);
 }
 /* ************************************************************************* */
-
--- gtsam-4.1.0.orig/gtsam/linear/SubgraphBuilder.cpp
+++ gtsam-4.1.0/gtsam/linear/SubgraphBuilder.cpp
@@ -383,7 +383,7 @@ Subgraph SubgraphBuilder::operator()(con
   const vector<size_t> tree = buildTree(gfg, forward_ordering, weights);
   if (tree.size() != n - 1) {
     throw std::runtime_error(
-        "SubgraphBuilder::operator() failure: tree.size() != n-1");
+        "SubgraphBuilder::operator() failure: tree.size() != n-1, might be caused by disconnected graph");
   }
 
   // Downweight the tree edges to zero.
--- gtsam-4.1.0.orig/gtsam/navigation/AHRSFactor.h
+++ gtsam-4.1.0/gtsam/navigation/AHRSFactor.h
@@ -42,7 +42,7 @@ class GTSAM_EXPORT PreintegratedAhrsMeas
 
  public:
 
-  /// Default constructor, only for serialization and Cython wrapper
+  /// Default constructor, only for serialization and wrappers
   PreintegratedAhrsMeasurements() {}
 
   /**
--- gtsam-4.1.0.orig/gtsam/navigation/CombinedImuFactor.h
+++ gtsam-4.1.0/gtsam/navigation/CombinedImuFactor.h
@@ -145,7 +145,7 @@ public:
   /// @name Constructors
   /// @{
 
-  /// Default constructor only for serialization and Cython wrapper
+  /// Default constructor only for serialization and wrappers
   PreintegratedCombinedMeasurements() {
     preintMeasCov_.setZero();
   }
--- gtsam-4.1.0.orig/gtsam/navigation/ImuFactor.h
+++ gtsam-4.1.0/gtsam/navigation/ImuFactor.h
@@ -80,7 +80,7 @@ protected:
 
 public:
 
-  /// Default constructor for serialization and Cython wrapper
+  /// Default constructor for serialization and wrappers
   PreintegratedImuMeasurements() {
     preintMeasCov_.setZero();
   }
--- gtsam-4.1.0.orig/gtsam/navigation/NavState.cpp
+++ gtsam-4.1.0/gtsam/navigation/NavState.cpp
@@ -89,8 +89,8 @@ Matrix7 NavState::matrix() const {
 //------------------------------------------------------------------------------
 ostream& operator<<(ostream& os, const NavState& state) {
   os << "R: " << state.attitude() << "\n";
-  os << "p: " << state.position() << "\n";
-  os << "v: " << Point3(state.velocity());
+  os << "p: " << state.position().transpose() << "\n";
+  os << "v: " << state.velocity().transpose();
   return os;
 }
 
@@ -218,28 +218,37 @@ Vector9 NavState::coriolis(double dt, co
   const double dt2 = dt * dt;
   const Vector3 omega_cross_vel = omega.cross(n_v);
 
-  Vector9 xi;
-  Matrix3 D_dP_R;
-  dR(xi) << nRb.unrotate((-dt) * omega, H ? &D_dP_R : 0);
-  dP(xi) << ((-dt2) * omega_cross_vel); // NOTE(luca): we got rid of the 2 wrt INS paper
-  dV(xi) << ((-2.0 * dt) * omega_cross_vel);
+  // Get perturbations in nav frame
+  Vector9 n_xi, xi;
+  Matrix3 D_dR_R, D_dP_R, D_dV_R, D_body_nav;
+  dR(n_xi) << ((-dt) * omega);
+  dP(n_xi) << ((-dt2) * omega_cross_vel); // NOTE(luca): we got rid of the 2 wrt INS paper
+  dV(n_xi) << ((-2.0 * dt) * omega_cross_vel);
   if (secondOrder) {
     const Vector3 omega_cross2_t = omega.cross(omega.cross(n_t));
-    dP(xi) -= (0.5 * dt2) * omega_cross2_t;
-    dV(xi) -= dt * omega_cross2_t;
+    dP(n_xi) -= (0.5 * dt2) * omega_cross2_t;
+    dV(n_xi) -= dt * omega_cross2_t;
   }
+
+  // Transform n_xi into the body frame
+  xi << nRb.unrotate(dR(n_xi), H ? &D_dR_R : 0, H ? &D_body_nav : 0), 
+        nRb.unrotate(dP(n_xi), H ? &D_dP_R : 0),
+        nRb.unrotate(dV(n_xi), H ? &D_dV_R : 0);
+
   if (H) {
     H->setZero();
     const Matrix3 Omega = skewSymmetric(omega);
     const Matrix3 D_cross_state = Omega * R();
     H->setZero();
-    D_R_R(H) << D_dP_R;
-    D_t_v(H) << (-dt2) * D_cross_state;
-    D_v_v(H) << (-2.0 * dt) * D_cross_state;
+    D_R_R(H) << D_dR_R;
+    D_t_v(H) << D_body_nav * (-dt2) * D_cross_state;
+    D_t_R(H) << D_dP_R;
+    D_v_v(H) << D_body_nav * (-2.0 * dt) * D_cross_state;
+    D_v_R(H) << D_dV_R;
     if (secondOrder) {
       const Matrix3 D_cross2_state = Omega * D_cross_state;
-      D_t_t(H) -= (0.5 * dt2) * D_cross2_state;
-      D_v_t(H) -= dt * D_cross2_state;
+      D_t_t(H) -= D_body_nav * (0.5 * dt2) * D_cross2_state;
+      D_v_t(H) -= D_body_nav * dt * D_cross2_state;
     }
   }
   return xi;
--- gtsam-4.1.0.orig/gtsam/navigation/tests/testNavState.cpp
+++ gtsam-4.1.0/gtsam/navigation/tests/testNavState.cpp
@@ -192,6 +192,49 @@ TEST(NavState, Coriolis2) {
   EXPECT(assert_equal(numericalDerivative21(coriolis, state2, true), aH));
 }
 
+TEST(NavState, Coriolis3) {
+  /** Consider a massless planet with an attached nav frame at 
+   *  n_omega = [0 0 1]', and a body at position n_t = [1 0 0]', travelling with 
+   *  velocity n_v = [0 1 0]'. Orient the body so that it is not instantaneously
+   *  aligned with the nav frame (i.e., nRb != I_3x3). Test that first and 
+   *  second order Coriolis corrections are as expected.
+   */
+
+  // Get true first and second order coriolis accelerations
+  double dt = 2.0, dt2 = dt * dt;
+  Vector3 n_omega(0.0, 0.0, 1.0), n_t(1.0, 0.0, 0.0), n_v(0.0, 1.0, 0.0);
+  Vector3 n_aCorr1 = -2.0 * n_omega.cross(n_v),
+          n_aCorr2 = -n_omega.cross(n_omega.cross(n_t));
+  Rot3 nRb = Rot3(-1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0),
+       bRn = nRb.inverse();
+
+  // Get expected first and second order corrections in the nav frame
+  Vector3 n_dP1e = 0.5 * dt2 * n_aCorr1, 
+          n_dP2e = 0.5 * dt2 * (n_aCorr1 + n_aCorr2),
+          n_dV1e = dt * n_aCorr1, 
+          n_dV2e = dt * (n_aCorr1 + n_aCorr2);
+
+  // Get expected first and second order corrections in the body frame
+  Vector3 dRe = -dt * (bRn * n_omega),
+          b_dP1e = bRn * n_dP1e, b_dP2e = bRn * n_dP2e,
+          b_dV1e = bRn * n_dV1e, b_dV2e = bRn * n_dV2e;
+
+  // Get actual first and scond order corrections in body frame
+  NavState kState2(nRb, n_t, n_v);
+  Vector9 dXi1a = kState2.coriolis(dt, n_omega, false),
+          dXi2a = kState2.coriolis(dt, n_omega, true);
+  Vector3 dRa = NavState::dR(dXi1a),
+          b_dP1a = NavState::dP(dXi1a), b_dV1a = NavState::dV(dXi1a),
+          b_dP2a = NavState::dP(dXi2a), b_dV2a = NavState::dV(dXi2a);
+
+  EXPECT(assert_equal(dRe, dRa));
+  EXPECT(assert_equal(b_dP1e, b_dP1a));
+  EXPECT(assert_equal(b_dV1e, b_dV1a));
+  EXPECT(assert_equal(b_dP2e, b_dP2a));
+  EXPECT(assert_equal(b_dV2e, b_dV2a));
+
+}
+
 /* ************************************************************************* */
 TEST(NavState, CorrectPIM) {
   Vector9 xi;
@@ -215,7 +258,7 @@ TEST(NavState, Stream)
   os << state;
 
   string expected;
-  expected = "R: [\n\t1, 0, 0;\n\t0, 1, 0;\n\t0, 0, 1\n]\np: 0\n0\n0\nv: 0\n0\n0";
+  expected = "R: [\n\t1, 0, 0;\n\t0, 1, 0;\n\t0, 0, 1\n]\np: 0 0 0\nv: 0 0 0";
 
   EXPECT(os.str() == expected);
 }
--- gtsam-4.1.0.orig/gtsam/nonlinear/ISAM2Result.h
+++ gtsam-4.1.0/gtsam/nonlinear/ISAM2Result.h
@@ -176,6 +176,8 @@ struct ISAM2Result {
   size_t getVariablesRelinearized() const { return variablesRelinearized; }
   size_t getVariablesReeliminated() const { return variablesReeliminated; }
   size_t getCliques() const { return cliques; }
+  double getErrorBefore() const { return errorBefore ? *errorBefore : std::nan(""); }
+  double getErrorAfter() const { return errorAfter ? *errorAfter : std::nan(""); }
 };
 
 }  // namespace gtsam
--- gtsam-4.1.0.orig/gtsam/nonlinear/Marginals.h
+++ gtsam-4.1.0/gtsam/nonlinear/Marginals.h
@@ -48,7 +48,7 @@ protected:
 
 public:
 
-  /// Default constructor only for Cython wrapper
+  /// Default constructor only for wrappers
   Marginals(){}
 
   /** Construct a marginals class from a nonlinear factor graph.
@@ -156,7 +156,7 @@ protected:
   FastMap<Key, size_t> indices_;
 
 public:
-  /// Default constructor only for Cython wrapper
+  /// Default constructor only for wrappers
   JointMarginal() {}
 
   /** Access a block, corresponding to a pair of variables, of the joint
--- gtsam-4.1.0.orig/gtsam/nonlinear/NonlinearConjugateGradientOptimizer.h
+++ gtsam-4.1.0/gtsam/nonlinear/NonlinearConjugateGradientOptimizer.h
@@ -200,6 +200,10 @@ boost::tuple<V, int> nonlinearConjugateG
     currentValues = system.advance(prevValues, alpha, direction);
     currentError = system.error(currentValues);
 
+    // User hook:
+    if (params.iterationHook)
+      params.iterationHook(iteration, prevError, currentError);
+
     // Maybe show output
     if (params.verbosity >= NonlinearOptimizerParams::ERROR)
       std::cout << "iteration: " << iteration << ", currentError: " << currentError << std::endl;
--- gtsam-4.1.0.orig/gtsam/nonlinear/NonlinearFactorGraph.cpp
+++ gtsam-4.1.0/gtsam/nonlinear/NonlinearFactorGraph.cpp
@@ -205,42 +205,49 @@ void NonlinearFactorGraph::saveGraph(std
     // Create factors and variable connections
     for(size_t i = 0; i < size(); ++i) {
       const NonlinearFactor::shared_ptr& factor = at(i);
-      if(formatting.plotFactorPoints) {
+      // If null pointer, move on to the next
+      if (!factor) {
+        continue;
+      }
+
+      if (formatting.plotFactorPoints) {
         const KeyVector& keys = factor->keys();
-        if (formatting.binaryEdges && keys.size()==2) {
-          stm << "  var" << keys[0] << "--" << "var" << keys[1] << ";\n";
+        if (formatting.binaryEdges && keys.size() == 2) {
+          stm << "  var" << keys[0] << "--"
+              << "var" << keys[1] << ";\n";
         } else {
           // Make each factor a dot
           stm << "  factor" << i << "[label=\"\", shape=point";
           {
-            map<size_t, Point2>::const_iterator pos = formatting.factorPositions.find(i);
-            if(pos != formatting.factorPositions.end())
-              stm << ", pos=\"" << formatting.scale*(pos->second.x() - minX) << ","
-                  << formatting.scale*(pos->second.y() - minY) << "!\"";
+            map<size_t, Point2>::const_iterator pos =
+                formatting.factorPositions.find(i);
+            if (pos != formatting.factorPositions.end())
+              stm << ", pos=\"" << formatting.scale * (pos->second.x() - minX)
+                  << "," << formatting.scale * (pos->second.y() - minY)
+                  << "!\"";
           }
           stm << "];\n";
 
           // Make factor-variable connections
-          if(formatting.connectKeysToFactor && factor) {
-            for(Key key: *factor) {
-              stm << "  var" << key << "--" << "factor" << i << ";\n";
+          if (formatting.connectKeysToFactor && factor) {
+            for (Key key : *factor) {
+              stm << "  var" << key << "--"
+                  << "factor" << i << ";\n";
             }
           }
         }
-      }
-      else {
-        if(factor) {
-          Key k;
-          bool firstTime = true;
-          for(Key key: *this->at(i)) {
-            if(firstTime) {
-              k = key;
-              firstTime = false;
-              continue;
-            }
-            stm << "  var" << key << "--" << "var" << k << ";\n";
+      } else {
+        Key k;
+        bool firstTime = true;
+        for (Key key : *this->at(i)) {
+          if (firstTime) {
             k = key;
+            firstTime = false;
+            continue;
           }
+          stm << "  var" << key << "--"
+              << "var" << k << ";\n";
+          k = key;
         }
       }
     }
--- gtsam-4.1.0.orig/gtsam/nonlinear/NonlinearOptimizer.cpp
+++ gtsam-4.1.0/gtsam/nonlinear/NonlinearOptimizer.cpp
@@ -88,20 +88,28 @@ void NonlinearOptimizer::defaultOptimize
   }
 
   // Iterative loop
+  double newError = currentError; // used to avoid repeated calls to error()
   do {
     // Do next iteration
-    currentError = error(); // TODO(frank): don't do this twice at first !? Computed above!
+    currentError = newError;
     iterate();
     tictoc_finishedIteration();
 
+    // Update newError for either printouts or conditional-end checks:
+    newError = error();
+
+    // User hook:
+    if (params.iterationHook)
+      params.iterationHook(iterations(), currentError, newError);
+
     // Maybe show output
     if (params.verbosity >= NonlinearOptimizerParams::VALUES)
       values().print("newValues");
     if (params.verbosity >= NonlinearOptimizerParams::ERROR)
-      cout << "newError: " << error() << endl;
+      cout << "newError: " << newError << endl;
   } while (iterations() < params.maxIterations &&
            !checkConvergence(params.relativeErrorTol, params.absoluteErrorTol, params.errorTol,
-                             currentError, error(), params.verbosity) && std::isfinite(currentError));
+                             currentError, newError, params.verbosity) && std::isfinite(currentError));
 
   // Printing if verbose
   if (params.verbosity >= NonlinearOptimizerParams::TERMINATION) {
--- gtsam-4.1.0.orig/gtsam/nonlinear/NonlinearOptimizer.h
+++ gtsam-4.1.0/gtsam/nonlinear/NonlinearOptimizer.h
@@ -81,7 +81,7 @@ protected:
 
 public:
   /** A shared pointer to this class */
-  typedef boost::shared_ptr<const NonlinearOptimizer> shared_ptr;
+  using shared_ptr = boost::shared_ptr<const NonlinearOptimizer>;
 
   /// @name Standard interface
   /// @{
--- gtsam-4.1.0.orig/gtsam/nonlinear/NonlinearOptimizerParams.h
+++ gtsam-4.1.0/gtsam/nonlinear/NonlinearOptimizerParams.h
@@ -38,21 +38,12 @@ public:
     SILENT, TERMINATION, ERROR, VALUES, DELTA, LINEAR
   };
 
-  size_t maxIterations; ///< The maximum iterations to stop iterating (default 100)
-  double relativeErrorTol; ///< The maximum relative error decrease to stop iterating (default 1e-5)
-  double absoluteErrorTol; ///< The maximum absolute error decrease to stop iterating (default 1e-5)
-  double errorTol; ///< The maximum total error to stop iterating (default 0.0)
-  Verbosity verbosity; ///< The printing verbosity during optimization (default SILENT)
-  Ordering::OrderingType orderingType; ///< The method of ordering use during variable elimination (default COLAMD)
-
-  NonlinearOptimizerParams() :
-      maxIterations(100), relativeErrorTol(1e-5), absoluteErrorTol(1e-5), errorTol(
-          0.0), verbosity(SILENT), orderingType(Ordering::COLAMD),
-          linearSolverType(MULTIFRONTAL_CHOLESKY) {}
-
-  virtual ~NonlinearOptimizerParams() {
-  }
-  virtual void print(const std::string& str = "") const;
+  size_t maxIterations = 100; ///< The maximum iterations to stop iterating (default 100)
+  double relativeErrorTol = 1e-5; ///< The maximum relative error decrease to stop iterating (default 1e-5)
+  double absoluteErrorTol = 1e-5; ///< The maximum absolute error decrease to stop iterating (default 1e-5)
+  double errorTol = 0.0; ///< The maximum total error to stop iterating (default 0.0)
+  Verbosity verbosity = SILENT; ///< The printing verbosity during optimization (default SILENT)
+  Ordering::OrderingType orderingType = Ordering::COLAMD; ///< The method of ordering use during variable elimination (default COLAMD)
 
   size_t getMaxIterations() const { return maxIterations; }
   double getRelativeErrorTol() const { return relativeErrorTol; }
@@ -71,6 +62,37 @@ public:
   static Verbosity verbosityTranslator(const std::string &s) ;
   static std::string verbosityTranslator(Verbosity value) ;
 
+  /** Type for an optional user-provided hook to be called after each
+   * internal optimizer iteration. See iterationHook below. */
+  using IterationHook = std::function<
+    void(size_t /*iteration*/, double/*errorBefore*/, double/*errorAfter*/)>;
+
+  /** Optional user-provided iteration hook to be called after each
+   * optimization iteration (Default: none).
+   * Note that `IterationHook` is defined as a std::function<> with this
+   * signature:
+   * \code
+   *  void(size_t iteration, double errorBefore, double errorAfter)
+   * \endcode
+   * which allows binding by means of a reference to a regular function:
+   * \code
+   *  void foo(size_t iteration, double errorBefore, double errorAfter);
+   *  // ...
+   *  lmOpts.iterationHook = &foo;
+   * \endcode
+   * or to a C++11 lambda (preferred if you need to capture additional
+   * context variables, such that the optimizer object itself, the factor graph,
+   * etc.):
+   * \code
+   *  lmOpts.iterationHook = [&](size_t iter, double oldError, double newError)
+   *  {
+   *    // ...
+   *  };
+   * \endcode
+   * or to the result of a properly-formed `std::bind` call.
+   */
+  IterationHook iterationHook;
+
   /** See NonlinearOptimizerParams::linearSolverType */
   enum LinearSolverType {
     MULTIFRONTAL_CHOLESKY,
@@ -81,10 +103,16 @@ public:
     CHOLMOD, /* Experimental Flag */
   };
 
-  LinearSolverType linearSolverType; ///< The type of linear solver to use in the nonlinear optimizer
+  LinearSolverType linearSolverType = MULTIFRONTAL_CHOLESKY; ///< The type of linear solver to use in the nonlinear optimizer
   boost::optional<Ordering> ordering; ///< The optional variable elimination ordering, or empty to use COLAMD (default: empty)
   IterativeOptimizationParameters::shared_ptr iterativeParams; ///< The container for iterativeOptimization parameters. used in CG Solvers.
 
+  NonlinearOptimizerParams() = default;
+  virtual ~NonlinearOptimizerParams() {
+  }
+
+  virtual void print(const std::string& str = "") const;
+
   inline bool isMultifrontal() const {
     return (linearSolverType == MULTIFRONTAL_CHOLESKY)
         || (linearSolverType == MULTIFRONTAL_QR);
--- gtsam-4.1.0.orig/gtsam/nonlinear/Values-inl.h
+++ gtsam-4.1.0/gtsam/nonlinear/Values-inl.h
@@ -338,19 +338,18 @@ namespace gtsam {
    }  // internal
 
    /* ************************************************************************* */
-   template<typename ValueType>
-   ValueType Values::at(Key j) const {
+   template <typename ValueType>
+   const ValueType Values::at(Key j) const {
      // Find the item
      KeyValueMap::const_iterator item = values_.find(j);
 
      // Throw exception if it does not exist
-     if(item == values_.end())
-       throw ValuesKeyDoesNotExist("at", j);
+     if (item == values_.end()) throw ValuesKeyDoesNotExist("at", j);
 
-    // Check the type and throw exception if incorrect
-    // h() split in two lines to avoid internal compiler error (MSVC2017)
-    auto h = internal::handle<ValueType>();
-    return h(j,item->second);
+     // Check the type and throw exception if incorrect
+     // h() split in two lines to avoid internal compiler error (MSVC2017)
+     auto h = internal::handle<ValueType>();
+     return h(j, item->second);
   }
 
   /* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/nonlinear/Values.h
+++ gtsam-4.1.0/gtsam/nonlinear/Values.h
@@ -187,8 +187,8 @@ namespace gtsam {
      * Dynamic matrices/vectors can be retrieved as fixed-size, but not vice-versa.
      * @return The stored value
      */
-    template<typename ValueType>
-    ValueType at(Key j) const;
+    template <typename ValueType>
+    const ValueType at(Key j) const;
 
     /// version for double
     double atDouble(size_t key) const { return at<double>(key);}
--- gtsam-4.1.0.orig/gtsam/nonlinear/tests/testAdaptAutoDiff.cpp
+++ gtsam-4.1.0/gtsam/nonlinear/tests/testAdaptAutoDiff.cpp
@@ -41,7 +41,7 @@ struct Cal3Bundler0 : public Cal3Bundler
                double v0 = 0)
       : Cal3Bundler(f, k1, k2, u0, v0) {}
   Cal3Bundler0 retract(const Vector& d) const {
-    return Cal3Bundler0(fx() + d(0), k1() + d(1), k2() + d(2), u0(), v0());
+    return Cal3Bundler0(fx() + d(0), k1() + d(1), k2() + d(2), px(), py());
   }
   Vector3 localCoordinates(const Cal3Bundler0& T2) const {
     return T2.vector() - vector();
--- gtsam-4.1.0.orig/gtsam/nonlinear/tests/testFunctorizedFactor.cpp
+++ gtsam-4.1.0/gtsam/nonlinear/tests/testFunctorizedFactor.cpp
@@ -19,6 +19,7 @@
 
 #include <CppUnitLite/TestHarness.h>
 #include <gtsam/base/Testable.h>
+#include <gtsam/base/TestableAssertions.h>
 #include <gtsam/inference/Symbol.h>
 #include <gtsam/nonlinear/FunctorizedFactor.h>
 #include <gtsam/nonlinear/factorTesting.h>
@@ -115,16 +116,6 @@ TEST(FunctorizedFactor, Print) {
   auto factor =
       MakeFunctorizedFactor<Matrix>(key, X, model, MultiplyFunctor(multiplier));
 
-  // redirect output to buffer so we can compare
-  stringstream buffer;
-  streambuf *old = cout.rdbuf(buffer.rdbuf());
-
-  factor.print();
-
-  // get output string and reset stdout
-  string actual = buffer.str();
-  cout.rdbuf(old);
-
   string expected =
       "  keys = { X0 }\n"
       "  noise model: unit (9) \n"
@@ -135,7 +126,7 @@ TEST(FunctorizedFactor, Print) {
       "]\n"
       "  noise model sigmas: 1 1 1 1 1 1 1 1 1\n";
 
-  CHECK_EQUAL(expected, actual);
+  EXPECT(assert_print_equal(expected, factor));
 }
 
 /* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/nonlinear/tests/testValues.cpp
+++ gtsam-4.1.0/gtsam/nonlinear/tests/testValues.cpp
@@ -595,15 +595,7 @@ TEST(Values, Demangle) {
   values.insert(key1, v);
   string expected = "Values with 1 values:\nValue v1: (Eigen::Matrix<double, 1, 3, 1, 1, 3>)\n[\n	5, 6, 7\n]\n\n";
 
-  stringstream buffer;
-  streambuf * old = cout.rdbuf(buffer.rdbuf());
-
-  values.print();
-
-  string actual = buffer.str();
-  cout.rdbuf(old);
-
-  EXPECT(assert_equal(expected, actual));
+  EXPECT(assert_print_equal(expected, values));
 }
 
 /* ************************************************************************* */
--- /dev/null
+++ gtsam-4.1.0/gtsam/sfm/MFAS.cpp
@@ -0,0 +1,171 @@
+/**
+ *  @file  MFAS.cpp
+ *  @brief Source file for the MFAS class
+ *  @author Akshay Krishnan
+ *  @date July 2020
+ */
+
+#include <gtsam/sfm/MFAS.h>
+
+#include <algorithm>
+#include <map>
+#include <unordered_map>
+#include <vector>
+#include <unordered_set>
+
+using namespace gtsam;
+using std::map;
+using std::pair;
+using std::unordered_map;
+using std::vector;
+using std::unordered_set;
+
+// A node in the graph.
+struct GraphNode {
+  double inWeightSum;               // Sum of absolute weights of incoming edges
+  double outWeightSum;              // Sum of absolute weights of outgoing edges
+  unordered_set<Key> inNeighbors;   // Nodes from which there is an incoming edge
+  unordered_set<Key> outNeighbors;  // Nodes to which there is an outgoing edge
+
+  // Heuristic for the node that is to select nodes in MFAS.
+  double heuristic() const { return (outWeightSum + 1) / (inWeightSum + 1); }
+};
+
+// A graph is a map from key to GraphNode. This function returns the graph from
+// the edgeWeights between keys.
+unordered_map<Key, GraphNode> graphFromEdges(
+    const map<MFAS::KeyPair, double>& edgeWeights) {
+  unordered_map<Key, GraphNode> graph;
+
+  for (const auto& edgeWeight : edgeWeights) {
+    // The weights can be either negative or positive. The direction of the edge
+    // is the direction of positive weight. This means that the edges is from
+    // edge.first -> edge.second if weight is positive and edge.second ->
+    // edge.first if weight is negative.
+    const MFAS::KeyPair& edge = edgeWeight.first;
+    const double& weight = edgeWeight.second;
+
+    Key edgeSource = weight >= 0 ? edge.first : edge.second;
+    Key edgeDest = weight >= 0 ? edge.second : edge.first;
+
+    // Update the in weight and neighbors for the destination.
+    graph[edgeDest].inWeightSum += std::abs(weight);
+    graph[edgeDest].inNeighbors.insert(edgeSource);
+
+    // Update the out weight and neighbors for the source.
+    graph[edgeSource].outWeightSum += std::abs(weight);
+    graph[edgeSource].outNeighbors.insert(edgeDest);
+  }
+  return graph;
+}
+
+// Selects the next node in the ordering from the graph.
+Key selectNextNodeInOrdering(const unordered_map<Key, GraphNode>& graph) {
+  // Find the root nodes in the graph.
+  for (const auto& keyNode : graph) {
+    // It is a root node if the inWeightSum is close to zero.
+    if (keyNode.second.inWeightSum < 1e-8) {
+      // TODO(akshay-krishnan) if there are multiple roots, it is better to
+      // choose the one with highest heuristic. This is missing in the 1dsfm
+      // solution.
+      return keyNode.first;
+    }
+  }
+  // If there are no root nodes, return the node with the highest heuristic.
+  return std::max_element(graph.begin(), graph.end(),
+                          [](const std::pair<Key, GraphNode>& keyNode1,
+                             const std::pair<Key, GraphNode>& keyNode2) {
+                            return keyNode1.second.heuristic() <
+                                   keyNode2.second.heuristic();
+                          })
+      ->first;
+}
+
+// Returns the absolute weight of the edge between node1 and node2.
+double absWeightOfEdge(const Key key1, const Key key2,
+                       const map<MFAS::KeyPair, double>& edgeWeights) {
+  // Check the direction of the edge before returning.
+  return edgeWeights.find(MFAS::KeyPair(key1, key2)) != edgeWeights.end()
+             ? std::abs(edgeWeights.at(MFAS::KeyPair(key1, key2)))
+             : std::abs(edgeWeights.at(MFAS::KeyPair(key2, key1)));
+}
+
+// Removes a node from the graph and updates edge weights of its neighbors.
+void removeNodeFromGraph(const Key node,
+                         const map<MFAS::KeyPair, double> edgeWeights,
+                         unordered_map<Key, GraphNode>& graph) {
+  // Update the outweights and outNeighbors of node's inNeighbors
+  for (const Key neighbor : graph[node].inNeighbors) {
+    // the edge could be either (*it, choice) with a positive weight or
+    // (choice, *it) with a negative weight
+    graph[neighbor].outWeightSum -=
+        absWeightOfEdge(node, neighbor, edgeWeights);
+    graph[neighbor].outNeighbors.erase(node);
+  }
+  // Update the inWeights and inNeighbors of node's outNeighbors
+  for (const Key neighbor : graph[node].outNeighbors) {
+    graph[neighbor].inWeightSum -= absWeightOfEdge(node, neighbor, edgeWeights);
+    graph[neighbor].inNeighbors.erase(node);
+  }
+  // Erase node.
+  graph.erase(node);
+}
+
+MFAS::MFAS(const TranslationEdges& relativeTranslations,
+           const Unit3& projectionDirection) {
+  // Iterate over edges, obtain weights by projecting
+  // their relativeTranslations along the projection direction
+  for (const auto& measurement : relativeTranslations) {
+    edgeWeights_[std::make_pair(measurement.key1(), measurement.key2())] =
+        measurement.measured().dot(projectionDirection);
+  }
+}
+
+KeyVector MFAS::computeOrdering() const {
+  KeyVector ordering;  // Nodes in MFAS order (result).
+
+  // A graph is an unordered map from keys to nodes. Each node contains a list
+  // of its adjacent nodes. Create the graph from the edgeWeights.
+  unordered_map<Key, GraphNode> graph = graphFromEdges(edgeWeights_);
+
+  // In each iteration, one node is removed from the graph and appended to the
+  // ordering.
+  while (!graph.empty()) {
+    Key selection = selectNextNodeInOrdering(graph);
+    removeNodeFromGraph(selection, edgeWeights_, graph);
+    ordering.push_back(selection);
+  }
+  return ordering;
+}
+
+map<MFAS::KeyPair, double> MFAS::computeOutlierWeights() const {
+  // Find the ordering.
+  KeyVector ordering = computeOrdering();
+
+  // Create a map from the node key to its position in the ordering. This makes
+  // it easier to lookup positions of different nodes.
+  unordered_map<Key, int> orderingPositions;
+  for (size_t i = 0; i < ordering.size(); i++) {
+    orderingPositions[ordering[i]] = i;
+  }
+
+  map<KeyPair, double> outlierWeights;
+  // Check if the direction of each edge is consistent with the ordering.
+  for (const auto& edgeWeight : edgeWeights_) {
+    // Find edge source and destination.
+    Key source = edgeWeight.first.first;
+    Key dest = edgeWeight.first.second;
+    if (edgeWeight.second < 0) {
+      std::swap(source, dest);
+    }
+
+    // If the direction is not consistent with the ordering (i.e dest occurs
+    // before src), it is an outlier edge, and has non-zero outlier weight.
+    if (orderingPositions.at(dest) < orderingPositions.at(source)) {
+      outlierWeights[edgeWeight.first] = std::abs(edgeWeight.second);
+    } else {
+      outlierWeights[edgeWeight.first] = 0;
+    }
+  }
+  return outlierWeights;
+}
--- /dev/null
+++ gtsam-4.1.0/gtsam/sfm/MFAS.h
@@ -0,0 +1,101 @@
+/* ----------------------------------------------------------------------------
+
+ * GTSAM Copyright 2010-2020, Georgia Tech Research Corporation,
+ * Atlanta, Georgia 30332-0415
+ * All Rights Reserved
+ * Authors: Frank Dellaert, et al. (see THANKS for the full author list)
+
+ * See LICENSE for the license information
+
+ * -------------------------------------------------------------------------- */
+
+#pragma once
+
+/**
+ *  @file  MFAS.h
+ *  @brief MFAS class to solve Minimum Feedback Arc Set graph problem
+ *  @author Akshay Krishnan
+ *  @date September 2020
+ */
+
+#include <gtsam/geometry/Unit3.h>
+#include <gtsam/inference/Key.h>
+#include <gtsam/sfm/BinaryMeasurement.h>
+
+#include <memory>
+#include <unordered_map>
+#include <vector>
+
+namespace gtsam {
+
+/**
+  The MFAS class to solve a Minimum feedback arc set (MFAS)
+  problem. We implement the solution from:
+  Kyle Wilson and Noah Snavely, "Robust Global Translations with 1DSfM",
+  Proceedings of the European Conference on Computer Vision, ECCV 2014
+
+  Given a weighted directed graph, the objective in a Minimum feedback arc set
+  problem is to obtain a directed acyclic graph by removing
+  edges such that the total weight of removed edges is minimum.
+
+  Although MFAS is a general graph problem and can be applied in many areas,
+  this classed was designed for the purpose of outlier rejection in a
+  translation averaging for SfM setting. For more details, refer to the above
+  paper. The nodes of the graph in this context represents cameras in 3D and the
+  edges between them represent unit translations in the world coordinate frame,
+  i.e w_aZb is the unit translation from a to b expressed in the world
+  coordinate frame. The weights for the edges are obtained by projecting the
+  unit translations in a projection direction.
+  @addtogroup SFM
+*/
+class MFAS {
+ public:
+  // used to represent edges between two nodes in the graph. When used in
+  // translation averaging for global SfM
+  using KeyPair = std::pair<Key, Key>;
+  using TranslationEdges = std::vector<BinaryMeasurement<Unit3>>;
+
+ private:
+  // edges with a direction such that all weights are positive
+  // i.e, edges that originally had negative weights are flipped
+  std::map<KeyPair, double> edgeWeights_;
+
+ public:
+  /**
+   * @brief Construct from the weighted directed edges
+   * between the nodes. Each node is identified by a Key.
+   * @param edgeWeights: weights of edges in the graph
+   */
+  MFAS(const std::map<KeyPair, double> &edgeWeights)
+      : edgeWeights_(edgeWeights) {}
+
+  /**
+   * @brief Constructor to be used in the context of translation averaging.
+   * Here, the nodes of the graph are cameras in 3D and the edges have a unit
+   * translation direction between them. The weights of the edges is computed by
+   * projecting them along a projection direction.
+   * @param relativeTranslations translation directions between the cameras
+   * @param projectionDirection direction in which edges are to be projected
+   */
+  MFAS(const TranslationEdges &relativeTranslations,
+       const Unit3 &projectionDirection);
+
+  /**
+   * @brief Computes the 1D MFAS ordering of nodes in the graph
+   * @return orderedNodes: vector of nodes in the obtained order
+   */
+  KeyVector computeOrdering() const;
+
+  /**
+   * @brief Computes the outlier weights of the graph. We define the outlier
+   * weight of a edge to be zero if the edge is an inlier and the magnitude of
+   * its edgeWeight if it is an outlier. This function internally calls
+   * computeOrdering and uses the obtained ordering to identify outlier edges.
+   * @return outlierWeights: map from an edge to its outlier weight.
+   */
+  std::map<KeyPair, double> computeOutlierWeights() const;
+};
+
+typedef std::map<std::pair<Key, Key>, double> KeyPairDoubleMap;
+
+}  // namespace gtsam
--- gtsam-4.1.0.orig/gtsam/sfm/ShonanAveraging.cpp
+++ gtsam-4.1.0/gtsam/sfm/ShonanAveraging.cpp
@@ -16,26 +16,25 @@
  * @brief  Shonan Averaging algorithm
  */
 
-#include <gtsam/sfm/ShonanAveraging.h>
-
+#include <SymEigsSolver.h>
 #include <gtsam/linear/PCGSolver.h>
 #include <gtsam/linear/SubgraphPreconditioner.h>
 #include <gtsam/nonlinear/LevenbergMarquardtOptimizer.h>
 #include <gtsam/nonlinear/NonlinearEquality.h>
 #include <gtsam/nonlinear/NonlinearFactorGraph.h>
+#include <gtsam/sfm/ShonanAveraging.h>
+#include <gtsam/sfm/ShonanFactor.h>
 #include <gtsam/sfm/ShonanGaugeFactor.h>
 #include <gtsam/slam/FrobeniusFactor.h>
 #include <gtsam/slam/KarcherMeanFactor-inl.h>
-#include <gtsam/sfm/ShonanFactor.h>
 
 #include <Eigen/Eigenvalues>
-#include <SymEigsSolver.h>
-
 #include <algorithm>
 #include <complex>
 #include <iostream>
 #include <map>
 #include <random>
+#include <set>
 #include <vector>
 
 namespace gtsam {
@@ -50,8 +49,11 @@ template <size_t d>
 ShonanAveragingParameters<d>::ShonanAveragingParameters(
     const LevenbergMarquardtParams &_lm, const std::string &method,
     double optimalityThreshold, double alpha, double beta, double gamma)
-    : lm(_lm), optimalityThreshold(optimalityThreshold), alpha(alpha),
-      beta(beta), gamma(gamma) {
+    : lm(_lm),
+      optimalityThreshold(optimalityThreshold),
+      alpha(alpha),
+      beta(beta),
+      gamma(gamma) {
   // By default, we will do conjugate gradient
   lm.linearSolverType = LevenbergMarquardtParams::Iterative;
 
@@ -92,29 +94,40 @@ template struct ShonanAveragingParameter
 
 /* ************************************************************************* */
 // Calculate number of unknown rotations referenced by measurements
+// Throws exception of keys are not numbered as expected (may change in future).
 template <size_t d>
-static size_t
-NrUnknowns(const typename ShonanAveraging<d>::Measurements &measurements) {
+static size_t NrUnknowns(
+    const typename ShonanAveraging<d>::Measurements &measurements) {
+  Key maxKey = 0;
   std::set<Key> keys;
   for (const auto &measurement : measurements) {
-    keys.insert(measurement.key1());
-    keys.insert(measurement.key2());
+    for (const Key &key : measurement.keys()) {
+      maxKey = std::max(key, maxKey);
+      keys.insert(key);
+    }
+  }
+  size_t N = keys.size();
+  if (maxKey != N - 1) {
+    throw std::invalid_argument(
+        "As of now, ShonanAveraging expects keys numbered 0..N-1");
   }
-  return keys.size();
+  return N;
 }
 
 /* ************************************************************************* */
 template <size_t d>
 ShonanAveraging<d>::ShonanAveraging(const Measurements &measurements,
                                     const Parameters &parameters)
-    : parameters_(parameters), measurements_(measurements),
+    : parameters_(parameters),
+      measurements_(measurements),
       nrUnknowns_(NrUnknowns<d>(measurements)) {
   for (const auto &measurement : measurements_) {
     const auto &model = measurement.noiseModel();
     if (model && model->dim() != SO<d>::dimension) {
       measurement.print("Factor with incorrect noise model:\n");
-      throw std::invalid_argument("ShonanAveraging: measurements passed to "
-                                  "constructor have incorrect dimension.");
+      throw std::invalid_argument(
+          "ShonanAveraging: measurements passed to "
+          "constructor have incorrect dimension.");
     }
   }
   Q_ = buildQ();
@@ -196,7 +209,7 @@ Matrix ShonanAveraging<d>::StiefelElemen
   Matrix S(p, N * d);
   for (const auto it : values.filter<SOn>()) {
     S.middleCols<d>(it.key * d) =
-        it.value.matrix().leftCols<d>(); // project Qj to Stiefel
+        it.value.matrix().leftCols<d>();  // project Qj to Stiefel
   }
   return S;
 }
@@ -227,7 +240,8 @@ Values ShonanAveraging<3>::projectFrom(s
 }
 
 /* ************************************************************************* */
-template <size_t d> static Matrix RoundSolutionS(const Matrix &S) {
+template <size_t d>
+static Matrix RoundSolutionS(const Matrix &S) {
   const size_t N = S.cols() / d;
   // First, compute a thin SVD of S
   Eigen::JacobiSVD<Matrix> svd(S, Eigen::ComputeThinV);
@@ -246,8 +260,7 @@ template <size_t d> static Matrix RoundS
   for (size_t i = 0; i < N; ++i) {
     // Compute the determinant of the ith dxd block of R
     double determinant = R.middleCols<d>(d * i).determinant();
-    if (determinant > 0)
-      ++numPositiveBlocks;
+    if (determinant > 0) ++numPositiveBlocks;
   }
 
   if (numPositiveBlocks < N / 2) {
@@ -263,7 +276,8 @@ template <size_t d> static Matrix RoundS
 }
 
 /* ************************************************************************* */
-template <> Values ShonanAveraging<2>::roundSolutionS(const Matrix &S) const {
+template <>
+Values ShonanAveraging<2>::roundSolutionS(const Matrix &S) const {
   // Round to a 2*2N matrix
   Matrix R = RoundSolutionS<2>(S);
 
@@ -276,7 +290,8 @@ template <> Values ShonanAveraging<2>::r
   return values;
 }
 
-template <> Values ShonanAveraging<3>::roundSolutionS(const Matrix &S) const {
+template <>
+Values ShonanAveraging<3>::roundSolutionS(const Matrix &S) const {
   // Round to a 3*3N matrix
   Matrix R = RoundSolutionS<3>(S);
 
@@ -332,7 +347,8 @@ static double Kappa(const BinaryMeasurem
 }
 
 /* ************************************************************************* */
-template <size_t d> Sparse ShonanAveraging<d>::buildD() const {
+template <size_t d>
+Sparse ShonanAveraging<d>::buildD() const {
   // Each measurement contributes 2*d elements along the diagonal of the
   // degree matrix.
   static constexpr size_t stride = 2 * d;
@@ -366,7 +382,8 @@ template <size_t d> Sparse ShonanAveragi
 }
 
 /* ************************************************************************* */
-template <size_t d> Sparse ShonanAveraging<d>::buildQ() const {
+template <size_t d>
+Sparse ShonanAveraging<d>::buildQ() const {
   // Each measurement contributes 2*d^2 elements on a pair of symmetric
   // off-diagonal blocks
   static constexpr size_t stride = 2 * d * d;
@@ -513,12 +530,12 @@ struct MatrixProdFunctor {
 //   - We've been using 10^-4 for the nonnegativity tolerance
 //   - for numLanczosVectors, 20 is a good default value
 
-static bool
-SparseMinimumEigenValue(const Sparse &A, const Matrix &S, double *minEigenValue,
-                        Vector *minEigenVector = 0, size_t *numIterations = 0,
-                        size_t maxIterations = 1000,
-                        double minEigenvalueNonnegativityTolerance = 10e-4,
-                        Eigen::Index numLanczosVectors = 20) {
+static bool SparseMinimumEigenValue(
+    const Sparse &A, const Matrix &S, double *minEigenValue,
+    Vector *minEigenVector = 0, size_t *numIterations = 0,
+    size_t maxIterations = 1000,
+    double minEigenvalueNonnegativityTolerance = 10e-4,
+    Eigen::Index numLanczosVectors = 20) {
   // a. Estimate the largest-magnitude eigenvalue of this matrix using Lanczos
   MatrixProdFunctor lmOperator(A);
   Spectra::SymEigsSolver<double, Spectra::SELECT_EIGENVALUE::LARGEST_MAGN,
@@ -530,8 +547,7 @@ SparseMinimumEigenValue(const Sparse &A,
       maxIterations, 1e-4, Spectra::SELECT_EIGENVALUE::LARGEST_MAGN);
 
   // Check convergence and bail out if necessary
-  if (lmConverged != 1)
-    return false;
+  if (lmConverged != 1) return false;
 
   const double lmEigenValue = lmEigenValueSolver.eigenvalues()(0);
 
@@ -541,7 +557,7 @@ SparseMinimumEigenValue(const Sparse &A,
     *minEigenValue = lmEigenValue;
     if (minEigenVector) {
       *minEigenVector = lmEigenValueSolver.eigenvectors(1).col(0);
-      minEigenVector->normalize(); // Ensure that this is a unit vector
+      minEigenVector->normalize();  // Ensure that this is a unit vector
     }
     return true;
   }
@@ -578,7 +594,7 @@ SparseMinimumEigenValue(const Sparse &A,
   Vector perturbation(v0.size());
   perturbation.setRandom();
   perturbation.normalize();
-  Vector xinit = v0 + (.03 * v0.norm()) * perturbation; // Perturb v0 by ~3%
+  Vector xinit = v0 + (.03 * v0.norm()) * perturbation;  // Perturb v0 by ~3%
 
   // Use this to initialize the eigensolver
   minEigenValueSolver.init(xinit.data());
@@ -590,21 +606,20 @@ SparseMinimumEigenValue(const Sparse &A,
       maxIterations, minEigenvalueNonnegativityTolerance / lmEigenValue,
       Spectra::SELECT_EIGENVALUE::LARGEST_MAGN);
 
-  if (minConverged != 1)
-    return false;
+  if (minConverged != 1) return false;
 
   *minEigenValue = minEigenValueSolver.eigenvalues()(0) + 2 * lmEigenValue;
   if (minEigenVector) {
     *minEigenVector = minEigenValueSolver.eigenvectors(1).col(0);
-    minEigenVector->normalize(); // Ensure that this is a unit vector
+    minEigenVector->normalize();  // Ensure that this is a unit vector
   }
-  if (numIterations)
-    *numIterations = minEigenValueSolver.num_iterations();
+  if (numIterations) *numIterations = minEigenValueSolver.num_iterations();
   return true;
 }
 
 /* ************************************************************************* */
-template <size_t d> Sparse ShonanAveraging<d>::computeA(const Matrix &S) const {
+template <size_t d>
+Sparse ShonanAveraging<d>::computeA(const Matrix &S) const {
   auto Lambda = computeLambda(S);
   return Lambda - Q_;
 }
@@ -628,8 +643,8 @@ double ShonanAveraging<d>::computeMinEig
 
 /* ************************************************************************* */
 template <size_t d>
-std::pair<double, Vector>
-ShonanAveraging<d>::computeMinEigenVector(const Values &values) const {
+std::pair<double, Vector> ShonanAveraging<d>::computeMinEigenVector(
+    const Values &values) const {
   Vector minEigenVector;
   double minEigenValue = computeMinEigenValue(values, &minEigenVector);
   return std::make_pair(minEigenValue, minEigenVector);
@@ -643,20 +658,25 @@ bool ShonanAveraging<d>::checkOptimality
 }
 
 /* ************************************************************************* */
-/// Create a tangent direction xi with eigenvector segment v_i
 template <size_t d>
-Vector ShonanAveraging<d>::MakeATangentVector(size_t p, const Vector &v,
-                                              size_t i) {
+VectorValues ShonanAveraging<d>::TangentVectorValues(size_t p,
+                                                     const Vector &v) {
+  VectorValues delta;
   // Create a tangent direction xi with eigenvector segment v_i
   const size_t dimension = SOn::Dimension(p);
-  const auto v_i = v.segment<d>(d * i);
-  Vector xi = Vector::Zero(dimension);
-  double sign = pow(-1.0, round((p + 1) / 2) + 1);
-  for (size_t j = 0; j < d; j++) {
-    xi(j + p - d - 1) = sign * v_i(d - j - 1);
-    sign = -sign;
+  double sign0 = pow(-1.0, round((p + 1) / 2) + 1);
+  for (size_t i = 0; i < v.size() / d; i++) {
+    // Assumes key is 0-based integer
+    const auto v_i = v.segment<d>(d * i);
+    Vector xi = Vector::Zero(dimension);
+    double sign = sign0;
+    for (size_t j = 0; j < d; j++) {
+      xi(j + p - d - 1) = sign * v_i(d - j - 1);
+      sign = -sign;
+    }
+    delta.insert(i, xi);
   }
-  return xi;
+  return delta;
 }
 
 /* ************************************************************************* */
@@ -690,14 +710,8 @@ template <size_t d>
 Values ShonanAveraging<d>::LiftwithDescent(size_t p, const Values &values,
                                            const Vector &minEigenVector) {
   Values lifted = LiftTo<SOn>(p, values);
-  for (auto it : lifted.filter<SOn>()) {
-    // Create a tangent direction xi with eigenvector segment v_i
-    // Assumes key is 0-based integer
-    const Vector xi = MakeATangentVector(p, minEigenVector, it.key);
-    // Move the old value in the descent direction
-    it.value = it.value.retract(xi);
-  }
-  return lifted;
+  VectorValues delta = TangentVectorValues(p, minEigenVector);
+  return lifted.retract(delta);
 }
 
 /* ************************************************************************* */
@@ -750,7 +764,8 @@ Values ShonanAveraging<d>::initializeRan
 }
 
 /* ************************************************************************* */
-template <size_t d> Values ShonanAveraging<d>::initializeRandomly() const {
+template <size_t d>
+Values ShonanAveraging<d>::initializeRandomly() const {
   return initializeRandomly(kRandomNumberGenerator);
 }
 
@@ -759,7 +774,7 @@ template <size_t d>
 Values ShonanAveraging<d>::initializeRandomlyAt(size_t p,
                                                 std::mt19937 &rng) const {
   const Values randomRotations = initializeRandomly(rng);
-  return LiftTo<Rot3>(p, randomRotations); // lift to p!
+  return LiftTo<Rot3>(p, randomRotations);  // lift to p!
 }
 
 /* ************************************************************************* */
@@ -823,8 +838,8 @@ ShonanAveraging3::ShonanAveraging3(strin
 
 // Extract Rot3 measurement from Pose3 betweenfactors
 // Modeled after similar function in dataset.cpp
-static BinaryMeasurement<Rot3>
-convert(const BetweenFactor<Pose3>::shared_ptr &f) {
+static BinaryMeasurement<Rot3> convert(
+    const BetweenFactor<Pose3>::shared_ptr &f) {
   auto gaussian =
       boost::dynamic_pointer_cast<noiseModel::Gaussian>(f->noiseModel());
   if (!gaussian)
@@ -837,12 +852,11 @@ convert(const BetweenFactor<Pose3>::shar
       noiseModel::Gaussian::Covariance(M.block<3, 3>(3, 3), true));
 }
 
-static ShonanAveraging3::Measurements
-extractRot3Measurements(const BetweenFactorPose3s &factors) {
+static ShonanAveraging3::Measurements extractRot3Measurements(
+    const BetweenFactorPose3s &factors) {
   ShonanAveraging3::Measurements result;
   result.reserve(factors.size());
-  for (auto f : factors)
-    result.push_back(convert(f));
+  for (auto f : factors) result.push_back(convert(f));
   return result;
 }
 
@@ -851,4 +865,4 @@ ShonanAveraging3::ShonanAveraging3(const
     : ShonanAveraging<3>(extractRot3Measurements(factors), parameters) {}
 
 /* ************************************************************************* */
-} // namespace gtsam
+}  // namespace gtsam
--- gtsam-4.1.0.orig/gtsam/sfm/ShonanAveraging.h
+++ gtsam-4.1.0/gtsam/sfm/ShonanAveraging.h
@@ -20,36 +20,39 @@
 
 #include <gtsam/base/Matrix.h>
 #include <gtsam/base/Vector.h>
+#include <gtsam/dllexport.h>
 #include <gtsam/geometry/Rot2.h>
 #include <gtsam/geometry/Rot3.h>
+#include <gtsam/linear/VectorValues.h>
 #include <gtsam/nonlinear/LevenbergMarquardtParams.h>
 #include <gtsam/sfm/BinaryMeasurement.h>
 #include <gtsam/slam/dataset.h>
-#include <gtsam/dllexport.h>
 
 #include <Eigen/Sparse>
 #include <map>
 #include <string>
 #include <type_traits>
 #include <utility>
+#include <vector>
 
 namespace gtsam {
 class NonlinearFactorGraph;
 class LevenbergMarquardtOptimizer;
 
 /// Parameters governing optimization etc.
-template <size_t d> struct GTSAM_EXPORT ShonanAveragingParameters {
+template <size_t d>
+struct GTSAM_EXPORT ShonanAveragingParameters {
   // Select Rot2 or Rot3 interface based template parameter d
   using Rot = typename std::conditional<d == 2, Rot2, Rot3>::type;
   using Anchor = std::pair<size_t, Rot>;
 
   // Paremeters themselves:
-  LevenbergMarquardtParams lm; // LM parameters
-  double optimalityThreshold;  // threshold used in checkOptimality
-  Anchor anchor;               // pose to use as anchor if not Karcher
-  double alpha;                // weight of anchor-based prior (default 0)
-  double beta;                 // weight of Karcher-based prior (default 1)
-  double gamma;                // weight of gauge-fixing factors (default 0)
+  LevenbergMarquardtParams lm;  // LM parameters
+  double optimalityThreshold;   // threshold used in checkOptimality
+  Anchor anchor;                // pose to use as anchor if not Karcher
+  double alpha;                 // weight of anchor-based prior (default 0)
+  double beta;                  // weight of Karcher-based prior (default 1)
+  double gamma;                 // weight of gauge-fixing factors (default 0)
 
   ShonanAveragingParameters(const LevenbergMarquardtParams &lm =
                                 LevenbergMarquardtParams::CeresDefaults(),
@@ -64,6 +67,7 @@ template <size_t d> struct GTSAM_EXPORT
   double getOptimalityThreshold() const { return optimalityThreshold; }
 
   void setAnchor(size_t index, const Rot &value) { anchor = {index, value}; }
+  std::pair<size_t, Rot> getAnchor() { return anchor; }
 
   void setAnchorWeight(double value) { alpha = value; }
   double getAnchorWeight() { return alpha; }
@@ -93,8 +97,9 @@ using ShonanAveragingParameters3 = Shona
  *    European Computer Vision Conference, 2020.
  * You can view our ECCV spotlight video at https://youtu.be/5ppaqMyHtE0
  */
-template <size_t d> class GTSAM_EXPORT ShonanAveraging {
-public:
+template <size_t d>
+class GTSAM_EXPORT ShonanAveraging {
+ public:
   using Sparse = Eigen::SparseMatrix<double>;
 
   // Define the Parameters type and use its typedef of the rotation type:
@@ -105,13 +110,13 @@ public:
   // TODO(frank): use BinaryMeasurement?
   using Measurements = std::vector<BinaryMeasurement<Rot>>;
 
-private:
+ private:
   Parameters parameters_;
   Measurements measurements_;
   size_t nrUnknowns_;
-  Sparse D_; // Sparse (diagonal) degree matrix
-  Sparse Q_; // Sparse measurement matrix, == \tilde{R} in Eriksson18cvpr
-  Sparse L_; // connection Laplacian L = D - Q, needed for optimality check
+  Sparse D_;  // Sparse (diagonal) degree matrix
+  Sparse Q_;  // Sparse measurement matrix, == \tilde{R} in Eriksson18cvpr
+  Sparse L_;  // connection Laplacian L = D - Q, needed for optimality check
 
   /**
    * Build 3Nx3N sparse matrix consisting of rotation measurements, arranged as
@@ -122,7 +127,7 @@ private:
   /// Build 3Nx3N sparse degree matrix D
   Sparse buildD() const;
 
-public:
+ public:
   /// @name Standard Constructors
   /// @{
 
@@ -156,12 +161,12 @@ public:
   /// @name Matrix API (advanced use, debugging)
   /// @{
 
-  Sparse D() const { return D_; }              ///< Sparse version of D
-  Matrix denseD() const { return Matrix(D_); } ///< Dense version of D
-  Sparse Q() const { return Q_; }              ///< Sparse version of Q
-  Matrix denseQ() const { return Matrix(Q_); } ///< Dense version of Q
-  Sparse L() const { return L_; }              ///< Sparse version of L
-  Matrix denseL() const { return Matrix(L_); } ///< Dense version of L
+  Sparse D() const { return D_; }               ///< Sparse version of D
+  Matrix denseD() const { return Matrix(D_); }  ///< Dense version of D
+  Sparse Q() const { return Q_; }               ///< Sparse version of Q
+  Matrix denseQ() const { return Matrix(Q_); }  ///< Dense version of Q
+  Sparse L() const { return L_; }               ///< Sparse version of L
+  Matrix denseL() const { return Matrix(L_); }  ///< Dense version of L
 
   /// Version that takes pxdN Stiefel manifold elements
   Sparse computeLambda(const Matrix &S) const;
@@ -200,8 +205,8 @@ public:
   /// Project pxdN Stiefel manifold matrix S to Rot3^N
   Values roundSolutionS(const Matrix &S) const;
 
-  /// Create a tangent direction xi with eigenvector segment v_i
-  static Vector MakeATangentVector(size_t p, const Vector &v, size_t i);
+  /// Create a VectorValues with eigenvector v_i
+  static VectorValues TangentVectorValues(size_t p, const Vector &v);
 
   /// Calculate the riemannian gradient of F(values) at values
   Matrix riemannianGradient(size_t p, const Values &values) const;
@@ -220,11 +225,10 @@ public:
    * @param minEigenVector corresponding to minEigenValue at level p-1
    * @return values of type SO(p)
    */
-  Values
-  initializeWithDescent(size_t p, const Values &values,
-                        const Vector &minEigenVector, double minEigenValue,
-                        double gradienTolerance = 1e-2,
-                        double preconditionedGradNormTolerance = 1e-4) const;
+  Values initializeWithDescent(
+      size_t p, const Values &values, const Vector &minEigenVector,
+      double minEigenValue, double gradienTolerance = 1e-2,
+      double preconditionedGradNormTolerance = 1e-4) const;
   /// @}
   /// @name Advanced API
   /// @{
@@ -237,11 +241,11 @@ public:
 
   /**
    * Create initial Values of type SO(p)
-   * @param p the dimensionality of the rotation manifold 
+   * @param p the dimensionality of the rotation manifold
    */
   Values initializeRandomlyAt(size_t p, std::mt19937 &rng) const;
 
-  /// Version of initializeRandomlyAt with fixed random seed. 
+  /// Version of initializeRandomlyAt with fixed random seed.
   Values initializeRandomlyAt(size_t p) const;
 
   /**
@@ -300,7 +304,8 @@ public:
   Values roundSolution(const Values &values) const;
 
   /// Lift Values of type T to SO(p)
-  template <class T> static Values LiftTo(size_t p, const Values &values) {
+  template <class T>
+  static Values LiftTo(size_t p, const Values &values) {
     Values result;
     for (const auto it : values.filter<T>()) {
       result.insert(it.key, SOn::Lift(p, it.value.matrix()));
@@ -327,7 +332,7 @@ public:
    */
   Values initializeRandomly(std::mt19937 &rng) const;
 
-  /// Random initialization for wrapper, fixed random seed. 
+  /// Random initialization for wrapper, fixed random seed.
   Values initializeRandomly() const;
 
   /**
@@ -346,20 +351,22 @@ public:
 // convenience interface with file access.
 
 class ShonanAveraging2 : public ShonanAveraging<2> {
-public:
+ public:
   ShonanAveraging2(const Measurements &measurements,
                    const Parameters &parameters = Parameters());
-  ShonanAveraging2(string g2oFile, const Parameters &parameters = Parameters());
+  explicit ShonanAveraging2(string g2oFile,
+                            const Parameters &parameters = Parameters());
 };
 
 class ShonanAveraging3 : public ShonanAveraging<3> {
-public:
+ public:
   ShonanAveraging3(const Measurements &measurements,
                    const Parameters &parameters = Parameters());
-  ShonanAveraging3(string g2oFile, const Parameters &parameters = Parameters());
+  explicit ShonanAveraging3(string g2oFile,
+                            const Parameters &parameters = Parameters());
 
   // TODO(frank): Deprecate after we land pybind wrapper
   ShonanAveraging3(const BetweenFactorPose3s &factors,
                    const Parameters &parameters = Parameters());
 };
-} // namespace gtsam
+}  // namespace gtsam
--- gtsam-4.1.0.orig/gtsam/sfm/TranslationRecovery.cpp
+++ gtsam-4.1.0/gtsam/sfm/TranslationRecovery.cpp
@@ -45,9 +45,8 @@ NonlinearFactorGraph TranslationRecovery
 }
 
 void TranslationRecovery::addPrior(const double scale,
-                                   NonlinearFactorGraph *graph) const {
-  //TODO(akshay-krishnan): make this an input argument                                     
-  auto priorNoiseModel = noiseModel::Isotropic::Sigma(3, 0.01);
+                                   NonlinearFactorGraph *graph,
+                                   const SharedNoiseModel &priorNoiseModel) const {
   auto edge = relativeTranslations_.begin();
   graph->emplace_shared<PriorFactor<Point3> >(edge->key1(), Point3(0, 0, 0), priorNoiseModel);
   graph->emplace_shared<PriorFactor<Point3> >(edge->key2(), scale * edge->measured().point3(),
--- gtsam-4.1.0.orig/gtsam/sfm/TranslationRecovery.h
+++ gtsam-4.1.0/gtsam/sfm/TranslationRecovery.h
@@ -68,9 +68,7 @@ class TranslationRecovery {
    */
   TranslationRecovery(const TranslationEdges &relativeTranslations,
                       const LevenbergMarquardtParams &lmParams = LevenbergMarquardtParams())
-      : relativeTranslations_(relativeTranslations), params_(lmParams) {
-    params_.setVerbosityLM("Summary");
-  }
+      : relativeTranslations_(relativeTranslations), params_(lmParams) {}
 
   /**
    * @brief Build the factor graph to do the optimization.
@@ -84,8 +82,11 @@ class TranslationRecovery {
    *
    * @param scale scale for first relative translation which fixes gauge.
    * @param graph factor graph to which prior is added.
+   * @param priorNoiseModel the noise model to use with the prior.
    */
-  void addPrior(const double scale, NonlinearFactorGraph *graph) const;
+  void addPrior(const double scale, NonlinearFactorGraph *graph,
+                const SharedNoiseModel &priorNoiseModel =
+                    noiseModel::Isotropic::Sigma(3, 0.01)) const;
 
   /**
    * @brief Create random initial translations.
--- /dev/null
+++ gtsam-4.1.0/gtsam/sfm/tests/testMFAS.cpp
@@ -0,0 +1,104 @@
+/**
+ *  @file  testMFAS.cpp
+ *  @brief Unit tests for the MFAS class
+ *  @author Akshay Krishnan
+ *  @date July 2020
+ */
+
+#include <gtsam/sfm/MFAS.h>
+
+#include <CppUnitLite/TestHarness.h>
+
+using namespace std;
+using namespace gtsam;
+
+/**
+ * We (partially) use the example from the paper on 1dsfm
+ * (https://research.cs.cornell.edu/1dsfm/docs/1DSfM_ECCV14.pdf, Fig 1, Page 5)
+ * for the unit tests here. The only change is that we leave out node 4 and use
+ * only nodes 0-3. This makes the test easier to understand and also
+ * avoids an ambiguity in the ground truth ordering that arises due to
+ * insufficient edges in the geaph when using the 4th node.
+ */
+
+// edges in the graph - last edge from node 3 to 0 is an outlier
+vector<MFAS::KeyPair> edges = {make_pair(3, 2), make_pair(0, 1), make_pair(3, 1),
+                         make_pair(1, 2), make_pair(0, 2), make_pair(3, 0)};
+// nodes in the graph
+KeyVector nodes = {Key(0), Key(1), Key(2), Key(3)};
+// weights from projecting in direction-1 (bad direction, outlier accepted)
+vector<double> weights1 = {2, 1.5, 0.5, 0.25, 1, 0.75};
+// weights from projecting in direction-2 (good direction, outlier rejected)
+vector<double> weights2 = {0.5, 0.75, -0.25, 0.75, 1, 0.5};
+
+// helper function to obtain map from keypairs to weights from the 
+// vector representations
+map<MFAS::KeyPair, double> getEdgeWeights(const vector<MFAS::KeyPair> &edges,
+                                         const vector<double> &weights) {
+  map<MFAS::KeyPair, double> edgeWeights;
+  for (size_t i = 0; i < edges.size(); i++) {
+    edgeWeights[edges[i]] = weights[i];
+  }
+  return edgeWeights;
+}
+
+// test the ordering and the outlierWeights function using weights2 - outlier
+// edge is rejected when projected in a direction that gives weights2
+TEST(MFAS, OrderingWeights2) {
+  MFAS mfas_obj(getEdgeWeights(edges, weights2));
+
+  KeyVector ordered_nodes = mfas_obj.computeOrdering();
+
+  // ground truth (expected) ordering in this example
+  KeyVector gt_ordered_nodes = {0, 1, 3, 2};
+
+  // check if the expected ordering is obtained
+  for (size_t i = 0; i < ordered_nodes.size(); i++) {
+    EXPECT_LONGS_EQUAL(gt_ordered_nodes[i], ordered_nodes[i]);
+  }
+
+  map<MFAS::KeyPair, double> outlier_weights = mfas_obj.computeOutlierWeights();
+
+  // since edge between 3 and 0 is inconsistent with the ordering, it must have
+  // positive outlier weight, other outlier weights must be zero
+  for (auto &edge : edges) {
+    if (edge == make_pair(Key(3), Key(0)) ||
+        edge == make_pair(Key(0), Key(3))) {
+      EXPECT_DOUBLES_EQUAL(outlier_weights[edge], 0.5, 1e-6);
+    } else {
+      EXPECT_DOUBLES_EQUAL(outlier_weights[edge], 0, 1e-6);
+    }
+  }
+}
+
+// test the ordering function and the outlierWeights method using
+// weights1 (outlier edge is accepted when projected in a direction that
+// produces weights1)
+TEST(MFAS, OrderingWeights1) {
+  MFAS mfas_obj(getEdgeWeights(edges, weights1));
+
+  KeyVector ordered_nodes = mfas_obj.computeOrdering();
+
+  // "ground truth" expected ordering in this example
+  KeyVector gt_ordered_nodes = {3, 0, 1, 2};
+
+  // check if the expected ordering is obtained
+  for (size_t i = 0; i < ordered_nodes.size(); i++) {
+    EXPECT_LONGS_EQUAL(gt_ordered_nodes[i], ordered_nodes[i]);
+  }
+
+  map<MFAS::KeyPair, double> outlier_weights = mfas_obj.computeOutlierWeights();
+
+  // since edge between 3 and 0 is inconsistent with the ordering, it must have
+  // positive outlier weight, other outlier weights must be zero
+  for (auto &edge : edges) {
+    EXPECT_DOUBLES_EQUAL(outlier_weights[edge], 0, 1e-6);
+  }
+}
+
+/* ************************************************************************* */
+int main() {
+  TestResult tr;
+  return TestRegistry::runAllTests(tr);
+}
+/* ************************************************************************* */
--- gtsam-4.1.0.orig/gtsam/sfm/tests/testShonanAveraging.cpp
+++ gtsam-4.1.0/gtsam/sfm/tests/testShonanAveraging.cpp
@@ -92,6 +92,27 @@ TEST(ShonanAveraging3, checkOptimality)
 }
 
 /* ************************************************************************* */
+TEST(ShonanAveraging3, checkSubgraph) {
+  // Create parameter with solver set to SUBGRAPH
+  auto params = ShonanAveragingParameters3(
+      gtsam::LevenbergMarquardtParams::CeresDefaults(), "SUBGRAPH");
+  ShonanAveraging3::Measurements measurements;
+
+  // The toyExample.g2o has 5 vertices, from 0-4
+  // The edges are: 1-2, 2-3, 3-4, 3-1, 1-4, 0-1,
+  // which can build a connected graph
+  auto subgraphShonan = fromExampleName("toyExample.g2o", params);
+
+  // Create initial random estimation
+  Values initial;
+  initial = subgraphShonan.initializeRandomly(kRandomNumberGenerator);
+
+  // Run Shonan with SUBGRAPH solver
+  auto result = subgraphShonan.run(initial, 3, 3);
+  EXPECT_DOUBLES_EQUAL(1e-11, subgraphShonan.cost(result.first), 1e-4);
+}
+
+/* ************************************************************************* */
 TEST(ShonanAveraging3, tryOptimizingAt3) {
   const Values randomRotations = kShonan.initializeRandomly(kRandomNumberGenerator);
   Values initial = ShonanAveraging3::LiftTo<Rot3>(3, randomRotations);  // convert to SOn
@@ -121,18 +142,17 @@ TEST(ShonanAveraging3, tryOptimizingAt4)
 }
 
 /* ************************************************************************* */
-TEST(ShonanAveraging3, MakeATangentVector) {
+TEST(ShonanAveraging3, TangentVectorValues) {
   Vector9 v;
   v << 1, 2, 3, 4, 5, 6, 7, 8, 9;
-  Matrix expected(5, 5);
-  expected << 0, 0, 0, 0, -4, //
-      0, 0, 0, 0, -5,         //
-      0, 0, 0, 0, -6,         //
-      0, 0, 0, 0, 0,          //
-      4, 5, 6, 0, 0;
-  const Vector xi_1 = ShonanAveraging3::MakeATangentVector(5, v, 1);
-  const auto actual = SOn::Hat(xi_1);
-  CHECK(assert_equal(expected, actual));
+  Vector expected0(10), expected1(10), expected2(10);
+  expected0 << 0, 3, -2, 1, 0, 0, 0, 0, 0, 0;
+  expected1 << 0, 6, -5, 4, 0, 0, 0, 0, 0, 0;
+  expected2 << 0, 9, -8, 7, 0, 0, 0, 0, 0, 0;
+  const VectorValues xi = ShonanAveraging3::TangentVectorValues(5, v);
+  EXPECT(assert_equal(expected0, xi[0]));
+  EXPECT(assert_equal(expected1, xi[1]));
+  EXPECT(assert_equal(expected2, xi[2]));
 }
 
 /* ************************************************************************* */
@@ -168,7 +188,8 @@ TEST(ShonanAveraging3, CheckWithEigen) {
       minEigenValue = min(lambdas(i), minEigenValue);
 
   // Actual check
-  EXPECT_DOUBLES_EQUAL(minEigenValue, lambda, 1e-12);
+  EXPECT_DOUBLES_EQUAL(0, lambda, 1e-11);
+  EXPECT_DOUBLES_EQUAL(0, minEigenValue, 1e-11);
 
   // Construct test descent direction (as minEigenVector is not predictable
   // across platforms, being one from a basically flat 3d- subspace)
--- gtsam-4.1.0.orig/gtsam/slam/dataset.cpp
+++ gtsam-4.1.0/gtsam/slam/dataset.cpp
@@ -1130,6 +1130,13 @@ bool readBAL(const string &filename, Sfm
 }
 
 /* ************************************************************************* */
+SfmData readBal(const string &filename) {
+  SfmData data;
+  readBAL(filename, data);
+  return data;
+}
+
+/* ************************************************************************* */
 bool writeBAL(const string &filename, SfmData &data) {
   // Open the output file
   ofstream os;
@@ -1157,8 +1164,8 @@ bool writeBAL(const string &filename, Sf
     for (size_t k = 0; k < track.number_measurements();
          k++) { // for each observation of the 3D point j
       size_t i = track.measurements[k].first; // camera id
-      double u0 = data.cameras[i].calibration().u0();
-      double v0 = data.cameras[i].calibration().v0();
+      double u0 = data.cameras[i].calibration().px();
+      double v0 = data.cameras[i].calibration().py();
 
       if (u0 != 0 || v0 != 0) {
         cout << "writeBAL has not been tested for calibration with nonzero "
--- gtsam-4.1.0.orig/gtsam/slam/dataset.h
+++ gtsam-4.1.0/gtsam/slam/dataset.h
@@ -211,16 +211,18 @@ GTSAM_EXPORT GraphAndValues load3D(const
 /// A measurement with its camera index
 typedef std::pair<size_t, Point2> SfmMeasurement;
 
-/// SfmTrack
+/// Sift index for SfmTrack
 typedef std::pair<size_t, size_t> SiftIndex;
 
 /// Define the structure for the 3D points
 struct SfmTrack {
   SfmTrack(): p(0,0,0) {}
+  SfmTrack(const gtsam::Point3& pt) : p(pt) {}
   Point3 p; ///< 3D position of the point
   float r, g, b; ///< RGB color of the 3D point
   std::vector<SfmMeasurement> measurements; ///< The 2D image projections (id,(u,v))
   std::vector<SiftIndex> siftIndices;
+  
   /// Total number of measurements in this track
   size_t number_measurements() const {
     return measurements.size();
@@ -233,8 +235,17 @@ struct SfmTrack {
   SiftIndex siftIndex(size_t idx) const {
     return siftIndices[idx];
   }
+  /// Get 3D point
+  const Point3& point3() const {
+    return p;
+  }
+  /// Add measurement (camera_idx, Point2) to track
+  void add_measurement(size_t idx, const gtsam::Point2& m) {
+    measurements.emplace_back(idx, m);
+  }
 };
 
+
 /// Define the structure for the camera poses
 typedef PinholeCamera<Cal3Bundler> SfmCamera;
 
@@ -257,6 +268,14 @@ struct SfmData {
   SfmTrack track(size_t idx) const {
     return tracks[idx];
   }
+  /// Add a track to SfmData
+  void add_track(const SfmTrack& t)  {
+    tracks.push_back(t);
+  }
+  /// Add a camera to SfmData
+  void add_camera(const SfmCamera& cam){
+    cameras.push_back(cam);
+  }
 };
 
 /**
@@ -278,6 +297,14 @@ GTSAM_EXPORT bool readBundler(const std:
 GTSAM_EXPORT bool readBAL(const std::string& filename, SfmData &data);
 
 /**
+ * @brief This function parses a "Bundle Adjustment in the Large" (BAL) file and returns the data
+ * as a SfmData structure. Mainly used by wrapped code.
+ * @param filename The name of the BAL file.
+ * @return SfM structure where the data is stored.
+ */
+GTSAM_EXPORT SfmData readBal(const std::string& filename);
+
+/**
  * @brief This function writes a "Bundle Adjustment in the Large" (BAL) file from a
  * SfmData structure
  * @param filename The name of the BAL file to write
@@ -354,6 +381,7 @@ parse3DFactors(const std::string &filena
                const noiseModel::Diagonal::shared_ptr &model = nullptr,
                size_t maxIndex = 0);
 
+using BinaryMeasurementsUnit3 = std::vector<BinaryMeasurement<Unit3>>;
 #ifdef GTSAM_ALLOW_DEPRECATED_SINCE_V41
 inline boost::optional<IndexedPose> parseVertex(std::istream &is,
                                                 const std::string &tag) {
--- gtsam-4.1.0.orig/gtsam_extra.cmake.in
+++ gtsam-4.1.0/gtsam_extra.cmake.in
@@ -7,8 +7,3 @@ set (GTSAM_VERSION_STRING "@GTSAM_VERSIO
 
 set (GTSAM_USE_TBB @GTSAM_USE_TBB@)
 set (GTSAM_DEFAULT_ALLOCATOR @GTSAM_DEFAULT_ALLOCATOR@)
-
-if("@GTSAM_INSTALL_CYTHON_TOOLBOX@")
-  list(APPEND GTSAM_CYTHON_INSTALL_PATH "@GTSAM_CYTHON_INSTALL_PATH@")
-  list(APPEND GTSAM_EIGENCY_INSTALL_PATH "@GTSAM_EIGENCY_INSTALL_PATH@")
-endif()
--- gtsam-4.1.0.orig/gtsam_unstable/geometry/Similarity3.cpp
+++ gtsam-4.1.0/gtsam_unstable/geometry/Similarity3.cpp
@@ -19,9 +19,68 @@
 
 #include <gtsam/geometry/Pose3.h>
 #include <gtsam/base/Manifold.h>
+#include <gtsam/slam/KarcherMeanFactor-inl.h>
 
 namespace gtsam {
 
+using std::vector;
+using PointPairs = vector<Point3Pair>;
+
+namespace {
+/// Subtract centroids from point pairs.
+static PointPairs subtractCentroids(const PointPairs &abPointPairs,
+                                    const Point3Pair &centroids) {
+  PointPairs d_abPointPairs;
+  for (const Point3Pair& abPair : abPointPairs) {
+    Point3 da = abPair.first - centroids.first;
+    Point3 db = abPair.second - centroids.second;
+    d_abPointPairs.emplace_back(da, db);
+  }
+  return d_abPointPairs;
+}
+
+/// Form inner products x and y and calculate scale.
+static const double calculateScale(const PointPairs &d_abPointPairs,
+                                   const Rot3 &aRb) {
+  double x = 0, y = 0;
+  Point3 da, db;
+  for (const Point3Pair& d_abPair : d_abPointPairs) {
+    std::tie(da, db) = d_abPair;
+    const Vector3 da_prime = aRb * db;
+    y += da.transpose() * da_prime;
+    x += da_prime.transpose() * da_prime;
+  }
+  const double s = y / x;
+  return s;
+}
+
+/// Form outer product H.
+static Matrix3 calculateH(const PointPairs &d_abPointPairs) {
+  Matrix3 H = Z_3x3;
+  for (const Point3Pair& d_abPair : d_abPointPairs) {
+    H += d_abPair.first * d_abPair.second.transpose();
+  }
+  return H;
+}
+
+/// This method estimates the similarity transform from differences point pairs, given a known or estimated rotation and point centroids.
+static Similarity3 align(const PointPairs &d_abPointPairs, const Rot3 &aRb,
+                         const Point3Pair &centroids) {
+  const double s = calculateScale(d_abPointPairs, aRb);
+  const Point3 aTb = (centroids.first - s * (aRb * centroids.second)) / s;
+  return Similarity3(aRb, aTb, s);
+}
+
+/// This method estimates the similarity transform from point pairs, given a known or estimated rotation.
+// Refer to: http://www5.informatik.uni-erlangen.de/Forschung/Publikationen/2005/Zinsser05-PSR.pdf Chapter 3
+static Similarity3 alignGivenR(const PointPairs &abPointPairs,
+                               const Rot3 &aRb) {
+  auto centroids = means(abPointPairs);
+  auto d_abPointPairs = subtractCentroids(abPointPairs, centroids);
+  return align(d_abPointPairs, aRb, centroids);
+}
+}  // namespace
+
 Similarity3::Similarity3() :
     t_(0,0,0), s_(1) {
 }
@@ -54,15 +113,15 @@ bool Similarity3::operator==(const Simil
 void Similarity3::print(const std::string& s) const {
   std::cout << std::endl;
   std::cout << s;
-  rotation().print("R:\n");
-  std::cout << "t: " << translation().transpose() << "s: " << scale() << std::endl;
+  rotation().print("\nR:\n");
+  std::cout << "t: " << translation().transpose() << " s: " << scale() << std::endl;
 }
 
 Similarity3 Similarity3::identity() {
   return Similarity3();
 }
-Similarity3 Similarity3::operator*(const Similarity3& T) const {
-  return Similarity3(R_ * T.R_, ((1.0 / T.s_) * t_) + R_ * T.t_, s_ * T.s_);
+Similarity3 Similarity3::operator*(const Similarity3& S) const {
+  return Similarity3(R_ * S.R_, ((1.0 / S.s_) * t_) + R_ * S.t_, s_ * S.s_);
 }
 
 Similarity3 Similarity3::inverse() const {
@@ -85,11 +144,51 @@ Point3 Similarity3::transformFrom(const
   return s_ * q;
 }
 
+Pose3 Similarity3::transformFrom(const Pose3& T) const {
+  Rot3 R = R_.compose(T.rotation());
+  Point3 t = Point3(s_ * (R_ * T.translation() + t_));
+  return Pose3(R, t);
+}
+
 Point3 Similarity3::operator*(const Point3& p) const {
   return transformFrom(p);
 }
 
-Matrix4 Similarity3::wedge(const Vector7& xi) {
+Similarity3 Similarity3::Align(const PointPairs &abPointPairs) {
+  // Refer to Chapter 3 of
+  // http://www5.informatik.uni-erlangen.de/Forschung/Publikationen/2005/Zinsser05-PSR.pdf
+  if (abPointPairs.size() < 3)
+    throw std::runtime_error("input should have at least 3 pairs of points");
+  auto centroids = means(abPointPairs);
+  auto d_abPointPairs = subtractCentroids(abPointPairs, centroids);
+  Matrix3 H = calculateH(d_abPointPairs);
+  // ClosestTo finds rotation matrix closest to H in Frobenius sense
+  Rot3 aRb = Rot3::ClosestTo(H);
+  return align(d_abPointPairs, aRb, centroids);
+}
+
+Similarity3 Similarity3::Align(const vector<Pose3Pair> &abPosePairs) {
+  const size_t n = abPosePairs.size();
+  if (n < 2)
+    throw std::runtime_error("input should have at least 2 pairs of poses");
+
+  // calculate rotation
+  vector<Rot3> rotations;
+  PointPairs abPointPairs;
+  rotations.reserve(n);
+  abPointPairs.reserve(n);
+  Pose3 wTa, wTb;
+  for (const Pose3Pair &abPair : abPosePairs) {
+    std::tie(wTa, wTb) = abPair;
+    rotations.emplace_back(wTa.rotation().compose(wTb.rotation().inverse()));
+    abPointPairs.emplace_back(wTa.translation(), wTb.translation());
+  }
+  const Rot3 aRb = FindKarcherMean<Rot3>(rotations);
+
+  return alignGivenR(abPointPairs, aRb);
+}
+
+Matrix4 Similarity3::wedge(const Vector7 &xi) {
   // http://www.ethaneade.org/latex2html/lie/node29.html
   const auto w = xi.head<3>();
   const auto u = xi.segment<3>(3);
@@ -128,12 +227,13 @@ Matrix3 Similarity3::GetV(Vector3 w, dou
     W = 1.0 / 24.0 - theta2 / 720.0;
   }
   const double lambda2 = lambda * lambda, lambda3 = lambda2 * lambda;
+  const double expMinLambda = exp(-lambda);
   double A, alpha = 0.0, beta, mu;
   if (lambda2 > 1e-9) {
-    A = (1.0 - exp(-lambda)) / lambda;
+    A = (1.0 - expMinLambda) / lambda;
     alpha = 1.0 / (1.0 + theta2 / lambda2);
-    beta = (exp(-lambda) - 1 + lambda) / lambda2;
-    mu = (1 - lambda + (0.5 * lambda2) - exp(-lambda)) / lambda3;
+    beta = (expMinLambda - 1 + lambda) / lambda2;
+    mu = (1 - lambda + (0.5 * lambda2) - expMinLambda) / lambda3;
   } else {
     A = 1.0 - lambda / 2.0 + lambda2 / 6.0;
     beta = 0.5 - lambda / 6.0 + lambda2 / 24.0 - lambda3 / 120.0;
--- gtsam-4.1.0.orig/gtsam_unstable/geometry/Similarity3.h
+++ gtsam-4.1.0/gtsam_unstable/geometry/Similarity3.h
@@ -19,10 +19,12 @@
 
 #include <gtsam/geometry/Rot3.h>
 #include <gtsam/geometry/Point3.h>
+#include <gtsam/geometry/Pose3.h>
 #include <gtsam/base/Lie.h>
 #include <gtsam/base/Manifold.h>
 #include <gtsam_unstable/dllexport.h>
 
+
 namespace gtsam {
 
 // Forward declarations
@@ -87,7 +89,7 @@ public:
   GTSAM_UNSTABLE_EXPORT static Similarity3 identity();
 
   /// Composition
-  GTSAM_UNSTABLE_EXPORT Similarity3 operator*(const Similarity3& T) const;
+  GTSAM_UNSTABLE_EXPORT Similarity3 operator*(const Similarity3& S) const;
 
   /// Return the inverse
   GTSAM_UNSTABLE_EXPORT Similarity3 inverse() const;
@@ -101,9 +103,32 @@ public:
       OptionalJacobian<3, 7> H1 = boost::none, //
       OptionalJacobian<3, 3> H2 = boost::none) const;
 
+  /** 
+   * Action on a pose T.
+   * |Rs  ts|   |R t|   |Rs*R Rs*t+ts| 
+   * |0  1/s| * |0 1| = | 0      1/s |, the result is still a Sim3 object.
+   * To retrieve a Pose3, we normalized the scale value into 1.
+   * |Rs*R Rs*t+ts|   |Rs*R s(Rs*t+ts)|
+   * | 0      1/s | = |  0       1    |
+   * 
+   * This group action satisfies the compatibility condition. 
+   * For more details, refer to: https://en.wikipedia.org/wiki/Group_action
+   */
+  GTSAM_UNSTABLE_EXPORT Pose3 transformFrom(const Pose3& T) const;
+
   /** syntactic sugar for transformFrom */
   GTSAM_UNSTABLE_EXPORT Point3 operator*(const Point3& p) const;
 
+  /**
+   *  Create Similarity3 by aligning at least three point pairs
+   */
+  GTSAM_UNSTABLE_EXPORT static Similarity3 Align(const std::vector<Point3Pair>& abPointPairs);
+  
+  /**
+   *  Create Similarity3 by aligning at least two pose pairs
+   */
+  GTSAM_UNSTABLE_EXPORT static Similarity3 Align(const std::vector<Pose3Pair>& abPosePairs);
+
   /// @}
   /// @name Lie Group
   /// @{
@@ -182,8 +207,8 @@ public:
   /// @name Helper functions
   /// @{
 
-  /// Calculate expmap and logmap coefficients.
 private:
+  /// Calculate expmap and logmap coefficients.
   static Matrix3 GetV(Vector3 w, double lambda);
 
   /// @}
--- gtsam-4.1.0.orig/gtsam_unstable/geometry/tests/testSimilarity3.cpp
+++ gtsam-4.1.0/gtsam_unstable/geometry/tests/testSimilarity3.cpp
@@ -51,6 +51,8 @@ static const Similarity3 T4(R, P, s);
 static const Similarity3 T5(R, P, 10);
 static const Similarity3 T6(Rot3(), Point3(1, 1, 0), 2); // Simpler transform
 
+const double degree = M_PI / 180;
+
 //******************************************************************************
 TEST(Similarity3, Concepts) {
   BOOST_CONCEPT_ASSERT((IsGroup<Similarity3 >));
@@ -256,6 +258,118 @@ TEST(Similarity3, GroupAction) {
 }
 
 //******************************************************************************
+// Group action on Pose3
+TEST(Similarity3, GroupActionPose3) {
+  Similarity3 bSa(Rot3::Ry(180 * degree), Point3(2, 3, 5), 2.0);
+
+  // Create source poses
+  Pose3 Ta1(Rot3(), Point3(0, 0, 0));
+  Pose3 Ta2(Rot3(-1, 0, 0, 0, -1, 0, 0, 0, 1), Point3(4, 0, 0));
+
+  // Create destination poses
+  Pose3 expected_Tb1(Rot3(-1, 0, 0, 0, 1, 0, 0, 0, -1), Point3(4, 6, 10));
+  Pose3 expected_Tb2(Rot3(1, 0, 0, 0, -1, 0, 0, 0, -1), Point3(-4, 6, 10));
+
+  EXPECT(assert_equal(expected_Tb1, bSa.transformFrom(Ta1)));
+  EXPECT(assert_equal(expected_Tb2, bSa.transformFrom(Ta2)));
+}
+
+// Test left group action compatibility.
+// cSa*Ta = cSb*bSa*Ta
+TEST(Similarity3, GroupActionPose3_Compatibility) {
+  Similarity3 bSa(Rot3::Ry(180 * degree), Point3(2, 3, 5), 2.0);
+  Similarity3 cSb(Rot3::Ry(90 * degree), Point3(-10, -4, 0), 3.0);
+  Similarity3 cSa(Rot3::Ry(270 * degree), Point3(0, 1, -2), 6.0);
+
+  // Create poses
+  Pose3 Ta1(Rot3(), Point3(0, 0, 0));
+  Pose3 Ta2(Rot3(-1, 0, 0, 0, -1, 0, 0, 0, 1), Point3(4, 0, 0));
+  Pose3 Tb1(Rot3(-1, 0, 0, 0, 1, 0, 0, 0, -1), Point3(4, 6, 10));
+  Pose3 Tb2(Rot3(1, 0, 0, 0, -1, 0, 0, 0, -1), Point3(-4, 6, 10));
+  Pose3 Tc1(Rot3(0, 0, -1, 0, 1, 0, 1, 0, 0), Point3(0, 6, -12));
+  Pose3 Tc2(Rot3(0, 0, -1, 0, -1, 0, -1, 0, 0), Point3(0, 6, 12));
+
+  EXPECT(assert_equal(Tc1, cSb.transformFrom(Tb1)));
+  EXPECT(assert_equal(Tc2, cSb.transformFrom(Tb2)));
+
+  EXPECT(assert_equal(cSa.transformFrom(Ta1), cSb.transformFrom(Tb1)));
+  EXPECT(assert_equal(cSa.transformFrom(Ta2), cSb.transformFrom(Tb2)));
+}
+
+//******************************************************************************
+// Align with Point3 Pairs
+TEST(Similarity3, AlignPoint3_1) {
+  Similarity3 expected_aSb(Rot3::Rz(-90 * degree), Point3(3, 4, 5), 2.0);
+
+  Point3 b1(0, 0, 0), b2(3, 0, 0), b3(3, 0, 4);
+
+  Point3Pair ab1(make_pair(expected_aSb.transformFrom(b1), b1));
+  Point3Pair ab2(make_pair(expected_aSb.transformFrom(b2), b2));
+  Point3Pair ab3(make_pair(expected_aSb.transformFrom(b3), b3));
+
+  vector<Point3Pair> correspondences{ab1, ab2, ab3};
+
+  Similarity3 actual_aSb = Similarity3::Align(correspondences);
+  EXPECT(assert_equal(expected_aSb, actual_aSb));
+}
+
+TEST(Similarity3, AlignPoint3_2) {
+  Similarity3 expected_aSb(Rot3(), Point3(10, 10, 0), 1.0);
+
+  Point3 b1(0, 0, 0), b2(20, 10, 0), b3(10, 20, 0);
+
+  Point3Pair ab1(make_pair(expected_aSb.transformFrom(b1), b1));
+  Point3Pair ab2(make_pair(expected_aSb.transformFrom(b2), b2));
+  Point3Pair ab3(make_pair(expected_aSb.transformFrom(b3), b3));
+
+  vector<Point3Pair> correspondences{ab1, ab2, ab3};
+
+  Similarity3 actual_aSb = Similarity3::Align(correspondences);
+  EXPECT(assert_equal(expected_aSb, actual_aSb));
+}
+
+TEST(Similarity3, AlignPoint3_3) {
+  Similarity3 expected_aSb(Rot3::RzRyRx(0.3, 0.2, 0.1), Point3(20, 10, 5), 1.0);
+
+  Point3 b1(0, 0, 1), b2(10, 0, 2), b3(20, -10, 30);
+
+  Point3Pair ab1(make_pair(expected_aSb.transformFrom(b1), b1));
+  Point3Pair ab2(make_pair(expected_aSb.transformFrom(b2), b2));
+  Point3Pair ab3(make_pair(expected_aSb.transformFrom(b3), b3));
+
+  vector<Point3Pair> correspondences{ab1, ab2, ab3};
+
+  Similarity3 actual_aSb = Similarity3::Align(correspondences);
+  EXPECT(assert_equal(expected_aSb, actual_aSb));
+}
+
+//******************************************************************************
+// Align with Pose3 Pairs
+TEST(Similarity3, AlignPose3) {
+  Similarity3 expected_aSb(Rot3::Ry(180 * degree), Point3(2, 3, 5), 2.0);
+
+  // Create source poses
+  Pose3 Ta1(Rot3(), Point3(0, 0, 0));
+  Pose3 Ta2(Rot3(-1, 0, 0, 0, -1, 0, 0, 0, 1), Point3(4, 0, 0));
+
+  // Create destination poses
+  Pose3 Tb1(Rot3(-1, 0, 0, 0, 1, 0, 0, 0, -1), Point3(4, 6, 10));
+  Pose3 Tb2(Rot3(1, 0, 0, 0, -1, 0, 0, 0, -1), Point3(-4, 6, 10));
+
+  Pose3Pair bTa1(make_pair(Tb1, Ta1));
+  Pose3Pair bTa2(make_pair(Tb2, Ta2));
+
+  vector<Pose3Pair> correspondences{bTa1, bTa2};
+
+  // Cayley transform cannot accommodate 180 degree rotations,
+  // hence we only test for Expmap
+#ifdef GTSAM_ROT3_EXPMAP
+  Similarity3 actual_aSb = Similarity3::Align(correspondences);
+  EXPECT(assert_equal(expected_aSb, actual_aSb));
+#endif
+}
+
+//******************************************************************************
 // Test very simple prior optimization example
 TEST(Similarity3, Optimization) {
   // Create a PriorFactor with a Sim3 prior
--- gtsam-4.1.0.orig/gtsam_unstable/gtsam_unstable.i
+++ gtsam-4.1.0/gtsam_unstable/gtsam_unstable.i
@@ -5,8 +5,6 @@
 // specify the classes from gtsam we are using
 virtual class gtsam::Value;
 class gtsam::Vector6;
-class gtsam::LieScalar;
-class gtsam::LieVector;
 class gtsam::Point2;
 class gtsam::Point2Vector;
 class gtsam::Rot2;
@@ -476,14 +474,12 @@ virtual class DGroundConstraint : gtsam:
   DGroundConstraint(size_t key, Vector constraint, const gtsam::noiseModel::Base* model);
 };
 
-#include <gtsam/base/deprecated/LieScalar.h>
-
 #include <gtsam_unstable/dynamics/VelocityConstraint3.h>
 virtual class VelocityConstraint3 : gtsam::NonlinearFactor {
   /** Standard constructor */
   VelocityConstraint3(size_t key1, size_t key2, size_t velKey, double dt);
 
-  Vector evaluateError(const gtsam::LieScalar& x1, const gtsam::LieScalar& x2, const gtsam::LieScalar& v) const;
+  Vector evaluateError(const double& x1, const double& x2, const double& v) const;
 };
 
 #include <gtsam_unstable/dynamics/Pendulum.h>
@@ -491,7 +487,7 @@ virtual class PendulumFactor1 : gtsam::N
   /** Standard constructor */
   PendulumFactor1(size_t k1, size_t k, size_t velKey, double dt);
 
-  Vector evaluateError(const gtsam::LieScalar& qk1, const gtsam::LieScalar& qk, const gtsam::LieScalar& v) const;
+  Vector evaluateError(const double& qk1, const double& qk, const double& v) const;
 };
 
 #include <gtsam_unstable/dynamics/Pendulum.h>
@@ -499,21 +495,21 @@ virtual class PendulumFactor2 : gtsam::N
   /** Standard constructor */
   PendulumFactor2(size_t vk1, size_t vk, size_t qKey, double dt, double L, double g);
 
-  Vector evaluateError(const gtsam::LieScalar& vk1, const gtsam::LieScalar& vk, const gtsam::LieScalar& q) const;
+  Vector evaluateError(const double& vk1, const double& vk, const double& q) const;
 };
 
 virtual class PendulumFactorPk : gtsam::NonlinearFactor {
   /** Standard constructor */
   PendulumFactorPk(size_t pk, size_t qk, size_t qk1, double h, double m, double r, double g, double alpha);
 
-  Vector evaluateError(const gtsam::LieScalar& pk, const gtsam::LieScalar& qk, const gtsam::LieScalar& qk1) const;
+  Vector evaluateError(const double& pk, const double& qk, const double& qk1) const;
 };
 
 virtual class PendulumFactorPk1 : gtsam::NonlinearFactor {
   /** Standard constructor */
   PendulumFactorPk1(size_t pk1, size_t qk, size_t qk1, double h, double m, double r, double g, double alpha);
 
-  Vector evaluateError(const gtsam::LieScalar& pk1, const gtsam::LieScalar& qk, const gtsam::LieScalar& qk1) const;
+  Vector evaluateError(const double& pk1, const double& qk, const double& qk1) const;
 };
 
 #include <gtsam_unstable/dynamics/SimpleHelicopter.h>
--- gtsam-4.1.0.orig/gtsam_unstable/linear/ActiveSetSolver-inl.h
+++ gtsam-4.1.0/gtsam_unstable/linear/ActiveSetSolver-inl.h
@@ -149,7 +149,7 @@ Template JacobianFactor::shared_ptr This
     // to compute the least-square approximation of dual variables
     return boost::make_shared<JacobianFactor>(Aterms, b);
   } else {
-    return boost::make_shared<JacobianFactor>();
+    return nullptr;
   }
 }
 
@@ -165,14 +165,13 @@ Template JacobianFactor::shared_ptr This
  *  if lambda = 0  you are on the constraint
  *  if lambda > 0  you are violating the constraint.
  */
-Template GaussianFactorGraph::shared_ptr This::buildDualGraph(
+Template GaussianFactorGraph This::buildDualGraph(
     const InequalityFactorGraph& workingSet, const VectorValues& delta) const {
-  GaussianFactorGraph::shared_ptr dualGraph(new GaussianFactorGraph());
+  GaussianFactorGraph dualGraph;
   for (Key key : constrainedKeys_) {
     // Each constrained key becomes a factor in the dual graph
-    JacobianFactor::shared_ptr dualFactor =
-        createDualFactor(key, workingSet, delta);
-    if (!dualFactor->empty()) dualGraph->push_back(dualFactor);
+    auto dualFactor = createDualFactor(key, workingSet, delta);
+    if (dualFactor) dualGraph.push_back(dualFactor);
   }
   return dualGraph;
 }
@@ -193,19 +192,16 @@ This::buildWorkingGraph(const Inequality
 Template typename This::State This::iterate(
     const typename This::State& state) const {
   // Algorithm 16.3 from Nocedal06book.
-  // Solve with the current working set eqn 16.39, but instead of solving for p
-  // solve for x
-  GaussianFactorGraph workingGraph =
-      buildWorkingGraph(state.workingSet, state.values);
+  // Solve with the current working set eqn 16.39, but solve for x not p
+  auto workingGraph = buildWorkingGraph(state.workingSet, state.values);
   VectorValues newValues = workingGraph.optimize();
   // If we CAN'T move further
   // if p_k = 0 is the original condition, modified by Duy to say that the state
   // update is zero.
   if (newValues.equals(state.values, 1e-7)) {
     // Compute lambda from the dual graph
-    GaussianFactorGraph::shared_ptr dualGraph = buildDualGraph(state.workingSet,
-        newValues);
-    VectorValues duals = dualGraph->optimize();
+    auto dualGraph = buildDualGraph(state.workingSet, newValues);
+    VectorValues duals = dualGraph.optimize();
     int leavingFactor = identifyLeavingConstraint(state.workingSet, duals);
     // If all inequality constraints are satisfied: We have the solution!!
     if (leavingFactor < 0) {
--- gtsam-4.1.0.orig/gtsam_unstable/linear/ActiveSetSolver.h
+++ gtsam-4.1.0/gtsam_unstable/linear/ActiveSetSolver.h
@@ -154,8 +154,8 @@ protected:
 public: /// Just for testing...
 
   /// Builds a dual graph from the current working set.
-  GaussianFactorGraph::shared_ptr buildDualGraph(
-      const InequalityFactorGraph& workingSet, const VectorValues& delta) const;
+  GaussianFactorGraph buildDualGraph(const InequalityFactorGraph &workingSet,
+                                     const VectorValues &delta) const;
 
   /**
    * Build a working graph of cost, equality and active inequality constraints
--- gtsam-4.1.0.orig/gtsam_unstable/linear/EqualityFactorGraph.h
+++ gtsam-4.1.0/gtsam_unstable/linear/EqualityFactorGraph.h
@@ -31,6 +31,11 @@ class EqualityFactorGraph: public Factor
 public:
   typedef boost::shared_ptr<EqualityFactorGraph> shared_ptr;
 
+  /// Add a linear inequality, forwards arguments to LinearInequality.
+  template <class... Args> void add(Args &&... args) {
+    emplace_shared<LinearEquality>(std::forward<Args>(args)...);
+  }
+
   /// Compute error of a guess.
   double error(const VectorValues& x) const {
     double total_error = 0.;
--- gtsam-4.1.0.orig/gtsam_unstable/linear/InequalityFactorGraph.h
+++ gtsam-4.1.0/gtsam_unstable/linear/InequalityFactorGraph.h
@@ -47,6 +47,11 @@ public:
     return Base::equals(other, tol);
   }
 
+  /// Add a linear inequality, forwards arguments to LinearInequality.
+  template <class... Args> void add(Args &&... args) {
+    emplace_shared<LinearInequality>(std::forward<Args>(args)...);
+  }
+
   /**
    * Compute error of a guess.
    * Infinity error if it violates an inequality; zero otherwise. */
--- gtsam-4.1.0.orig/gtsam_unstable/linear/LPInitSolver.h
+++ gtsam-4.1.0/gtsam_unstable/linear/LPInitSolver.h
@@ -21,7 +21,6 @@
 
 #include <gtsam_unstable/linear/LP.h>
 #include <gtsam/linear/GaussianFactorGraph.h>
-#include <CppUnitLite/Test.h>
 
 namespace gtsam {
 /**
@@ -83,7 +82,7 @@ private:
       const InequalityFactorGraph& inequalities) const;
 
   // friend class for unit-testing private methods
-  FRIEND_TEST(LPInitSolver, initialization);
+  friend class LPInitSolverInitializationTest;
 };
 
 }
--- gtsam-4.1.0.orig/gtsam_unstable/linear/QPSParser.cpp
+++ gtsam-4.1.0/gtsam_unstable/linear/QPSParser.cpp
@@ -81,7 +81,7 @@ class QPSVisitor {
       varname_to_key;  // Variable QPS string name to key
   std::unordered_map<Key, std::unordered_map<Key, Matrix11>>
       H;                 // H from hessian
-  double f;              // Constant term of quadratic cost
+  double f = 0;          // Constant term of quadratic cost
   std::string obj_name;  // the objective function has a name in the QPS
   std::string name_;     // the quadratic program has a name in the QPS
   std::unordered_map<Key, double>
@@ -175,10 +175,11 @@ class QPSVisitor {
     string var_ = fromChars<1>(vars);
     string row_ = fromChars<3>(vars);
     double coefficient = at_c<5>(vars);
-    if (row_ == obj_name)
+    if (row_ == obj_name) {
       f = -coefficient;
-    else
+    } else {
       b[row_] = coefficient;
+    }
 
     if (debug) {
       cout << "Added RHS for Var: " << var_ << " Row: " << row_
@@ -194,15 +195,17 @@ class QPSVisitor {
     string row2_ = fromChars<7>(vars);
     double coefficient1 = at_c<5>(vars);
     double coefficient2 = at_c<9>(vars);
-    if (row1_ == obj_name)
+    if (row1_ == obj_name) {
       f = -coefficient1;
-    else
+    } else {
       b[row1_] = coefficient1;
+    }
 
-    if (row2_ == obj_name)
+    if (row2_ == obj_name) {
       f = -coefficient2;
-    else
+    } else {
       b[row2_] = coefficient2;
+    }
 
     if (debug) {
       cout << "Added RHS for Var: " << var_ << " Row: " << row1_
--- gtsam-4.1.0.orig/gtsam_unstable/linear/tests/testLPSolver.cpp
+++ gtsam-4.1.0/gtsam_unstable/linear/tests/testLPSolver.cpp
@@ -16,21 +16,23 @@
  * @author Duy-Nguyen Ta
  */
 
+#include <gtsam_unstable/linear/LPInitSolver.h>
+#include <gtsam_unstable/linear/LPSolver.h>
+
 #include <gtsam/base/Testable.h>
-#include <gtsam/inference/Symbol.h>
 #include <gtsam/inference/FactorGraph-inst.h>
-#include <gtsam/linear/VectorValues.h>
+#include <gtsam/inference/Symbol.h>
 #include <gtsam/linear/GaussianFactorGraph.h>
+#include <gtsam/linear/VectorValues.h>
 #include <gtsam_unstable/linear/EqualityFactorGraph.h>
 #include <gtsam_unstable/linear/InequalityFactorGraph.h>
 #include <gtsam_unstable/linear/InfeasibleInitialValues.h>
+
 #include <CppUnitLite/TestHarness.h>
+
 #include <boost/foreach.hpp>
 #include <boost/range/adaptor/map.hpp>
 
-#include <gtsam_unstable/linear/LPSolver.h>
-#include <gtsam_unstable/linear/LPInitSolver.h>
-
 using namespace std;
 using namespace gtsam;
 using namespace gtsam::symbol_shorthand;
@@ -47,37 +49,27 @@ static const Vector kOne = Vector::Ones(
  */
 LP simpleLP1() {
   LP lp;
-  lp.cost = LinearCost(1, Vector2(-1., -1.));  // min -x1-x2 (max x1+x2)
-  lp.inequalities.push_back(
-      LinearInequality(1, Vector2(-1, 0), 0, 1));  // x1 >= 0
-  lp.inequalities.push_back(
-      LinearInequality(1, Vector2(0, -1), 0, 2));  //  x2 >= 0
-  lp.inequalities.push_back(
-      LinearInequality(1, Vector2(1, 2), 4, 3));  //  x1 + 2*x2 <= 4
-  lp.inequalities.push_back(
-      LinearInequality(1, Vector2(4, 2), 12, 4));  //  4x1 + 2x2 <= 12
-  lp.inequalities.push_back(
-      LinearInequality(1, Vector2(-1, 1), 1, 5));  //  -x1 + x2 <= 1
+  lp.cost = LinearCost(1, Vector2(-1., -1.));   // min -x1-x2 (max x1+x2)
+  lp.inequalities.add(1, Vector2(-1, 0), 0, 1); // x1 >= 0
+  lp.inequalities.add(1, Vector2(0, -1), 0, 2); //  x2 >= 0
+  lp.inequalities.add(1, Vector2(1, 2), 4, 3);  //  x1 + 2*x2 <= 4
+  lp.inequalities.add(1, Vector2(4, 2), 12, 4); //  4x1 + 2x2 <= 12
+  lp.inequalities.add(1, Vector2(-1, 1), 1, 5); //  -x1 + x2 <= 1
   return lp;
 }
 
 /* ************************************************************************* */
 namespace gtsam {
 
-TEST(LPInitSolver, infinite_loop_single_var) {
-  LP initchecker;
-  initchecker.cost = LinearCost(1, Vector3(0, 0, 1));  // min alpha
-  initchecker.inequalities.push_back(
-      LinearInequality(1, Vector3(-2, -1, -1), -2, 1));  //-2x-y-alpha <= -2
-  initchecker.inequalities.push_back(
-      LinearInequality(1, Vector3(-1, 2, -1), 6, 2));  // -x+2y-alpha <= 6
-  initchecker.inequalities.push_back(
-      LinearInequality(1, Vector3(-1, 0, -1), 0, 3));  // -x - alpha <= 0
-  initchecker.inequalities.push_back(
-      LinearInequality(1, Vector3(1, 0, -1), 20, 4));  // x - alpha <= 20
-  initchecker.inequalities.push_back(
-      LinearInequality(1, Vector3(0, -1, -1), 0, 5));  // -y - alpha <= 0
-  LPSolver solver(initchecker);
+TEST(LPInitSolver, InfiniteLoopSingleVar) {
+  LP lp;
+  lp.cost = LinearCost(1, Vector3(0, 0, 1));          // min alpha
+  lp.inequalities.add(1, Vector3(-2, -1, -1), -2, 1); //-2x-y-a <= -2
+  lp.inequalities.add(1, Vector3(-1, 2, -1), 6, 2);   // -x+2y-a <= 6
+  lp.inequalities.add(1, Vector3(-1, 0, -1), 0, 3);   // -x - a <= 0
+  lp.inequalities.add(1, Vector3(1, 0, -1), 20, 4);   // x - a <= 20
+  lp.inequalities.add(1, Vector3(0, -1, -1), 0, 5);   // -y - a <= 0
+  LPSolver solver(lp);
   VectorValues starter;
   starter.insert(1, Vector3(0, 0, 2));
   VectorValues results, duals;
@@ -87,25 +79,23 @@ TEST(LPInitSolver, infinite_loop_single_
   CHECK(assert_equal(results, expected, 1e-7));
 }
 
-TEST(LPInitSolver, infinite_loop_multi_var) {
-  LP initchecker;
+TEST(LPInitSolver, InfiniteLoopMultiVar) {
+  LP lp;
   Key X = symbol('X', 1);
   Key Y = symbol('Y', 1);
   Key Z = symbol('Z', 1);
-  initchecker.cost = LinearCost(Z, kOne);  // min alpha
-  initchecker.inequalities.push_back(
-      LinearInequality(X, -2.0 * kOne, Y, -1.0 * kOne, Z, -1.0 * kOne, -2,
-                       1));  //-2x-y-alpha <= -2
-  initchecker.inequalities.push_back(
-      LinearInequality(X, -1.0 * kOne, Y, 2.0 * kOne, Z, -1.0 * kOne, 6,
-                       2));  // -x+2y-alpha <= 6
-  initchecker.inequalities.push_back(LinearInequality(
-      X, -1.0 * kOne, Z, -1.0 * kOne, 0, 3));  // -x - alpha <= 0
-  initchecker.inequalities.push_back(LinearInequality(
-      X, 1.0 * kOne, Z, -1.0 * kOne, 20, 4));  // x - alpha <= 20
-  initchecker.inequalities.push_back(LinearInequality(
-      Y, -1.0 * kOne, Z, -1.0 * kOne, 0, 5));  // -y - alpha <= 0
-  LPSolver solver(initchecker);
+  lp.cost = LinearCost(Z, kOne); // min alpha
+  lp.inequalities.add(X, -2.0 * kOne, Y, -1.0 * kOne, Z, -1.0 * kOne, -2,
+                      1); //-2x-y-alpha <= -2
+  lp.inequalities.add(X, -1.0 * kOne, Y, 2.0 * kOne, Z, -1.0 * kOne, 6,
+                      2); // -x+2y-alpha <= 6
+  lp.inequalities.add(X, -1.0 * kOne, Z, -1.0 * kOne, 0,
+                      3); // -x - alpha <= 0
+  lp.inequalities.add(X, 1.0 * kOne, Z, -1.0 * kOne, 20,
+                      4); // x - alpha <= 20
+  lp.inequalities.add(Y, -1.0 * kOne, Z, -1.0 * kOne, 0,
+                      5); // -y - alpha <= 0
+  LPSolver solver(lp);
   VectorValues starter;
   starter.insert(X, kZero);
   starter.insert(Y, kZero);
@@ -119,7 +109,7 @@ TEST(LPInitSolver, infinite_loop_multi_v
   CHECK(assert_equal(results, expected, 1e-7));
 }
 
-TEST(LPInitSolver, initialization) {
+TEST(LPInitSolver, Initialization) {
   LP lp = simpleLP1();
   LPInitSolver initSolver(lp);
 
@@ -138,19 +128,19 @@ TEST(LPInitSolver, initialization) {
   LP::shared_ptr initLP = initSolver.buildInitialLP(yKey);
   LP expectedInitLP;
   expectedInitLP.cost = LinearCost(yKey, kOne);
-  expectedInitLP.inequalities.push_back(LinearInequality(
-      1, Vector2(-1, 0), 2, Vector::Constant(1, -1), 0, 1));  // -x1 - y <= 0
-  expectedInitLP.inequalities.push_back(LinearInequality(
-      1, Vector2(0, -1), 2, Vector::Constant(1, -1), 0, 2));  // -x2 - y <= 0
-  expectedInitLP.inequalities.push_back(
-      LinearInequality(1, Vector2(1, 2), 2, Vector::Constant(1, -1), 4,
-                       3));  //  x1 + 2*x2 - y <= 4
-  expectedInitLP.inequalities.push_back(
-      LinearInequality(1, Vector2(4, 2), 2, Vector::Constant(1, -1), 12,
-                       4));  //  4x1 + 2x2 - y <= 12
-  expectedInitLP.inequalities.push_back(
-      LinearInequality(1, Vector2(-1, 1), 2, Vector::Constant(1, -1), 1,
-                       5));  //  -x1 + x2 - y <= 1
+  expectedInitLP.inequalities.add(1, Vector2(-1, 0), 2, Vector::Constant(1, -1),
+                                  0, 1); // -x1 - y <= 0
+  expectedInitLP.inequalities.add(1, Vector2(0, -1), 2, Vector::Constant(1, -1),
+                                  0, 2); // -x2 - y <= 0
+  expectedInitLP.inequalities.add(1, Vector2(1, 2), 2, Vector::Constant(1, -1),
+                                  4,
+                                  3); //  x1 + 2*x2 - y <= 4
+  expectedInitLP.inequalities.add(1, Vector2(4, 2), 2, Vector::Constant(1, -1),
+                                  12,
+                                  4); //  4x1 + 2x2 - y <= 12
+  expectedInitLP.inequalities.add(1, Vector2(-1, 1), 2, Vector::Constant(1, -1),
+                                  1,
+                                  5); //  -x1 + x2 - y <= 1
   CHECK(assert_equal(expectedInitLP, *initLP, 1e-10));
   LPSolver lpSolveInit(*initLP);
   VectorValues xy0(x0);
@@ -164,7 +154,7 @@ TEST(LPInitSolver, initialization) {
   VectorValues x = initSolver.solve();
   CHECK(lp.isFeasible(x));
 }
-}
+} // namespace gtsam
 
 /* ************************************************************************* */
 /**
@@ -173,28 +163,24 @@ TEST(LPInitSolver, initialization) {
  *  x - y = 5
  *  x + 2y = 6
  */
-TEST(LPSolver, overConstrainedLinearSystem) {
+TEST(LPSolver, OverConstrainedLinearSystem) {
   GaussianFactorGraph graph;
   Matrix A1 = Vector3(1, 1, 1);
   Matrix A2 = Vector3(1, -1, 2);
   Vector b = Vector3(1, 5, 6);
-  JacobianFactor factor(1, A1, 2, A2, b, noiseModel::Constrained::All(3));
-  graph.push_back(factor);
+  graph.add(1, A1, 2, A2, b, noiseModel::Constrained::All(3));
 
   VectorValues x = graph.optimize();
   // This check confirms that gtsam linear constraint solver can't handle
   // over-constrained system
-  CHECK(factor.error(x) != 0.0);
+  CHECK(graph[0]->error(x) != 0.0);
 }
 
 TEST(LPSolver, overConstrainedLinearSystem2) {
   GaussianFactorGraph graph;
-  graph.emplace_shared<JacobianFactor>(1, I_1x1, 2, I_1x1, kOne,
-                                 noiseModel::Constrained::All(1));
-  graph.emplace_shared<JacobianFactor>(1, I_1x1, 2, -I_1x1, 5 * kOne,
-                                 noiseModel::Constrained::All(1));
-  graph.emplace_shared<JacobianFactor>(1, I_1x1, 2, 2 * I_1x1, 6 * kOne,
-                                 noiseModel::Constrained::All(1));
+  graph.add(1, I_1x1, 2, I_1x1, kOne, noiseModel::Constrained::All(1));
+  graph.add(1, I_1x1, 2, -I_1x1, 5 * kOne, noiseModel::Constrained::All(1));
+  graph.add(1, I_1x1, 2, 2 * I_1x1, 6 * kOne, noiseModel::Constrained::All(1));
   VectorValues x = graph.optimize();
   // This check confirms that gtsam linear constraint solver can't handle
   // over-constrained system
@@ -202,7 +188,7 @@ TEST(LPSolver, overConstrainedLinearSyst
 }
 
 /* ************************************************************************* */
-TEST(LPSolver, simpleTest1) {
+TEST(LPSolver, SimpleTest1) {
   LP lp = simpleLP1();
   LPSolver lpSolver(lp);
   VectorValues init;
@@ -222,7 +208,7 @@ TEST(LPSolver, simpleTest1) {
 }
 
 /* ************************************************************************* */
-TEST(LPSolver, testWithoutInitialValues) {
+TEST(LPSolver, TestWithoutInitialValues) {
   LP lp = simpleLP1();
   LPSolver lpSolver(lp);
   VectorValues result, duals, expectedResult;
--- gtsam-4.1.0.orig/gtsam_unstable/linear/tests/testQPSolver.cpp
+++ gtsam-4.1.0/gtsam_unstable/linear/tests/testQPSolver.cpp
@@ -17,10 +17,12 @@
  * @author Ivan Dario Jimenez
  */
 
+#include <gtsam_unstable/linear/QPSParser.h>
+#include <gtsam_unstable/linear/QPSolver.h>
+
 #include <gtsam/base/Testable.h>
 #include <gtsam/inference/Symbol.h>
-#include <gtsam_unstable/linear/QPSolver.h>
-#include <gtsam_unstable/linear/QPSParser.h>
+
 #include <CppUnitLite/TestHarness.h>
 
 using namespace std;
@@ -40,15 +42,15 @@ QP createTestCase() {
   // Hence, we have G11=2, G12 = -1, g1 = +3, G22 = 2, g2 = 0, f = 10
   //TODO:  THIS TEST MIGHT BE WRONG : the last parameter  might be 5 instead of 10 because the form of the equation
   // Should be 0.5x'Gx + gx + f : Nocedal 449
-  qp.cost.push_back(
-      HessianFactor(X(1), X(2), 2.0 * I_1x1, -I_1x1, 3.0 * I_1x1, 2.0 * I_1x1,
-          Z_1x1, 10.0));
+  qp.cost.push_back(HessianFactor(X(1), X(2), 2.0 * I_1x1, -I_1x1, 3.0 * I_1x1,
+                                  2.0 * I_1x1, Z_1x1, 10.0));
 
   // Inequality constraints
-  qp.inequalities.push_back(LinearInequality(X(1), I_1x1, X(2), I_1x1, 2, 0)); // x1 + x2 <= 2 --> x1 + x2 -2 <= 0, --> b=2
-  qp.inequalities.push_back(LinearInequality(X(1), -I_1x1, 0, 1)); // -x1     <= 0
-  qp.inequalities.push_back(LinearInequality(X(2), -I_1x1, 0, 2)); //    -x2  <= 0
-  qp.inequalities.push_back(LinearInequality(X(1), I_1x1, 1.5, 3)); // x1      <= 3/2
+  qp.inequalities.add(X(1), I_1x1, X(2), I_1x1, 2,
+                      0); // x1 + x2 <= 2 --> x1 + x2 -2 <= 0, --> b=2
+  qp.inequalities.add(X(1), -I_1x1, 0, 1);  // -x1     <= 0
+  qp.inequalities.add(X(2), -I_1x1, 0, 2);  //    -x2  <= 0
+  qp.inequalities.add(X(1), I_1x1, 1.5, 3); // x1      <= 3/2
 
   return qp;
 }
@@ -94,16 +96,15 @@ QP createEqualityConstrainedTest() {
   // Note the Hessian encodes:
   //        0.5*x1'*G11*x1 + x1'*G12*x2 + 0.5*x2'*G22*x2 - x1'*g1 - x2'*g2 + 0.5*f
   // Hence, we have G11=2, G12 = 0, g1 = 0, G22 = 2, g2 = 0, f = 0
-  qp.cost.push_back(
-      HessianFactor(X(1), X(2), 2.0 * I_1x1, Z_1x1, Z_1x1, 2.0 * I_1x1, Z_1x1,
-          0.0));
+  qp.cost.push_back(HessianFactor(X(1), X(2), 2.0 * I_1x1, Z_1x1, Z_1x1,
+                                  2.0 * I_1x1, Z_1x1, 0.0));
 
   // Equality constraints
   // x1 + x2 = 1 --> x1 + x2 -1 = 0, hence we negate the b vector
   Matrix A1 = I_1x1;
   Matrix A2 = I_1x1;
   Vector b = -kOne;
-  qp.equalities.push_back(LinearEquality(X(1), A1, X(2), A2, b, 0));
+  qp.equalities.add(X(1), A1, X(2), A2, b, 0);
 
   return qp;
 }
@@ -118,9 +119,8 @@ TEST(QPSolver, dual) {
 
   QPSolver solver(qp);
 
-  GaussianFactorGraph::shared_ptr dualGraph = solver.buildDualGraph(
-      qp.inequalities, initialValues);
-  VectorValues dual = dualGraph->optimize();
+  auto dualGraph = solver.buildDualGraph(qp.inequalities, initialValues);
+  VectorValues dual = dualGraph.optimize();
   VectorValues expectedDual;
   expectedDual.insert(0, (Vector(1) << 2.0).finished());
   CHECK(assert_equal(expectedDual, dual, 1e-10));
@@ -135,19 +135,19 @@ TEST(QPSolver, indentifyActiveConstraint
   currentSolution.insert(X(1), Z_1x1);
   currentSolution.insert(X(2), Z_1x1);
 
-  InequalityFactorGraph workingSet = solver.identifyActiveConstraints(
-      qp.inequalities, currentSolution);
+  auto workingSet =
+      solver.identifyActiveConstraints(qp.inequalities, currentSolution);
 
   CHECK(!workingSet.at(0)->active()); // inactive
-  CHECK(workingSet.at(1)->active());// active
-  CHECK(workingSet.at(2)->active());// active
-  CHECK(!workingSet.at(3)->active());// inactive
+  CHECK(workingSet.at(1)->active());  // active
+  CHECK(workingSet.at(2)->active());  // active
+  CHECK(!workingSet.at(3)->active()); // inactive
 
   VectorValues solution = solver.buildWorkingGraph(workingSet).optimize();
-  VectorValues expectedSolution;
-  expectedSolution.insert(X(1), kZero);
-  expectedSolution.insert(X(2), kZero);
-  CHECK(assert_equal(expectedSolution, solution, 1e-100));
+  VectorValues expected;
+  expected.insert(X(1), kZero);
+  expected.insert(X(2), kZero);
+  CHECK(assert_equal(expected, solution, 1e-100));
 }
 
 /* ************************************************************************* */
@@ -159,24 +159,24 @@ TEST(QPSolver, iterate) {
   currentSolution.insert(X(1), Z_1x1);
   currentSolution.insert(X(2), Z_1x1);
 
-  std::vector<VectorValues> expectedSolutions(4), expectedDuals(4);
-  expectedSolutions[0].insert(X(1), kZero);
-  expectedSolutions[0].insert(X(2), kZero);
+  std::vector<VectorValues> expected(4), expectedDuals(4);
+  expected[0].insert(X(1), kZero);
+  expected[0].insert(X(2), kZero);
   expectedDuals[0].insert(1, (Vector(1) << 3).finished());
   expectedDuals[0].insert(2, kZero);
 
-  expectedSolutions[1].insert(X(1), (Vector(1) << 1.5).finished());
-  expectedSolutions[1].insert(X(2), kZero);
+  expected[1].insert(X(1), (Vector(1) << 1.5).finished());
+  expected[1].insert(X(2), kZero);
   expectedDuals[1].insert(3, (Vector(1) << 1.5).finished());
 
-  expectedSolutions[2].insert(X(1), (Vector(1) << 1.5).finished());
-  expectedSolutions[2].insert(X(2), (Vector(1) << 0.75).finished());
+  expected[2].insert(X(1), (Vector(1) << 1.5).finished());
+  expected[2].insert(X(2), (Vector(1) << 0.75).finished());
 
-  expectedSolutions[3].insert(X(1), (Vector(1) << 1.5).finished());
-  expectedSolutions[3].insert(X(2), (Vector(1) << 0.5).finished());
+  expected[3].insert(X(1), (Vector(1) << 1.5).finished());
+  expected[3].insert(X(2), (Vector(1) << 0.5).finished());
 
-  InequalityFactorGraph workingSet = solver.identifyActiveConstraints(
-      qp.inequalities, currentSolution);
+  auto workingSet =
+      solver.identifyActiveConstraints(qp.inequalities, currentSolution);
 
   QPSolver::State state(currentSolution, VectorValues(), workingSet, false,
                         100);
@@ -188,12 +188,12 @@ TEST(QPSolver, iterate) {
     // Forst10book do not follow exactly what we implemented from Nocedal06book.
     // Specifically, we do not re-identify active constraints and
     // do not recompute dual variables after every step!!!
-//    CHECK(assert_equal(expectedSolutions[it], state.values, 1e-10));
-//    CHECK(assert_equal(expectedDuals[it], state.duals, 1e-10));
+    //    CHECK(assert_equal(expected[it], state.values, 1e-10));
+    //    CHECK(assert_equal(expectedDuals[it], state.duals, 1e-10));
     it++;
   }
 
-  CHECK(assert_equal(expectedSolutions[3], state.values, 1e-10));
+  CHECK(assert_equal(expected[3], state.values, 1e-10));
 }
 
 /* ************************************************************************* */
@@ -204,182 +204,161 @@ TEST(QPSolver, optimizeForst10book_pg171
   VectorValues initialValues;
   initialValues.insert(X(1), Z_1x1);
   initialValues.insert(X(2), Z_1x1);
-  VectorValues solution;
-  boost::tie(solution, boost::tuples::ignore) = solver.optimize(initialValues);
-  VectorValues expectedSolution;
-  expectedSolution.insert(X(1), (Vector(1) << 1.5).finished());
-  expectedSolution.insert(X(2), (Vector(1) << 0.5).finished());
-  CHECK(assert_equal(expectedSolution, solution, 1e-100));
+  VectorValues solution = solver.optimize(initialValues).first;
+  VectorValues expected;
+  expected.insert(X(1), (Vector(1) << 1.5).finished());
+  expected.insert(X(2), (Vector(1) << 0.5).finished());
+  CHECK(assert_equal(expected, solution, 1e-100));
 }
 
 pair<QP, QP> testParser(QPSParser parser) {
   QP exampleqp = parser.Parse();
-  QP expectedqp;
+  QP expected;
   Key X1(Symbol('X', 1)), X2(Symbol('X', 2));
   // min f(x,y) = 4 + 1.5x -y + 0.58x^2 + 2xy + 2yx + 10y^2
-  expectedqp.cost.push_back(
-      HessianFactor(X1, X2, 8.0 * I_1x1, 2.0 * I_1x1, -1.5 * kOne, 10.0 * I_1x1,
-          2.0 * kOne, 8.0));
-  // 2x + y >= 2
-  // -x + 2y <= 6
-  expectedqp.inequalities.push_back(
-      LinearInequality(X1, -2.0 * I_1x1, X2, -I_1x1, -2, 0));
-  expectedqp.inequalities.push_back(
-      LinearInequality(X1, -I_1x1, X2, 2.0 * I_1x1, 6, 1));
-  // x<= 20
-  expectedqp.inequalities.push_back(LinearInequality(X1, I_1x1, 20, 4));
-  //x >= 0
-  expectedqp.inequalities.push_back(LinearInequality(X1, -I_1x1, 0, 2));
-  // y > = 0
-  expectedqp.inequalities.push_back(LinearInequality(X2, -I_1x1, 0, 3));
-  return std::make_pair(expectedqp, exampleqp);
-}
-;
+  expected.cost.push_back(HessianFactor(X1, X2, 8.0 * I_1x1, 2.0 * I_1x1,
+                                        -1.5 * kOne, 10.0 * I_1x1, 2.0 * kOne,
+                                        8.0));
+
+  expected.inequalities.add(X1, -2.0 * I_1x1, X2, -I_1x1, -2, 0); // 2x + y >= 2
+  expected.inequalities.add(X1, -I_1x1, X2, 2.0 * I_1x1, 6, 1); // -x + 2y <= 6
+  expected.inequalities.add(X1, I_1x1, 20, 4);                  // x<= 20
+  expected.inequalities.add(X1, -I_1x1, 0, 2);                  // x >= 0
+  expected.inequalities.add(X2, -I_1x1, 0, 3);                  // y > = 0
+  return {expected, exampleqp};
+};
 
 TEST(QPSolver, ParserSyntaticTest) {
-  auto expectedActual = testParser(QPSParser("QPExample.QPS"));
-  CHECK(assert_equal(expectedActual.first.cost, expectedActual.second.cost,
+  auto result = testParser(QPSParser("QPExample.QPS"));
+  CHECK(assert_equal(result.first.cost, result.second.cost, 1e-7));
+  CHECK(assert_equal(result.first.inequalities, result.second.inequalities,
                      1e-7));
-  CHECK(assert_equal(expectedActual.first.inequalities,
-                     expectedActual.second.inequalities, 1e-7));
-  CHECK(assert_equal(expectedActual.first.equalities,
-                     expectedActual.second.equalities, 1e-7));
+  CHECK(assert_equal(result.first.equalities, result.second.equalities, 1e-7));
 }
 
 TEST(QPSolver, ParserSemanticTest) {
-  auto expected_actual = testParser(QPSParser("QPExample.QPS"));
-  VectorValues actualSolution, expectedSolution;
-  boost::tie(expectedSolution, boost::tuples::ignore) =
-      QPSolver(expected_actual.first).optimize();
-  boost::tie(actualSolution, boost::tuples::ignore) =
-      QPSolver(expected_actual.second).optimize();
-  CHECK(assert_equal(actualSolution, expectedSolution, 1e-7));
+  auto result = testParser(QPSParser("QPExample.QPS"));
+  VectorValues expected = QPSolver(result.first).optimize().first;
+  VectorValues actual = QPSolver(result.second).optimize().first;
+  CHECK(assert_equal(actual, expected, 1e-7));
 }
 
-TEST(QPSolver, QPExampleTest){
+TEST(QPSolver, QPExampleTest) {
   QP problem = QPSParser("QPExample.QPS").Parse();
-  VectorValues actualSolution;
   auto solver = QPSolver(problem);
-  boost::tie(actualSolution, boost::tuples::ignore) = solver.optimize();
-  VectorValues expectedSolution;
-  expectedSolution.insert(Symbol('X',1),0.7625*I_1x1);
-  expectedSolution.insert(Symbol('X',2),0.4750*I_1x1);
-  double error_expected = problem.cost.error(expectedSolution);
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(expectedSolution, actualSolution, 1e-7))
+  VectorValues actual = solver.optimize().first;
+  VectorValues expected;
+  expected.insert(Symbol('X', 1), 0.7625 * I_1x1);
+  expected.insert(Symbol('X', 2), 0.4750 * I_1x1);
+  double error_expected = problem.cost.error(expected);
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(expected, actual, 1e-7))
   CHECK(assert_equal(error_expected, error_actual))
 }
 
 TEST(QPSolver, HS21) {
   QP problem = QPSParser("HS21.QPS").Parse();
-  VectorValues actualSolution;
-  VectorValues expectedSolution;
-  expectedSolution.insert(Symbol('X',1), 2.0*I_1x1);
-  expectedSolution.insert(Symbol('X',2), 0.0*I_1x1);
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
+  VectorValues expected;
+  expected.insert(Symbol('X', 1), 2.0 * I_1x1);
+  expected.insert(Symbol('X', 2), 0.0 * I_1x1);
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
   CHECK(assert_equal(-99.9599999, error_actual, 1e-7))
-  CHECK(assert_equal(expectedSolution, actualSolution))
+  CHECK(assert_equal(expected, actual))
 }
 
 TEST(QPSolver, HS35) {
   QP problem = QPSParser("HS35.QPS").Parse();
-  VectorValues actualSolution;
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(1.11111111e-01,error_actual, 1e-7))
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(1.11111111e-01, error_actual, 1e-7))
 }
 
 TEST(QPSolver, HS35MOD) {
   QP problem = QPSParser("HS35MOD.QPS").Parse();
-  VectorValues actualSolution;
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(2.50000001e-01,error_actual, 1e-7))
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(2.50000001e-01, error_actual, 1e-7))
 }
 
 TEST(QPSolver, HS51) {
   QP problem = QPSParser("HS51.QPS").Parse();
-  VectorValues actualSolution;
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(8.88178420e-16,error_actual, 1e-7))
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(8.88178420e-16, error_actual, 1e-7))
 }
 
 TEST(QPSolver, HS52) {
   QP problem = QPSParser("HS52.QPS").Parse();
-  VectorValues actualSolution;
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(5.32664756,error_actual, 1e-7))
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(5.32664756, error_actual, 1e-7))
 }
 
-TEST(QPSolver, HS268) { // This test needs an extra order of magnitude of tolerance than the rest
+TEST(QPSolver, HS268) { // This test needs an extra order of magnitude of
+                        // tolerance than the rest
   QP problem = QPSParser("HS268.QPS").Parse();
-  VectorValues actualSolution;
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(5.73107049e-07,error_actual, 1e-6))
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(5.73107049e-07, error_actual, 1e-6))
 }
 
 TEST(QPSolver, QPTEST) { // REQUIRES Jacobian Fix
   QP problem = QPSParser("QPTEST.QPS").Parse();
-  VectorValues actualSolution;
-  boost::tie(actualSolution, boost::tuples::ignore) = QPSolver(problem).optimize();
-  double error_actual = problem.cost.error(actualSolution);
-  CHECK(assert_equal(0.437187500e01,error_actual, 1e-7))
+  VectorValues actual = QPSolver(problem).optimize().first;
+  double error_actual = problem.cost.error(actual);
+  CHECK(assert_equal(0.437187500e01, error_actual, 1e-7))
 }
 
 /* ************************************************************************* */
-// Create Matlab's test graph as in http://www.mathworks.com/help/optim/ug/quadprog.html
+// Create Matlab's test graph as in
+// http://www.mathworks.com/help/optim/ug/quadprog.html
 QP createTestMatlabQPEx() {
   QP qp;
 
   // Objective functions 0.5*x1^2 + x2^2 - x1*x2 - 2*x1 -6*x2
   // Note the Hessian encodes:
-  //        0.5*x1'*G11*x1 + x1'*G12*x2 + 0.5*x2'*G22*x2 - x1'*g1 - x2'*g2 + 0.5*f
+  //        0.5*x1'*G11*x1 + x1'*G12*x2 + 0.5*x2'*G22*x2 - x1'*g1 - x2'*g2 +
+  //        0.5*f
   // Hence, we have G11=1, G12 = -1, g1 = +2, G22 = 2, g2 = +6, f = 0
-  qp.cost.push_back(
-      HessianFactor(X(1), X(2), 1.0 * I_1x1, -I_1x1, 2.0 * I_1x1, 2.0 * I_1x1,
-          6 * I_1x1, 1000.0));
+  qp.cost.push_back(HessianFactor(X(1), X(2), 1.0 * I_1x1, -I_1x1, 2.0 * I_1x1,
+                                  2.0 * I_1x1, 6 * I_1x1, 1000.0));
 
   // Inequality constraints
-  qp.inequalities.push_back(LinearInequality(X(1), I_1x1, X(2), I_1x1, 2, 0)); // x1 + x2 <= 2
-  qp.inequalities.push_back(
-      LinearInequality(X(1), -I_1x1, X(2), 2 * I_1x1, 2, 1)); //-x1 + 2*x2 <=2
-  qp.inequalities.push_back(
-      LinearInequality(X(1), 2 * I_1x1, X(2), I_1x1, 3, 2)); // 2*x1 + x2 <=3
-  qp.inequalities.push_back(LinearInequality(X(1), -I_1x1, 0, 3)); // -x1      <= 0
-  qp.inequalities.push_back(LinearInequality(X(2), -I_1x1, 0, 4)); //      -x2 <= 0
+  qp.inequalities.add(X(1), I_1x1, X(2), I_1x1, 2, 0);      // x1 + x2 <= 2
+  qp.inequalities.add(X(1), -I_1x1, X(2), 2 * I_1x1, 2, 1); //-x1 + 2*x2 <=2
+  qp.inequalities.add(X(1), 2 * I_1x1, X(2), I_1x1, 3, 2);  // 2*x1 + x2 <=3
+  qp.inequalities.add(X(1), -I_1x1, 0, 3);                  // -x1      <= 0
+  qp.inequalities.add(X(2), -I_1x1, 0, 4);                  //      -x2 <= 0
 
   return qp;
 }
 
-///* ************************************************************************* */
+///* *************************************************************************
+///*/
 TEST(QPSolver, optimizeMatlabEx) {
   QP qp = createTestMatlabQPEx();
   QPSolver solver(qp);
   VectorValues initialValues;
   initialValues.insert(X(1), Z_1x1);
   initialValues.insert(X(2), Z_1x1);
-  VectorValues solution;
-  boost::tie(solution, boost::tuples::ignore) = solver.optimize(initialValues);
-  VectorValues expectedSolution;
-  expectedSolution.insert(X(1), (Vector(1) << 2.0 / 3.0).finished());
-  expectedSolution.insert(X(2), (Vector(1) << 4.0 / 3.0).finished());
-  CHECK(assert_equal(expectedSolution, solution, 1e-7));
+  VectorValues solution = solver.optimize(initialValues).first;
+  VectorValues expected;
+  expected.insert(X(1), (Vector(1) << 2.0 / 3.0).finished());
+  expected.insert(X(2), (Vector(1) << 4.0 / 3.0).finished());
+  CHECK(assert_equal(expected, solution, 1e-7));
 }
 
-///* ************************************************************************* */
+///* *************************************************************************
+///*/
 TEST(QPSolver, optimizeMatlabExNoinitials) {
   QP qp = createTestMatlabQPEx();
   QPSolver solver(qp);
-  VectorValues solution;
-  boost::tie(solution, boost::tuples::ignore) = solver.optimize();
-  VectorValues expectedSolution;
-  expectedSolution.insert(X(1), (Vector(1) << 2.0 / 3.0).finished());
-  expectedSolution.insert(X(2), (Vector(1) << 4.0 / 3.0).finished());
-  CHECK(assert_equal(expectedSolution, solution, 1e-7));
+  VectorValues solution = solver.optimize().first;
+  VectorValues expected;
+  expected.insert(X(1), (Vector(1) << 2.0 / 3.0).finished());
+  expected.insert(X(2), (Vector(1) << 4.0 / 3.0).finished());
+  CHECK(assert_equal(expected, solution, 1e-7));
 }
 
 /* ************************************************************************* */
@@ -387,18 +366,15 @@ TEST(QPSolver, optimizeMatlabExNoinitial
 QP createTestNocedal06bookEx16_4() {
   QP qp;
 
-  qp.cost.push_back(JacobianFactor(X(1), I_1x1, I_1x1));
-  qp.cost.push_back(JacobianFactor(X(2), I_1x1, 2.5 * I_1x1));
+  qp.cost.add(X(1), I_1x1, I_1x1);
+  qp.cost.add(X(2), I_1x1, 2.5 * I_1x1);
 
   // Inequality constraints
-  qp.inequalities.push_back(
-      LinearInequality(X(1), -I_1x1, X(2), 2 * I_1x1, 2, 0));
-  qp.inequalities.push_back(
-      LinearInequality(X(1), I_1x1, X(2), 2 * I_1x1, 6, 1));
-  qp.inequalities.push_back(
-      LinearInequality(X(1), I_1x1, X(2), -2 * I_1x1, 2, 2));
-  qp.inequalities.push_back(LinearInequality(X(1), -I_1x1, 0.0, 3));
-  qp.inequalities.push_back(LinearInequality(X(2), -I_1x1, 0.0, 4));
+  qp.inequalities.add(X(1), -I_1x1, X(2), 2 * I_1x1, 2, 0);
+  qp.inequalities.add(X(1), I_1x1, X(2), 2 * I_1x1, 6, 1);
+  qp.inequalities.add(X(1), I_1x1, X(2), -2 * I_1x1, 2, 2);
+  qp.inequalities.add(X(1), -I_1x1, 0.0, 3);
+  qp.inequalities.add(X(2), -I_1x1, 0.0, 4);
 
   return qp;
 }
@@ -410,21 +386,19 @@ TEST(QPSolver, optimizeNocedal06bookEx16
   initialValues.insert(X(1), (Vector(1) << 2.0).finished());
   initialValues.insert(X(2), Z_1x1);
 
-  VectorValues solution;
-  boost::tie(solution, boost::tuples::ignore) = solver.optimize(initialValues);
-  VectorValues expectedSolution;
-  expectedSolution.insert(X(1), (Vector(1) << 1.4).finished());
-  expectedSolution.insert(X(2), (Vector(1) << 1.7).finished());
-  CHECK(assert_equal(expectedSolution, solution, 1e-7));
+  VectorValues solution = solver.optimize(initialValues).first;
+  VectorValues expected;
+  expected.insert(X(1), (Vector(1) << 1.4).finished());
+  expected.insert(X(2), (Vector(1) << 1.7).finished());
+  CHECK(assert_equal(expected, solution, 1e-7));
 }
 
 /* ************************************************************************* */
 TEST(QPSolver, failedSubproblem) {
   QP qp;
-  qp.cost.push_back(JacobianFactor(X(1), I_2x2, Z_2x1));
+  qp.cost.add(X(1), I_2x2, Z_2x1);
   qp.cost.push_back(HessianFactor(X(1), Z_2x2, Z_2x1, 100.0));
-  qp.inequalities.push_back(
-      LinearInequality(X(1), (Matrix(1, 2) << -1.0, 0.0).finished(), -1.0, 0));
+  qp.inequalities.add(X(1), (Matrix(1, 2) << -1.0, 0.0).finished(), -1.0, 0);
 
   VectorValues expected;
   expected.insert(X(1), (Vector(2) << 1.0, 0.0).finished());
@@ -433,8 +407,7 @@ TEST(QPSolver, failedSubproblem) {
   initialValues.insert(X(1), (Vector(2) << 10.0, 100.0).finished());
 
   QPSolver solver(qp);
-  VectorValues solution;
-  boost::tie(solution, boost::tuples::ignore) = solver.optimize(initialValues);
+  VectorValues solution = solver.optimize(initialValues).first;
 
   CHECK(assert_equal(expected, solution, 1e-7));
 }
@@ -442,10 +415,9 @@ TEST(QPSolver, failedSubproblem) {
 /* ************************************************************************* */
 TEST(QPSolver, infeasibleInitial) {
   QP qp;
-  qp.cost.push_back(JacobianFactor(X(1), I_2x2, Vector::Zero(2)));
+  qp.cost.add(X(1), I_2x2, Vector::Zero(2));
   qp.cost.push_back(HessianFactor(X(1), Z_2x2, Vector::Zero(2), 100.0));
-  qp.inequalities.push_back(
-      LinearInequality(X(1), (Matrix(1, 2) << -1.0, 0.0).finished(), -1.0, 0));
+  qp.inequalities.add(X(1), (Matrix(1, 2) << -1.0, 0.0).finished(), -1.0, 0);
 
   VectorValues expected;
   expected.insert(X(1), (Vector(2) << 1.0, 0.0).finished());
@@ -464,4 +436,3 @@ int main() {
   return TestRegistry::runAllTests(tr);
 }
 /* ************************************************************************* */
-
--- gtsam-4.1.0.orig/gtsam_unstable/slam/serialization.cpp
+++ gtsam-4.1.0/gtsam_unstable/slam/serialization.cpp
@@ -43,7 +43,6 @@ typedef PriorFactor<Pose3>
 typedef PriorFactor<Cal3_S2>              PriorFactorCal3_S2;
 typedef PriorFactor<Cal3DS2>              PriorFactorCal3DS2;
 typedef PriorFactor<CalibratedCamera>     PriorFactorCalibratedCamera;
-typedef PriorFactor<SimpleCamera>         PriorFactorSimpleCamera;
 typedef PriorFactor<PinholeCameraCal3_S2> PriorFactorPinholeCameraCal3_S2;
 typedef PriorFactor<StereoCamera>         PriorFactorStereoCamera;
 
@@ -68,7 +67,6 @@ typedef NonlinearEquality<Pose3>
 typedef NonlinearEquality<Cal3_S2>                NonlinearEqualityCal3_S2;
 typedef NonlinearEquality<Cal3DS2>                NonlinearEqualityCal3DS2;
 typedef NonlinearEquality<CalibratedCamera>       NonlinearEqualityCalibratedCamera;
-typedef NonlinearEquality<SimpleCamera>           NonlinearEqualitySimpleCamera;
 typedef NonlinearEquality<PinholeCameraCal3_S2>   NonlinearEqualityPinholeCameraCal3_S2;
 typedef NonlinearEquality<StereoCamera>           NonlinearEqualityStereoCamera;
 
@@ -77,10 +75,8 @@ typedef RangeFactor<Pose3, Point3>
 typedef RangeFactor<Pose2, Pose2>                               RangeFactorPose2;
 typedef RangeFactor<Pose3, Pose3>                               RangeFactorPose3;
 typedef RangeFactor<CalibratedCamera, Point3>                   RangeFactorCalibratedCameraPoint;
-typedef RangeFactor<SimpleCamera, Point3>                       RangeFactorSimpleCameraPoint;
 typedef RangeFactor<PinholeCameraCal3_S2, Point3>               RangeFactorPinholeCameraCal3_S2Point;
 typedef RangeFactor<CalibratedCamera, CalibratedCamera>         RangeFactorCalibratedCamera;
-typedef RangeFactor<SimpleCamera, SimpleCamera>                 RangeFactorSimpleCamera;
 typedef RangeFactor<PinholeCameraCal3_S2, PinholeCameraCal3_S2> RangeFactorPinholeCameraCal3_S2;
 
 typedef BearingRangeFactor<Pose2, Point2>  BearingRangeFactor2D;
@@ -90,6 +86,7 @@ typedef GenericProjectionFactor<Pose3, P
 typedef GenericProjectionFactor<Pose3, Point3, Cal3DS2> GenericProjectionFactorCal3DS2;
 
 typedef gtsam::GeneralSFMFactor<gtsam::PinholeCameraCal3_S2, gtsam::Point3> GeneralSFMFactorCal3_S2;
+//TODO fix issue 621
 //typedef gtsam::GeneralSFMFactor<gtsam::PinholeCameraCal3DS2, gtsam::Point3> GeneralSFMFactorCal3DS2;
 
 typedef gtsam::GeneralSFMFactor2<gtsam::Cal3_S2> GeneralSFMFactor2Cal3_S2;
@@ -129,7 +126,6 @@ GTSAM_VALUE_EXPORT(gtsam::Cal3_S2);
 GTSAM_VALUE_EXPORT(gtsam::Cal3DS2);
 GTSAM_VALUE_EXPORT(gtsam::Cal3_S2Stereo);
 GTSAM_VALUE_EXPORT(gtsam::CalibratedCamera);
-GTSAM_VALUE_EXPORT(gtsam::SimpleCamera);
 GTSAM_VALUE_EXPORT(gtsam::PinholeCameraCal3_S2);
 GTSAM_VALUE_EXPORT(gtsam::StereoCamera);
 
@@ -150,7 +146,6 @@ BOOST_CLASS_EXPORT_GUID(PriorFactorPose3
 BOOST_CLASS_EXPORT_GUID(PriorFactorCal3_S2, "gtsam::PriorFactorCal3_S2");
 BOOST_CLASS_EXPORT_GUID(PriorFactorCal3DS2, "gtsam::PriorFactorCal3DS2");
 BOOST_CLASS_EXPORT_GUID(PriorFactorCalibratedCamera, "gtsam::PriorFactorCalibratedCamera");
-BOOST_CLASS_EXPORT_GUID(PriorFactorSimpleCamera, "gtsam::PriorFactorSimpleCamera");
 BOOST_CLASS_EXPORT_GUID(PriorFactorStereoCamera, "gtsam::PriorFactorStereoCamera");
 
 BOOST_CLASS_EXPORT_GUID(BetweenFactorLieVector, "gtsam::BetweenFactorLieVector");
@@ -174,7 +169,6 @@ BOOST_CLASS_EXPORT_GUID(NonlinearEqualit
 BOOST_CLASS_EXPORT_GUID(NonlinearEqualityCal3_S2, "gtsam::NonlinearEqualityCal3_S2");
 BOOST_CLASS_EXPORT_GUID(NonlinearEqualityCal3DS2, "gtsam::NonlinearEqualityCal3DS2");
 BOOST_CLASS_EXPORT_GUID(NonlinearEqualityCalibratedCamera, "gtsam::NonlinearEqualityCalibratedCamera");
-BOOST_CLASS_EXPORT_GUID(NonlinearEqualitySimpleCamera, "gtsam::NonlinearEqualitySimpleCamera");
 BOOST_CLASS_EXPORT_GUID(NonlinearEqualityStereoCamera, "gtsam::NonlinearEqualityStereoCamera");
 
 BOOST_CLASS_EXPORT_GUID(RangeFactor2D, "gtsam::RangeFactor2D");
@@ -182,9 +176,7 @@ BOOST_CLASS_EXPORT_GUID(RangeFactor3D, "
 BOOST_CLASS_EXPORT_GUID(RangeFactorPose2, "gtsam::RangeFactorPose2");
 BOOST_CLASS_EXPORT_GUID(RangeFactorPose3, "gtsam::RangeFactorPose3");
 BOOST_CLASS_EXPORT_GUID(RangeFactorCalibratedCameraPoint, "gtsam::RangeFactorCalibratedCameraPoint");
-BOOST_CLASS_EXPORT_GUID(RangeFactorSimpleCameraPoint, "gtsam::RangeFactorSimpleCameraPoint");
 BOOST_CLASS_EXPORT_GUID(RangeFactorCalibratedCamera, "gtsam::RangeFactorCalibratedCamera");
-BOOST_CLASS_EXPORT_GUID(RangeFactorSimpleCamera, "gtsam::RangeFactorSimpleCamera");
 
 BOOST_CLASS_EXPORT_GUID(BearingRangeFactor2D, "gtsam::BearingRangeFactor2D");
 
@@ -192,12 +184,29 @@ BOOST_CLASS_EXPORT_GUID(GenericProjectio
 BOOST_CLASS_EXPORT_GUID(GenericProjectionFactorCal3DS2, "gtsam::GenericProjectionFactorCal3DS2");
 
 BOOST_CLASS_EXPORT_GUID(GeneralSFMFactorCal3_S2, "gtsam::GeneralSFMFactorCal3_S2");
+//TODO Fix issue 621
 //BOOST_CLASS_EXPORT_GUID(GeneralSFMFactorCal3DS2, "gtsam::GeneralSFMFactorCal3DS2");
 
 BOOST_CLASS_EXPORT_GUID(GeneralSFMFactor2Cal3_S2, "gtsam::GeneralSFMFactor2Cal3_S2");
 
 BOOST_CLASS_EXPORT_GUID(GenericStereoFactor3D, "gtsam::GenericStereoFactor3D");
 
+#ifdef GTSAM_ALLOW_DEPRECATED_SINCE_V41
+
+typedef PriorFactor<SimpleCamera>               PriorFactorSimpleCamera;
+typedef NonlinearEquality<SimpleCamera>         NonlinearEqualitySimpleCamera;
+typedef RangeFactor<SimpleCamera, Point3>       RangeFactorSimpleCameraPoint;
+typedef RangeFactor<SimpleCamera, SimpleCamera> RangeFactorSimpleCamera;
+
+GTSAM_VALUE_EXPORT(gtsam::SimpleCamera);
+BOOST_CLASS_EXPORT_GUID(PriorFactorSimpleCamera, "gtsam::PriorFactorSimpleCamera");
+BOOST_CLASS_EXPORT_GUID(NonlinearEqualitySimpleCamera, "gtsam::NonlinearEqualitySimpleCamera");
+BOOST_CLASS_EXPORT_GUID(RangeFactorSimpleCameraPoint, "gtsam::RangeFactorSimpleCameraPoint");
+BOOST_CLASS_EXPORT_GUID(RangeFactorSimpleCamera, "gtsam::RangeFactorSimpleCamera");
+
+#endif
+
+
 /* ************************************************************************* */
 // Actual implementations of functions
 /* ************************************************************************* */
--- gtsam-4.1.0.orig/matlab/CMakeLists.txt
+++ gtsam-4.1.0/matlab/CMakeLists.txt
@@ -2,6 +2,10 @@
 
 include(GtsamMatlabWrap)
 
+# Record the root dir for gtsam - needed during external builds, e.g., ROS
+set(GTSAM_SOURCE_ROOT_DIR ${GTSAM_SOURCE_DIR})
+message(STATUS "GTSAM_SOURCE_ROOT_DIR: [${GTSAM_SOURCE_ROOT_DIR}]")
+
 # Tests
 #message(STATUS "Installing Matlab Toolbox")
 install_matlab_scripts("${GTSAM_SOURCE_ROOT_DIR}/matlab/" "*.m;*.fig")
@@ -21,7 +25,7 @@ install_matlab_scripts("${GTSAM_SOURCE_R
 file(GLOB matlab_examples_data_graph "${GTSAM_SOURCE_ROOT_DIR}/examples/Data/*.graph")
 file(GLOB matlab_examples_data_mat "${GTSAM_SOURCE_ROOT_DIR}/examples/Data/*.mat")
 file(GLOB matlab_examples_data_txt "${GTSAM_SOURCE_ROOT_DIR}/examples/Data/*.txt")
-set(matlab_examples_data ${matlab_examples_data_graph} ${matlab_examples_data_mat} ${matlab_examples_data_txt}) 
+set(matlab_examples_data ${matlab_examples_data_graph} ${matlab_examples_data_mat} ${matlab_examples_data_txt})
 if(GTSAM_BUILD_TYPE_POSTFIXES)
 	foreach(build_type ${CMAKE_CONFIGURATION_TYPES})
 		string(TOUPPER "${build_type}" build_type_upper)
@@ -38,4 +42,3 @@ if(GTSAM_BUILD_TYPE_POSTFIXES)
 else()
 	install(FILES ${matlab_examples_data} DESTINATION ${GTSAM_TOOLBOX_INSTALL_PATH}/gtsam_examples/Data)
 endif()
-
--- gtsam-4.1.0.orig/matlab/README.md
+++ gtsam-4.1.0/matlab/README.md
@@ -4,16 +4,16 @@ http://borg.cc.gatech.edu/projects/gtsam
 
 This is the GTSAM MATLAB toolbox, a MATLAB wrapper around the GTSAM C++ library. To build it, enable `GTSAM_INSTALL_MATLAB_TOOLBOX=ON` in CMake.
 
-The interface to the toolbox is generated automatically by the wrap
-tool which directly parses C++ header files. The tool generates matlab proxy objects together with all the native functions for wrapping and unwrapping scalar and non scalar types and objects. The interface generated by the wrap tool also redirects the standard output stream (cout) to matlab's console.
+The interface to the toolbox is generated automatically by the wrap tool which directly parses C++ header files.
+The tool generates matlab proxy objects together with all the native functions for wrapping and unwrapping scalar and non scalar types and objects.
+The interface generated by the wrap tool also redirects the standard output stream (cout) to matlab's console.
 
 ## Ubuntu
 
-If you have a newer Ubuntu system (later than 10.04), you must make a small modification to your MATLAB installation, due to MATLAB being distributed with an old version of the C++ standard library.  Delete or rename all files starting with `libstdc++` in your MATLAB installation directory, in paths:
-
-	/usr/local/MATLAB/[version]/sys/os/[system]/ 
-	/usr/local/MATLAB/[version]/bin/[system]/
+If you have a newer Ubuntu system (later than 10.04), you must make a small modification to your MATLAB installation, due to MATLAB being distributed with an old version of the C++ standard library. Delete or rename all files starting with `libstdc++` in your MATLAB installation directory, in paths:
 
+    /usr/local/MATLAB/[version]/sys/os/[system]/
+    /usr/local/MATLAB/[version]/bin/[system]/
 
 ## Adding the toolbox to your MATLAB path
 
@@ -37,25 +37,28 @@ export LD_LIBRARY_PATH=<install-path>/gt
 
 ### Linker issues
 
-If you compile the MATLAB toolbox and everything compiles smoothly, but when you run any MATLAB script, you get following error messages in MATLAB
+If you compile the MATLAB toolbox and everything compiles smoothly, but when you run any MATLAB script, you get any of the following error messages in MATLAB
+
 ```
 Invalid MEX-file '/usr/local/gtsam_toolbox/gtsam_wrapper.mexa64':
 Missing symbol 'mexAtExit' required by '/usr/local/gtsam_toolbox/gtsam_wrapper.mexa64'
 Missing symbol 'mexCallMATLABWithObject' required by '/usr/local/gtsam_toolbox/gtsam_wrapper.mexa64'
 ...
 ```
+
 run following shell line
+
 ```sh
 export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6
 ```
-before you run MATLAB from the same shell. 
 
-This mainly happens if you have GCC >= 5 and newer version MATLAB like R2017a.
+before you run MATLAB from the same shell.
 
+This mainly happens if you have GCC >= 5 and newer version MATLAB like R2017a.
 
 ## Trying out the examples
 
-The examples are located in the 'gtsam_examples' subfolder.  You may either run them individually at the MATLAB command line, or open the GTSAM example GUI by running 'gtsamExamples'.  Example:
+The examples are located in the 'gtsam_examples' subfolder. You may either run them individually at the MATLAB command line, or open the GTSAM example GUI by running 'gtsamExamples'. Example:
 
 ```matlab
 >> cd /Users/yourname/toolbox  % Change to wherever you installed the toolbox
@@ -65,7 +68,7 @@ The examples are located in the 'gtsam_e
 
 ## Running the unit tests
 
-The GTSAM MATLAB toolbox also has a small set of unit tests located in the gtsam_tests directory.  Example:
+The GTSAM MATLAB toolbox also has a small set of unit tests located in the gtsam_tests directory. Example:
 
 ```matlab
 >> cd /Users/yourname/toolbox  % Change to wherever you installed the toolbox
@@ -86,4 +89,4 @@ Tests complete!
 
 ## Writing your own code
 
-Coding for the GTSAM MATLAB toolbox is straightforward and very fast once you understand a few basic concepts!  Please see the manual to get started.
+Coding for the GTSAM MATLAB toolbox is straightforward and very fast once you understand a few basic concepts! Please see the manual to get started.
--- gtsam-4.1.0.orig/matlab/gtsam_tests/testSerialization.m
+++ gtsam-4.1.0/matlab/gtsam_tests/testSerialization.m
@@ -28,10 +28,6 @@ serialized_pose1 = pose1.string_serializ
 pose1ds = Pose2.string_deserialize(serialized_pose1);
 CHECK('pose1ds.equals(pose1, 1e-9)', pose1ds.equals(pose1, 1e-9));
 
-serialized_landmark1 = landmark1.string_serialize();
-landmark1ds = Point2.string_deserialize(serialized_landmark1);
-CHECK('landmark1ds.equals(landmark1, 1e-9)', landmark1ds.equals(landmark1, 1e-9));
-
 %% Create and serialize Values
 values = Values;
 values.insert(i1, pose1);
--- gtsam-4.1.0.orig/python/CMakeLists.txt
+++ gtsam-4.1.0/python/CMakeLists.txt
@@ -4,6 +4,10 @@ if (NOT GTSAM_BUILD_PYTHON)
     return()
 endif()
 
+# Common directory for storing data/datasets stored with the package.
+# This will store the data in the Python site package directly.
+set(GTSAM_PYTHON_DATASET_DIR "./gtsam/Data")
+
 # Generate setup.py.
 file(READ "${PROJECT_SOURCE_DIR}/README.md" README_CONTENTS)
 configure_file(${PROJECT_SOURCE_DIR}/python/setup.py.in
@@ -26,11 +30,15 @@ set(ignore
     gtsam::ISAM2ThresholdMapValue
     gtsam::FactorIndices
     gtsam::FactorIndexSet
+    gtsam::IndexPairSetMap
+    gtsam::IndexPairVector
     gtsam::BetweenFactorPose2s
     gtsam::BetweenFactorPose3s
     gtsam::Point2Vector
     gtsam::Pose3Vector
-    gtsam::KeyVector)
+    gtsam::KeyVector
+    gtsam::BinaryMeasurementsUnit3
+    gtsam::KeyPairDoubleMap)
 
 pybind_wrap(gtsam_py # target
             ${PROJECT_SOURCE_DIR}/gtsam/gtsam.i # interface_header
@@ -72,7 +80,10 @@ set(ignore
         gtsam::Point2Vector
         gtsam::Pose3Vector
         gtsam::KeyVector
-        gtsam::FixedLagSmootherKeyTimestampMapValue)
+        gtsam::FixedLagSmootherKeyTimestampMapValue
+        gtsam::BinaryMeasurementsUnit3
+        gtsam::KeyPairDoubleMap)
+        
 pybind_wrap(gtsam_unstable_py # target
         ${PROJECT_SOURCE_DIR}/gtsam_unstable/gtsam_unstable.i # interface_header
         "gtsam_unstable.cpp" # generated_cpp
--- gtsam-4.1.0.orig/python/README.md
+++ gtsam-4.1.0/python/README.md
@@ -18,8 +18,10 @@ This is the Python wrapper around the GT
 
 ## Install
 
-- Run cmake with the `GTSAM_BUILD_PYTHON` cmake flag enabled to configure building the wrapper. The wrapped module will be built and copied to the directory `<PROJECT_BINARY_DIR>/python`.
-
+- Run cmake with the `GTSAM_BUILD_PYTHON` cmake flag enabled to configure building the wrapper. The wrapped module will be built and copied to the directory `<PROJECT_BINARY_DIR>/python`. For example, if your local Python version is 3.6.10, then you should run:
+  ```bash
+  cmake .. -DGTSAM_BUILD_PYTHON=1 -DGTSAM_PYTHON_VERSION=3.6.10
+  ```
 - Build GTSAM and the wrapper with `make` (or `ninja` if you use `-GNinja`).
 
 - To install, simply run `make python-install` (`ninja python-install`).
--- gtsam-4.1.0.orig/python/gtsam/__init__.py
+++ gtsam-4.1.0/python/gtsam/__init__.py
@@ -1,4 +1,6 @@
+from . import utils
 from .gtsam import *
+from .utils import findExampleDataFile
 
 
 def _init():
--- gtsam-4.1.0.orig/python/gtsam/examples/ImuFactorExample.py
+++ gtsam-4.1.0/python/gtsam/examples/ImuFactorExample.py
@@ -104,7 +104,7 @@ class ImuFactorExample(PreintegrationExa
 
                 if verbose:
                     print(factor)
-                    print(pim.predict(actual_state_i, self.actualBias))
+                    print(pim.predict(initial_state_i, self.actualBias))
 
                 pim.resetIntegration()
 
@@ -125,7 +125,7 @@ class ImuFactorExample(PreintegrationExa
                 i += 1
 
         # add priors on end
-        # self.addPrior(num_poses - 1, graph)
+        self.addPrior(num_poses - 1, graph)
 
         initial.print_("Initial values:")
 
--- gtsam-4.1.0.orig/python/gtsam/examples/ImuFactorISAM2Example.py
+++ gtsam-4.1.0/python/gtsam/examples/ImuFactorISAM2Example.py
@@ -1,6 +1,6 @@
 """
-iSAM2 example with ImuFactor.
-Author: Robert Truax (C++), Frank Dellaert, Varun Agrawal
+ImuFactor example with iSAM2.
+Authors: Robert Truax (C++), Frank Dellaert, Varun Agrawal (Python)
 """
 # pylint: disable=invalid-name, E1101
 
@@ -8,9 +8,11 @@ from __future__ import print_function
 
 import math
 
-import gtsam
 import matplotlib.pyplot as plt
 import numpy as np
+from mpl_toolkits.mplot3d import Axes3D  # pylint: disable=W0611
+
+import gtsam
 from gtsam import (ISAM2, BetweenFactorConstantBias, Cal3_S2,
                    ConstantTwistScenario, ImuFactor, NonlinearFactorGraph,
                    PinholeCameraCal3_S2, Point3, Pose3,
@@ -18,7 +20,6 @@ from gtsam import (ISAM2, BetweenFactorC
                    PriorFactorVector, Rot3, Values)
 from gtsam.symbol_shorthand import B, V, X
 from gtsam.utils import plot
-from mpl_toolkits.mplot3d import Axes3D  # pylint: disable=W0611
 
 
 def vector3(x, y, z):
@@ -58,7 +59,6 @@ def get_camera(radius):
 
 def get_scenario(radius, pose_0, angular_velocity, delta_t):
     """Create the set of ground-truth landmarks and poses"""
-
     angular_velocity_vector = vector3(0, -angular_velocity, 0)
     linear_velocity_vector = vector3(radius * angular_velocity, 0, 0)
     scenario = ConstantTwistScenario(
--- gtsam-4.1.0.orig/python/gtsam/examples/PreintegrationExample.py
+++ gtsam-4.1.0/python/gtsam/examples/PreintegrationExample.py
@@ -111,7 +111,7 @@ class PreintegrationExample(object):
     def plotGroundTruthPose(self, t, scale=0.3, time_interval=0.01):
         # plot ground truth pose, as well as prediction from integrated IMU measurements
         actualPose = self.scenario.pose(t)
-        plot_pose3(POSES_FIG, actualPose, 0.3)
+        plot_pose3(POSES_FIG, actualPose, scale)
         t = actualPose.translation()
         self.maxDim = max([max(np.abs(t)), self.maxDim])
         ax = plt.gca()
--- gtsam-4.1.0.orig/python/gtsam/examples/README.md
+++ gtsam-4.1.0/python/gtsam/examples/README.md
@@ -3,50 +3,62 @@
 | C++ Example Name                                      | Ported |
 |-------------------------------------------------------|--------|
 | CameraResectioning                                    |        |
+| CombinedImuFactorsExample                             |        |
 | CreateSFMExampleData                                  |        |
+| DiscreteBayesNetExample                               |        |
 | DiscreteBayesNet_FG                                   | none of the required discrete functionality is exposed through Python |
 | easyPoint2KalmanFilter                                | ExtendedKalmanFilter not yet exposed through Python |
 | elaboratePoint2KalmanFilter                           | GaussianSequentialSolver not yet exposed through Python |
-| ImuFactorExample2                                     | X      |
+| FisheyeExample                                        |        |
+| HMMExample                                            |        |
+| ImuFactorsExample2                                    | :heavy_check_mark:      |
 | ImuFactorsExample                                     |        |
+| IMUKittiExampleGPS                                    |        |
+| InverseKinematicsExampleExpressions.cpp               |        |
 | ISAM2Example_SmartFactor                              |        |
 | ISAM2_SmartFactorStereo_IMU                           |        |
 | LocalizationExample                                   | impossible? |
 | METISOrderingExample                                  |        |
-| OdometryExample                                       | X      |
-| PlanarSLAMExample                                     | X      |
-| Pose2SLAMExample                                      | X      |
+| OdometryExample                                       | :heavy_check_mark:      |
+| PlanarSLAMExample                                     | :heavy_check_mark:      |
+| Pose2SLAMExample                                      | :heavy_check_mark:      |
 | Pose2SLAMExampleExpressions                           |        |
-| Pose2SLAMExample_g2o                                  | X      |
+| Pose2SLAMExample_g2o                                  | :heavy_check_mark:      |
 | Pose2SLAMExample_graph                                |        |
 | Pose2SLAMExample_graphviz                             |        |
 | Pose2SLAMExample_lago                                 | lago not yet exposed through Python |
 | Pose2SLAMStressTest                                   |        |
 | Pose2SLAMwSPCG                                        |        |
+| Pose3Localization                                 |        |
 | Pose3SLAMExample_changeKeys                           |        |
 | Pose3SLAMExampleExpressions_BearingRangeWithTransform |        |
-| Pose3SLAMExample_g2o                                  | X      |
-| Pose3SLAMExample_initializePose3Chordal               |        |
+| Pose3SLAMExample_g2o                                  | :heavy_check_mark:      |
+| Pose3SLAMExample_initializePose3Chordal               | :heavy_check_mark:        |
 | Pose3SLAMExample_initializePose3Gradient              |        |
 | RangeISAMExample_plaza2                               |        |
 | SelfCalibrationExample                                |        |
+| SFMdata                                               |        |     
 | SFMExample_bal_COLAMD_METIS                           |        |
-| SFMExample_bal                                        |        |
-| SFMExample                                            | X      |
+| SFMExample_bal                                        | :heavy_check_mark:      |
+| SFMExample                                            | :heavy_check_mark:      |
 | SFMExampleExpressions_bal                             |        |
 | SFMExampleExpressions                                 |        |
 | SFMExample_SmartFactor                                |        |
 | SFMExample_SmartFactorPCG                             |        |
-| SimpleRotation                                        | X      |
+| ShonanAveragingCLI                                    | :heavy_check_mark:       |
+| SimpleRotation                                        | :heavy_check_mark:      |
 | SolverComparer                                        |        |
 | StereoVOExample                                       |        |
 | StereoVOExample_large                                 |        |
 | TimeTBB                                               |        |
 | UGM_chain                                             | discrete functionality not yet exposed |
 | UGM_small                                             | discrete functionality not yet exposed |
-| VisualISAM2Example                                    | X      |
-| VisualISAMExample                                     | X      |
+| VisualISAM2Example                                    | :heavy_check_mark:      |
+| VisualISAMExample                                     | :heavy_check_mark:      |
 
 Extra Examples (with no C++ equivalent)
+- DogLegOptimizerExample
+- GPSFactorExample
 - PlanarManipulatorExample
-- SFMData
\ No newline at end of file
+- PreintegrationExample
+- SFMData
--- /dev/null
+++ gtsam-4.1.0/python/gtsam/examples/SFMExample_bal.py
@@ -0,0 +1,118 @@
+"""
+  GTSAM Copyright 2010, Georgia Tech Research Corporation,
+  Atlanta, Georgia 30332-0415
+  All Rights Reserved
+  Authors: Frank Dellaert, et al. (see THANKS for the full author list)
+
+  See LICENSE for the license information
+
+  Solve a structure-from-motion problem from a "Bundle Adjustment in the Large" file
+  Author: Frank Dellaert (Python: Akshay Krishnan, John Lambert)
+"""
+
+import argparse
+import logging
+import sys
+
+import matplotlib.pyplot as plt
+import numpy as np
+
+import gtsam
+from gtsam import (
+    GeneralSFMFactorCal3Bundler,
+    PinholeCameraCal3Bundler,
+    PriorFactorPinholeCameraCal3Bundler,
+    readBal,
+    symbol_shorthand
+)
+
+C = symbol_shorthand.C
+P = symbol_shorthand.P
+
+
+logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
+
+def run(args):
+    """ Run LM optimization with BAL input data and report resulting error """
+    input_file = gtsam.findExampleDataFile(args.input_file)
+
+    # Load the SfM data from file
+    scene_data = readBal(input_file)
+    logging.info(f"read {scene_data.number_tracks()} tracks on {scene_data.number_cameras()} cameras\n")
+
+    # Create a factor graph
+    graph = gtsam.NonlinearFactorGraph()
+
+    # We share *one* noiseModel between all projection factors
+    noise = gtsam.noiseModel.Isotropic.Sigma(2, 1.0) # one pixel in u and v
+
+    # Add measurements to the factor graph
+    j = 0
+    for t_idx in range(scene_data.number_tracks()):
+        track = scene_data.track(t_idx) # SfmTrack
+        # retrieve the SfmMeasurement objects
+        for m_idx in range(track.number_measurements()):
+            # i represents the camera index, and uv is the 2d measurement
+            i, uv = track.measurement(m_idx)
+            # note use of shorthand symbols C and P
+            graph.add(GeneralSFMFactorCal3Bundler(uv, noise, C(i), P(j)))
+        j += 1
+
+    # Add a prior on pose x1. This indirectly specifies where the origin is.
+    graph.push_back(
+        gtsam.PriorFactorPinholeCameraCal3Bundler(
+            C(0), scene_data.camera(0), gtsam.noiseModel.Isotropic.Sigma(9, 0.1)
+        )
+    )
+    # Also add a prior on the position of the first landmark to fix the scale
+    graph.push_back(
+        gtsam.PriorFactorPoint3(
+            P(0), scene_data.track(0).point3(), gtsam.noiseModel.Isotropic.Sigma(3, 0.1)
+        )
+    )
+
+    # Create initial estimate
+    initial = gtsam.Values()
+    
+    i = 0
+    # add each PinholeCameraCal3Bundler
+    for cam_idx in range(scene_data.number_cameras()):
+        camera = scene_data.camera(cam_idx)
+        initial.insert(C(i), camera)
+        i += 1
+
+    j = 0
+    # add each SfmTrack
+    for t_idx in range(scene_data.number_tracks()):
+        track = scene_data.track(t_idx)  
+        initial.insert(P(j), track.point3())
+        j += 1
+
+    # Optimize the graph and print results
+    try:
+        params = gtsam.LevenbergMarquardtParams()
+        params.setVerbosityLM("ERROR")
+        lm = gtsam.LevenbergMarquardtOptimizer(graph, initial, params)
+        result = lm.optimize()
+    except Exception as e:
+        logging.exception("LM Optimization failed")
+        return
+    # Error drops from ~2764.22 to ~0.046
+    logging.info(f"final error: {graph.error(result)}")
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument(
+        '-i',
+        '--input_file',
+        type=str,
+        default="dubrovnik-3-7-pre",
+        help='Read SFM data from the specified BAL file'
+        'The data format is described here: https://grail.cs.washington.edu/projects/bal/.'
+        'BAL files contain (nrPoses, nrPoints, nrObservations), followed by (i,j,u,v) tuples, '
+        'then (wx,wy,wz,tx,ty,tz,f,k1,k1) as Bundler camera calibrations w/ Rodrigues vector'
+        'and (x,y,z) 3d point initializations.'
+    )
+    run(parser.parse_args())
+
--- /dev/null
+++ gtsam-4.1.0/python/gtsam/examples/TranslationAveragingExample.py
@@ -0,0 +1,144 @@
+"""
+GTSAM Copyright 2010-2018, Georgia Tech Research Corporation,
+Atlanta, Georgia 30332-0415
+All Rights Reserved
+Authors: Frank Dellaert, et al. (see THANKS for the full author list)
+
+See LICENSE for the license information
+
+This example shows how 1dsfm uses outlier rejection (MFAS) and optimization (translation recovery)
+together for estimating global translations from relative translation directions and global rotations.
+The purpose of this example is to illustrate the connection between these two classes using a small SfM dataset.
+
+Author: Akshay Krishnan
+Date: September 2020
+"""
+
+from collections import defaultdict
+from typing import List, Tuple
+
+import numpy as np
+
+import gtsam
+from gtsam.examples import SFMdata
+
+# Hyperparameters for 1dsfm, values used from Kyle Wilson's code.
+MAX_1DSFM_PROJECTION_DIRECTIONS = 48
+OUTLIER_WEIGHT_THRESHOLD = 0.1
+
+
+def get_data() -> Tuple[gtsam.Values, List[gtsam.BinaryMeasurementUnit3]]:
+    """"Returns global rotations and unit translation directions between 8 cameras
+    that lie on a circle and face the center. The poses of 8 cameras are obtained from SFMdata
+    and the unit translations directions between some camera pairs are computed from their
+    global translations. """
+    fx, fy, s, u0, v0 = 50.0, 50.0, 0.0, 50.0, 50.0
+    wTc_list = SFMdata.createPoses(gtsam.Cal3_S2(fx, fy, s, u0, v0))
+    # Rotations of the cameras in the world frame.
+    wRc_values = gtsam.Values()
+    # Normalized translation directions from camera i to camera j
+    # in the coordinate frame of camera i.
+    i_iZj_list = []
+    for i in range(0, len(wTc_list) - 2):
+        # Add the rotation.
+        wRi = wTc_list[i].rotation()
+        wRc_values.insert(i, wRi)
+        # Create unit translation measurements with next two poses.
+        for j in range(i + 1, i + 3):
+            # Compute the translation from pose i to pose j, in the world reference frame.
+            w_itj = wTc_list[j].translation() - wTc_list[i].translation()
+            # Obtain the translation in the camera i's reference frame.
+            i_itj = wRi.unrotate(w_itj)
+            # Compute the normalized unit translation direction.
+            i_iZj = gtsam.Unit3(i_itj)
+            i_iZj_list.append(gtsam.BinaryMeasurementUnit3(
+                i, j, i_iZj, gtsam.noiseModel.Isotropic.Sigma(3, 0.01)))
+    # Add the last two rotations.
+    wRc_values.insert(len(wTc_list) - 1, wTc_list[-1].rotation())
+    wRc_values.insert(len(wTc_list) - 2, wTc_list[-2].rotation())
+    return wRc_values, i_iZj_list
+
+
+def filter_outliers(w_iZj_list: gtsam.BinaryMeasurementsUnit3) -> gtsam.BinaryMeasurementsUnit3:
+    """Removes outliers from a list of Unit3 measurements that are the 
+    translation directions from camera i to camera j in the world frame."""
+
+    # Indices of measurements that are to be used as projection directions.
+    # These are randomly chosen. All sampled directions must be unique.
+    num_directions_to_sample = min(
+        MAX_1DSFM_PROJECTION_DIRECTIONS, len(w_iZj_list))
+    sampled_indices = np.random.choice(
+        len(w_iZj_list), num_directions_to_sample, replace=False)
+
+    # Sample projection directions from the measurements.
+    projection_directions = [w_iZj_list[idx].measured()
+                             for idx in sampled_indices]
+
+    outlier_weights = []
+    # Find the outlier weights for each direction using MFAS.
+    for direction in projection_directions:
+        algorithm = gtsam.MFAS(w_iZj_list, direction)
+        outlier_weights.append(algorithm.computeOutlierWeights())
+
+    # Compute average of outlier weights. Each outlier weight is a map from a pair of Keys
+    # (camera IDs) to a weight, where weights are proportional to the probability of the edge
+    # being an outlier.
+    avg_outlier_weights = defaultdict(float)
+    for outlier_weight_dict in outlier_weights:
+        for keypair, weight in outlier_weight_dict.items():
+            avg_outlier_weights[keypair] += weight / len(outlier_weights)
+
+    # Remove w_iZj that have weight greater than threshold, these are outliers.
+    w_iZj_inliers = gtsam.BinaryMeasurementsUnit3()
+    [w_iZj_inliers.append(w_iZj) for w_iZj in w_iZj_list if avg_outlier_weights[(
+        w_iZj.key1(), w_iZj.key2())] < OUTLIER_WEIGHT_THRESHOLD]
+
+    return w_iZj_inliers
+
+
+def estimate_poses(i_iZj_list: gtsam.BinaryMeasurementsUnit3,
+                   wRc_values: gtsam.Values) -> gtsam.Values:
+    """Estimate poses given rotations and normalized translation directions between cameras.
+
+    Args:
+        i_iZj_list: List of normalized translation direction measurements between camera pairs, 
+                    Z here refers to measurements. The measurements are of camera j with reference 
+                    to camera i (iZj), in camera i's coordinate frame (i_). iZj represents a unit 
+                    vector to j in i's frame and is not a transformation. 
+        wRc_values: Rotations of the cameras in the world frame.
+
+    Returns:
+        gtsam.Values: Estimated poses.
+    """
+
+    # Convert the translation direction measurements to world frame using the rotations.
+    w_iZj_list = gtsam.BinaryMeasurementsUnit3()
+    for i_iZj in i_iZj_list:
+        w_iZj = gtsam.Unit3(wRc_values.atRot3(i_iZj.key1())
+                                      .rotate(i_iZj.measured().point3()))
+        w_iZj_list.append(gtsam.BinaryMeasurementUnit3(
+            i_iZj.key1(), i_iZj.key2(), w_iZj, i_iZj.noiseModel()))
+
+    # Remove the outliers in the unit translation directions.
+    w_iZj_inliers = filter_outliers(w_iZj_list)
+
+    # Run the optimizer to obtain translations for normalized directions.
+    wtc_values = gtsam.TranslationRecovery(w_iZj_inliers).run()
+
+    wTc_values = gtsam.Values()
+    for key in wRc_values.keys():
+        wTc_values.insert(key, gtsam.Pose3(
+            wRc_values.atRot3(key), wtc_values.atPoint3(key)))
+    return wTc_values
+
+
+def main():
+    wRc_values, i_iZj_list = get_data()
+    wTc_values = estimate_poses(i_iZj_list, wRc_values)
+    print("**** Translation averaging output ****")
+    print(wTc_values)
+    print("**************************************")
+
+
+if __name__ == '__main__':
+    main()
--- gtsam-4.1.0.orig/python/gtsam/preamble.h
+++ gtsam-4.1.0/python/gtsam/preamble.h
@@ -9,3 +9,4 @@ PYBIND11_MAKE_OPAQUE(std::vector<gtsam::
 PYBIND11_MAKE_OPAQUE(std::vector<gtsam::Pose3>);
 PYBIND11_MAKE_OPAQUE(std::vector<boost::shared_ptr<gtsam::BetweenFactor<gtsam::Pose3> > >);
 PYBIND11_MAKE_OPAQUE(std::vector<boost::shared_ptr<gtsam::BetweenFactor<gtsam::Pose2> > >);
+PYBIND11_MAKE_OPAQUE(std::vector<gtsam::IndexPair>);
--- gtsam-4.1.0.orig/python/gtsam/specializations.h
+++ gtsam-4.1.0/python/gtsam/specializations.h
@@ -9,3 +9,7 @@ py::bind_vector<std::vector<gtsam::Point
 py::bind_vector<std::vector<gtsam::Pose3> >(m_, "Pose3Vector");
 py::bind_vector<std::vector<boost::shared_ptr<gtsam::BetweenFactor<gtsam::Pose3> > > >(m_, "BetweenFactorPose3s");
 py::bind_vector<std::vector<boost::shared_ptr<gtsam::BetweenFactor<gtsam::Pose2> > > >(m_, "BetweenFactorPose2s");
+py::bind_vector<std::vector<gtsam::BinaryMeasurement<gtsam::Unit3> > >(m_, "BinaryMeasurementsUnit3");
+py::bind_map<gtsam::IndexPairSetMap>(m_, "IndexPairSetMap");
+py::bind_vector<gtsam::IndexPairVector>(m_, "IndexPairVector");
+py::bind_map<gtsam::KeyPairDoubleMap>(m_, "KeyPairDoubleMap");
--- gtsam-4.1.0.orig/python/gtsam/tests/test_JacobianFactor.py
+++ gtsam-4.1.0/python/gtsam/tests/test_JacobianFactor.py
@@ -19,7 +19,7 @@ from gtsam.utils.test_case import GtsamT
 class TestJacobianFactor(GtsamTestCase):
 
     def test_eliminate(self):
-        # Recommended way to specify a matrix (see cython/README)
+        # Recommended way to specify a matrix (see python/README)
         Ax2 = np.array(
            [[-5., 0.],
             [+0., -5.],
--- gtsam-4.1.0.orig/python/gtsam/tests/test_Pose3.py
+++ gtsam-4.1.0/python/gtsam/tests/test_Pose3.py
@@ -65,6 +65,14 @@ class TestPose3(GtsamTestCase):
         actual = Pose3.adjoint_(xi, xi)
         np.testing.assert_array_equal(actual, expected)
 
+    def test_serialization(self):
+        """Test if serialization is working normally"""
+        expected = Pose3(Rot3.Ypr(0.0, 1.0, 0.0), Point3(1, 1, 0))
+        actual = Pose3()
+        serialized = expected.serialize()
+        actual.deserialize(serialized)
+        self.gtsamAssertEquals(expected, actual, 1e-10)
+
 
 if __name__ == "__main__":
     unittest.main()
--- /dev/null
+++ gtsam-4.1.0/python/gtsam/tests/test_SfmData.py
@@ -0,0 +1,79 @@
+"""
+GTSAM Copyright 2010-2019, Georgia Tech Research Corporation,
+Atlanta, Georgia 30332-0415
+All Rights Reserved
+
+See LICENSE for the license information
+
+Unit tests for testing dataset access.
+Author: Frank Dellaert (Python: Sushmita Warrier)
+"""
+# pylint: disable=invalid-name, no-name-in-module, no-member
+
+from __future__ import print_function
+
+import unittest
+
+import numpy as np
+
+import gtsam
+from gtsam.utils.test_case import GtsamTestCase
+
+
+class TestSfmData(GtsamTestCase):
+    """Tests for SfmData and SfmTrack modules."""
+
+    def setUp(self):
+        """Initialize SfmData and SfmTrack"""
+        self.data = gtsam.SfmData()
+        # initialize SfmTrack with 3D point
+        self.tracks = gtsam.SfmTrack()
+
+    def test_tracks(self):
+        """Test functions in SfmTrack"""
+        # measurement is of format (camera_idx, imgPoint)
+        # create arbitrary camera indices for two cameras
+        i1, i2 = 4,5
+        # create arbitrary image measurements for cameras i1 and i2
+        uv_i1 = gtsam.Point2(12.6, 82)
+        # translating point uv_i1 along X-axis
+        uv_i2 = gtsam.Point2(24.88, 82)
+        # add measurements to the track
+        self.tracks.add_measurement(i1, uv_i1)
+        self.tracks.add_measurement(i2, uv_i2)
+        # Number of measurements in the track is 2
+        self.assertEqual(self.tracks.number_measurements(), 2)
+        # camera_idx in the first measurement of the track corresponds to i1
+        cam_idx, img_measurement = self.tracks.measurement(0)
+        self.assertEqual(cam_idx, i1)
+        np.testing.assert_array_almost_equal(
+            gtsam.Point3(0.,0.,0.), 
+            self.tracks.point3()
+        )
+
+
+    def test_data(self):
+        """Test functions in SfmData"""
+        # Create new track with 3 measurements
+        i1, i2, i3 = 3,5,6
+        uv_i1 = gtsam.Point2(21.23, 45.64)
+        # translating along X-axis
+        uv_i2 = gtsam.Point2(45.7, 45.64)
+        uv_i3 = gtsam.Point2(68.35, 45.64)
+        # add measurements and arbitrary point to the track
+        measurements = [(i1, uv_i1), (i2, uv_i2), (i3, uv_i3)]
+        pt = gtsam.Point3(1.0, 6.0, 2.0)
+        track2 = gtsam.SfmTrack(pt)
+        track2.add_measurement(i1, uv_i1)
+        track2.add_measurement(i2, uv_i2)
+        track2.add_measurement(i3, uv_i3)
+        self.data.add_track(self.tracks)
+        self.data.add_track(track2)
+        # Number of tracks in SfmData is 2
+        self.assertEqual(self.data.number_tracks(), 2)
+        # camera idx of first measurement of second track corresponds to i1
+        cam_idx, img_measurement = self.data.track(1).measurement(0)
+        self.assertEqual(cam_idx, i1)
+
+if __name__ == '__main__':
+    unittest.main()
--- gtsam-4.1.0.orig/python/gtsam/tests/test_SimpleCamera.py
+++ gtsam-4.1.0/python/gtsam/tests/test_SimpleCamera.py
@@ -14,11 +14,12 @@ import unittest
 import numpy as np
 
 import gtsam
-from gtsam import Cal3_S2, Point3, Pose2, Pose3, Rot3, SimpleCamera
+from gtsam import Cal3_S2, Point3, Pose2, Pose3, Rot3, PinholeCameraCal3_S2 as SimpleCamera
 from gtsam.utils.test_case import GtsamTestCase
 
 K = Cal3_S2(625, 625, 0, 0, 0)
 
+
 class TestSimpleCamera(GtsamTestCase):
 
     def test_constructor(self):
@@ -29,15 +30,15 @@ class TestSimpleCamera(GtsamTestCase):
 
     def test_level2(self):
         # Create a level camera, looking in Y-direction
-        pose2 = Pose2(0.4,0.3,math.pi/2.0)
+        pose2 = Pose2(0.4, 0.3, math.pi/2.0)
         camera = SimpleCamera.Level(K, pose2, 0.1)
 
         # expected
-        x = Point3(1,0,0)
-        y = Point3(0,0,-1)
-        z = Point3(0,1,0)
-        wRc = Rot3(x,y,z)
-        expected = Pose3(wRc,Point3(0.4,0.3,0.1))
+        x = Point3(1, 0, 0)
+        y = Point3(0, 0, -1)
+        z = Point3(0, 1, 0)
+        wRc = Rot3(x, y, z)
+        expected = Pose3(wRc, Point3(0.4, 0.3, 0.1))
         self.gtsamAssertEquals(camera.pose(), expected, 1e-9)
 
 
--- /dev/null
+++ gtsam-4.1.0/python/gtsam/tests/test_TranslationRecovery.py
@@ -0,0 +1,63 @@
+from __future__ import print_function
+
+import numpy as np
+import unittest
+
+import gtsam
+
+""" Returns example pose values of 3 points A, B and C in the world frame """
+def ExampleValues():
+    T = []
+    T.append(gtsam.Point3(np.array([3.14, 1.59, 2.65])))
+    T.append(gtsam.Point3(np.array([-1.0590e+00, -3.6017e-02, -1.5720e+00])))
+    T.append(gtsam.Point3(np.array([8.5034e+00, 6.7499e+00, -3.6383e+00])))
+    
+    data = gtsam.Values()
+    for i in range(len(T)):
+        data.insert(i, gtsam.Pose3(gtsam.Rot3(), T[i]))
+    return data
+
+""" Returns binary measurements for the points in the given edges."""
+def SimulateMeasurements(gt_poses, graph_edges):
+    measurements = gtsam.BinaryMeasurementsUnit3()
+    for edge in graph_edges:
+        Ta = gt_poses.atPose3(edge[0]).translation()
+        Tb = gt_poses.atPose3(edge[1]).translation()
+        measurements.append(gtsam.BinaryMeasurementUnit3( \
+            edge[0], edge[1], gtsam.Unit3(Tb - Ta), \
+            gtsam.noiseModel.Isotropic.Sigma(3, 0.01)))
+    return measurements
+
+""" Tests for the translation recovery class """
+class TestTranslationRecovery(unittest.TestCase):
+    """Test selected Translation Recovery methods."""
+
+    def test_constructor(self):
+        """Construct from binary measurements."""
+        algorithm = gtsam.TranslationRecovery(gtsam.BinaryMeasurementsUnit3())
+        self.assertIsInstance(algorithm, gtsam.TranslationRecovery)
+
+    def test_run(self):
+        gt_poses = ExampleValues()
+        measurements = SimulateMeasurements(gt_poses, [[0, 1], [0, 2], [1, 2]])
+
+        # Set verbosity to Silent for tests
+        lmParams = gtsam.LevenbergMarquardtParams()
+        lmParams.setVerbosityLM("silent")
+
+        algorithm = gtsam.TranslationRecovery(measurements, lmParams)
+        scale = 2.0
+        result = algorithm.run(scale)
+
+        w_aTc = gt_poses.atPose3(2).translation() - gt_poses.atPose3(0).translation()
+        w_aTb = gt_poses.atPose3(1).translation() - gt_poses.atPose3(0).translation()
+        w_aTc_expected = w_aTc*scale/np.linalg.norm(w_aTb)
+        w_aTb_expected = w_aTb*scale/np.linalg.norm(w_aTb)
+
+        np.testing.assert_array_almost_equal(result.atPoint3(0), np.array([0,0,0]), 6, "Origin result is incorrect.")
+        np.testing.assert_array_almost_equal(result.atPoint3(1), w_aTb_expected, 6, "Point B result is incorrect.")
+        np.testing.assert_array_almost_equal(result.atPoint3(2), w_aTc_expected, 6, "Point C result is incorrect.")
+
+if __name__ == "__main__":
+    unittest.main()
+
--- gtsam-4.1.0.orig/python/gtsam/tests/test_dsf_map.py
+++ gtsam-4.1.0/python/gtsam/tests/test_dsf_map.py
@@ -35,6 +35,20 @@ class TestDSFMap(GtsamTestCase):
         dsf.merge(pair1, pair2)
         self.assertEqual(key(dsf.find(pair1)), key(dsf.find(pair2)))
 
+    def test_sets(self):
+        from gtsam import IndexPair
+        dsf = gtsam.DSFMapIndexPair()
+        dsf.merge(IndexPair(0, 1), IndexPair(1,2))
+        dsf.merge(IndexPair(0, 1), IndexPair(3,4))
+        dsf.merge(IndexPair(4,5), IndexPair(6,8))
+        sets = dsf.sets()
+
+        for i in sets:
+            s = sets[i]
+            for val in gtsam.IndexPairSetAsArray(s):
+                val.i()
+                val.j()
+
 
 if __name__ == '__main__':
     unittest.main()
--- gtsam-4.1.0.orig/python/gtsam/utils/__init__.py
+++ gtsam-4.1.0/python/gtsam/utils/__init__.py
@@ -0,0 +1,22 @@
+import glob
+import os.path as osp
+
+
+def findExampleDataFile(name):
+    """
+    Find the example data file specified by `name`.
+    """
+    # This is okay since gtsam will already be loaded
+    # before this function is accessed. Thus no effect.
+    import gtsam
+
+    site_package_path = gtsam.__path__[0]
+    # add the * at the end to glob the entire directory
+    data_path = osp.join(site_package_path, "Data", "*")
+
+    extensions = ("", ".graph", ".txt", ".out", ".xml", ".g2o")
+
+    for data_file_path in glob.glob(data_path, recursive=True):
+        for ext in extensions:
+            if (name + ext) == osp.basename(data_file_path):
+                return data_file_path
--- gtsam-4.1.0.orig/python/gtsam/utils/plot.py
+++ gtsam-4.1.0/python/gtsam/utils/plot.py
@@ -36,18 +36,15 @@ def set_axes_equal(fignum):
     ax.set_zlim3d([origin[2] - radius, origin[2] + radius])
 
 
-def ellipsoid(xc, yc, zc, rx, ry, rz, n):
+def ellipsoid(rx, ry, rz, n):
     """
     Numpy equivalent of Matlab's ellipsoid function.
 
     Args:
-        xc (double): Center of ellipsoid in X-axis.
-        yc (double): Center of ellipsoid in Y-axis.
-        zc (double): Center of ellipsoid in Z-axis.
         rx (double): Radius of ellipsoid in X-axis.
         ry (double): Radius of ellipsoid in Y-axis.
         rz (double): Radius of ellipsoid in Z-axis.
-        n (int): The granularity of the ellipsoid plotted. 
+        n (int): The granularity of the ellipsoid plotted.
 
     Returns:
         tuple[numpy.ndarray]: The points in the x, y and z axes to use for the surface plot.
@@ -72,7 +69,8 @@ def plot_covariance_ellipse_3d(axes, ori
     Args:
         axes (matplotlib.axes.Axes): Matplotlib axes.
         origin (gtsam.Point3): The origin in the world frame.
-        P (numpy.ndarray): The marginal covariance matrix of the 3D point which will be represented as an ellipse.
+        P (numpy.ndarray): The marginal covariance matrix of the 3D point
+            which will be represented as an ellipse.
         scale (float): Scaling factor of the radii of the covariance ellipse.
         n (int): Defines the granularity of the ellipse. Higher values indicate finer ellipses.
         alpha (float): Transparency value for the plotted surface in the range [0, 1].
@@ -85,7 +83,7 @@ def plot_covariance_ellipse_3d(axes, ori
     rx, ry, rz = radii
 
     # generate data for "unrotated" ellipsoid
-    xc, yc, zc = ellipsoid(0, 0, 0, rx, ry, rz, n)
+    xc, yc, zc = ellipsoid(rx, ry, rz, n)
 
     # rotate data with orientation matrix U and center c
     data = np.kron(U[:, 0:1], xc) + np.kron(U[:, 1:2], yc) + \
@@ -106,7 +104,8 @@ def plot_pose2_on_axes(axes, pose, axis_
         axes (matplotlib.axes.Axes): Matplotlib axes.
         pose (gtsam.Pose2): The pose to be plotted.
         axis_length (float): The length of the camera axes.
-        covariance (numpy.ndarray): Marginal covariance matrix to plot the uncertainty of the estimation.
+        covariance (numpy.ndarray): Marginal covariance matrix to plot
+            the uncertainty of the estimation.
     """
     # get rotation and translation (center)
     gRp = pose.rotation().matrix()  # rotation from pose to global
@@ -146,7 +145,8 @@ def plot_pose2(fignum, pose, axis_length
         fignum (int): Integer representing the figure number to use for plotting.
         pose (gtsam.Pose2): The pose to be plotted.
         axis_length (float): The length of the camera axes.
-        covariance (numpy.ndarray): Marginal covariance matrix to plot the uncertainty of the estimation.
+        covariance (numpy.ndarray): Marginal covariance matrix to plot
+            the uncertainty of the estimation.
         axis_labels (iterable[string]): List of axis labels to set.
     """
     # get figure object
@@ -215,7 +215,8 @@ def plot_3d_points(fignum, values, lines
         fignum (int): Integer representing the figure number to use for plotting.
         values (gtsam.Values): Values dictionary consisting of points to be plotted.
         linespec (string): String representing formatting options for Matplotlib.
-        marginals (numpy.ndarray): Marginal covariance matrix to plot the uncertainty of the estimation.
+        marginals (numpy.ndarray): Marginal covariance matrix to plot the
+            uncertainty of the estimation.
         title (string): The title of the plot.
         axis_labels (iterable[string]): List of axis labels to set.
     """
@@ -238,6 +239,7 @@ def plot_3d_points(fignum, values, lines
             continue
             # I guess it's not a Point3
 
+    fig = plt.figure(fignum)
     fig.suptitle(title)
     fig.canvas.set_window_title(title.lower())
 
--- gtsam-4.1.0.orig/python/setup.py.in
+++ gtsam-4.1.0/python/setup.py.in
@@ -1,3 +1,4 @@
+import glob
 import os
 import sys
 
@@ -8,6 +9,11 @@ except ImportError:
 
 packages = find_packages(where=".")
 print("PACKAGES: ", packages)
+
+data_path = '${GTSAM_SOURCE_DIR}/examples/Data/'
+data_files_and_directories = glob.glob(data_path + '**', recursive=True)
+data_files = [x for x in data_files_and_directories if not os.path.isdir(x)]
+
 package_data = {
     '': [
         './*.so',
@@ -44,6 +50,7 @@ setup(
     ],
     packages=packages,
     package_data=package_data,
+    data_files=[('${GTSAM_PYTHON_DATASET_DIR}', data_files),],
     test_suite="gtsam.tests",
     install_requires=["numpy"],
     zip_safe=False,
--- gtsam-4.1.0.orig/tests/testNonlinearOptimizer.cpp
+++ gtsam-4.1.0/tests/testNonlinearOptimizer.cpp
@@ -567,6 +567,58 @@ TEST( NonlinearOptimizer, logfile )
 }
 
 /* ************************************************************************* */
+TEST( NonlinearOptimizer, iterationHook_LM )
+{
+  NonlinearFactorGraph fg(example::createReallyNonlinearFactorGraph());
+
+  Point2 x0(3,3);
+  Values c0;
+  c0.insert(X(1), x0);
+
+  // Levenberg-Marquardt
+  LevenbergMarquardtParams lmParams;
+  size_t lastIterCalled = 0;
+  lmParams.iterationHook = [&](size_t iteration, double oldError, double newError)
+  {
+    // Tests:
+    lastIterCalled = iteration;
+    EXPECT(newError<oldError);
+    
+    // Example of evolution printout:
+    //std::cout << "iter: " << iteration << " error: " << oldError << " => " << newError <<"\n";
+  };
+  LevenbergMarquardtOptimizer(fg, c0, lmParams).optimize();
+  
+  EXPECT(lastIterCalled>5);
+}
+/* ************************************************************************* */
+TEST( NonlinearOptimizer, iterationHook_CG )
+{
+  NonlinearFactorGraph fg(example::createReallyNonlinearFactorGraph());
+
+  Point2 x0(3,3);
+  Values c0;
+  c0.insert(X(1), x0);
+
+  // Levenberg-Marquardt
+  NonlinearConjugateGradientOptimizer::Parameters cgParams;
+  size_t lastIterCalled = 0;
+  cgParams.iterationHook = [&](size_t iteration, double oldError, double newError)
+  {
+    // Tests:
+    lastIterCalled = iteration;
+    EXPECT(newError<oldError);
+    
+    // Example of evolution printout:
+    //std::cout << "iter: " << iteration << " error: " << oldError << " => " << newError <<"\n";
+  };
+  NonlinearConjugateGradientOptimizer(fg, c0, cgParams).optimize();
+  
+  EXPECT(lastIterCalled>5);
+}
+
+
+/* ************************************************************************* */
 //// Minimal traits example
 struct MyType : public Vector3 {
   using Vector3::Vector3;
--- gtsam-4.1.0.orig/tests/testSerializationSLAM.cpp
+++ gtsam-4.1.0/tests/testSerializationSLAM.cpp
@@ -89,10 +89,8 @@ typedef RangeFactor<Pose3, Point3>
 typedef RangeFactor<Pose2, Pose2>                               RangeFactorPose2;
 typedef RangeFactor<Pose3, Pose3>                               RangeFactorPose3;
 typedef RangeFactor<CalibratedCamera, Point3>                   RangeFactorCalibratedCameraPoint;
-typedef RangeFactor<SimpleCamera, Point3>                       RangeFactorSimpleCameraPoint;
 typedef RangeFactor<PinholeCameraCal3_S2, Point3>               RangeFactorPinholeCameraCal3_S2Point;
 typedef RangeFactor<CalibratedCamera, CalibratedCamera>         RangeFactorCalibratedCamera;
-typedef RangeFactor<SimpleCamera, SimpleCamera>                 RangeFactorSimpleCamera;
 typedef RangeFactor<PinholeCameraCal3_S2, PinholeCameraCal3_S2> RangeFactorPinholeCameraCal3_S2;
 
 typedef BearingRangeFactor<Pose2, Point2>  BearingRangeFactor2D;
@@ -102,6 +100,7 @@ typedef GenericProjectionFactor<Pose3, P
 typedef GenericProjectionFactor<Pose3, Point3, Cal3DS2> GenericProjectionFactorCal3DS2;
 
 typedef gtsam::GeneralSFMFactor<gtsam::PinholeCameraCal3_S2, gtsam::Point3> GeneralSFMFactorCal3_S2;
+//TODO Fix issue 621 for this to work
 //typedef gtsam::GeneralSFMFactor<gtsam::PinholeCameraCal3DS2, gtsam::Point3> GeneralSFMFactorCal3DS2;
 
 typedef gtsam::GeneralSFMFactor2<gtsam::Cal3_S2> GeneralSFMFactor2Cal3_S2;
@@ -145,7 +144,6 @@ GTSAM_VALUE_EXPORT(gtsam::Cal3_S2);
 GTSAM_VALUE_EXPORT(gtsam::Cal3DS2);
 GTSAM_VALUE_EXPORT(gtsam::Cal3_S2Stereo);
 GTSAM_VALUE_EXPORT(gtsam::CalibratedCamera);
-GTSAM_VALUE_EXPORT(gtsam::SimpleCamera);
 GTSAM_VALUE_EXPORT(gtsam::PinholeCameraCal3_S2);
 GTSAM_VALUE_EXPORT(gtsam::StereoCamera);
 
@@ -190,9 +188,9 @@ BOOST_CLASS_EXPORT_GUID(RangeFactor3D, "
 BOOST_CLASS_EXPORT_GUID(RangeFactorPose2, "gtsam::RangeFactorPose2");
 BOOST_CLASS_EXPORT_GUID(RangeFactorPose3, "gtsam::RangeFactorPose3");
 BOOST_CLASS_EXPORT_GUID(RangeFactorCalibratedCameraPoint, "gtsam::RangeFactorCalibratedCameraPoint");
-BOOST_CLASS_EXPORT_GUID(RangeFactorSimpleCameraPoint, "gtsam::RangeFactorSimpleCameraPoint");
+BOOST_CLASS_EXPORT_GUID(RangeFactorPinholeCameraCal3_S2Point, "gtsam::RangeFactorPinholeCameraCal3_S2Point");
 BOOST_CLASS_EXPORT_GUID(RangeFactorCalibratedCamera, "gtsam::RangeFactorCalibratedCamera");
-BOOST_CLASS_EXPORT_GUID(RangeFactorSimpleCamera, "gtsam::RangeFactorSimpleCamera");
+BOOST_CLASS_EXPORT_GUID(RangeFactorPinholeCameraCal3_S2, "gtsam::RangeFactorPinholeCameraCal3_S2");
 
 BOOST_CLASS_EXPORT_GUID(BearingRangeFactor2D, "gtsam::BearingRangeFactor2D");
 
@@ -200,6 +198,7 @@ BOOST_CLASS_EXPORT_GUID(GenericProjectio
 BOOST_CLASS_EXPORT_GUID(GenericProjectionFactorCal3DS2, "gtsam::GenericProjectionFactorCal3DS2");
 
 BOOST_CLASS_EXPORT_GUID(GeneralSFMFactorCal3_S2, "gtsam::GeneralSFMFactorCal3_S2");
+//TODO fix issue 621
 //BOOST_CLASS_EXPORT_GUID(GeneralSFMFactorCal3DS2, "gtsam::GeneralSFMFactorCal3DS2");
 
 BOOST_CLASS_EXPORT_GUID(GeneralSFMFactor2Cal3_S2, "gtsam::GeneralSFMFactor2Cal3_S2");
@@ -352,9 +351,9 @@ TEST (testSerializationSLAM, factors) {
   RangeFactorPose2 rangeFactorPose2(a08, b08, 2.0, model1);
   RangeFactorPose3 rangeFactorPose3(a09, b09, 2.0, model1);
   RangeFactorCalibratedCameraPoint rangeFactorCalibratedCameraPoint(a12, a05, 2.0, model1);
-  RangeFactorSimpleCameraPoint rangeFactorSimpleCameraPoint(a13, a05, 2.0, model1);
+  RangeFactorPinholeCameraCal3_S2Point rangeFactorPinholeCameraCal3_S2Point(a13, a05, 2.0, model1);
   RangeFactorCalibratedCamera rangeFactorCalibratedCamera(a12, b12, 2.0, model1);
-  RangeFactorSimpleCamera rangeFactorSimpleCamera(a13, b13, 2.0, model1);
+  RangeFactorPinholeCameraCal3_S2 rangeFactorPinholeCameraCal3_S2(a13, b13, 2.0, model1);
 
   BearingRangeFactor2D bearingRangeFactor2D(a08, a03, rot2, 2.0, model2);
 
@@ -405,9 +404,9 @@ TEST (testSerializationSLAM, factors) {
   graph += rangeFactorPose2;
   graph += rangeFactorPose3;
   graph += rangeFactorCalibratedCameraPoint;
-  graph += rangeFactorSimpleCameraPoint;
+  graph += rangeFactorPinholeCameraCal3_S2Point;
   graph += rangeFactorCalibratedCamera;
-  graph += rangeFactorSimpleCamera;
+  graph += rangeFactorPinholeCameraCal3_S2;
 
   graph += bearingRangeFactor2D;
 
@@ -463,9 +462,9 @@ TEST (testSerializationSLAM, factors) {
   EXPECT(equalsObj<RangeFactorPose2>(rangeFactorPose2));
   EXPECT(equalsObj<RangeFactorPose3>(rangeFactorPose3));
   EXPECT(equalsObj<RangeFactorCalibratedCameraPoint>(rangeFactorCalibratedCameraPoint));
-  EXPECT(equalsObj<RangeFactorSimpleCameraPoint>(rangeFactorSimpleCameraPoint));
+  EXPECT(equalsObj<RangeFactorPinholeCameraCal3_S2Point>(rangeFactorPinholeCameraCal3_S2Point));
   EXPECT(equalsObj<RangeFactorCalibratedCamera>(rangeFactorCalibratedCamera));
-  EXPECT(equalsObj<RangeFactorSimpleCamera>(rangeFactorSimpleCamera));
+  EXPECT(equalsObj<RangeFactorPinholeCameraCal3_S2>(rangeFactorPinholeCameraCal3_S2));
 
   EXPECT(equalsObj<BearingRangeFactor2D>(bearingRangeFactor2D));
 
@@ -521,9 +520,9 @@ TEST (testSerializationSLAM, factors) {
   EXPECT(equalsXML<RangeFactorPose2>(rangeFactorPose2));
   EXPECT(equalsXML<RangeFactorPose3>(rangeFactorPose3));
   EXPECT(equalsXML<RangeFactorCalibratedCameraPoint>(rangeFactorCalibratedCameraPoint));
-  EXPECT(equalsXML<RangeFactorSimpleCameraPoint>(rangeFactorSimpleCameraPoint));
+  EXPECT(equalsXML<RangeFactorPinholeCameraCal3_S2Point>(rangeFactorPinholeCameraCal3_S2Point));
   EXPECT(equalsXML<RangeFactorCalibratedCamera>(rangeFactorCalibratedCamera));
-  EXPECT(equalsXML<RangeFactorSimpleCamera>(rangeFactorSimpleCamera));
+  EXPECT(equalsXML<RangeFactorPinholeCameraCal3_S2>(rangeFactorPinholeCameraCal3_S2));
 
   EXPECT(equalsXML<BearingRangeFactor2D>(bearingRangeFactor2D));
 
@@ -579,9 +578,9 @@ TEST (testSerializationSLAM, factors) {
   EXPECT(equalsBinary<RangeFactorPose2>(rangeFactorPose2));
   EXPECT(equalsBinary<RangeFactorPose3>(rangeFactorPose3));
   EXPECT(equalsBinary<RangeFactorCalibratedCameraPoint>(rangeFactorCalibratedCameraPoint));
-  EXPECT(equalsBinary<RangeFactorSimpleCameraPoint>(rangeFactorSimpleCameraPoint));
+  EXPECT(equalsBinary<RangeFactorPinholeCameraCal3_S2Point>(rangeFactorPinholeCameraCal3_S2Point));
   EXPECT(equalsBinary<RangeFactorCalibratedCamera>(rangeFactorCalibratedCamera));
-  EXPECT(equalsBinary<RangeFactorSimpleCamera>(rangeFactorSimpleCamera));
+  EXPECT(equalsBinary<RangeFactorPinholeCameraCal3_S2>(rangeFactorPinholeCameraCal3_S2));
 
   EXPECT(equalsBinary<BearingRangeFactor2D>(bearingRangeFactor2D));
 
--- gtsam-4.1.0.orig/wrap/cmake/PybindWrap.cmake
+++ gtsam-4.1.0/wrap/cmake/PybindWrap.cmake
@@ -27,15 +27,24 @@ set(PYBIND11_PYTHON_VERSION ${WRAP_PYTHO
 
 add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/../pybind11 pybind11)
 
-# User-friendly Pybind11 wrapping and installing function. Builds a Pybind11
-# module from the provided interface_header. For example, for the interface
-# header gtsam.h, this will build the wrap module 'gtsam_py.cc'.
+# User-friendly Pybind11 wrapping and installing function.
+# Builds a Pybind11 module from the provided interface_header.
+# For example, for the interface header gtsam.h, this will
+# build the wrap module 'gtsam_py.cc'.
 #
 # Arguments:
 # ~~~
+# target: The Make target
 # interface_header:  The relative path to the wrapper interface definition file.
-# install_path: destination to install the library libs: libraries to link with
-# dependencies: Dependencies which need to be built before the wrapper
+# generated_cpp: The name of the cpp file which is generated from the tpl file.
+# module_name: The name of the Python module to use.
+# top_namespace: The C++ namespace under which the code to be wrapped exists.
+# ignore_classes: CMake list of classes to ignore from wrapping.
+# install_path: Destination to install the library.
+# module_template: The template file (.tpl) from which to generate the Pybind11 module.
+# libs: Libraries to link with.
+# dependencies: Dependencies which need to be built before the wrapper.
+# use_boost (optional): Flag indicating whether to include Boost.
 function(pybind_wrap
          target
          interface_header
@@ -137,7 +146,7 @@ function(install_python_scripts
       else()
         set(build_type_tag "")
       endif()
-      # Split up filename to strip trailing '/' in WRAP_CYTHON_INSTALL_PATH if
+      # Split up filename to strip trailing '/' in GTSAM_PY_INSTALL_PATH if
       # there is one
       get_filename_component(location "${dest_directory}" PATH)
       get_filename_component(name "${dest_directory}" NAME)
--- gtsam-4.1.0.orig/wrap/matlab_wrapper.py
+++ gtsam-4.1.0/wrap/matlab_wrapper.py
@@ -210,18 +210,26 @@ class MatlabWrapper(object):
         else:
             formatted_type_name += name
 
-        if len(type_name.instantiations) == 1:
-            if separator == "::":  # C++
-                formatted_type_name += '<{}>'.format(cls._format_type_name(type_name.instantiations[0],
-                                                                            include_namespace=include_namespace,
-                                                                            constructor=constructor, method=method))
-            else:
+        if separator == "::":  # C++
+            templates = []
+            for idx in range(len(type_name.instantiations)):
+                template = '{}'.format(cls._format_type_name(type_name.instantiations[idx],
+                                                             include_namespace=include_namespace,
+                                                             constructor=constructor, method=method))
+                templates.append(template)
+
+            if len(templates) > 0:  # If there are no templates
+                formatted_type_name += '<{}>'.format(','.join(templates))
+
+        else:
+            for idx in range(len(type_name.instantiations)):
                 formatted_type_name += '{}'.format(cls._format_type_name(
-                    type_name.instantiations[0],
+                    type_name.instantiations[idx],
                     separator=separator,
                     include_namespace=False,
                     constructor=constructor, method=method
                 ))
+
         return formatted_type_name
 
     @classmethod
--- gtsam-4.1.0.orig/wrap/pybind11/.appveyor.yml
+++ gtsam-4.1.0/wrap/pybind11/.appveyor.yml
@@ -1,64 +1,32 @@
 version: 1.0.{build}
 image:
-- Visual Studio 2017
 - Visual Studio 2015
 test: off
 skip_branch_with_pr: true
 build:
   parallel: true
 platform:
-- x64
 - x86
 environment:
   matrix:
   - PYTHON: 36
-    CPP: 14
     CONFIG: Debug
   - PYTHON: 27
-    CPP: 14
     CONFIG: Debug
-  - CONDA: 36
-    CPP: latest
-    CONFIG: Release
-matrix:
-  exclude:
-    - image: Visual Studio 2015
-      platform: x86
-    - image: Visual Studio 2015
-      CPP: latest
-    - image: Visual Studio 2017
-      CPP: latest
-      platform: x86
 install:
 - ps: |
-    if ($env:PLATFORM -eq "x64") { $env:CMAKE_ARCH = "x64" }
-    if ($env:APPVEYOR_JOB_NAME -like "*Visual Studio 2017*") {
-      $env:CMAKE_GENERATOR = "Visual Studio 15 2017"
-      $env:CMAKE_INCLUDE_PATH = "C:\Libraries\boost_1_64_0"
-      $env:CXXFLAGS = "-permissive-"
-    } else {
-      $env:CMAKE_GENERATOR = "Visual Studio 14 2015"
-    }
-    if ($env:PYTHON) {
-      if ($env:PLATFORM -eq "x64") { $env:PYTHON = "$env:PYTHON-x64" }
-      $env:PATH = "C:\Python$env:PYTHON\;C:\Python$env:PYTHON\Scripts\;$env:PATH"
-      python -W ignore -m pip install --upgrade pip wheel
-      python -W ignore -m pip install pytest numpy --no-warn-script-location
-    } elseif ($env:CONDA) {
-      if ($env:CONDA -eq "27") { $env:CONDA = "" }
-      if ($env:PLATFORM -eq "x64") { $env:CONDA = "$env:CONDA-x64" }
-      $env:PATH = "C:\Miniconda$env:CONDA\;C:\Miniconda$env:CONDA\Scripts\;$env:PATH"
-      $env:PYTHONHOME = "C:\Miniconda$env:CONDA"
-      conda --version
-      conda install -y -q pytest numpy scipy
-    }
+    $env:CMAKE_GENERATOR = "Visual Studio 14 2015"
+    if ($env:PLATFORM -eq "x64") { $env:PYTHON = "$env:PYTHON-x64" }
+    $env:PATH = "C:\Python$env:PYTHON\;C:\Python$env:PYTHON\Scripts\;$env:PATH"
+    python -W ignore -m pip install --upgrade pip wheel
+    python -W ignore -m pip install pytest numpy --no-warn-script-location
 - ps: |
-    Start-FileDownload 'http://bitbucket.org/eigen/eigen/get/3.3.3.zip'
-    7z x 3.3.3.zip -y > $null
-    $env:CMAKE_INCLUDE_PATH = "eigen-eigen-67e894c6cd8f;$env:CMAKE_INCLUDE_PATH"
+    Start-FileDownload 'https://gitlab.com/libeigen/eigen/-/archive/3.3.7/eigen-3.3.7.zip'
+    7z x eigen-3.3.7.zip -y > $null
+    $env:CMAKE_INCLUDE_PATH = "eigen-3.3.7;$env:CMAKE_INCLUDE_PATH"
 build_script:
 - cmake -G "%CMAKE_GENERATOR%" -A "%CMAKE_ARCH%"
-    -DPYBIND11_CPP_STANDARD=/std:c++%CPP%
+    -DCMAKE_CXX_STANDARD=14
     -DPYBIND11_WERROR=ON
     -DDOWNLOAD_CATCH=ON
     -DCMAKE_SUPPRESS_REGENERATION=1
@@ -66,5 +34,4 @@ build_script:
 - set MSBuildLogger="C:\Program Files\AppVeyor\BuildAgent\Appveyor.MSBuildLogger.dll"
 - cmake --build . --config %CONFIG% --target pytest -- /m /v:m /logger:%MSBuildLogger%
 - cmake --build . --config %CONFIG% --target cpptest -- /m /v:m /logger:%MSBuildLogger%
-- if "%CPP%"=="latest" (cmake --build . --config %CONFIG% --target test_cmake_build -- /m /v:m /logger:%MSBuildLogger%)
 on_failure: if exist "tests\test_cmake_build" type tests\test_cmake_build\*.log*
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.clang-tidy
@@ -0,0 +1,13 @@
+FormatStyle: file
+
+Checks: '
+llvm-namespace-comment,
+modernize-use-override,
+readability-container-size-empty,
+modernize-use-using,
+modernize-use-equals-default,
+modernize-use-auto,
+modernize-use-emplace,
+'
+
+HeaderFilterRegex: 'pybind11/.*h'
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.cmake-format.yaml
@@ -0,0 +1,73 @@
+parse:
+  additional_commands:
+    pybind11_add_module:
+      flags:
+        - THIN_LTO
+        - MODULE
+        - SHARED
+        - NO_EXTRAS
+        - EXCLUDE_FROM_ALL
+        - SYSTEM
+
+format:
+  line_width: 99
+  tab_size: 2
+
+  # If an argument group contains more than this many sub-groups
+  # (parg or kwarg groups) then force it to a vertical layout.
+  max_subgroups_hwrap: 2
+
+  # If a positional argument group contains more than this many
+  # arguments, then force it to a vertical layout.
+  max_pargs_hwrap: 6
+
+  # If a cmdline positional group consumes more than this many
+  # lines without nesting, then invalidate the layout (and nest)
+  max_rows_cmdline: 2
+  separate_ctrl_name_with_space: false
+  separate_fn_name_with_space: false
+  dangle_parens: false
+
+  # If the trailing parenthesis must be 'dangled' on its on
+  # 'line, then align it to this reference: `prefix`: the start'
+  # 'of the statement,  `prefix-indent`: the start of the'
+  # 'statement, plus one indentation  level, `child`: align to'
+  # the column of the arguments
+  dangle_align: prefix
+  # If the statement spelling length (including space and
+  # parenthesis) is smaller than this amount, then force reject
+  # nested layouts.
+  min_prefix_chars: 4
+
+  # If the statement spelling length (including space and
+  # parenthesis) is larger than the tab width by more than this
+  # amount, then force reject un-nested layouts.
+  max_prefix_chars: 10
+
+  # If a candidate layout is wrapped horizontally but it exceeds
+  # this many lines, then reject the layout.
+  max_lines_hwrap: 2
+
+  line_ending: unix
+
+  # Format command names consistently as 'lower' or 'upper' case
+  command_case: canonical
+
+  # Format keywords consistently as 'lower' or 'upper' case
+  # unchanged is valid too
+  keyword_case: 'upper'
+
+  # A list of command names which should always be wrapped
+  always_wrap: []
+
+  # If true, the argument lists which are known to be sortable
+  # will be sorted lexicographically
+  enable_sort: true
+
+  # If true, the parsers may infer whether or not an argument
+  # list is sortable (without annotation).
+  autosort: false
+
+# Causes a few issues - can be solved later, possibly.
+markup:
+  enable_markup: false
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/CONTRIBUTING.md
@@ -0,0 +1,319 @@
+Thank you for your interest in this project! Please refer to the following
+sections on how to contribute code and bug reports.
+
+### Reporting bugs
+
+Before submitting a question or bug report, please take a moment of your time
+and ensure that your issue isn't already discussed in the project documentation
+provided at [pybind11.readthedocs.org][] or in the [issue tracker][]. You can
+also check [gitter][] to see if it came up before.
+
+Assuming that you have identified a previously unknown problem or an important
+question, it's essential that you submit a self-contained and minimal piece of
+code that reproduces the problem. In other words: no external dependencies,
+isolate the function(s) that cause breakage, submit matched and complete C++
+and Python snippets that can be easily compiled and run in isolation; or
+ideally make a small PR with a failing test case that can be used as a starting
+point.
+
+## Pull requests
+
+Contributions are submitted, reviewed, and accepted using GitHub pull requests.
+Please refer to [this article][using pull requests] for details and adhere to
+the following rules to make the process as smooth as possible:
+
+* Make a new branch for every feature you're working on.
+* Make small and clean pull requests that are easy to review but make sure they
+  do add value by themselves.
+* Add tests for any new functionality and run the test suite (`cmake --build
+  build --target pytest`) to ensure that no existing features break.
+* Please run [`pre-commit`][pre-commit] to check your code matches the
+  project style. (Note that `gawk` is required.) Use `pre-commit run
+  --all-files` before committing (or use installed-mode, check pre-commit docs)
+  to verify your code passes before pushing to save time.
+* This project has a strong focus on providing general solutions using a
+  minimal amount of code, thus small pull requests are greatly preferred.
+
+### Licensing of contributions
+
+pybind11 is provided under a BSD-style license that can be found in the
+``LICENSE`` file. By using, distributing, or contributing to this project, you
+agree to the terms and conditions of this license.
+
+You are under no obligation whatsoever to provide any bug fixes, patches, or
+upgrades to the features, functionality or performance of the source code
+("Enhancements") to anyone; however, if you choose to make your Enhancements
+available either publicly, or directly to the author of this software, without
+imposing a separate written license agreement for such Enhancements, then you
+hereby grant the following license: a non-exclusive, royalty-free perpetual
+license to install, use, modify, prepare derivative works, incorporate into
+other computer software, distribute, and sublicense such enhancements or
+derivative works thereof, in binary and source code form.
+
+
+## Development of pybind11
+
+To setup an ideal development environment, run the following commands on a
+system with CMake 3.14+:
+
+```bash
+python3 -m venv venv
+source venv/bin/activate
+pip install -r tests/requirements.txt
+cmake -S . -B build -DDOWNLOAD_CATCH=ON -DDOWNLOAD_EIGEN=ON
+cmake --build build -j4
+```
+
+Tips:
+
+* You can use `virtualenv` (from PyPI) instead of `venv` (which is Python 3
+  only).
+* You can select any name for your environment folder; if it contains "env" it
+  will be ignored by git.
+* If you don’t have CMake 3.14+, just add “cmake” to the pip install command.
+* You can use `-DPYBIND11_FINDPYTHON=ON` to use FindPython on CMake 3.12+
+* In classic mode, you may need to set `-DPYTHON_EXECUTABLE=/path/to/python`.
+  FindPython uses `-DPython_ROOT_DIR=/path/to` or
+  `-DPython_EXECUTABLE=/path/to/python`.
+
+### Configuration options
+
+In CMake, configuration options are given with “-D”. Options are stored in the
+build directory, in the `CMakeCache.txt` file, so they are remembered for each
+build directory. Two selections are special - the generator, given with `-G`,
+and the compiler, which is selected based on environment variables `CXX` and
+similar, or `-DCMAKE_CXX_COMPILER=`. Unlike the others, these cannot be changed
+after the initial run.
+
+The valid options are:
+
+* `-DCMAKE_BUILD_TYPE`: Release, Debug, MinSizeRel, RelWithDebInfo
+* `-DPYBIND11_FINDPYTHON=ON`: Use CMake 3.12+’s FindPython instead of the
+  classic, deprecated, custom FindPythonLibs
+* `-DPYBIND11_NOPYTHON=ON`: Disable all Python searching (disables tests)
+* `-DBUILD_TESTING=ON`: Enable the tests
+* `-DDOWNLOAD_CATCH=ON`: Download catch to build the C++ tests
+* `-DOWNLOAD_EIGEN=ON`: Download Eigen for the NumPy tests
+* `-DPYBIND11_INSTALL=ON/OFF`: Enable the install target (on by default for the
+  master project)
+* `-DUSE_PYTHON_INSTALL_DIR=ON`: Try to install into the python dir
+
+
+<details><summary>A few standard CMake tricks: (click to expand)</summary><p>
+
+* Use `cmake --build build -v` to see the commands used to build the files.
+* Use `cmake build -LH` to list the CMake options with help.
+* Use `ccmake` if available to see a curses (terminal) gui, or `cmake-gui` for
+  a completely graphical interface (not present in the PyPI package).
+* Use `cmake --build build -j12` to build with 12 cores (for example).
+* Use `-G` and the name of a generator to use something different. `cmake
+  --help` lists the generators available.
+      - On Unix, setting `CMAKE_GENERATER=Ninja` in your environment will give
+        you automatic mulithreading on all your CMake projects!
+* Open the `CMakeLists.txt` with QtCreator to generate for that IDE.
+* You can use `-DCMAKE_EXPORT_COMPILE_COMMANDS=ON` to generate the `.json` file
+  that some tools expect.
+
+</p></details>
+
+
+To run the tests, you can "build" the check target:
+
+```bash
+cmake --build build --target check
+```
+
+`--target` can be spelled `-t` in CMake 3.15+. You can also run individual
+tests with these targets:
+
+* `pytest`: Python tests only
+* `cpptest`: C++ tests only
+* `test_cmake_build`: Install / subdirectory tests
+
+If you want to build just a subset of tests, use
+`-DPYBIND11_TEST_OVERRIDE="test_callbacks.cpp;test_pickling.cpp"`. If this is
+empty, all tests will be built.
+
+### Formatting
+
+All formatting is handled by pre-commit.
+
+Install with brew (macOS) or pip (any OS):
+
+```bash
+# Any OS
+python3 -m pip install pre-commit
+
+# OR macOS with homebrew:
+brew install pre-commit
+```
+
+Then, you can run it on the items you've added to your staging area, or all
+files:
+
+```bash
+pre-commit run
+# OR
+pre-commit run --all-files
+```
+
+And, if you want to always use it, you can install it as a git hook (hence the
+name, pre-commit):
+
+```bash
+pre-commit install
+```
+
+### Clang-Tidy
+
+To run Clang tidy, the following recipe should work. Files will be modified in
+place, so you can use git to monitor the changes.
+
+```bash
+docker run --rm -v $PWD:/pybind11 -it silkeh/clang:10
+apt-get update && apt-get install python3-dev python3-pytest
+cmake -S pybind11/ -B build -DCMAKE_CXX_CLANG_TIDY="$(which clang-tidy);-fix"
+cmake --build build
+```
+
+### Include what you use
+
+To run include what you use, install (`brew install include-what-you-use` on
+macOS), then run:
+
+```bash
+cmake -S . -B build-iwyu -DCMAKE_CXX_INCLUDE_WHAT_YOU_USE=$(which include-what-you-use)
+cmake --build build
+```
+
+The report is sent to stderr; you can pip it into a file if you wish.
+
+### Build recipes
+
+This builds with the Intel compiler (assuming it is in your path, along with a
+recent CMake and Python 3):
+
+```bash
+python3 -m venv venv
+. venv/bin/activate
+pip install pytest
+cmake -S . -B build-intel -DCMAKE_CXX_COMPILER=$(which icpc) -DDOWNLOAD_CATCH=ON -DDOWNLOAD_EIGEN=ON -DPYBIND11_WERROR=ON
+```
+
+This will test the PGI compilers:
+
+```bash
+docker run --rm -it -v $PWD:/pybind11 nvcr.io/hpc/pgi-compilers:ce
+apt-get update && apt-get install -y python3-dev python3-pip python3-pytest
+wget -qO- "https://cmake.org/files/v3.18/cmake-3.18.2-Linux-x86_64.tar.gz" | tar --strip-components=1 -xz -C /usr/local
+cmake -S pybind11/ -B build
+cmake --build build
+```
+
+### Explanation of the SDist/wheel building design
+
+> These details below are _only_ for packaging the Python sources from git. The
+> SDists and wheels created do not have any extra requirements at all and are
+> completely normal.
+
+The main objective of the packaging system is to create SDists (Python's source
+distribution packages) and wheels (Python's binary distribution packages) that
+include everything that is needed to work with pybind11, and which can be
+installed without any additional dependencies. This is more complex than it
+appears: in order to support CMake as a first class language even when using
+the PyPI package, they must include the _generated_ CMake files (so as not to
+require CMake when installing the `pybind11` package itself). They should also
+provide the option to install to the "standard" location
+(`<ENVROOT>/include/pybind11` and `<ENVROOT>/share/cmake/pybind11`) so they are
+easy to find with CMake, but this can cause problems if you are not an
+environment or using ``pyproject.toml`` requirements. This was solved by having
+two packages; the "nice" pybind11 package that stores the includes and CMake
+files inside the package, that you get access to via functions in the package,
+and a `pybind11-global` package that can be included via `pybind11[global]` if
+you want the more invasive but discoverable file locations.
+
+If you want to install or package the GitHub source, it is best to have Pip 10
+or newer on Windows, macOS, or Linux (manylinux1 compatible, includes most
+distributions).  You can then build the SDists, or run any procedure that makes
+SDists internally, like making wheels or installing.
+
+
+```bash
+# Editable development install example
+python3 -m pip install -e .
+```
+
+Since Pip itself does not have an `sdist` command (it does have `wheel` and
+`install`), you may want to use the upcoming `build` package:
+
+```bash
+python3 -m pip install build
+
+# Normal package
+python3 -m build -s .
+
+# Global extra
+PYBIND11_GLOBAL_SDIST=1 python3 -m build -s .
+```
+
+If you want to use the classic "direct" usage of `python setup.py`, you will
+need CMake 3.15+ and either `make` or `ninja` preinstalled (possibly via `pip
+install cmake ninja`), since directly running Python on `setup.py` cannot pick
+up and install `pyproject.toml` requirements. As long as you have those two
+things, though, everything works the way you would expect:
+
+```bash
+# Normal package
+python3 setup.py sdist
+
+# Global extra
+PYBIND11_GLOBAL_SDIST=1 python3 setup.py sdist
+```
+
+A detailed explanation of the build procedure design for developers wanting to
+work on or maintain the packaging system is as follows:
+
+#### 1. Building from the source directory
+
+When you invoke any `setup.py` command from the source directory, including
+`pip wheel .` and `pip install .`, you will activate a full source build. This
+is made of the following steps:
+
+1. If the tool is PEP 518 compliant, like Pip 10+, it will create a temporary
+   virtual environment and install the build requirements (mostly CMake) into
+   it. (if you are not on Windows, macOS, or a manylinux compliant system, you
+   can disable this with `--no-build-isolation` as long as you have CMake 3.15+
+   installed)
+2. The environment variable `PYBIND11_GLOBAL_SDIST` is checked - if it is set
+   and truthy, this will be make the accessory `pybind11-global` package,
+   instead of the normal `pybind11` package. This package is used for
+   installing the files directly to your environment root directory, using
+   `pybind11[global]`.
+2. `setup.py` reads the version from `pybind11/_version.py` and verifies it
+   matches `includes/pybind11/detail/common.h`.
+3. CMake is run with `-DCMAKE_INSTALL_PREIFX=pybind11`. Since the CMake install
+   procedure uses only relative paths and is identical on all platforms, these
+   files are valid as long as they stay in the correct relative position to the
+   includes. `pybind11/share/cmake/pybind11` has the CMake files, and
+   `pybind11/include` has the includes. The build directory is discarded.
+4. Simpler files are placed in the SDist: `tools/setup_*.py.in`,
+   `tools/pyproject.toml` (`main` or `global`)
+5. The package is created by running the setup function in the
+   `tools/setup_*.py`.  `setup_main.py` fills in Python packages, and
+   `setup_global.py` fills in only the data/header slots.
+6. A context manager cleans up the temporary CMake install directory (even if
+   an error is thrown).
+
+### 2. Building from SDist
+
+Since the SDist has the rendered template files in `tools` along with the
+includes and CMake files in the correct locations, the builds are completely
+trivial and simple. No extra requirements are required. You can even use Pip 9
+if you really want to.
+
+
+[pre-commit]: https://pre-commit.com
+[pybind11.readthedocs.org]: http://pybind11.readthedocs.org/en/latest
+[issue tracker]: https://github.com/pybind/pybind11/issues
+[gitter]: https://gitter.im/pybind/Lobby
+[using pull requests]: https://help.github.com/articles/using-pull-requests
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/ISSUE_TEMPLATE/bug-report.md
@@ -0,0 +1,28 @@
+---
+name: Bug Report
+about: File an issue about a bug
+title: "[BUG] "
+---
+
+
+Make sure you've completed the following steps before submitting your issue -- thank you!
+
+1. Make sure you've read the [documentation][]. Your issue may be addressed there.
+2. Search the [issue tracker][] to verify that this hasn't already been reported. +1 or comment there if it has.
+3. Consider asking first in the [Gitter chat room][].
+4. Include a self-contained and minimal piece of code that reproduces the problem. If that's not possible, try to make the description as clear as possible.
+    a. If possible, make a PR with a new, failing test to give us a starting point to work on!
+
+[documentation]: https://pybind11.readthedocs.io
+[issue tracker]: https://github.com/pybind/pybind11/issues
+[Gitter chat room]: https://gitter.im/pybind/Lobby
+
+*After reading, remove this checklist and the template text in parentheses below.*
+
+## Issue description
+
+(Provide a short description, state the expected behavior and what actually happens.)
+
+## Reproducible example code
+
+(The code should be minimal, have no external dependencies, isolate the function(s) that cause breakage. Submit matched and complete C++ and Python snippets that can be easily compiled and run to diagnose the issue.)
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/ISSUE_TEMPLATE/config.yml
@@ -0,0 +1,5 @@
+blank_issues_enabled: false
+contact_links:
+  - name: Gitter room
+    url: https://gitter.im/pybind/Lobby
+    about: A room for discussing pybind11 with an active community
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/ISSUE_TEMPLATE/feature-request.md
@@ -0,0 +1,16 @@
+---
+name: Feature Request
+about: File an issue about adding a feature
+title: "[FEAT] "
+---
+
+
+Make sure you've completed the following steps before submitting your issue -- thank you!
+
+1. Check if your feature has already been mentioned / rejected / planned in other issues.
+2. If those resources didn't help, consider asking in the [Gitter chat room][] to see if this is interesting / useful to a larger audience and possible to implement reasonably,
+4. If you have a useful feature that passes the previous items (or not suitable for chat), please fill in the details below.
+
+[Gitter chat room]: https://gitter.im/pybind/Lobby
+
+*After reading, remove this checklist.*
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/ISSUE_TEMPLATE/question.md
@@ -0,0 +1,21 @@
+---
+name: Question
+about: File an issue about unexplained behavior
+title: "[QUESTION] "
+---
+
+If you have a question, please check the following first:
+
+1. Check if your question has already been answered in the [FAQ][] section.
+2. Make sure you've read the [documentation][]. Your issue may be addressed there.
+3. If those resources didn't help and you only have a short question (not a bug report), consider asking in the [Gitter chat room][]
+4. Search the [issue tracker][], including the closed issues, to see if your question has already been asked/answered. +1 or comment if it has been asked but has no answer.
+5. If you have a more complex question which is not answered in the previous items (or not suitable for chat), please fill in the details below.
+6. Include a self-contained and minimal piece of code that illustrates your question. If that's not possible, try to make the description as clear as possible.
+
+[FAQ]: http://pybind11.readthedocs.io/en/latest/faq.html
+[documentation]: https://pybind11.readthedocs.io
+[issue tracker]: https://github.com/pybind/pybind11/issues
+[Gitter chat room]: https://gitter.im/pybind/Lobby
+
+*After reading, remove this checklist.*
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/workflows/ci.yml
@@ -0,0 +1,519 @@
+name: CI
+
+on:
+  workflow_dispatch:
+  pull_request:
+  push:
+    branches:
+      - master
+      - stable
+      - v*
+
+jobs:
+  # This is the "main" test suite, which tests a large number of different
+  # versions of default compilers and Python versions in GitHub Actions.
+  standard:
+    strategy:
+      fail-fast: false
+      matrix:
+        runs-on: [ubuntu-latest, windows-latest, macos-latest]
+        arch: [x64]
+        python:
+        - 2.7
+        - 3.5
+        - 3.8
+        - pypy2
+        - pypy3
+
+        # Items in here will either be added to the build matrix (if not
+        # present), or add new keys to an existing matrix element if all the
+        # existing keys match.
+        #
+        # We support three optional keys: args (both build), args1 (first
+        # build), and args2 (second build).
+        include:
+          - runs-on: ubuntu-latest
+            python: 3.6
+            arch: x64
+            args: >
+              -DPYBIND11_FINDPYTHON=ON
+          - runs-on: windows-2016
+            python: 3.7
+            arch: x86
+            args2: >
+              -DCMAKE_CXX_FLAGS="/permissive- /EHsc /GR"
+          - runs-on: windows-latest
+            python: 3.6
+            arch: x64
+            args: >
+              -DPYBIND11_FINDPYTHON=ON
+          - runs-on: windows-latest
+            python: 3.7
+            arch: x64
+
+          - runs-on: ubuntu-latest
+            python: 3.9-dev
+            arch: x64
+          - runs-on: macos-latest
+            python: 3.9-dev
+            arch: x64
+            args: >
+              -DPYBIND11_FINDPYTHON=ON
+
+        # These items will be removed from the build matrix, keys must match.
+        exclude:
+            # Currently 32bit only, and we build 64bit
+          - runs-on: windows-latest
+            python: pypy2
+            arch: x64
+          - runs-on: windows-latest
+            python: pypy3
+            arch: x64
+
+            # Currently broken on embed_test
+          - runs-on: windows-latest
+            python: 3.8
+            arch: x64
+          - runs-on: windows-latest
+            python: 3.9-dev
+            arch: x64
+
+    name: "🐍 ${{ matrix.python }} • ${{ matrix.runs-on }} • ${{ matrix.arch }} ${{ matrix.args }}"
+    runs-on: ${{ matrix.runs-on }}
+    continue-on-error: ${{ endsWith(matrix.python, 'dev') }}
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Setup Python ${{ matrix.python }}
+      uses: actions/setup-python@v2
+      with:
+        python-version: ${{ matrix.python }}
+        architecture: ${{ matrix.arch }}
+
+    - name: Setup Boost (Windows / Linux latest)
+      run: echo "::set-env name=BOOST_ROOT::$BOOST_ROOT_1_72_0"
+
+    - name: Update CMake
+      uses: jwlawson/actions-setup-cmake@v1.3
+
+    - name: Cache wheels
+      if: runner.os == 'macOS'
+      uses: actions/cache@v2
+      with:
+        # This path is specific to macOS - we really only need it for PyPy NumPy wheels
+        # See https://github.com/actions/cache/blob/master/examples.md#python---pip
+        # for ways to do this more generally
+        path: ~/Library/Caches/pip
+        # Look to see if there is a cache hit for the corresponding requirements file
+        key: ${{ runner.os }}-pip-${{ matrix.python }}-${{ matrix.arch }}-${{ hashFiles('tests/requirements.txt') }}
+
+    - name: Prepare env
+      run: python -m pip install -r tests/requirements.txt --prefer-binary
+
+    - name: Setup annotations on Linux
+      if: runner.os == 'Linux'
+      run: python -m pip install pytest-github-actions-annotate-failures
+
+    # First build - C++11 mode and inplace
+    - name: Configure C++11 ${{ matrix.args }}
+      run: >
+        cmake -S . -B .
+        -DPYBIND11_WERROR=ON
+        -DDOWNLOAD_CATCH=ON
+        -DDOWNLOAD_EIGEN=ON
+        -DCMAKE_CXX_STANDARD=11
+        ${{ matrix.args }}
+
+    - name: Build C++11
+      run: cmake --build . -j 2
+
+    - name: Python tests C++11
+      run: cmake --build . --target pytest -j 2
+
+    - name: C++11 tests
+      run: cmake --build .  --target cpptest -j 2
+
+    - name: Interface test C++11
+      run: cmake --build . --target test_cmake_build
+
+    - name: Clean directory
+      run: git clean -fdx
+
+    # Second build - C++17 mode and in a build directory
+    - name: Configure ${{ matrix.args2 }}
+      run: >
+        cmake -S . -B build2
+        -DPYBIND11_WERROR=ON
+        -DDOWNLOAD_CATCH=ON
+        -DDOWNLOAD_EIGEN=ON
+        -DCMAKE_CXX_STANDARD=17
+        ${{ matrix.args }}
+        ${{ matrix.args2 }}
+
+    - name: Build
+      run: cmake --build build2 -j 2
+
+    - name: Python tests
+      run: cmake --build build2 --target pytest
+
+    - name: C++ tests
+      run: cmake --build build2 --target cpptest
+
+    - name: Interface test
+      run: cmake --build build2 --target test_cmake_build
+
+    # Eventually Microsoft might have an action for setting up
+    # MSVC, but for now, this action works:
+    - name: Prepare compiler environment for Windows 🐍 2.7
+      if: matrix.python == 2.7 && runner.os == 'Windows'
+      uses: ilammy/msvc-dev-cmd@v1
+      with:
+        arch: x64
+
+    # This makes two environment variables available in the following step(s)
+    - name: Set Windows 🐍 2.7 environment variables
+      if: matrix.python == 2.7 && runner.os == 'Windows'
+      run: |
+        echo "::set-env name=DISTUTILS_USE_SDK::1"
+        echo "::set-env name=MSSdk::1"
+
+    # This makes sure the setup_helpers module can build packages using
+    # setuptools
+    - name: Setuptools helpers test
+      run: pytest tests/extra_setuptools
+
+
+  # Testing on clang using the excellent silkeh clang docker images
+  clang:
+    runs-on: ubuntu-latest
+    strategy:
+      fail-fast: false
+      matrix:
+        clang:
+          - 3.6
+          - 3.7
+          - 3.9
+          - 5
+          - 7
+          - 9
+          - dev
+
+    name: "🐍 3 • Clang ${{ matrix.clang }} • x64"
+    container: "silkeh/clang:${{ matrix.clang }}"
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Add wget and python3
+      run: apt-get update && apt-get install -y python3-dev python3-numpy python3-pytest libeigen3-dev
+
+    - name: Configure
+      shell: bash
+      run: >
+        cmake -S . -B build
+        -DPYBIND11_WERROR=ON
+        -DDOWNLOAD_CATCH=ON
+        -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)")
+
+    - name: Build
+      run: cmake --build build -j 2
+
+    - name: Python tests
+      run: cmake --build build --target pytest
+
+    - name: C++ tests
+      run: cmake --build build --target cpptest
+
+    - name: Interface test
+      run: cmake --build build --target test_cmake_build
+
+
+  # Testing NVCC; forces sources to behave like .cu files
+  cuda:
+    runs-on: ubuntu-latest
+    name: "🐍 3.8 • CUDA 11 • Ubuntu 20.04"
+    container: nvidia/cuda:11.0-devel-ubuntu20.04
+
+    steps:
+    - uses: actions/checkout@v2
+
+    # tzdata will try to ask for the timezone, so set the DEBIAN_FRONTEND
+    - name: Install 🐍 3
+      run: apt-get update && DEBIAN_FRONTEND="noninteractive" apt-get install -y cmake git python3-dev python3-pytest python3-numpy
+
+    - name: Configure
+      run: cmake -S . -B build -DPYBIND11_CUDA_TESTS=ON -DPYBIND11_WERROR=ON -DDOWNLOAD_CATCH=ON
+
+    - name: Build
+      run: cmake --build build -j2 --verbose
+
+    - name: Python tests
+      run: cmake --build build --target pytest
+
+
+  # Testing CentOS 8 + PGI compilers
+  centos-nvhpc8:
+    runs-on: ubuntu-latest
+    name: "🐍 3 • CentOS8 / PGI 20.7 • x64"
+    container: centos:8
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Add Python 3 and a few requirements
+      run: yum update -y && yum install -y git python3-devel python3-numpy python3-pytest make environment-modules
+
+    - name: Install CMake with pip
+      run: |
+        python3 -m pip install --upgrade pip
+        python3 -m pip install cmake --prefer-binary
+
+    - name: Install NVidia HPC SDK
+      run: yum -y install https://developer.download.nvidia.com/hpc-sdk/nvhpc-20-7-20.7-1.x86_64.rpm https://developer.download.nvidia.com/hpc-sdk/nvhpc-2020-20.7-1.x86_64.rpm
+
+    - name: Configure
+      shell: bash
+      run: |
+        source /etc/profile.d/modules.sh
+        module load /opt/nvidia/hpc_sdk/modulefiles/nvhpc/20.7
+        cmake -S . -B build -DDOWNLOAD_CATCH=ON -DCMAKE_CXX_STANDARD=14 -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)")
+
+    - name: Build
+      run: cmake --build build -j 2 --verbose
+
+    - name: Python tests
+      run: cmake --build build --target pytest
+
+    - name: C++ tests
+      run: cmake --build build --target cpptest
+
+    - name: Interface test
+      run: cmake --build build --target test_cmake_build
+
+
+  # Testing on CentOS 7 + PGI compilers, which seems to require more workarounds
+  centos-nvhpc7:
+    runs-on: ubuntu-latest
+    name: "🐍 3 • CentOS7 / PGI 20.7 • x64"
+    container: centos:7
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Add Python 3 and a few requirements
+      run: yum update -y && yum install -y epel-release && yum install -y git python3-devel make environment-modules cmake3
+
+    - name: Install NVidia HPC SDK
+      run:  yum -y install https://developer.download.nvidia.com/hpc-sdk/nvhpc-20-7-20.7-1.x86_64.rpm https://developer.download.nvidia.com/hpc-sdk/nvhpc-2020-20.7-1.x86_64.rpm
+
+    # On CentOS 7, we have to filter a few tests (compiler internal error)
+    # and allow deeper templete recursion (not needed on CentOS 8 with a newer
+    # standard library). On some systems, you many need further workarounds:
+    # https://github.com/pybind/pybind11/pull/2475
+    - name: Configure
+      shell: bash
+      run: |
+        source /etc/profile.d/modules.sh
+        module load /opt/nvidia/hpc_sdk/modulefiles/nvhpc/20.7
+        cmake3 -S . -B build -DDOWNLOAD_CATCH=ON \
+                            -DCMAKE_CXX_STANDARD=11 \
+                            -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)") \
+                            -DCMAKE_CXX_FLAGS="-Wc,--pending_instantiations=0" \
+                            -DPYBIND11_TEST_FILTER="test_smart_ptr.cpp;test_virtual_functions.cpp"
+
+    # Building before installing Pip should produce a warning but not an error
+    - name: Build
+      run: cmake3 --build build -j 2 --verbose
+
+    - name: Install CMake with pip
+      run: |
+        python3 -m pip install --upgrade pip
+        python3 -m pip install pytest
+
+    - name: Python tests
+      run: cmake3 --build build --target pytest
+
+    - name: C++ tests
+      run: cmake3 --build build --target cpptest
+
+    - name: Interface test
+      run: cmake3 --build build --target test_cmake_build
+
+  # Testing on GCC using the GCC docker images (only recent images supported)
+  gcc:
+    runs-on: ubuntu-latest
+    strategy:
+      fail-fast: false
+      matrix:
+        gcc:
+          - 7
+          - latest
+
+    name: "🐍 3 • GCC ${{ matrix.gcc }} • x64"
+    container: "gcc:${{ matrix.gcc }}"
+
+    steps:
+    - uses: actions/checkout@v1
+
+    - name: Add Python 3
+      run: apt-get update; apt-get install -y python3-dev python3-numpy python3-pytest python3-pip libeigen3-dev
+
+    - name: Update pip
+      run: python3 -m pip install --upgrade pip
+
+    - name: Setup CMake 3.18
+      uses: jwlawson/actions-setup-cmake@v1.3
+      with:
+        cmake-version: 3.18
+
+    - name: Configure
+      shell: bash
+      run: >
+        cmake -S . -B build
+        -DPYBIND11_WERROR=ON
+        -DDOWNLOAD_CATCH=ON
+        -DCMAKE_CXX_STANDARD=11
+        -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)")
+
+    - name: Build
+      run: cmake --build build -j 2
+
+    - name: Python tests
+      run: cmake --build build --target pytest
+
+    - name: C++ tests
+      run: cmake --build build --target cpptest
+
+    - name: Interface test
+      run: cmake --build build --target test_cmake_build
+
+
+  # Testing on CentOS (manylinux uses a centos base, and this is an easy way
+  # to get GCC 4.8, which is the manylinux1 compiler).
+  centos:
+    runs-on: ubuntu-latest
+    strategy:
+      fail-fast: false
+      matrix:
+        centos:
+          - 7  # GCC 4.8
+          - 8
+
+    name: "🐍 3 • CentOS ${{ matrix.centos }} • x64"
+    container: "centos:${{ matrix.centos }}"
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Add Python 3
+      run: yum update -y && yum install -y python3-devel gcc-c++ make git
+
+    - name: Update pip
+      run: python3 -m pip install --upgrade pip
+
+    - name: Install dependencies
+      run: python3 -m pip install cmake -r tests/requirements.txt --prefer-binary
+
+    - name: Configure
+      shell: bash
+      run: >
+        cmake -S . -B build
+        -DPYBIND11_WERROR=ON
+        -DDOWNLOAD_CATCH=ON
+        -DDOWNLOAD_EIGEN=ON
+        -DCMAKE_CXX_STANDARD=11
+        -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)")
+
+    - name: Build
+      run: cmake --build build -j 2
+
+    - name: Python tests
+      run: cmake --build build --target pytest
+
+    - name: C++ tests
+      run: cmake --build build --target cpptest
+
+    - name: Interface test
+      run: cmake --build build --target test_cmake_build
+
+
+  # This tests an "install" with the CMake tools
+  install-classic:
+    name: "🐍 3.5 • Debian • x86 •  Install"
+    runs-on: ubuntu-latest
+    container: i386/debian:stretch
+
+    steps:
+    - uses: actions/checkout@v1
+
+    - name: Install requirements
+      run: |
+        apt-get update
+        apt-get install -y git make cmake g++ libeigen3-dev python3-dev python3-pip
+        pip3 install "pytest==3.1.*"
+
+    - name: Configure for install
+      run: >
+        cmake .
+        -DPYBIND11_INSTALL=1 -DPYBIND11_TEST=0
+        -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)")
+
+    - name: Make and install
+      run: make install
+
+    - name: Copy tests to new directory
+      run: cp -a tests /pybind11-tests
+
+    - name: Make a new test directory
+      run: mkdir /build-tests
+
+    - name: Configure tests
+      run: >
+        cmake ../pybind11-tests
+        -DDOWNLOAD_CATCH=ON
+        -DPYBIND11_WERROR=ON
+        -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)")
+      working-directory: /build-tests
+
+    - name: Run tests
+      run: make pytest -j 2
+      working-directory: /build-tests
+
+
+  # This verifies that the documentation is not horribly broken, and does a
+  # basic sanity check on the SDist.
+  doxygen:
+    name: "Documentation build test"
+    runs-on: ubuntu-latest
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - uses: actions/setup-python@v2
+
+    - name: Install Doxygen
+      run: sudo apt install -y doxygen
+
+    - name: Install docs & setup requirements
+      run: python3 -m pip install -r docs/requirements.txt
+
+    - name: Build docs
+      run: python3 -m sphinx -W -b html docs docs/.build
+
+    - name: Make SDist
+      run: python3 setup.py sdist
+
+    - run: git status --ignored
+
+    - name: Check local include dir
+      run: >
+        ls pybind11;
+        python3 -c "import pybind11, pathlib; assert (a := pybind11.get_include()) == (b := str(pathlib.Path('include').resolve())), f'{a} != {b}'"
+
+    - name: Compare Dists (headers only)
+      working-directory: include
+      run: |
+        python3 -m pip install --user -U ../dist/*
+        installed=$(python3 -c "import pybind11; print(pybind11.get_include() + '/pybind11')")
+        diff -rq $installed ./pybind11
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/.github/workflows/configure.yml
@@ -0,0 +1,138 @@
+name: Config
+
+on:
+  workflow_dispatch:
+  pull_request:
+  push:
+    branches:
+      - master
+      - stable
+      - v*
+
+jobs:
+  # This tests various versions of CMake in various combinations, to make sure
+  # the configure step passes.
+  cmake:
+    strategy:
+      fail-fast: false
+      matrix:
+        runs-on: [ubuntu-latest, macos-latest, windows-latest]
+        arch: [x64]
+        cmake: [3.18]
+
+        include:
+        - runs-on: ubuntu-latest
+          arch: x64
+          cmake: 3.4
+
+        - runs-on: macos-latest
+          arch: x64
+          cmake: 3.7
+
+        - runs-on: windows-2016
+          arch: x86
+          cmake: 3.8
+
+        - runs-on: windows-2016
+          arch: x86
+          cmake: 3.18
+
+    name: 🐍 3.7 • CMake ${{ matrix.cmake }} • ${{ matrix.runs-on }}
+    runs-on: ${{ matrix.runs-on }}
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Setup Python 3.7
+      uses: actions/setup-python@v2
+      with:
+        python-version: 3.7
+        architecture: ${{ matrix.arch }}
+
+    - name: Prepare env
+      run: python -m pip install -r tests/requirements.txt
+
+    # An action for adding a specific version of CMake:
+    #   https://github.com/jwlawson/actions-setup-cmake
+    - name: Setup CMake ${{ matrix.cmake }}
+      uses: jwlawson/actions-setup-cmake@v1.3
+      with:
+        cmake-version: ${{ matrix.cmake }}
+
+    # These steps use a directory with a space in it intentionally
+    - name: Make build directories
+      run: mkdir "build dir"
+
+    - name: Configure
+      working-directory: build dir
+      shell: bash
+      run: >
+        cmake ..
+        -DPYBIND11_WERROR=ON
+        -DDOWNLOAD_CATCH=ON
+        -DPYTHON_EXECUTABLE=$(python -c "import sys; print(sys.executable)")
+
+    # Only build and test if this was manually triggered in the GitHub UI
+    - name: Build
+      working-directory: build dir
+      if: github.event_name == 'workflow_dispatch'
+      run: cmake --build . --config Release
+
+    - name: Test
+      working-directory: build dir
+      if: github.event_name == 'workflow_dispatch'
+      run: cmake --build . --config Release --target check
+
+  # This builds the sdists and wheels and makes sure the files are exactly as
+  # expected. Using Windows and Python 2.7, since that is often the most
+  # challenging matrix element.
+  test-packaging:
+    name: 🐍 2.7 • 📦 tests • windows-latest
+    runs-on: windows-latest
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Setup 🐍 2.7
+      uses: actions/setup-python@v2
+      with:
+        python-version: 2.7
+
+    - name: Prepare env
+      run: python -m pip install -r tests/requirements.txt --prefer-binary
+
+    - name: Python Packaging tests
+      run: pytest tests/extra_python_package/
+
+
+  # This runs the packaging tests and also builds and saves the packages as
+  # artifacts.
+  packaging:
+    name: 🐍 3.8 • 📦 & 📦 tests • ubuntu-latest
+    runs-on: ubuntu-latest
+
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Setup 🐍 3.8
+      uses: actions/setup-python@v2
+      with:
+        python-version: 3.8
+
+    - name: Prepare env
+      run: python -m pip install -r tests/requirements.txt build twine --prefer-binary
+
+    - name: Python Packaging tests
+      run: pytest tests/extra_python_package/
+
+    - name: Build SDist and wheels
+      run: |
+        python -m build -s -w .
+        PYBIND11_GLOBAL_SDIST=1 python -m build -s -w .
+
+    - name: Check metadata
+      run: twine check dist/*
+
+    - uses: actions/upload-artifact@v2
+      with:
+        path: dist/*
--- gtsam-4.1.0.orig/wrap/pybind11/.github/workflows/format.yml
+++ gtsam-4.1.0/wrap/pybind11/.github/workflows/format.yml
@@ -1,3 +1,6 @@
+# This is a format job. Pre-commit has a first-party GitHub action, so we use
+# that: https://github.com/pre-commit/action
+
 name: Format
 
 on:
@@ -17,3 +20,22 @@ jobs:
     - uses: actions/checkout@v2
     - uses: actions/setup-python@v2
     - uses: pre-commit/action@v2.0.0
+      with:
+        # Slow hooks are marked with manual - slow is okay here, run them too
+        extra_args: --hook-stage manual
+
+  clang-tidy:
+    name: Clang-Tidy
+    runs-on: ubuntu-latest
+    container: silkeh/clang:10
+    steps:
+    - uses: actions/checkout@v2
+
+    - name: Install requirements
+      run: apt-get update && apt-get install -y python3-dev python3-pytest
+
+    - name: Configure
+      run: cmake -S . -B build -DCMAKE_CXX_CLANG_TIDY="$(which clang-tidy);--warnings-as-errors=*"
+
+    - name: Build
+      run: cmake --build build -j 2
--- gtsam-4.1.0.orig/wrap/pybind11/.pre-commit-config.yaml
+++ gtsam-4.1.0/wrap/pybind11/.pre-commit-config.yaml
@@ -1,6 +1,21 @@
+# To use:
+#
+#     pre-commit run -a
+#
+# Or:
+#
+#     pre-commit install  # (runs every time you commit in git)
+#
+# To update this file:
+#
+#     pre-commit autoupdate
+#
+# See https://github.com/pre-commit/pre-commit
+
 repos:
+# Standard hooks
 - repo: https://github.com/pre-commit/pre-commit-hooks
-  rev: v3.1.0
+  rev: v3.2.0
   hooks:
   - id: check-added-large-files
   - id: check-case-conflict
@@ -14,15 +29,60 @@ repos:
   - id: trailing-whitespace
   - id: fix-encoding-pragma
 
+# Black, the code formatter, natively supports pre-commit
+- repo: https://github.com/psf/black
+  rev: 20.8b1
+  hooks:
+  - id: black
+    # Not all Python files are Blacked, yet
+    files: ^(setup.py|pybind11|tests/extra)
+
+# Changes tabs to spaces
 - repo: https://github.com/Lucas-C/pre-commit-hooks
-  rev: v1.1.7
+  rev: v1.1.9
   hooks:
   - id: remove-tabs
-    exclude: (Makefile|debian/rules|.gitmodules)(\.in)?$
 
+# Flake8 also supports pre-commit natively (same author)
 - repo: https://gitlab.com/pycqa/flake8
-  rev: 3.8.2
+  rev: 3.8.3
   hooks:
   - id: flake8
-    additional_dependencies: [flake8-bugbear]
+    additional_dependencies: [flake8-bugbear, pep8-naming]
     exclude: ^(docs/.*|tools/.*)$
+
+# CMake formatting
+- repo: https://github.com/cheshirekow/cmake-format-precommit
+  rev: v0.6.11
+  hooks:
+  - id: cmake-format
+    additional_dependencies: [pyyaml]
+    types: [file]
+    files: (\.cmake|CMakeLists.txt)(.in)?$
+
+# Checks the manifest for missing files (native support)
+- repo: https://github.com/mgedmin/check-manifest
+  rev: "0.42"
+  hooks:
+  - id: check-manifest
+    # This is a slow hook, so only run this if --hook-stage manual is passed
+    stages: [manual]
+    additional_dependencies: [cmake, ninja]
+
+# The original pybind11 checks for a few C++ style items
+- repo: local
+  hooks:
+  - id: disallow-caps
+    name: Disallow improper capitalization
+    language: pygrep
+    entry: PyBind|Numpy|Cmake
+    exclude: .pre-commit-config.yaml
+
+- repo: local
+  hooks:
+  - id: check-style
+    name: Classic check-style
+    language: system
+    types:
+    - c++
+    entry: ./tools/check-style.sh
--- gtsam-4.1.0.orig/wrap/pybind11/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/CMakeLists.txt
@@ -5,153 +5,263 @@
 # All rights reserved. Use of this source code is governed by a
 # BSD-style license that can be found in the LICENSE file.
 
-cmake_minimum_required(VERSION 2.8.12)
+cmake_minimum_required(VERSION 3.4)
 
-if (POLICY CMP0048)
-  # cmake warns if loaded from a min-3.0-required parent dir, so silence the warning:
-  cmake_policy(SET CMP0048 NEW)
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
 endif()
 
-# CMake versions < 3.4.0 do not support try_compile/pthread checks without C as active language.
-if(CMAKE_VERSION VERSION_LESS 3.4.0)
-  project(pybind11)
-else()
-  project(pybind11 CXX)
+# Extract project version from source
+file(STRINGS "${CMAKE_CURRENT_SOURCE_DIR}/include/pybind11/detail/common.h"
+     pybind11_version_defines REGEX "#define PYBIND11_VERSION_(MAJOR|MINOR|PATCH) ")
+
+foreach(ver ${pybind11_version_defines})
+  if(ver MATCHES [[#define PYBIND11_VERSION_(MAJOR|MINOR|PATCH) +([^ ]+)$]])
+    set(PYBIND11_VERSION_${CMAKE_MATCH_1} "${CMAKE_MATCH_2}")
+  endif()
+endforeach()
+
+if(PYBIND11_VERSION_PATCH MATCHES [[\.([a-zA-Z0-9]+)$]])
+  set(pybind11_VERSION_TYPE "${CMAKE_MATCH_1}")
+endif()
+string(REGEX MATCH "^[0-9]+" PYBIND11_VERSION_PATCH "${PYBIND11_VERSION_PATCH}")
+
+project(
+  pybind11
+  LANGUAGES CXX
+  VERSION "${PYBIND11_VERSION_MAJOR}.${PYBIND11_VERSION_MINOR}.${PYBIND11_VERSION_PATCH}")
+
+# Standard includes
+include(GNUInstallDirs)
+include(CMakePackageConfigHelpers)
+include(CMakeDependentOption)
+
+if(NOT pybind11_FIND_QUIETLY)
+  message(STATUS "pybind11 v${pybind11_VERSION} ${pybind11_VERSION_TYPE}")
 endif()
 
 # Check if pybind11 is being used directly or via add_subdirectory
-set(PYBIND11_MASTER_PROJECT OFF)
-if (CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_SOURCE_DIR)
+if(CMAKE_SOURCE_DIR STREQUAL PROJECT_SOURCE_DIR)
+  ### Warn if not an out-of-source builds
+  if(CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_CURRENT_BINARY_DIR)
+    set(lines
+        "You are building in-place. If that is not what you intended to "
+        "do, you can clean the source directory with:\n"
+        "rm -r CMakeCache.txt CMakeFiles/ cmake_uninstall.cmake pybind11Config.cmake "
+        "pybind11ConfigVersion.cmake tests/CMakeFiles/\n")
+    message(AUTHOR_WARNING ${lines})
+  endif()
+
   set(PYBIND11_MASTER_PROJECT ON)
+
+  if(OSX AND CMAKE_VERSION VERSION_LESS 3.7)
+    # Bug in macOS CMake < 3.7 is unable to download catch
+    message(WARNING "CMAKE 3.7+ needed on macOS to download catch, and newer HIGHLY recommended")
+  elseif(WINDOWS AND CMAKE_VERSION VERSION_LESS 3.8)
+    # Only tested with 3.8+ in CI.
+    message(WARNING "CMAKE 3.8+ tested on Windows, previous versions untested")
+  endif()
+
+  message(STATUS "CMake ${CMAKE_VERSION}")
+
+  if(CMAKE_CXX_STANDARD)
+    set(CMAKE_CXX_EXTENSIONS OFF)
+    set(CMAKE_CXX_STANDARD_REQUIRED ON)
+  endif()
+else()
+  set(PYBIND11_MASTER_PROJECT OFF)
+  set(pybind11_system SYSTEM)
 endif()
 
+# Options
 option(PYBIND11_INSTALL "Install pybind11 header files?" ${PYBIND11_MASTER_PROJECT})
-option(PYBIND11_TEST    "Build pybind11 test suite?"     ${PYBIND11_MASTER_PROJECT})
-
-list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_LIST_DIR}/tools")
+option(PYBIND11_TEST "Build pybind11 test suite?" ${PYBIND11_MASTER_PROJECT})
+option(PYBIND11_NOPYTHON "Disable search for Python" OFF)
 
-include(pybind11Tools)
+cmake_dependent_option(
+  USE_PYTHON_INCLUDE_DIR
+  "Install pybind11 headers in Python include directory instead of default installation prefix"
+  OFF "PYBIND11_INSTALL" OFF)
 
-# Cache variables so pybind11_add_module can be used in parent projects
-set(PYBIND11_INCLUDE_DIR "${CMAKE_CURRENT_LIST_DIR}/include" CACHE INTERNAL "")
-set(PYTHON_INCLUDE_DIRS ${PYTHON_INCLUDE_DIRS} CACHE INTERNAL "")
-set(PYTHON_LIBRARIES ${PYTHON_LIBRARIES} CACHE INTERNAL "")
-set(PYTHON_MODULE_PREFIX ${PYTHON_MODULE_PREFIX} CACHE INTERNAL "")
-set(PYTHON_MODULE_EXTENSION ${PYTHON_MODULE_EXTENSION} CACHE INTERNAL "")
-set(PYTHON_VERSION_MAJOR ${PYTHON_VERSION_MAJOR} CACHE INTERNAL "")
-set(PYTHON_VERSION_MINOR ${PYTHON_VERSION_MINOR} CACHE INTERNAL "")
+cmake_dependent_option(PYBIND11_FINDPYTHON "Force new FindPython" OFF
+                       "NOT CMAKE_VERSION VERSION_LESS 3.12" OFF)
 
 # NB: when adding a header don't forget to also add it to setup.py
 set(PYBIND11_HEADERS
-  include/pybind11/detail/class.h
-  include/pybind11/detail/common.h
-  include/pybind11/detail/descr.h
-  include/pybind11/detail/init.h
-  include/pybind11/detail/internals.h
-  include/pybind11/detail/typeid.h
-  include/pybind11/attr.h
-  include/pybind11/buffer_info.h
-  include/pybind11/cast.h
-  include/pybind11/chrono.h
-  include/pybind11/common.h
-  include/pybind11/complex.h
-  include/pybind11/options.h
-  include/pybind11/eigen.h
-  include/pybind11/embed.h
-  include/pybind11/eval.h
-  include/pybind11/functional.h
-  include/pybind11/numpy.h
-  include/pybind11/operators.h
-  include/pybind11/pybind11.h
-  include/pybind11/pytypes.h
-  include/pybind11/stl.h
-  include/pybind11/stl_bind.h
-)
-string(REPLACE "include/" "${CMAKE_CURRENT_SOURCE_DIR}/include/"
-       PYBIND11_HEADERS "${PYBIND11_HEADERS}")
-
-if (PYBIND11_TEST)
-  add_subdirectory(tests)
+    include/pybind11/detail/class.h
+    include/pybind11/detail/common.h
+    include/pybind11/detail/descr.h
+    include/pybind11/detail/init.h
+    include/pybind11/detail/internals.h
+    include/pybind11/detail/typeid.h
+    include/pybind11/attr.h
+    include/pybind11/buffer_info.h
+    include/pybind11/cast.h
+    include/pybind11/chrono.h
+    include/pybind11/common.h
+    include/pybind11/complex.h
+    include/pybind11/options.h
+    include/pybind11/eigen.h
+    include/pybind11/embed.h
+    include/pybind11/eval.h
+    include/pybind11/iostream.h
+    include/pybind11/functional.h
+    include/pybind11/numpy.h
+    include/pybind11/operators.h
+    include/pybind11/pybind11.h
+    include/pybind11/pytypes.h
+    include/pybind11/stl.h
+    include/pybind11/stl_bind.h)
+
+# Compare with grep and warn if mismatched
+if(PYBIND11_MASTER_PROJECT AND NOT CMAKE_VERSION VERSION_LESS 3.12)
+  file(
+    GLOB_RECURSE _pybind11_header_check
+    LIST_DIRECTORIES false
+    RELATIVE "${CMAKE_CURRENT_SOURCE_DIR}"
+    CONFIGURE_DEPENDS "include/pybind11/*.h")
+  set(_pybind11_here_only ${PYBIND11_HEADERS})
+  set(_pybind11_disk_only ${_pybind11_header_check})
+  list(REMOVE_ITEM _pybind11_here_only ${_pybind11_header_check})
+  list(REMOVE_ITEM _pybind11_disk_only ${PYBIND11_HEADERS})
+  if(_pybind11_here_only)
+    message(AUTHOR_WARNING "PYBIND11_HEADERS has extra files:" ${_pybind11_here_only})
+  endif()
+  if(_pybind11_disk_only)
+    message(AUTHOR_WARNING "PYBIND11_HEADERS is missing files:" ${_pybind11_disk_only})
+  endif()
 endif()
 
-include(GNUInstallDirs)
-include(CMakePackageConfigHelpers)
-
-# extract project version from source
-file(STRINGS "${PYBIND11_INCLUDE_DIR}/pybind11/detail/common.h" pybind11_version_defines
-     REGEX "#define PYBIND11_VERSION_(MAJOR|MINOR|PATCH) ")
-foreach(ver ${pybind11_version_defines})
-  if (ver MATCHES "#define PYBIND11_VERSION_(MAJOR|MINOR|PATCH) +([^ ]+)$")
-    set(PYBIND11_VERSION_${CMAKE_MATCH_1} "${CMAKE_MATCH_2}" CACHE INTERNAL "")
-  endif()
-endforeach()
-set(${PROJECT_NAME}_VERSION ${PYBIND11_VERSION_MAJOR}.${PYBIND11_VERSION_MINOR}.${PYBIND11_VERSION_PATCH})
-message(STATUS "pybind11 v${${PROJECT_NAME}_VERSION}")
+# CMake 3.12 added list(TRANSFORM <list> PREPEND
+# But we can't use it yet
+string(REPLACE "include/" "${CMAKE_CURRENT_SOURCE_DIR}/include/" PYBIND11_HEADERS
+               "${PYBIND11_HEADERS}")
 
-option (USE_PYTHON_INCLUDE_DIR "Install pybind11 headers in Python include directory instead of default installation prefix" OFF)
-if (USE_PYTHON_INCLUDE_DIR)
-    file(RELATIVE_PATH CMAKE_INSTALL_INCLUDEDIR ${CMAKE_INSTALL_PREFIX} ${PYTHON_INCLUDE_DIRS})
+# Cache variables so pybind11_add_module can be used in parent projects
+set(PYBIND11_INCLUDE_DIR
+    "${CMAKE_CURRENT_LIST_DIR}/include"
+    CACHE INTERNAL "")
+
+# Note: when creating targets, you cannot use if statements at configure time -
+# you need generator expressions, because those will be placed in the target file.
+# You can also place ifs *in* the Config.in, but not here.
+
+# This section builds targets, but does *not* touch Python
+
+# Build the headers-only target (no Python included):
+# (long name used here to keep this from clashing in subdirectory mode)
+add_library(pybind11_headers INTERFACE)
+add_library(pybind11::pybind11_headers ALIAS pybind11_headers) # to match exported target
+add_library(pybind11::headers ALIAS pybind11_headers) # easier to use/remember
+
+include("${CMAKE_CURRENT_SOURCE_DIR}/tools/pybind11Common.cmake")
+
+# Relative directory setting
+if(USE_PYTHON_INCLUDE_DIR AND DEFINED Python_INCLUDE_DIRS)
+  file(RELATIVE_PATH CMAKE_INSTALL_INCLUDEDIR ${CMAKE_INSTALL_PREFIX} ${Python_INCLUDE_DIRS})
+elseif(USE_PYTHON_INCLUDE_DIR AND DEFINED PYTHON_INCLUDE_DIR)
+  file(RELATIVE_PATH CMAKE_INSTALL_INCLUDEDIR ${CMAKE_INSTALL_PREFIX} ${PYTHON_INCLUDE_DIRS})
 endif()
 
-if(NOT (CMAKE_VERSION VERSION_LESS 3.0))  # CMake >= 3.0
-  # Build an interface library target:
-  add_library(pybind11 INTERFACE)
-  add_library(pybind11::pybind11 ALIAS pybind11)  # to match exported target
-  target_include_directories(pybind11 INTERFACE $<BUILD_INTERFACE:${PYBIND11_INCLUDE_DIR}>
-                                                $<BUILD_INTERFACE:${PYTHON_INCLUDE_DIRS}>
+# Fill in headers target
+target_include_directories(
+  pybind11_headers ${pybind11_system} INTERFACE $<BUILD_INTERFACE:${PYBIND11_INCLUDE_DIR}>
                                                 $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>)
-  target_compile_options(pybind11 INTERFACE $<BUILD_INTERFACE:${PYBIND11_CPP_STANDARD}>)
 
-  add_library(module INTERFACE)
-  add_library(pybind11::module ALIAS module)
-  if(NOT MSVC)
-    target_compile_options(module INTERFACE -fvisibility=hidden)
+target_compile_features(pybind11_headers INTERFACE cxx_inheriting_constructors cxx_user_literals
+                                                   cxx_right_angle_brackets)
+
+if(PYBIND11_INSTALL)
+  install(DIRECTORY ${PYBIND11_INCLUDE_DIR}/pybind11 DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})
+  # GNUInstallDirs "DATADIR" wrong here; CMake search path wants "share".
+  set(PYBIND11_CMAKECONFIG_INSTALL_DIR
+      "share/cmake/${PROJECT_NAME}"
+      CACHE STRING "install path for pybind11Config.cmake")
+
+  configure_package_config_file(
+    tools/${PROJECT_NAME}Config.cmake.in "${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}Config.cmake"
+    INSTALL_DESTINATION ${PYBIND11_CMAKECONFIG_INSTALL_DIR})
+
+  if(CMAKE_VERSION VERSION_LESS 3.14)
+    # Remove CMAKE_SIZEOF_VOID_P from ConfigVersion.cmake since the library does
+    # not depend on architecture specific settings or libraries.
+    set(_PYBIND11_CMAKE_SIZEOF_VOID_P ${CMAKE_SIZEOF_VOID_P})
+    unset(CMAKE_SIZEOF_VOID_P)
+
+    write_basic_package_version_file(
+      ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}ConfigVersion.cmake
+      VERSION ${PROJECT_VERSION}
+      COMPATIBILITY AnyNewerVersion)
+
+    set(CMAKE_SIZEOF_VOID_P ${_PYBIND11_CMAKE_SIZEOF_VOID_P})
+  else()
+    # CMake 3.14+ natively supports header-only libraries
+    write_basic_package_version_file(
+      ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}ConfigVersion.cmake
+      VERSION ${PROJECT_VERSION}
+      COMPATIBILITY AnyNewerVersion ARCH_INDEPENDENT)
   endif()
-  target_link_libraries(module INTERFACE pybind11::pybind11)
-  if(WIN32 OR CYGWIN)
-    target_link_libraries(module INTERFACE $<BUILD_INTERFACE:${PYTHON_LIBRARIES}>)
-  elseif(APPLE)
-    target_link_libraries(module INTERFACE "-undefined dynamic_lookup")
+
+  install(
+    FILES ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}Config.cmake
+          ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}ConfigVersion.cmake
+          tools/FindPythonLibsNew.cmake
+          tools/pybind11Common.cmake
+          tools/pybind11Tools.cmake
+          tools/pybind11NewTools.cmake
+    DESTINATION ${PYBIND11_CMAKECONFIG_INSTALL_DIR})
+
+  if(NOT PYBIND11_EXPORT_NAME)
+    set(PYBIND11_EXPORT_NAME "${PROJECT_NAME}Targets")
   endif()
 
-  add_library(embed INTERFACE)
-  add_library(pybind11::embed ALIAS embed)
-  target_link_libraries(embed INTERFACE pybind11::pybind11 $<BUILD_INTERFACE:${PYTHON_LIBRARIES}>)
-endif()
+  install(TARGETS pybind11_headers EXPORT "${PYBIND11_EXPORT_NAME}")
 
-if (PYBIND11_INSTALL)
-  install(DIRECTORY ${PYBIND11_INCLUDE_DIR}/pybind11 DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})
-  # GNUInstallDirs "DATADIR" wrong here; CMake search path wants "share".
-  set(PYBIND11_CMAKECONFIG_INSTALL_DIR "share/cmake/${PROJECT_NAME}" CACHE STRING "install path for pybind11Config.cmake")
+  install(
+    EXPORT "${PYBIND11_EXPORT_NAME}"
+    NAMESPACE "pybind11::"
+    DESTINATION ${PYBIND11_CMAKECONFIG_INSTALL_DIR})
+
+  # Uninstall target
+  if(PYBIND11_MASTER_PROJECT)
+    configure_file("${CMAKE_CURRENT_SOURCE_DIR}/tools/cmake_uninstall.cmake.in"
+                   "${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake" IMMEDIATE @ONLY)
 
-  configure_package_config_file(tools/${PROJECT_NAME}Config.cmake.in
-                                "${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}Config.cmake"
-                                INSTALL_DESTINATION ${PYBIND11_CMAKECONFIG_INSTALL_DIR})
-  # Remove CMAKE_SIZEOF_VOID_P from ConfigVersion.cmake since the library does
-  # not depend on architecture specific settings or libraries.
-  set(_PYBIND11_CMAKE_SIZEOF_VOID_P ${CMAKE_SIZEOF_VOID_P})
-  unset(CMAKE_SIZEOF_VOID_P)
-  write_basic_package_version_file(${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}ConfigVersion.cmake
-                                   VERSION ${${PROJECT_NAME}_VERSION}
-                                   COMPATIBILITY AnyNewerVersion)
-  set(CMAKE_SIZEOF_VOID_P ${_PYBIND11_CMAKE_SIZEOF_VOID_P})
-  install(FILES ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}Config.cmake
-                ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}ConfigVersion.cmake
-                tools/FindPythonLibsNew.cmake
-                tools/pybind11Tools.cmake
-          DESTINATION ${PYBIND11_CMAKECONFIG_INSTALL_DIR})
-
-  if(NOT (CMAKE_VERSION VERSION_LESS 3.0))
-    if(NOT PYBIND11_EXPORT_NAME)
-      set(PYBIND11_EXPORT_NAME "${PROJECT_NAME}Targets")
-    endif()
+    add_custom_target(uninstall COMMAND ${CMAKE_COMMAND} -P
+                                        ${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake)
+  endif()
+endif()
 
-    install(TARGETS pybind11 module embed
-            EXPORT "${PYBIND11_EXPORT_NAME}")
-    if(PYBIND11_MASTER_PROJECT)
-      install(EXPORT "${PYBIND11_EXPORT_NAME}"
-              NAMESPACE "${PROJECT_NAME}::"
-              DESTINATION ${PYBIND11_CMAKECONFIG_INSTALL_DIR})
+# BUILD_TESTING takes priority, but only if this is the master project
+if(PYBIND11_MASTER_PROJECT AND DEFINED BUILD_TESTING)
+  if(BUILD_TESTING)
+    if(_pybind11_nopython)
+      message(FATAL_ERROR "Cannot activate tests in NOPYTHON mode")
+    else()
+      add_subdirectory(tests)
+    endif()
+  endif()
+else()
+  if(PYBIND11_TEST)
+    if(_pybind11_nopython)
+      message(FATAL_ERROR "Cannot activate tests in NOPYTHON mode")
+    else()
+      add_subdirectory(tests)
     endif()
   endif()
 endif()
+
+# Better symmetry with find_package(pybind11 CONFIG) mode.
+if(NOT PYBIND11_MASTER_PROJECT)
+  set(pybind11_FOUND
+      TRUE
+      CACHE INTERNAL "true if pybind11 and all required components found on the system")
+  set(pybind11_INCLUDE_DIR
+      "${PYBIND11_INCLUDE_DIR}"
+      CACHE INTERNAL "Directory where pybind11 headers are located")
+endif()
--- gtsam-4.1.0.orig/wrap/pybind11/LICENSE
+++ gtsam-4.1.0/wrap/pybind11/LICENSE
@@ -25,5 +25,5 @@ CAUSED AND ON ANY THEORY OF LIABILITY, W
 OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
-Please also refer to the file CONTRIBUTING.md, which clarifies licensing of
+Please also refer to the file .github/CONTRIBUTING.md, which clarifies licensing of
 external contributions to this project including patches, pull requests, etc.
--- gtsam-4.1.0.orig/wrap/pybind11/MANIFEST.in
+++ gtsam-4.1.0/wrap/pybind11/MANIFEST.in
@@ -1,2 +1,4 @@
-recursive-include include/pybind11 *.h
-include LICENSE README.md CONTRIBUTING.md
+recursive-include pybind11/include/pybind11 *.h
+recursive-include pybind11 *.py
+include pybind11/share/cmake/pybind11/*.cmake
+include LICENSE README.md pyproject.toml setup.py setup.cfg
--- gtsam-4.1.0.orig/wrap/pybind11/README.md
+++ gtsam-4.1.0/wrap/pybind11/README.md
@@ -5,15 +5,14 @@
 [![Documentation Status](https://readthedocs.org/projects/pybind11/badge/?version=master)](http://pybind11.readthedocs.org/en/master/?badge=master)
 [![Documentation Status](https://readthedocs.org/projects/pybind11/badge/?version=stable)](http://pybind11.readthedocs.org/en/stable/?badge=stable)
 [![Gitter chat](https://img.shields.io/gitter/room/gitterHQ/gitter.svg)](https://gitter.im/pybind/Lobby)
-[![Build Status](https://travis-ci.org/pybind/pybind11.svg?branch=master)](https://travis-ci.org/pybind/pybind11)
+[![CI](https://github.com/pybind/pybind11/workflows/CI/badge.svg)](https://github.com/pybind/pybind11/actions)
 [![Build status](https://ci.appveyor.com/api/projects/status/riaj54pn4h08xy40?svg=true)](https://ci.appveyor.com/project/wjakob/pybind11)
 
-**pybind11** is a lightweight header-only library that exposes C++ types in Python
-and vice versa, mainly to create Python bindings of existing C++ code. Its
-goals and syntax are similar to the excellent
-[Boost.Python](http://www.boost.org/doc/libs/1_58_0/libs/python/doc/) library
-by David Abrahams: to minimize boilerplate code in traditional extension
-modules by inferring type information using compile-time introspection.
+**pybind11** is a lightweight header-only library that exposes C++ types in
+Python and vice versa, mainly to create Python bindings of existing C++ code.
+Its goals and syntax are similar to the excellent [Boost.Python][] library by
+David Abrahams: to minimize boilerplate code in traditional extension modules
+by inferring type information using compile-time introspection.
 
 The main issue with Boost.Python—and the reason for creating such a similar
 project—is Boost. Boost is an enormously large and complex suite of utility
@@ -26,19 +25,18 @@ become an excessively large and unnecess
 Think of this library as a tiny self-contained version of Boost.Python with
 everything stripped away that isn't relevant for binding generation. Without
 comments, the core header files only require ~4K lines of code and depend on
-Python (2.7 or 3.x, or PyPy2.7 >= 5.7) and the C++ standard library. This
-compact implementation was possible thanks to some of the new C++11 language
-features (specifically: tuples, lambda functions and variadic templates). Since
-its creation, this library has grown beyond Boost.Python in many ways, leading
-to dramatically simpler binding code in many common situations.
+Python (2.7 or 3.5+, or PyPy) and the C++ standard library. This compact
+implementation was possible thanks to some of the new C++11 language features
+(specifically: tuples, lambda functions and variadic templates). Since its
+creation, this library has grown beyond Boost.Python in many ways, leading to
+dramatically simpler binding code in many common situations.
 
 Tutorial and reference documentation is provided at
-[http://pybind11.readthedocs.org/en/master](http://pybind11.readthedocs.org/en/master).
-A PDF version of the manual is available
-[here](https://media.readthedocs.org/pdf/pybind11/master/pybind11.pdf).
+[pybind11.readthedocs.org][].  A PDF version of the manual is available
+[here][docs-pdf].
 
 ## Core features
-pybind11 can map the following core C++ features to Python
+pybind11 can map the following core C++ features to Python:
 
 - Functions accepting and returning custom data structures per value, reference, or pointer
 - Instance methods and static methods
@@ -51,15 +49,15 @@ pybind11 can map the following core C++
 - Custom operators
 - Single and multiple inheritance
 - STL data structures
-- Smart pointers with reference counting like ``std::shared_ptr``
+- Smart pointers with reference counting like `std::shared_ptr`
 - Internal references with correct reference counting
 - C++ classes with virtual (and pure virtual) methods can be extended in Python
 
 ## Goodies
 In addition to the core functionality, pybind11 provides some extra goodies:
 
-- Python 2.7, 3.x, and PyPy (PyPy2.7 >= 5.7) are supported with an
-  implementation-agnostic interface.
+- Python 2.7, 3.5+, and PyPy (tested on 7.3) are supported with an implementation-agnostic
+  interface.
 
 - It is possible to bind C++11 lambda functions with captured variables. The
   lambda capture data is stored inside the resulting Python function object.
@@ -83,10 +81,10 @@ In addition to the core functionality, p
 - Binaries are generally smaller by a factor of at least 2 compared to
   equivalent bindings generated by Boost.Python. A recent pybind11 conversion
   of PyRosetta, an enormous Boost.Python binding project,
-  [reported](http://graylab.jhu.edu/RosettaCon2016/PyRosetta-4.pdf) a binary
-  size reduction of **5.4x** and compile time reduction by **5.8x**.
+  [reported][pyrosetta-report] a binary size reduction of **5.4x** and compile
+  time reduction by **5.8x**.
 
-- Function signatures are precomputed at compile time (using ``constexpr``),
+- Function signatures are precomputed at compile time (using `constexpr`),
   leading to smaller binaries.
 
 - With little extra effort, C++ types can be pickled and unpickled similar to
@@ -97,8 +95,11 @@ In addition to the core functionality, p
 1. Clang/LLVM 3.3 or newer (for Apple Xcode's clang, this is 5.0.0 or newer)
 2. GCC 4.8 or newer
 3. Microsoft Visual Studio 2015 Update 3 or newer
-4. Intel C++ compiler 17 or newer (16 with pybind11 v2.0 and 15 with pybind11 v2.0 and a [workaround](https://github.com/pybind/pybind11/issues/276))
+4. Intel C++ compiler 17 or newer (16 with pybind11 v2.0 and 15 with pybind11
+   v2.0 and a [workaround][intel-15-workaround])
 5. Cygwin/GCC (tested on 2.5.1)
+6. NVCC (CUDA 11 tested)
+7. NVIDIA PGI (20.7 tested)
 
 ## About
 
@@ -122,8 +123,23 @@ Henry Schreiner,
 Ivan Smirnov, and
 Patrick Stewart.
 
+### Contributing
+
+See the [contributing guide][] for information on building and contributing to
+pybind11.
+
+
 ### License
 
 pybind11 is provided under a BSD-style license that can be found in the
-``LICENSE`` file. By using, distributing, or contributing to this project,
+[`LICENSE`][] file. By using, distributing, or contributing to this project,
 you agree to the terms and conditions of this license.
+
+
+[pybind11.readthedocs.org]: http://pybind11.readthedocs.org/en/master
+[docs-pdf]: https://media.readthedocs.org/pdf/pybind11/master/pybind11.pdf
+[Boost.Python]: http://www.boost.org/doc/libs/1_58_0/libs/python/doc/
+[pyrosetta-report]: http://graylab.jhu.edu/RosettaCon2016/PyRosetta-4.pdf
+[contributing guide]:  https://github.com/pybind/pybind11/blob/master/.github/CONTRIBUTING.md
+[`LICENSE`]: https://github.com/pybind/pybind11/blob/master/LICENSE
+[intel-15-workaround]: https://github.com/pybind/pybind11/issues/276
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/cast/custom.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/cast/custom.rst
@@ -29,9 +29,9 @@ The following Python snippet demonstrate
     from example import print
     print(A())
 
-To register the necessary conversion routines, it is necessary to add
-a partial overload to the ``pybind11::detail::type_caster<T>`` template.
-Although this is an implementation detail, adding partial overloads to this
+To register the necessary conversion routines, it is necessary to add an
+instantiation of the ``pybind11::detail::type_caster<T>`` template.
+Although this is an implementation detail, adding an instantiation of this
 type is explicitly allowed.
 
 .. code-block:: cpp
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/cast/eigen.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/cast/eigen.rst
@@ -274,7 +274,7 @@ Vectors versus column/row matrices
 
 Eigen and numpy have fundamentally different notions of a vector.  In Eigen, a
 vector is simply a matrix with the number of columns or rows set to 1 at
-compile time (for a column vector or row vector, respectively).  Numpy, in
+compile time (for a column vector or row vector, respectively).  NumPy, in
 contrast, has comparable 2-dimensional 1xN and Nx1 arrays, but *also* has
 1-dimensional arrays of size N.
 
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/cast/index.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/cast/index.rst
@@ -1,3 +1,5 @@
+.. _type-conversions:
+
 Type conversions
 ################
 
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/cast/stl.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/cast/stl.rst
@@ -157,7 +157,7 @@ the declaration
 
 before any binding code (e.g. invocations to ``class_::def()``, etc.). This
 macro must be specified at the top level (and outside of any namespaces), since
-it instantiates a partial template overload. If your binding code consists of
+it adds a template instantiation of ``type_caster``. If your binding code consists of
 multiple compilation units, it must be present in every file (typically via a
 common header) preceding any usage of ``std::vector<int>``. Opaque types must
 also have a corresponding ``class_`` declaration to associate them with a name
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/classes.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/classes.rst
@@ -71,7 +71,7 @@ helper class that is defined as follows:
 
         /* Trampoline (need one for each virtual function) */
         std::string go(int n_times) override {
-            PYBIND11_OVERLOAD_PURE(
+            PYBIND11_OVERRIDE_PURE(
                 std::string, /* Return type */
                 Animal,      /* Parent class */
                 go,          /* Name of function in C++ (must match Python name) */
@@ -80,10 +80,10 @@ helper class that is defined as follows:
         }
     };
 
-The macro :c:macro:`PYBIND11_OVERLOAD_PURE` should be used for pure virtual
-functions, and :c:macro:`PYBIND11_OVERLOAD` should be used for functions which have
+The macro :c:macro:`PYBIND11_OVERRIDE_PURE` should be used for pure virtual
+functions, and :c:macro:`PYBIND11_OVERRIDE` should be used for functions which have
 a default implementation.  There are also two alternate macros
-:c:macro:`PYBIND11_OVERLOAD_PURE_NAME` and :c:macro:`PYBIND11_OVERLOAD_NAME` which
+:c:macro:`PYBIND11_OVERRIDE_PURE_NAME` and :c:macro:`PYBIND11_OVERRIDE_NAME` which
 take a string-valued name argument between the *Parent class* and *Name of the
 function* slots, which defines the name of function in Python. This is required
 when the C++ and Python versions of the
@@ -122,7 +122,7 @@ Bindings should be made against the actu
 
 Note, however, that the above is sufficient for allowing python classes to
 extend ``Animal``, but not ``Dog``: see :ref:`virtual_and_inheritance` for the
-necessary steps required to providing proper overload support for inherited
+necessary steps required to providing proper overriding support for inherited
 classes.
 
 The Python session below shows how to override ``Animal::go`` and invoke it via
@@ -149,8 +149,7 @@ memory for the C++ portion of the instan
 will generally leave the C++ instance in an invalid state and cause undefined
 behavior if the C++ instance is subsequently used.
 
-.. versionadded:: 2.5.1
-
+.. versionchanged:: 2.6
    The default pybind11 metaclass will throw a ``TypeError`` when it detects
    that ``__init__`` was not called by a derived class.
 
@@ -160,7 +159,7 @@ Here is an example:
 
     class Dachshund(Dog):
         def __init__(self, name):
-            Dog.__init__(self) # Without this, undefined behavior may occur if the C++ portions are referenced.
+            Dog.__init__(self) # Without this, a TypeError is raised.
             self.name = name
         def bark(self):
             return "yap!"
@@ -182,15 +181,24 @@ Please take a look at the :ref:`macro_no
 
     - because in these cases there is no C++ variable to reference (the value
       is stored in the referenced Python variable), pybind11 provides one in
-      the PYBIND11_OVERLOAD macros (when needed) with static storage duration.
-      Note that this means that invoking the overloaded method on *any*
+      the PYBIND11_OVERRIDE macros (when needed) with static storage duration.
+      Note that this means that invoking the overridden method on *any*
       instance will change the referenced value stored in *all* instances of
       that type.
 
     - Attempts to modify a non-const reference will not have the desired
       effect: it will change only the static cache variable, but this change
       will not propagate to underlying Python instance, and the change will be
-      replaced the next time the overload is invoked.
+      replaced the next time the override is invoked.
+
+.. warning::
+
+    The :c:macro:`PYBIND11_OVERRIDE` and accompanying macros used to be called
+    ``PYBIND11_OVERLOAD`` up until pybind11 v2.5.0, and :func:`get_override`
+    used to be called ``get_overload``. This naming was corrected and the older
+    macro and function names may soon be deprecated, in order to reduce
+    confusion with overloaded functions and methods and ``py::overload_cast``
+    (see :ref:`classes`).
 
 .. seealso::
 
@@ -238,20 +246,20 @@ override the ``name()`` method):
     class PyAnimal : public Animal {
     public:
         using Animal::Animal; // Inherit constructors
-        std::string go(int n_times) override { PYBIND11_OVERLOAD_PURE(std::string, Animal, go, n_times); }
-        std::string name() override { PYBIND11_OVERLOAD(std::string, Animal, name, ); }
+        std::string go(int n_times) override { PYBIND11_OVERRIDE_PURE(std::string, Animal, go, n_times); }
+        std::string name() override { PYBIND11_OVERRIDE(std::string, Animal, name, ); }
     };
     class PyDog : public Dog {
     public:
         using Dog::Dog; // Inherit constructors
-        std::string go(int n_times) override { PYBIND11_OVERLOAD(std::string, Dog, go, n_times); }
-        std::string name() override { PYBIND11_OVERLOAD(std::string, Dog, name, ); }
-        std::string bark() override { PYBIND11_OVERLOAD(std::string, Dog, bark, ); }
+        std::string go(int n_times) override { PYBIND11_OVERRIDE(std::string, Dog, go, n_times); }
+        std::string name() override { PYBIND11_OVERRIDE(std::string, Dog, name, ); }
+        std::string bark() override { PYBIND11_OVERRIDE(std::string, Dog, bark, ); }
     };
 
 .. note::
 
-    Note the trailing commas in the ``PYBIND11_OVERLOAD`` calls to ``name()``
+    Note the trailing commas in the ``PYBIND11_OVERIDE`` calls to ``name()``
     and ``bark()``. These are needed to portably implement a trampoline for a
     function that does not take any arguments. For functions that take
     a nonzero number of arguments, the trailing comma must be omitted.
@@ -266,9 +274,9 @@ declare or override any virtual methods
     class PyHusky : public Husky {
     public:
         using Husky::Husky; // Inherit constructors
-        std::string go(int n_times) override { PYBIND11_OVERLOAD_PURE(std::string, Husky, go, n_times); }
-        std::string name() override { PYBIND11_OVERLOAD(std::string, Husky, name, ); }
-        std::string bark() override { PYBIND11_OVERLOAD(std::string, Husky, bark, ); }
+        std::string go(int n_times) override { PYBIND11_OVERRIDE_PURE(std::string, Husky, go, n_times); }
+        std::string name() override { PYBIND11_OVERRIDE(std::string, Husky, name, ); }
+        std::string bark() override { PYBIND11_OVERRIDE(std::string, Husky, bark, ); }
     };
 
 There is, however, a technique that can be used to avoid this duplication
@@ -281,15 +289,15 @@ follows:
     template <class AnimalBase = Animal> class PyAnimal : public AnimalBase {
     public:
         using AnimalBase::AnimalBase; // Inherit constructors
-        std::string go(int n_times) override { PYBIND11_OVERLOAD_PURE(std::string, AnimalBase, go, n_times); }
-        std::string name() override { PYBIND11_OVERLOAD(std::string, AnimalBase, name, ); }
+        std::string go(int n_times) override { PYBIND11_OVERRIDE_PURE(std::string, AnimalBase, go, n_times); }
+        std::string name() override { PYBIND11_OVERRIDE(std::string, AnimalBase, name, ); }
     };
     template <class DogBase = Dog> class PyDog : public PyAnimal<DogBase> {
     public:
         using PyAnimal<DogBase>::PyAnimal; // Inherit constructors
         // Override PyAnimal's pure virtual go() with a non-pure one:
-        std::string go(int n_times) override { PYBIND11_OVERLOAD(std::string, DogBase, go, n_times); }
-        std::string bark() override { PYBIND11_OVERLOAD(std::string, DogBase, bark, ); }
+        std::string go(int n_times) override { PYBIND11_OVERRIDE(std::string, DogBase, go, n_times); }
+        std::string bark() override { PYBIND11_OVERRIDE(std::string, DogBase, bark, ); }
     };
 
 This technique has the advantage of requiring just one trampoline method to be
@@ -342,7 +350,7 @@ valid for the trampoline class but not t
 for performance reasons: when the trampoline class is not needed for anything
 except virtual method dispatching, not initializing the trampoline class
 improves performance by avoiding needing to do a run-time check to see if the
-inheriting python instance has an overloaded method.
+inheriting python instance has an overridden method.
 
 Sometimes, however, it is useful to always initialize a trampoline class as an
 intermediate class that does more than just handle virtual method dispatching.
@@ -373,7 +381,7 @@ references (See also :ref:`faq_reference
 this is to use the method body of the trampoline class to do conversions to the
 input and return of the Python method.
 
-The main building block to do so is the :func:`get_overload`, this function
+The main building block to do so is the :func:`get_override`, this function
 allows retrieving a method implemented in Python from within the trampoline's
 methods. Consider for example a C++ method which has the signature
 ``bool myMethod(int32_t& value)``, where the return indicates whether
@@ -385,10 +393,10 @@ Python side by allowing the Python funct
     bool MyClass::myMethod(int32_t& value)
     {
         pybind11::gil_scoped_acquire gil;  // Acquire the GIL while in this scope.
-        // Try to look up the overloaded method on the Python side.
-        pybind11::function overload = pybind11::get_overload(this, "myMethod");
-        if (overload) {  // method is found
-            auto obj = overload(value);  // Call the Python function.
+        // Try to look up the overridden method on the Python side.
+        pybind11::function override = pybind11::get_override(this, "myMethod");
+        if (override) {  // method is found
+            auto obj = override(value);  // Call the Python function.
             if (py::isinstance<py::int_>(obj)) {  // check if it returned a Python integer type
                 value = obj.cast<int32_t>();  // Cast it and assign it to the value.
                 return true;  // Return true; value should be used.
@@ -559,6 +567,46 @@ crucial that instances are deallocated o
     py::class_<MyClass, std::unique_ptr<MyClass, py::nodelete>>(m, "MyClass")
         .def(py::init<>())
 
+.. _destructors_that_call_python:
+
+Destructors that call Python
+============================
+
+If a Python function is invoked from a C++ destructor, an exception may be thrown
+of type :class:`error_already_set`. If this error is thrown out of a class destructor,
+``std::terminate()`` will be called, terminating the process. Class destructors
+must catch all exceptions of type :class:`error_already_set` to discard the Python
+exception using :func:`error_already_set::discard_as_unraisable`.
+
+Every Python function should be treated as *possibly throwing*. When a Python generator
+stops yielding items, Python will throw a ``StopIteration`` exception, which can pass
+though C++ destructors if the generator's stack frame holds the last reference to C++
+objects.
+
+For more information, see :ref:`the documentation on exceptions <unraisable_exceptions>`.
+
+.. code-block:: cpp
+
+    class MyClass {
+    public:
+        ~MyClass() {
+            try {
+                py::print("Even printing is dangerous in a destructor");
+                py::exec("raise ValueError('This is an unraisable exception')");
+            } catch (py::error_already_set &e) {
+                // error_context should be information about where/why the occurred,
+                // e.g. use __func__ to get the name of the current function
+                e.discard_as_unraisable(__func__);
+            }
+        }
+    };
+
+.. note::
+
+    pybind11 does not support C++ destructors marked ``noexcept(false)``.
+
+.. versionadded:: 2.6
+
 .. _implicit_conversions:
 
 Implicit conversions
@@ -1065,7 +1113,7 @@ described trampoline:
 
     class Trampoline : public A {
     public:
-        int foo() const override { PYBIND11_OVERLOAD(int, A, foo, ); }
+        int foo() const override { PYBIND11_OVERRIDE(int, A, foo, ); }
     };
 
     class Publicist : public A {
@@ -1109,6 +1157,8 @@ error:
 
 .. note:: This attribute is currently ignored on PyPy
 
+.. versionadded:: 2.6
+
 Custom automatic downcasters
 ============================
 
@@ -1191,3 +1241,21 @@ appropriate derived-class pointer (e.g.
     more complete example, including a demonstration of how to provide
     automatic downcasting for an entire class hierarchy without
     writing one get() function for each class.
+
+Accessing the type object
+=========================
+
+You can get the type object from a C++ class that has already been registered using:
+
+.. code-block:: python
+
+    py::type T_py = py::type::of<T>();
+
+You can directly use ``py::type::of(ob)`` to get the type object from any python
+object, just like ``type(ob)`` in Python.
+
+.. note::
+
+    Other types, like ``py::type::of<int>()``, do not work, see :ref:`type-conversions`.
+
+.. versionadded:: 2.6
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/embedding.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/embedding.rst
@@ -18,7 +18,7 @@ information, see :doc:`/compiling`.
 
 .. code-block:: cmake
 
-    cmake_minimum_required(VERSION 3.0)
+    cmake_minimum_required(VERSION 3.4)
     project(example)
 
     find_package(pybind11 REQUIRED)  # or `add_subdirectory(pybind11)`
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/exceptions.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/exceptions.rst
@@ -1,18 +1,24 @@
 Exceptions
 ##########
 
-Built-in exception translation
-==============================
+Built-in C++ to Python exception translation
+============================================
 
-When C++ code invoked from Python throws an ``std::exception``, it is
-automatically converted into a Python ``Exception``. pybind11 defines multiple
-special exception classes that will map to different types of Python
-exceptions:
+When Python calls C++ code through pybind11, pybind11 provides a C++ exception handler
+that will trap C++ exceptions, translate them to the corresponding Python exception,
+and raise them so that Python code can handle them.
+
+pybind11 defines translations for ``std::exception`` and its standard
+subclasses, and several special exception classes that translate to specific
+Python exceptions. Note that these are not actually Python exceptions, so they
+cannot be examined using the Python C API. Instead, they are pure C++ objects
+that pybind11 will translate the corresponding Python exception when they arrive
+at its exception handler.
 
 .. tabularcolumns:: |p{0.5\textwidth}|p{0.45\textwidth}|
 
 +--------------------------------------+--------------------------------------+
-|  C++ exception type                  |  Python exception type               |
+|  Exception thrown by C++             |  Translated to Python exception type |
 +======================================+======================================+
 | :class:`std::exception`              | ``RuntimeError``                     |
 +--------------------------------------+--------------------------------------+
@@ -46,16 +52,11 @@ exceptions:
 |                                      | ``__setitem__`` in dict-like         |
 |                                      | objects, etc.)                       |
 +--------------------------------------+--------------------------------------+
-| :class:`pybind11::error_already_set` | Indicates that the Python exception  |
-|                                      | flag has already been set via Python |
-|                                      | API calls from C++ code; this C++    |
-|                                      | exception is used to propagate such  |
-|                                      | a Python exception back to Python.   |
-+--------------------------------------+--------------------------------------+
 
-When a Python function invoked from C++ throws an exception, it is converted
-into a C++ exception of type :class:`error_already_set` whose string payload
-contains a textual summary.
+Exception translation is not bidirectional. That is, *catching* the C++
+exceptions defined above above will not trap exceptions that originate from
+Python. For that, catch :class:`pybind11::error_already_set`. See :ref:`below
+<handling_python_exceptions_cpp>` for further details.
 
 There is also a special exception :class:`cast_error` that is thrown by
 :func:`handle::call` when the input arguments cannot be converted to Python
@@ -78,6 +79,19 @@ This call creates a Python exception cla
 module and automatically converts any encountered exceptions of type ``CppExp``
 into Python exceptions of type ``PyExp``.
 
+It is possible to specify base class for the exception using the third
+parameter, a `handle`:
+
+.. code-block:: cpp
+
+    py::register_exception<CppExp>(module, "PyExp", PyExc_RuntimeError);
+
+Then `PyExp` can be caught both as `PyExp` and `RuntimeError`.
+
+The class objects of the built-in Python exceptions are listed in the Python
+documentation on `Standard Exceptions <https://docs.python.org/3/c-api/exceptions.html#standard-exceptions>`_.
+The default base class is `PyExc_Exception`.
+
 When more advanced exception translation is needed, the function
 ``py::register_exception_translator(translator)`` can be used to register
 functions that can translate arbitrary exception types (and which may include
@@ -100,7 +114,6 @@ and use this in the associated exception
 to make this a static declaration when using it inside a lambda expression
 without requiring capturing).
 
-
 The following example demonstrates this for a hypothetical exception classes
 ``MyCustomException`` and ``OtherException``: the first is translated to a
 custom python exception ``MyCustomError``, while the second is translated to a
@@ -134,7 +147,7 @@ section.
 
 .. note::
 
-    You must call either ``PyErr_SetString`` or a custom exception's call
+    Call either ``PyErr_SetString`` or a custom exception's call
     operator (``exc(string)``) for every exception caught in a custom exception
     translator.  Failure to do so will cause Python to crash with ``SystemError:
     error return without exception set``.
@@ -142,3 +155,144 @@ section.
     Exceptions that you do not plan to handle should simply not be caught, or
     may be explicitly (re-)thrown to delegate it to the other,
     previously-declared existing exception translators.
+
+.. _handling_python_exceptions_cpp:
+
+Handling exceptions from Python in C++
+======================================
+
+When C++ calls Python functions, such as in a callback function or when
+manipulating Python objects, and Python raises an ``Exception``, pybind11
+converts the Python exception into a C++ exception of type
+:class:`pybind11::error_already_set` whose payload contains a C++ string textual
+summary and the actual Python exception. ``error_already_set`` is used to
+propagate Python exception back to Python (or possibly, handle them in C++).
+
+.. tabularcolumns:: |p{0.5\textwidth}|p{0.45\textwidth}|
+
++--------------------------------------+--------------------------------------+
+|  Exception raised in Python          |  Thrown as C++ exception type        |
++======================================+======================================+
+| Any Python ``Exception``             | :class:`pybind11::error_already_set` |
++--------------------------------------+--------------------------------------+
+
+For example:
+
+.. code-block:: cpp
+
+    try {
+        // open("missing.txt", "r")
+        auto file = py::module::import("io").attr("open")("missing.txt", "r");
+        auto text = file.attr("read")();
+        file.attr("close")();
+    } catch (py::error_already_set &e) {
+        if (e.matches(PyExc_FileNotFoundError)) {
+            py::print("missing.txt not found");
+        } else if (e.match(PyExc_PermissionError)) {
+            py::print("missing.txt found but not accessible");
+        } else {
+            throw;
+        }
+    }
+
+Note that C++ to Python exception translation does not apply here, since that is
+a method for translating C++ exceptions to Python, not vice versa. The error raised
+from Python is always ``error_already_set``.
+
+This example illustrates this behavior:
+
+.. code-block:: cpp
+
+    try {
+        py::eval("raise ValueError('The Ring')");
+    } catch (py::value_error &boromir) {
+        // Boromir never gets the ring
+        assert(false);
+    } catch (py::error_already_set &frodo) {
+        // Frodo gets the ring
+        py::print("I will take the ring");
+    }
+
+    try {
+        // py::value_error is a request for pybind11 to raise a Python exception
+        throw py::value_error("The ball");
+    } catch (py::error_already_set &cat) {
+        // cat won't catch the ball since
+        // py::value_error is not a Python exception
+        assert(false);
+    } catch (py::value_error &dog) {
+        // dog will catch the ball
+        py::print("Run Spot run");
+        throw;  // Throw it again (pybind11 will raise ValueError)
+    }
+
+Handling errors from the Python C API
+=====================================
+
+Where possible, use :ref:`pybind11 wrappers <wrappers>` instead of calling
+the Python C API directly. When calling the Python C API directly, in
+addition to manually managing reference counts, one must follow the pybind11
+error protocol, which is outlined here.
+
+After calling the Python C API, if Python returns an error,
+``throw py::error_already_set();``, which allows pybind11 to deal with the
+exception and pass it back to the Python interpreter. This includes calls to
+the error setting functions such as ``PyErr_SetString``.
+
+.. code-block:: cpp
+
+    PyErr_SetString(PyExc_TypeError, "C API type error demo");
+    throw py::error_already_set();
+
+    // But it would be easier to simply...
+    throw py::type_error("pybind11 wrapper type error");
+
+Alternately, to ignore the error, call `PyErr_Clear
+<https://docs.python.org/3/c-api/exceptions.html#c.PyErr_Clear>`_.
+
+Any Python error must be thrown or cleared, or Python/pybind11 will be left in
+an invalid state.
+
+.. _unraisable_exceptions:
+
+Handling unraisable exceptions
+==============================
+
+If a Python function invoked from a C++ destructor or any function marked
+``noexcept(true)`` (collectively, "noexcept functions") throws an exception, there
+is no way to propagate the exception, as such functions may not throw.
+Should they throw or fail to catch any exceptions in their call graph,
+the C++ runtime calls ``std::terminate()`` to abort immediately.
+
+Similarly, Python exceptions raised in a class's ``__del__`` method do not
+propagate, but are logged by Python as an unraisable error. In Python 3.8+, a
+`system hook is triggered
+<https://docs.python.org/3/library/sys.html#sys.unraisablehook>`_
+and an auditing event is logged.
+
+Any noexcept function should have a try-catch block that traps
+class:`error_already_set` (or any other exception that can occur). Note that
+pybind11 wrappers around Python exceptions such as
+:class:`pybind11::value_error` are *not* Python exceptions; they are C++
+exceptions that pybind11 catches and converts to Python exceptions. Noexcept
+functions cannot propagate these exceptions either. A useful approach is to
+convert them to Python exceptions and then ``discard_as_unraisable`` as shown
+below.
+
+.. code-block:: cpp
+
+    void nonthrowing_func() noexcept(true) {
+        try {
+            // ...
+        } catch (py::error_already_set &eas) {
+            // Discard the Python error using Python APIs, using the C++ magic
+            // variable __func__. Python already knows the type and value and of the
+            // exception object.
+            eas.discard_as_unraisable(__func__);
+        } catch (const std::exception &e) {
+            // Log and discard C++ exceptions.
+            third_party::log(e);
+        }
+    }
+
+.. versionadded:: 2.6
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/functions.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/functions.rst
@@ -360,7 +360,7 @@ like so:
 .. code-block:: cpp
 
     py::class_<MyClass>("MyClass")
-        .def("myFunction", py::arg("arg") = (SomeType *) nullptr);
+        .def("myFunction", py::arg("arg") = static_cast<SomeType *>(nullptr));
 
 Keyword-only arguments
 ======================
@@ -378,17 +378,37 @@ argument in a function definition:
     f(1, b=2)    # good
     f(1, 2)      # TypeError: f() takes 1 positional argument but 2 were given
 
-Pybind11 provides a ``py::kwonly`` object that allows you to implement
+Pybind11 provides a ``py::kw_only`` object that allows you to implement
 the same behaviour by specifying the object between positional and keyword-only
 argument annotations when registering the function:
 
 .. code-block:: cpp
 
     m.def("f", [](int a, int b) { /* ... */ },
-          py::arg("a"), py::kwonly(), py::arg("b"));
+          py::arg("a"), py::kw_only(), py::arg("b"));
 
-Note that, as in Python, you cannot combine this with a ``py::args`` argument.
-This feature does *not* require Python 3 to work.
+Note that you currently cannot combine this with a ``py::args`` argument.  This
+feature does *not* require Python 3 to work.
+
+.. versionadded:: 2.6
+
+Positional-only arguments
+=========================
+
+Python 3.8 introduced a new positional-only argument syntax, using ``/`` in the
+function definition (note that this has been a convention for CPython
+positional arguments, such as in ``pow()``, since Python 2). You can
+do the same thing in any version of Python using ``py::pos_only()``:
+
+.. code-block:: cpp
+
+   m.def("f", [](int a, int b) { /* ... */ },
+          py::arg("a"), py::pos_only(), py::arg("b"));
+
+You now cannot give argument ``a`` by keyword. This can be combined with
+keyword-only arguments, as well.
+
+.. versionadded:: 2.6
 
 .. _nonconverting_arguments:
 
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/misc.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/misc.rst
@@ -7,14 +7,14 @@ General notes regarding convenience macr
 ==========================================
 
 pybind11 provides a few convenience macros such as
-:func:`PYBIND11_DECLARE_HOLDER_TYPE` and ``PYBIND11_OVERLOAD_*``. Since these
+:func:`PYBIND11_DECLARE_HOLDER_TYPE` and ``PYBIND11_OVERRIDE_*``. Since these
 are "just" macros that are evaluated in the preprocessor (which has no concept
 of types), they *will* get confused by commas in a template argument; for
 example, consider:
 
 .. code-block:: cpp
 
-    PYBIND11_OVERLOAD(MyReturnType<T1, T2>, Class<T3, T4>, func)
+    PYBIND11_OVERRIDE(MyReturnType<T1, T2>, Class<T3, T4>, func)
 
 The limitation of the C preprocessor interprets this as five arguments (with new
 arguments beginning after each comma) rather than three.  To get around this,
@@ -26,10 +26,10 @@ using the ``PYBIND11_TYPE`` macro:
     // Version 1: using a type alias
     using ReturnType = MyReturnType<T1, T2>;
     using ClassType = Class<T3, T4>;
-    PYBIND11_OVERLOAD(ReturnType, ClassType, func);
+    PYBIND11_OVERRIDE(ReturnType, ClassType, func);
 
     // Version 2: using the PYBIND11_TYPE macro:
-    PYBIND11_OVERLOAD(PYBIND11_TYPE(MyReturnType<T1, T2>),
+    PYBIND11_OVERRIDE(PYBIND11_TYPE(MyReturnType<T1, T2>),
                       PYBIND11_TYPE(Class<T3, T4>), func)
 
 The ``PYBIND11_MAKE_OPAQUE`` macro does *not* require the above workarounds.
@@ -59,7 +59,7 @@ could be realized as follows (important
             /* Acquire GIL before calling Python code */
             py::gil_scoped_acquire acquire;
 
-            PYBIND11_OVERLOAD_PURE(
+            PYBIND11_OVERRIDE_PURE(
                 std::string, /* Return type */
                 Animal,      /* Parent class */
                 go,          /* Name of function */
@@ -176,9 +176,9 @@ pybind11 version. Consider the following
 
 .. code-block:: cpp
 
-    auto data = (MyData *) py::get_shared_data("mydata");
+    auto data = reinterpret_cast<MyData *>(py::get_shared_data("mydata"));
     if (!data)
-        data = (MyData *) py::set_shared_data("mydata", new MyData(42));
+        data = static_cast<MyData *>(py::set_shared_data("mydata", new MyData(42)));
 
 If the above snippet was used in several separately compiled extension modules,
 the first one to be imported would create a ``MyData`` instance and associate
@@ -304,3 +304,34 @@ the default settings are restored to pre
 
 .. [#f4] http://www.sphinx-doc.org
 .. [#f5] http://github.com/pybind/python_example
+
+.. _avoiding-cpp-types-in-docstrings:
+
+Avoiding C++ types in docstrings
+================================
+
+Docstrings are generated at the time of the declaration, e.g. when ``.def(...)`` is called.
+At this point parameter and return types should be known to pybind11.
+If a custom type is not exposed yet through a ``py::class_`` constructor or a custom type caster,
+its C++ type name will be used instead to generate the signature in the docstring:
+
+.. code-block:: text
+
+     |  __init__(...)
+     |      __init__(self: example.Foo, arg0: ns::Bar) -> None
+                                              ^^^^^^^
+
+
+This limitation can be circumvented by ensuring that C++ classes are registered with pybind11
+before they are used as a parameter or return type of a function:
+
+.. code-block:: cpp
+
+    PYBIND11_MODULE(example, m) {
+
+        auto pyFoo = py::class_<ns::Foo>(m, "Foo");
+        auto pyBar = py::class_<ns::Bar>(m, "Bar");
+
+        pyFoo.def(py::init<const ns::Bar&>());
+        pyBar.def(py::init<const ns::Foo&>());
+    }
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/pycpp/numpy.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/pycpp/numpy.rst
@@ -81,7 +81,7 @@ buffer objects (e.g. a NumPy matrix).
     constexpr bool rowMajor = Matrix::Flags & Eigen::RowMajorBit;
 
     py::class_<Matrix>(m, "Matrix", py::buffer_protocol())
-        .def("__init__", [](py::buffer b) {
+        .def(py::init([](py::buffer b) {
             typedef Eigen::Stride<Eigen::Dynamic, Eigen::Dynamic> Strides;
 
             /* Request a buffer descriptor from Python */
@@ -101,8 +101,8 @@ buffer objects (e.g. a NumPy matrix).
             auto map = Eigen::Map<Matrix, 0, Strides>(
                 static_cast<Scalar *>(info.ptr), info.shape[0], info.shape[1], strides);
 
-            return Matrix(m);
-        });
+            return Matrix(map);
+        }));
 
 For reference, the ``def_buffer()`` call for this Eigen data type should look
 as follows:
@@ -274,9 +274,9 @@ simply using ``vectorize``).
 
         py::buffer_info buf3 = result.request();
 
-        double *ptr1 = (double *) buf1.ptr,
-               *ptr2 = (double *) buf2.ptr,
-               *ptr3 = (double *) buf3.ptr;
+        double *ptr1 = static_cast<double *>(buf1.ptr);
+        double *ptr2 = static_cast<double *>(buf2.ptr);
+        double *ptr3 = static_cast<double *>(buf3.ptr);
 
         for (size_t idx = 0; idx < buf1.shape[0]; idx++)
             ptr3[idx] = ptr1[idx] + ptr2[idx];
@@ -371,6 +371,8 @@ Ellipsis
 Python 3 provides a convenient ``...`` ellipsis notation that is often used to
 slice multidimensional arrays. For instance, the following snippet extracts the
 middle dimensions of a tensor with the first and last index set to zero.
+In Python 2, the syntactic sugar ``...`` is not available, but the singleton
+``Ellipsis`` (of type ``ellipsis``) can still be used directly.
 
 .. code-block:: python
 
@@ -385,6 +387,9 @@ operation on the C++ side:
    py::array a = /* A NumPy array */;
    py::array b = a[py::make_tuple(0, py::ellipsis(), 0)];
 
+.. versionchanged:: 2.6
+   ``py::ellipsis()`` is now also avaliable in Python 2.
+
 Memory view
 ===========
 
@@ -426,3 +431,6 @@ We can also use ``memoryview::from_memor
 .. note::
 
     ``memoryview::from_memory`` is not available in Python 2.
+
+.. versionchanged:: 2.6
+    ``memoryview::from_memory`` added.
--- gtsam-4.1.0.orig/wrap/pybind11/docs/advanced/pycpp/object.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/advanced/pycpp/object.rst
@@ -1,6 +1,8 @@
 Python types
 ############
 
+.. _wrappers:
+
 Available wrappers
 ==================
 
@@ -13,6 +15,13 @@ Available types include :class:`handle`,
 :class:`iterable`, :class:`iterator`, :class:`function`, :class:`buffer`,
 :class:`array`, and :class:`array_t`.
 
+.. warning::
+
+    Be sure to review the :ref:`pytypes_gotchas` before using this heavily in
+    your C++ API.
+
+.. _casting_back_and_forth:
+
 Casting back and forth
 ======================
 
@@ -55,6 +64,7 @@ This example obtains a reference to the
     py::object scipy = py::module::import("scipy");
     return scipy.attr("__version__");
 
+
 .. _calling_python_functions:
 
 Calling Python functions
@@ -168,3 +178,74 @@ Generalized unpacking according to PEP44
     Python functions from C++, including keywords arguments and unpacking.
 
 .. _PEP448: https://www.python.org/dev/peps/pep-0448/
+
+.. _implicit_casting:
+
+Implicit casting
+================
+
+When using the C++ interface for Python types, or calling Python functions,
+objects of type :class:`object` are returned. It is possible to invoke implicit
+conversions to subclasses like :class:`dict`. The same holds for the proxy objects
+returned by ``operator[]`` or ``obj.attr()``.
+Casting to subtypes improves code readability and allows values to be passed to
+C++ functions that require a specific subtype rather than a generic :class:`object`.
+
+.. code-block:: cpp
+
+    #include <pybind11/numpy.h>
+    using namespace pybind11::literals;
+
+    py::module os = py::module::import("os");
+    py::module path = py::module::import("os.path");  // like 'import os.path as path'
+    py::module np = py::module::import("numpy");  // like 'import numpy as np'
+
+    py::str curdir_abs = path.attr("abspath")(path.attr("curdir"));
+    py::print(py::str("Current directory: ") + curdir_abs);
+    py::dict environ = os.attr("environ");
+    py::print(environ["HOME"]);
+    py::array_t<float> arr = np.attr("ones")(3, "dtype"_a="float32");
+    py::print(py::repr(arr + py::int_(1)));
+
+These implicit conversions are available for subclasses of :class:`object`; there
+is no need to call ``obj.cast()`` explicitly as for custom classes, see
+:ref:`casting_back_and_forth`.
+
+.. note::
+    If a trivial conversion via move constructor is not possible, both implicit and
+    explicit casting (calling ``obj.cast()``) will attempt a "rich" conversion.
+    For instance, ``py::list env = os.attr("environ");`` will succeed and is
+    equivalent to the Python code ``env = list(os.environ)`` that produces a
+    list of the dict keys.
+
+..  TODO: Adapt text once PR #2349 has landed
+
+Handling exceptions
+===================
+
+Python exceptions from wrapper classes will be thrown as a ``py::error_already_set``.
+See :ref:`Handling exceptions from Python in C++
+<handling_python_exceptions_cpp>` for more information on handling exceptions
+raised when calling C++ wrapper classes.
+
+.. _pytypes_gotchas:
+
+Gotchas
+=======
+
+Default-Constructed Wrappers
+----------------------------
+
+When a wrapper type is default-constructed, it is **not** a valid Python object (i.e. it is not ``py::none()``). It is simply the same as
+``PyObject*`` null pointer. To check for this, use
+``static_cast<bool>(my_wrapper)``.
+
+Assigning py::none() to wrappers
+--------------------------------
+
+You may be tempted to use types like ``py::str`` and ``py::dict`` in C++
+signatures (either pure C++, or in bound signatures), and assign them default
+values of ``py::none()``. However, in a best case scenario, it will fail fast
+because ``None`` is not convertible to that type (e.g. ``py::dict``), or in a
+worse case scenario, it will silently work but corrupt the types you want to
+work with (e.g. ``py::str(py::none())`` will yield ``"None"`` in Python).
--- gtsam-4.1.0.orig/wrap/pybind11/docs/basics.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/basics.rst
@@ -11,11 +11,11 @@ included set of test cases.
 Compiling the test cases
 ========================
 
-Linux/MacOS
+Linux/macOS
 -----------
 
 On Linux  you'll need to install the **python-dev** or **python3-dev** packages as
-well as **cmake**. On Mac OS, the included python version works out of the box,
+well as **cmake**. On macOS, the included python version works out of the box,
 but **cmake** must still be installed.
 
 After installing the prerequisites, run
@@ -35,6 +35,14 @@ Windows
 On Windows, only **Visual Studio 2015** and newer are supported since pybind11 relies
 on various C++11 language features that break older versions of Visual Studio.
 
+.. Note::
+
+    To use the C++17 in Visual Studio 2017 (MSVC 14.1), pybind11 requires the flag
+    ``/permissive-`` to be passed to the compiler `to enforce standard conformance`_. When
+    building with Visual Studio 2019, this is not strictly necessary, but still adviced.
+
+..  _`to enforce standard conformance`: https://docs.microsoft.com/en-us/cpp/build/reference/permissive-standards-conformance?view=vs-2017
+
 To compile and run the tests:
 
 .. code-block:: batch
@@ -130,7 +138,7 @@ On Linux, the above example can be compi
 
     $ c++ -O3 -Wall -shared -std=c++11 -fPIC `python3 -m pybind11 --includes` example.cpp -o example`python3-config --extension-suffix`
 
-For more details on the required compiler flags on Linux and MacOS, see
+For more details on the required compiler flags on Linux and macOS, see
 :ref:`building_manually`. For complete cross-platform compilation instructions,
 refer to the :ref:`compiling` page.
 
--- gtsam-4.1.0.orig/wrap/pybind11/docs/changelog.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/changelog.rst
@@ -6,6 +6,165 @@ Changelog
 Starting with version 1.8.0, pybind11 releases use a `semantic versioning
 <http://semver.org>`_ policy.
 
+v2.6.0 (IN PROGRESS)
+--------------------
+
+See :ref:`upgrade-guide-2.6` for help upgrading to the new version.
+
+* Provide an additional spelling of ``py::module`` - ``py::module_`` (with a
+  trailing underscore), for C++20 compatibility. Only relevant when used
+  unqualified.
+  `#2489 <https://github.com/pybind/pybind11/pull/2489>`_
+
+* ``pybind11_add_module()`` now accepts an optional ``OPT_SIZE`` flag that
+  switches the binding target to size-based optimization regardless global
+  CMake build type (except in debug mode, where optimizations remain disabled).
+  This reduces binary size quite substantially (~25%).
+  `#2463 <https://github.com/pybind/pybind11/pull/2463>`_
+
+* Keyword-only arguments supported in Python 2 or 3 with ``py::kw_only()``.
+  `#2100 <https://github.com/pybind/pybind11/pull/2100>`_
+
+* Positional-only arguments supported in Python 2 or 3 with ``py::pos_only()``.
+  `#2459 <https://github.com/pybind/pybind11/pull/2459>`_
+
+* Access to the type object now provided with ``py::type::of<T>()`` and
+  ``py::type::of(h)``.
+  `#2364 <https://github.com/pybind/pybind11/pull/2364>`_
+
+
+* Perfect forwarding support for methods.
+  `#2048 <https://github.com/pybind/pybind11/pull/2048>`_
+
+* Added ``py::error_already_set::discard_as_unraisable()``.
+  `#2372 <https://github.com/pybind/pybind11/pull/2372>`_
+
+* ``py::hash`` is now public.
+  `#2217 <https://github.com/pybind/pybind11/pull/2217>`_
+
+* ``py::is_final()`` class modifier to block subclassing (CPython only).
+  `#2151 <https://github.com/pybind/pybind11/pull/2151>`_
+
+* ``py::memoryview``  update and documentation.
+  `#2223 <https://github.com/pybind/pybind11/pull/2223>`_
+
+* The Python package was reworked to be more powerful and useful.
+  `#2433 <https://github.com/pybind/pybind11/pull/2433>`_
+
+  * :ref:`build-setuptools` is easier thanks to a new
+    ``pybind11.setup_helpers`` module, which provides utilities to use
+    setuptools with pybind11. It can be used via PEP 518, ``setup_requires``,
+    or by directly copying ``setup_helpers.py`` into your project.
+
+  * CMake configuration files are now included in the Python package. Use
+    ``pybind11.get_cmake_dir()`` or ``python -m pybind11 --cmakedir`` to get
+    the directory with the CMake configuration files, or include the
+    site-packages location in your ``CMAKE_MODULE_PATH``. Or you can use the
+    new ``pybind11[global]`` extra when you install ``pybind11``, which
+    installs the CMake files and headers into your base environment in the
+    standard location
+
+  * ``pybind11-config`` is another way to write ``python -m pybind11`` if you
+    have your PATH set up.
+
+* Minimum CMake required increased to 3.4.
+  `#2338 <https://github.com/pybind/pybind11/pull/2338>`_ and
+  `#2370 <https://github.com/pybind/pybind11/pull/2370>`_
+
+  * Full integration with CMake’s C++ standard system replaces
+    ``PYBIND11_CPP_STANDARD``.
+
+  * Generated config file is now portable to different Python/compiler/CMake
+    versions.
+
+  * Virtual environments prioritized if ``PYTHON_EXECUTABLE`` is not set
+    (``venv``, ``virtualenv``, and ``conda``) (similar to the new FindPython
+    mode).
+
+  * Other CMake features now natively supported, like
+    ``CMAKE_INTERPROCEDURAL_OPTIMIZATION``, ``set(CMAKE_CXX_VISIBILITY_PRESET
+    hidden)``.
+
+* Optional :ref:`find-python-mode` and :ref:`nopython-mode` with CMake.
+  `#2370 <https://github.com/pybind/pybind11/pull/2370>`_
+
+* Uninstall target added.
+  `#2265 <https://github.com/pybind/pybind11/pull/2265>`_ and
+  `#2346 <https://github.com/pybind/pybind11/pull/2346>`_
+
+* ``PYBIND11_OVERLOAD*`` macros and ``get_overload`` function replaced by
+  correctly-named ``PYBIND11_OVERRIDE*`` and ``get_override``, fixing
+  inconsistencies in the presene of a closing ``;`` in these macros.
+  ``get_type_overload`` is deprecated.
+  `#2325 <https://github.com/pybind/pybind11/pull/2325>`_
+
+Smaller or developer focused features:
+
+* Moved ``mkdoc.py`` to a new repo, `pybind11-mkdoc`_.
+
+.. _pybind11-mkdoc: https://github.com/pybind/pybind11-mkdoc
+
+* Error now thrown when ``__init__`` is forgotten on subclasses.
+  `#2152 <https://github.com/pybind/pybind11/pull/2152>`_
+
+* If ``__eq__`` defined but not ``__hash__``, ``__hash__`` is now set to
+  ``None``.
+  `#2291 <https://github.com/pybind/pybind11/pull/2291>`_
+
+* ``py::ellipsis`` now also works on Python 2.
+  `#2360 <https://github.com/pybind/pybind11/pull/2360>`_
+
+* Throw if conversion to ``str`` fails.
+  `#2477 <https://github.com/pybind/pybind11/pull/2477>`_
+
+* Added missing signature for ``py::array``.
+  `#2363 <https://github.com/pybind/pybind11/pull/2363>`_
+
+* Pointer to ``std::tuple`` & ``std::pair`` supported in cast.
+  `#2334 <https://github.com/pybind/pybind11/pull/2334>`_
+
+* Small fixes in NumPy support. ``py::array`` now uses ``py::ssize_t`` as first
+  argument type.
+  `#2293 <https://github.com/pybind/pybind11/pull/2293>`_
+
+* Bugfixes related to more extensive testing
+  `#2321 <https://github.com/pybind/pybind11/pull/2321>`_
+
+* Bug in timezone issue in Eastern hemisphere midnight fixed.
+  `#2438 <https://github.com/pybind/pybind11/pull/2438>`_
+
+* ``std::chrono::time_point`` now works when the resolution is not the same as
+  the system.
+  `#2481 <https://github.com/pybind/pybind11/pull/2481>`_
+
+* Bug fixed where ``py::array_t`` could accept arrays that did not match the
+  requested ordering.
+  `#2484 <https://github.com/pybind/pybind11/pull/2484>`_
+
+* PyPy fixes, including support for PyPy3 and PyPy 7.
+  `#2146 <https://github.com/pybind/pybind11/pull/2146>`_
+
+* CPython 3.9 fixes.
+  `#2253 <https://github.com/pybind/pybind11/pull/2253>`_
+
+* More C++20 support.
+  `#2489 <https://github.com/pybind/pybind11/pull/2489>`_
+
+* Debug Python interpreter support.
+  `#2025 <https://github.com/pybind/pybind11/pull/2025>`_
+
+* NVCC (CUDA 11) now supported and tested in CI.
+  `#2461 <https://github.com/pybind/pybind11/pull/2461>`_
+
+* NVIDIA PGI compilers now supported and tested in CI.
+  `#2475 <https://github.com/pybind/pybind11/pull/2475>`_
+
+* Extensive style checking in CI, with `pre-commit`_ support.
+
+.. _pre-commit: https://pre-commit.com
+
+
+
 v2.5.0 (Mar 31, 2020)
 -----------------------------------------------------
 
@@ -536,7 +695,7 @@ v2.2.0 (August 31, 2017)
   in reference cycles.
   `#856 <https://github.com/pybind/pybind11/pull/856>`_.
 
-* Numpy and buffer protocol related improvements:
+* NumPy and buffer protocol related improvements:
 
   1. Support for negative strides in Python buffer objects/numpy arrays. This
      required changing integers from unsigned to signed for the related C++ APIs.
@@ -1267,7 +1426,7 @@ Happy Christmas!
 * Improved support for ``std::shared_ptr<>`` conversions
 * Initial support for ``std::set<>`` conversions
 * Fixed type resolution issue for types defined in a separate plugin module
-* Cmake build system improvements
+* CMake build system improvements
 * Factored out generic functionality to non-templated code (smaller code size)
 * Added a code size / compile time benchmark vs Boost.Python
 * Added an appveyor CI script
--- gtsam-4.1.0.orig/wrap/pybind11/docs/classes.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/classes.rst
@@ -74,7 +74,7 @@ Note how ``print(p)`` produced a rather
     >>> print(p)
     <example.Pet object at 0x10cd98060>
 
-To address this, we could bind an utility function that returns a human-readable
+To address this, we could bind a utility function that returns a human-readable
 summary to the special method slot named ``__repr__``. Unfortunately, there is no
 suitable functionality in the ``Pet`` data structure, and it would be nice if
 we did not have to change it. This can easily be accomplished by binding a
@@ -373,8 +373,8 @@ sequence.
 
     py::class_<Pet>(m, "Pet")
        .def(py::init<const std::string &, int>())
-       .def("set", (void (Pet::*)(int)) &Pet::set, "Set the pet's age")
-       .def("set", (void (Pet::*)(const std::string &)) &Pet::set, "Set the pet's name");
+       .def("set", static_cast<void (Pet::*)(int)>(&Pet::set), "Set the pet's age")
+       .def("set", static_cast<void (Pet::*)(const std::string &)>(&Pet::set), "Set the pet's name");
 
 The overload signatures are also visible in the method's docstring:
 
--- gtsam-4.1.0.orig/wrap/pybind11/docs/compiling.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/compiling.rst
@@ -3,6 +3,8 @@
 Build systems
 #############
 
+.. _build-setuptools:
+
 Building with setuptools
 ========================
 
@@ -13,6 +15,135 @@ the [python_example]_ repository.
 
 .. [python_example] https://github.com/pybind/python_example
 
+A helper file is provided with pybind11 that can simplify usage with setuptools.
+
+To use pybind11 inside your ``setup.py``, you have to have some system to
+ensure that ``pybind11`` is installed when you build your package. There are
+four possible ways to do this, and pybind11 supports all four: You can ask all
+users to install pybind11 beforehand (bad), you can use
+:ref:`setup_helpers-pep518` (good, but very new and requires Pip 10),
+:ref:`setup_helpers-setup_requires` (discouraged by Python packagers now that
+PEP 518 is available, but it still works everywhere), or you can
+:ref:`setup_helpers-copy-manually` (always works but you have to manually sync
+your copy to get updates).
+
+An example of a ``setup.py`` using pybind11's helpers:
+
+.. code-block:: python
+
+    from setuptools import setup
+    from pybind11.setup_helpers import Pybind11Extension
+
+    ext_modules = [
+        Pybind11Extension(
+            "python_example",
+            ["src/main.cpp"],
+        ),
+    ]
+
+    setup(
+        ...,
+        ext_modules=ext_modules
+    )
+
+If you want to do an automatic search for the highest supported C++ standard,
+that is supported via a ``build_ext`` command override; it will only affect
+``Pybind11Extensions``:
+
+.. code-block:: python
+
+    from setuptools import setup
+    from pybind11.setup_helpers import Pybind11Extension, build_ext
+
+    ext_modules = [
+        Pybind11Extension(
+            "python_example",
+            ["src/main.cpp"],
+        ),
+    ]
+
+    setup(
+        ...,
+        cmdclass={"build_ext": build_ext},
+        ext_modules=ext_modules
+    )
+
+.. _setup_helpers-pep518:
+
+PEP 518 requirements (Pip 10+ required)
+---------------------------------------
+
+If you use `PEP 518's <https://www.python.org/dev/peps/pep-0518/>`_
+``pyproject.toml`` file, you can ensure that ``pybind11`` is available during
+the compilation of your project.  When this file exists, Pip will make a new
+virtual environment, download just the packages listed here in ``requires=``,
+and build a wheel (binary Python package). It will then throw away the
+environment, and install your wheel.
+
+Your ``pyproject.toml`` file will likely look something like this:
+
+.. code-block:: toml
+
+    [build-system]
+    requires = ["setuptools", "wheel", "pybind11==2.6.0"]
+    build-backend = "setuptools.build_meta"
+
+.. note::
+
+    The main drawback to this method is that a `PEP 517`_ compliant build tool,
+    such as Pip 10+, is required for this approach to work; older versions of
+    Pip completely ignore this file. If you distribute binaries (called wheels
+    in Python) using something like `cibuildwheel`_, remember that ``setup.py``
+    and ``pyproject.toml`` are not even contained in the wheel, so this high
+    Pip requirement is only for source builds, and will not affect users of
+    your binary wheels.
+
+.. _PEP 517: https://www.python.org/dev/peps/pep-0517/
+.. _cibuildwheel: https://cibuildwheel.readthedocs.io
+
+.. _setup_helpers-setup_requires:
+
+Classic ``setup_requires``
+--------------------------
+
+If you want to support old versions of Pip with the classic
+``setup_requires=["pybind11"]`` keyword argument to setup, which triggers a
+two-phase ``setup.py`` run, then you will need to use something like this to
+ensure the first pass works (which has not yet installed the ``setup_requires``
+packages, since it can't install something it does not know about):
+
+.. code-block:: python
+
+    try:
+        from pybind11.setup_helpers import Pybind11Extension
+    except ImportError:
+        from setuptools import Extension as Pybind11Extension
+
+
+It doesn't matter that the Extension class is not the enhanced subclass for the
+first pass run; and the second pass will have the ``setup_requires``
+requirements.
+
+This is obviously more of a hack than the PEP 518 method, but it supports
+ancient versions of Pip.
+
+.. _setup_helpers-copy-manually:
+
+Copy manually
+-------------
+
+You can also copy ``setup_helpers.py`` directly to your project; it was
+designed to be usable standalone, like the old example ``setup.py``. You can
+set ``include_pybind11=False`` to skip including the pybind11 package headers,
+so you can use it with git submodules and a specific git version. If you use
+this, you will need to import from a local file in ``setup.py`` and ensure the
+helper file is part of your MANIFEST.
+
+
+.. versionchanged:: 2.6
+
+    Added ``setup_helpers`` file.
+
 Building with cppimport
 ========================
 
@@ -33,8 +164,8 @@ extension module can be created with jus
 
 .. code-block:: cmake
 
-    cmake_minimum_required(VERSION 2.8.12)
-    project(example)
+    cmake_minimum_required(VERSION 3.4...3.18)
+    project(example LANGUAGES CXX)
 
     add_subdirectory(pybind11)
     pybind11_add_module(example example.cpp)
@@ -50,6 +181,9 @@ PyPI integration, can be found in the [c
 
 .. [cmake_example] https://github.com/pybind/cmake_example
 
+.. versionchanged:: 2.6
+   CMake 3.4+ is required.
+
 pybind11_add_module
 -------------------
 
@@ -59,7 +193,7 @@ function with the following signature:
 .. code-block:: cmake
 
     pybind11_add_module(<name> [MODULE | SHARED] [EXCLUDE_FROM_ALL]
-                        [NO_EXTRAS] [SYSTEM] [THIN_LTO] source1 [source2 ...])
+                        [NO_EXTRAS] [THIN_LTO] [OPT_SIZE] source1 [source2 ...])
 
 This function behaves very much like CMake's builtin ``add_library`` (in fact,
 it's a wrapper function around that command). It will add a library target
@@ -86,49 +220,62 @@ latter optimizations are never applied i
 given, they will always be disabled, even in ``Release`` mode. However, this
 will result in code bloat and is generally not recommended.
 
-By default, pybind11 and Python headers will be included with ``-I``. In order
-to include pybind11 as system library, e.g. to avoid warnings in downstream
-code with warn-levels outside of pybind11's scope, set the option ``SYSTEM``.
-
 As stated above, LTO is enabled by default. Some newer compilers also support
 different flavors of LTO such as `ThinLTO`_. Setting ``THIN_LTO`` will cause
 the function to prefer this flavor if available. The function falls back to
-regular LTO if ``-flto=thin`` is not available.
+regular LTO if ``-flto=thin`` is not available. If
+``CMAKE_INTERPROCEDURAL_OPTIMIZATION`` is set (either ON or OFF), then that
+will be respected instead of the built-in flag search.
+
+The ``OPT_SIZE`` flag enables size-based optimization equivalent to the
+standard ``/Os`` or ``-Os`` compiler flags and the ``MinSizeRel`` build type,
+which avoid optimizations that that can substantially increase the size of the
+resulting binary. This flag is particularly useful in projects that are split
+into performance-critical parts and associated bindings. In this case, we can
+compile the project in release mode (and hence, optimize performance globally),
+and specify ``OPT_SIZE`` for the binding target, where size might be the main
+concern as performance is often less critical here. A ~25% size reduction has
+been observed in practice. This flag only changes the optimization behavior at
+a per-target level and takes precedence over the global CMake build type
+(``Release``, ``RelWithDebInfo``) except for ``Debug`` builds, where
+optimizations remain disabled.
 
 .. _ThinLTO: http://clang.llvm.org/docs/ThinLTO.html
 
 Configuration variables
 -----------------------
 
-By default, pybind11 will compile modules with the C++14 standard, if available
-on the target compiler, falling back to C++11 if C++14 support is not
-available.  Note, however, that this default is subject to change: future
-pybind11 releases are expected to migrate to newer C++ standards as they become
-available.  To override this, the standard flag can be given explicitly in
-`CMAKE_CXX_STANDARD <https://cmake.org/cmake/help/v3.17/variable/CMAKE_CXX_STANDARD.html>`_:
+By default, pybind11 will compile modules with the compiler default or the
+minimum standard required by pybind11, whichever is higher.  You can set the
+standard explicitly with
+`CMAKE_CXX_STANDARD <https://cmake.org/cmake/help/latest/variable/CMAKE_CXX_STANDARD.html>`_:
 
 .. code-block:: cmake
 
-    # Use just one of these:
-    set(CMAKE_CXX_STANDARD 11)
-    set(CMAKE_CXX_STANDARD 14)
-    set(CMAKE_CXX_STANDARD 17) # Experimental C++17 support
-
-    add_subdirectory(pybind11)  # or find_package(pybind11)
-
-Note that this and all other configuration variables must be set **before** the
-call to ``add_subdirectory`` or ``find_package``. The variables can also be set
-when calling CMake from the command line using the ``-D<variable>=<value>`` flag.
-
-The target Python version can be selected by setting ``PYBIND11_PYTHON_VERSION``
-or an exact Python installation can be specified with ``PYTHON_EXECUTABLE``.
-For example:
+    set(CMAKE_CXX_STANDARD 14)  # or 11, 14, 17, 20
+    set(CMAKE_CXX_STANDARD_REQUIRED ON)  # optional, ensure standard is supported
+    set(CMAKE_CXX_EXTENSIONS OFF)  # optional, keep compiler extensionsn off
+
+
+The variables can also be set when calling CMake from the command line using
+the ``-D<variable>=<value>`` flag. You can also manually set ``CXX_STANDARD``
+on a target or use ``target_compile_features`` on your targets - anything that
+CMake supports.
+
+Classic Python support: The target Python version can be selected by setting
+``PYBIND11_PYTHON_VERSION`` or an exact Python installation can be specified
+with ``PYTHON_EXECUTABLE``.  For example:
 
 .. code-block:: bash
 
     cmake -DPYBIND11_PYTHON_VERSION=3.6 ..
-    # or
-    cmake -DPYTHON_EXECUTABLE=path/to/python ..
+
+    # Another method:
+    cmake -DPYTHON_EXECUTABLE=/path/to/python ..
+
+    # This often is a good way to get the current Python, works in environments:
+    cmake -DPYTHON_EXECUTABLE=$(python3 -c "import sys; print(sys.executable)") ..
+
 
 find_package vs. add_subdirectory
 ---------------------------------
@@ -139,8 +286,8 @@ See the `Config file`_ docstring for det
 
 .. code-block:: cmake
 
-    cmake_minimum_required(VERSION 2.8.12)
-    project(example)
+    cmake_minimum_required(VERSION 3.4...3.18)
+    project(example LANGUAGES CXX)
 
     find_package(pybind11 REQUIRED)
     pybind11_add_module(example example.cpp)
@@ -151,12 +298,19 @@ the pybind11 repository  :
 
 .. code-block:: bash
 
+    # Classic CMake
     cd pybind11
     mkdir build
     cd build
     cmake ..
     make install
 
+    # CMake 3.15+
+    cd pybind11
+    cmake -S . -B build
+    cmake --build build -j 2  # Build on 2 cores
+    cmake --install build
+
 Once detected, the aforementioned ``pybind11_add_module`` can be employed as
 before. The function usage and configuration variables are identical no matter
 if pybind11 is added as a subdirectory or found as an installed package. You
@@ -165,41 +319,134 @@ can refer to the same [cmake_example]_ r
 
 .. _Config file: https://github.com/pybind/pybind11/blob/master/tools/pybind11Config.cmake.in
 
-Advanced: interface library target
-----------------------------------
 
-When using a version of CMake greater than 3.0, pybind11 can additionally
-be used as a special *interface library* . The target ``pybind11::module``
-is available with pybind11 headers, Python headers and libraries as needed,
-and C++ compile definitions attached. This target is suitable for linking
-to an independently constructed (through ``add_library``, not
-``pybind11_add_module``) target in the consuming project.
+.. _find-python-mode:
+
+FindPython mode
+---------------
+
+CMake 3.12+ (3.15+ recommended) added a new module called FindPython that had a
+highly improved search algorithm and modern targets and tools. If you use
+FindPython, pybind11 will detect this and use the existing targets instead:
 
 .. code-block:: cmake
 
-    cmake_minimum_required(VERSION 3.0)
-    project(example)
+    cmake_minumum_required(VERSION 3.15...3.18)
+    project(example LANGUAGES CXX)
+
+    find_package(Python COMPONENTS Interpreter Development REQUIRED)
+    find_package(pybind11 CONFIG REQUIRED)
+    # or add_subdirectory(pybind11)
+
+    pybind11_add_module(example example.cpp)
+
+You can also use the targets (as listed below) with FindPython. If you define
+``PYBIND11_FINDPYTHON``, pybind11 will perform the FindPython step for you
+(mostly useful when building pybind11's own tests, or as a way to change search
+algorithms from the CMake invocation, with ``-DPYBIND11_FINDPYTHON=ON``.
+
+.. warning::
+
+    If you use FindPython2 and FindPython3 to dual-target Python, use the
+    individual targets listed below, and avoid targets that directly include
+    Python parts.
+
+There are `many ways to hint or force a discovery of a specific Python
+installation <https://cmake.org/cmake/help/latest/module/FindPython.html>`_),
+setting ``Python_ROOT_DIR`` may be the most common one (though with
+virtualenv/venv support, and Conda support, this tends to find the correct
+Python version more often than the old system did).
+
+.. versionadded:: 2.6
+
+Advanced: interface library targets
+-----------------------------------
+
+Pybind11 supports modern CMake usage patterns with a set of interface targets,
+available in all modes. The targets provided are:
+
+   ``pybind11::headers``
+     Just the pybind11 headers and minimum compile requirements
+
+   ``pybind11::python2_no_register``
+     Quiets the warning/error when mixing C++14 or higher and Python 2
+
+   ``pybind11::pybind11``
+     Python headers + ``pybind11::headers`` + ``pybind11::python2_no_register`` (Python 2 only)
+
+   ``pybind11::python_link_helper``
+     Just the "linking" part of pybind11:module
+
+   ``pybind11::module``
+     Everything for extension modules - ``pybind11::pybind11`` + ``Python::Module`` (FindPython CMake 3.15+) or ``pybind11::python_link_helper``
+
+   ``pybind11::embed``
+     Everything for embedding the Python interpreter - ``pybind11::pybind11`` + ``Python::Embed`` (FindPython) or Python libs
+
+   ``pybind11::lto`` / ``pybind11::thin_lto``
+     An alternative to `INTERPROCEDURAL_OPTIMIZATION` for adding link-time optimization.
+
+   ``pybind11::windows_extras``
+     ``/bigobj`` and ``/mp`` for MSVC.
+
+   ``pybind11::opt_size``
+     ``/Os`` for MSVC, ``-Os`` for other compilers. Does nothing for debug builds.
+
+Two helper functions are also provided:
+
+    ``pybind11_strip(target)``
+      Strips a target (uses ``CMAKE_STRIP`` after the target is built)
+
+    ``pybind11_extension(target)``
+      Sets the correct extension (with SOABI) for a target.
+
+You can use these targets to build complex applications. For example, the
+``add_python_module`` function is identical to:
+
+.. code-block:: cmake
+
+    cmake_minimum_required(VERSION 3.4)
+    project(example LANGUAGES CXX)
 
     find_package(pybind11 REQUIRED)  # or add_subdirectory(pybind11)
 
     add_library(example MODULE main.cpp)
-    target_link_libraries(example PRIVATE pybind11::module)
-    set_target_properties(example PROPERTIES PREFIX "${PYTHON_MODULE_PREFIX}"
-                                             SUFFIX "${PYTHON_MODULE_EXTENSION}")
+
+    target_link_libraries(example PRIVATE pybind11::module pybind11::lto pybind11::windows_extras)
+
+    pybind11_extension(example)
+    pybind11_strip(example)
+
+    set_target_properties(example PROPERTIES CXX_VISIBILITY_PRESET "hidden"
+                                             CUDA_VISIBILITY_PRESET "hidden")
+
+Instead of setting properties, you can set ``CMAKE_*`` variables to initialize these correctly.
 
 .. warning::
 
     Since pybind11 is a metatemplate library, it is crucial that certain
     compiler flags are provided to ensure high quality code generation. In
     contrast to the ``pybind11_add_module()`` command, the CMake interface
-    library only provides the *minimal* set of parameters to ensure that the
-    code using pybind11 compiles, but it does **not** pass these extra compiler
-    flags (i.e. this is up to you).
-
-    These include Link Time Optimization (``-flto`` on GCC/Clang/ICPC, ``/GL``
-    and ``/LTCG`` on Visual Studio) and .OBJ files with many sections on Visual
-    Studio (``/bigobj``).  The :ref:`FAQ <faq:symhidden>` contains an
-    explanation on why these are needed.
+    provides a *composable* set of targets to ensure that you retain flexibility.
+    It can be expecially important to provide or set these properties; the
+    :ref:`FAQ <faq:symhidden>` contains an explanation on why these are needed.
+
+.. versionadded:: 2.6
+
+.. _nopython-mode:
+
+Advanced: NOPYTHON mode
+-----------------------
+
+If you want complete control, you can set ``PYBIND11_NOPYTHON`` to completely
+disable Python integration (this also happens if you run ``FindPython2`` and
+``FindPython3`` without running ``FindPython``). This gives you complete
+freedom to integrate into an existing system (like `Scikit-Build's
+<https://scikit-build.readthedocs.io>`_ ``PythonExtensions``).
+``pybind11_add_module`` and ``pybind11_extension`` will be unavailable, and the
+targets will be missing any Python specific behavior.
+
+.. versionadded:: 2.6
 
 Embedding the Python interpreter
 --------------------------------
@@ -213,8 +460,8 @@ information about usage in C++, see :doc
 
 .. code-block:: cmake
 
-    cmake_minimum_required(VERSION 3.0)
-    project(example)
+    cmake_minimum_required(VERSION 3.4...3.18)
+    project(example LANGUAGES CXX)
 
     find_package(pybind11 REQUIRED)  # or add_subdirectory(pybind11)
 
@@ -251,7 +498,7 @@ Besides, the ``--extension-suffix`` opti
 on the distribution; in the latter case, the module extension can be manually
 set to ``.so``.
 
-On Mac OS: the build command is almost the same but it also requires passing
+On macOS: the build command is almost the same but it also requires passing
 the ``-undefined dynamic_lookup`` flag so as to ignore missing symbols when
 building the module:
 
@@ -275,6 +522,25 @@ build system that works on all platforms
     of possibly importing a second Python library into a process that already
     contains one (which will lead to a segfault).
 
+
+Building with vcpkg
+===================
+You can download and install pybind11 using the Microsoft `vcpkg
+<https://github.com/Microsoft/vcpkg/>`_ dependency manager:
+
+.. code-block:: bash
+
+    git clone https://github.com/Microsoft/vcpkg.git
+    cd vcpkg
+    ./bootstrap-vcpkg.sh
+    ./vcpkg integrate install
+    vcpkg install pybind11
+
+The pybind11 port in vcpkg is kept up to date by Microsoft team members and
+community contributors. If the version is out of date, please `create an issue
+or pull request <https://github.com/Microsoft/vcpkg/>`_ on the vcpkg
+repository.
+
 Generating binding code automatically
 =====================================
 
@@ -291,3 +557,10 @@ extensible, and applies to very complex
 classes or incorporating modern meta-programming constructs.
 
 .. [AutoWIG] https://github.com/StatisKit/AutoWIG
+
+[robotpy-build]_ is a is a pure python, cross platform build tool that aims to
+simplify creation of python wheels for pybind11 projects, and provide
+cross-project dependency management. Additionally, it is able to autogenerate
+customizable pybind11-based wrappers by parsing C++ header files.
+
+.. [robotpy-build] https://robotpy-build.readthedocs.io
--- gtsam-4.1.0.orig/wrap/pybind11/docs/faq.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/faq.rst
@@ -285,7 +285,7 @@ CMake code. Conflicts can arise, however
 Python detection in a system with several Python versions installed.
 
 This difference may cause inconsistencies and errors if *both* mechanisms are used in the same project. Consider the following
-Cmake code executed in a system with Python 2.7 and 3.x installed:
+CMake code executed in a system with Python 2.7 and 3.x installed:
 
 .. code-block:: cmake
 
--- gtsam-4.1.0.orig/wrap/pybind11/docs/reference.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/reference.rst
@@ -46,7 +46,7 @@ With reference counting
 Convenience classes for specific Python types
 =============================================
 
-.. doxygenclass:: module
+.. doxygenclass:: module_
     :members:
 
 .. doxygengroup:: pytypes
@@ -91,15 +91,15 @@ Inheritance
 
 See :doc:`/classes` and :doc:`/advanced/classes` for more detail.
 
-.. doxygendefine:: PYBIND11_OVERLOAD
+.. doxygendefine:: PYBIND11_OVERRIDE
 
-.. doxygendefine:: PYBIND11_OVERLOAD_PURE
+.. doxygendefine:: PYBIND11_OVERRIDE_PURE
 
-.. doxygendefine:: PYBIND11_OVERLOAD_NAME
+.. doxygendefine:: PYBIND11_OVERRIDE_NAME
 
-.. doxygendefine:: PYBIND11_OVERLOAD_PURE_NAME
+.. doxygendefine:: PYBIND11_OVERRIDE_PURE_NAME
 
-.. doxygenfunction:: get_overload
+.. doxygenfunction:: get_override
 
 Exceptions
 ==========
--- gtsam-4.1.0.orig/wrap/pybind11/docs/requirements.txt
+++ gtsam-4.1.0/wrap/pybind11/docs/requirements.txt
@@ -1 +1,5 @@
-breathe == 4.5.0
+breathe==4.20.0
+commonmark==0.9.1
+recommonmark==0.6.0
+sphinx==3.2.1
+sphinx_rtd_theme==0.5.0
--- gtsam-4.1.0.orig/wrap/pybind11/docs/upgrade.rst
+++ gtsam-4.1.0/wrap/pybind11/docs/upgrade.rst
@@ -8,6 +8,92 @@ to a new version. But it goes into more
 deprecated APIs and their replacements, build system changes, general code
 modernization and other useful information.
 
+.. _upgrade-guide-2.6:
+
+v2.6
+====
+
+The ``tools/clang`` submodule and ``tools/mkdoc.py`` have been moved to a
+standalone package, `pybind11-mkdoc`_. If you were using those tools, please
+use them via a pip install from the new location.
+
+.. _pybind11-mkdoc: https://github.com/pybind/pybind11-mkdoc
+
+An error is now thrown when ``__init__`` is forgotten on subclasses. This was
+incorrect before, but was not checked. Add a call to ``__init__`` if it is
+missing.
+
+The undocumented ``h.get_type()`` method has been deprecated and replaced by
+``py::type::of(h)``.
+
+If ``__eq__`` defined but not ``__hash__``, ``__hash__`` is now set to
+``None``, as in normal CPython. You should add ``__hash__`` if you intended the
+class to be hashable, possibly using the new ``py::hash`` shortcut.
+
+Usage of the ``PYBIND11_OVERLOAD*`` macros and ``get_overload`` function should
+be replaced by ``PYBIND11_OVERRIDE*`` and ``get_override``. In the future, the
+old macros may be deprecated and removed.
+
+The ``pybind11`` package on PyPI no longer fills the wheel "headers" slot - if
+you were using the headers from this slot, they are available by requesting the
+``global`` extra, that is, ``pip install "pybind11[global]"``. (Most users will
+be unaffected, as the ``pybind11/include`` location is reported by ``python -m
+pybind11 --includes`` and ``pybind11.get_include()`` is still correct and has
+not changed since 2.5).
+
+CMake support:
+--------------
+
+The minimum required version of CMake is now 3.4.  Several details of the CMake
+support have been deprecated; warnings will be shown if you need to change
+something. The changes are:
+
+* ``PYBIND11_CPP_STANDARD=<platform-flag>`` is deprecated, please use
+  ``CMAKE_CXX_STANDARD=<number>`` instead, or any other valid CMake CXX or CUDA
+  standard selection method, like ``target_compile_features``.
+
+* If you do not request a standard, pybind11 targets will compile with the
+  compiler default, but not less than C++11, instead of forcing C++14 always.
+  If you depend on the old behavior, please use ``set(CMAKE_CXX_STANDARD 14)``
+  instead.
+
+* Direct ``pybind11::module`` usage should always be accompanied by at least
+  ``set(CMAKE_CXX_VISIBILITY_PRESET hidden)`` or similar - it used to try to
+  manually force this compiler flag (but not correctly on all compilers or with
+  CUDA).
+
+* ``pybind11_add_module``'s ``SYSTEM`` argument is deprecated and does nothing;
+  linking now behaves like other imported libraries consistently in both
+  config and submodule mode, and behaves like a ``SYSTEM`` library by
+  default.
+
+* If ``PYTHON_EXECUTABLE`` is not set, virtual environments (``venv``,
+  ``virtualenv``, and ``conda``) are prioritized over the standard search
+  (similar to the new FindPython mode).
+
+In addition, the following changes may be of interest:
+
+* ``CMAKE_INTERPROCEDURAL_OPTIMIZATION`` will be respected by
+  ``pybind11_add_module`` if set instead of linking to ``pybind11::lto`` or
+  ``pybind11::thin_lto``.
+
+* Using ``find_package(Python COMPONENTS Interpreter Development)`` before
+  pybind11 will cause pybind11 to use the new Python mechanisms instead of its
+  own custom search, based on a patched version of classic ``FindPythonInterp``
+  / ``FindPythonLibs``. In the future, this may become the default.
+
+
+
+v2.5
+====
+
+The Python package now includes the headers as data in the package itself, as
+well as in the "headers" wheel slot. ``pybind11 --includes`` and
+``pybind11.get_include()`` report the new location, which is always correct
+regardless of how pybind11 was installed, making the old ``user=`` argument
+meaningless. If you are not using the function to get the location already, you
+are encouraged to switch to the package location.
+
 
 v2.2
 ====
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/attr.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/attr.h
@@ -40,8 +40,9 @@ struct sibling { handle value; sibling(c
 
 /// Annotation indicating that a class derives from another given type
 template <typename T> struct base {
+
     PYBIND11_DEPRECATED("base<T>() was deprecated in favor of specifying 'T' as a template argument to class_")
-    base() { }
+    base() { } // NOLINT(modernize-use-equals-default): breaks MSVC 2015 when adding an attribute
 };
 
 /// Keep patient alive while nurse lives
@@ -61,7 +62,7 @@ struct metaclass {
     handle value;
 
     PYBIND11_DEPRECATED("py::metaclass() is no longer required. It's turned on by default now.")
-    metaclass() {}
+    metaclass() { } // NOLINT(modernize-use-equals-default): breaks MSVC 2015 when adding an attribute
 
     /// Override pybind11's default metaclass
     explicit metaclass(handle value) : value(value) { }
@@ -138,7 +139,7 @@ struct function_record {
     function_record()
         : is_constructor(false), is_new_style_constructor(false), is_stateless(false),
           is_operator(false), is_method(false),
-          has_args(false), has_kwargs(false), has_kwonly_args(false) { }
+          has_args(false), has_kwargs(false), has_kw_only_args(false) { }
 
     /// Function name
     char *name = nullptr; /* why no C++ strings? They generate heavier code.. */
@@ -185,14 +186,17 @@ struct function_record {
     /// True if the function has a '**kwargs' argument
     bool has_kwargs : 1;
 
-    /// True once a 'py::kwonly' is encountered (any following args are keyword-only)
-    bool has_kwonly_args : 1;
+    /// True once a 'py::kw_only' is encountered (any following args are keyword-only)
+    bool has_kw_only_args : 1;
 
     /// Number of arguments (including py::args and/or py::kwargs, if present)
     std::uint16_t nargs;
 
     /// Number of trailing arguments (counted in `nargs`) that are keyword-only
-    std::uint16_t nargs_kwonly = 0;
+    std::uint16_t nargs_kw_only = 0;
+
+    /// Number of leading arguments (counted in `nargs`) that are positional-only
+    std::uint16_t nargs_pos_only = 0;
 
     /// Python method object
     PyMethodDef *def = nullptr;
@@ -366,10 +370,10 @@ template <> struct process_attribute<is_
     static void init(const is_new_style_constructor &, function_record *r) { r->is_new_style_constructor = true; }
 };
 
-inline void process_kwonly_arg(const arg &a, function_record *r) {
+inline void process_kw_only_arg(const arg &a, function_record *r) {
     if (!a.name || strlen(a.name) == 0)
-        pybind11_fail("arg(): cannot specify an unnamed argument after an kwonly() annotation");
-    ++r->nargs_kwonly;
+        pybind11_fail("arg(): cannot specify an unnamed argument after an kw_only() annotation");
+    ++r->nargs_kw_only;
 }
 
 /// Process a keyword argument attribute (*without* a default value)
@@ -379,7 +383,7 @@ template <> struct process_attribute<arg
             r->args.emplace_back("self", nullptr, handle(), true /*convert*/, false /*none not allowed*/);
         r->args.emplace_back(a.name, nullptr, handle(), !a.flag_noconvert, a.flag_none);
 
-        if (r->has_kwonly_args) process_kwonly_arg(a, r);
+        if (r->has_kw_only_args) process_kw_only_arg(a, r);
     }
 };
 
@@ -412,14 +416,21 @@ template <> struct process_attribute<arg
         }
         r->args.emplace_back(a.name, a.descr, a.value.inc_ref(), !a.flag_noconvert, a.flag_none);
 
-        if (r->has_kwonly_args) process_kwonly_arg(a, r);
+        if (r->has_kw_only_args) process_kw_only_arg(a, r);
     }
 };
 
 /// Process a keyword-only-arguments-follow pseudo argument
-template <> struct process_attribute<kwonly> : process_attribute_default<kwonly> {
-    static void init(const kwonly &, function_record *r) {
-        r->has_kwonly_args = true;
+template <> struct process_attribute<kw_only> : process_attribute_default<kw_only> {
+    static void init(const kw_only &, function_record *r) {
+        r->has_kw_only_args = true;
+    }
+};
+
+/// Process a positional-only-argument maker
+template <> struct process_attribute<pos_only> : process_attribute_default<pos_only> {
+    static void init(const pos_only &, function_record *r) {
+        r->nargs_pos_only = static_cast<std::uint16_t>(r->args.size());
     }
 };
 
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/buffer_info.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/buffer_info.h
@@ -24,7 +24,7 @@ struct buffer_info {
     std::vector<ssize_t> strides; // Number of bytes between adjacent entries (for each per dimension)
     bool readonly = false;        // flag to indicate if the underlying storage may be written to
 
-    buffer_info() { }
+    buffer_info() = default;
 
     buffer_info(void *ptr, ssize_t itemsize, const std::string &format, ssize_t ndim,
                 detail::any_container<ssize_t> shape_in, detail::any_container<ssize_t> strides_in, bool readonly=false)
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/cast.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/cast.h
@@ -59,7 +59,7 @@ public:
         Py_CLEAR(ptr);
 
         // A heuristic to reduce the stack's capacity (e.g. after long recursive calls)
-        if (stack.capacity() > 16 && stack.size() != 0 && stack.capacity() / stack.size() > 2)
+        if (stack.capacity() > 16 && !stack.empty() && stack.capacity() / stack.size() > 2)
             stack.shrink_to_fit();
     }
 
@@ -163,7 +163,7 @@ inline const std::vector<detail::type_in
  */
 PYBIND11_NOINLINE inline detail::type_info* get_type_info(PyTypeObject *type) {
     auto &bases = all_type_info(type);
-    if (bases.size() == 0)
+    if (bases.empty())
         return nullptr;
     if (bases.size() > 1)
         pybind11_fail("pybind11::detail::get_type_info: type has multiple pybind11-registered bases");
@@ -220,7 +220,7 @@ struct value_and_holder {
     {}
 
     // Default constructor (used to signal a value-and-holder not found by get_value_and_holder())
-    value_and_holder() {}
+    value_and_holder() = default;
 
     // Used for past-the-end iterator
     value_and_holder(size_t index) : index{index} {}
@@ -432,7 +432,7 @@ PYBIND11_NOINLINE inline std::string err
 
 #if !defined(PYPY_VERSION)
     if (scope.trace) {
-        PyTracebackObject *trace = (PyTracebackObject *) scope.trace;
+        auto *trace = (PyTracebackObject *) scope.trace;
 
         /* Get the deepest trace possible */
         while (trace->tb_next)
@@ -458,7 +458,7 @@ PYBIND11_NOINLINE inline handle get_obje
     auto &instances = get_internals().registered_instances;
     auto range = instances.equal_range(ptr);
     for (auto it = range.first; it != range.second; ++it) {
-        for (auto vh : values_and_holders(it->second)) {
+        for (const auto &vh : values_and_holders(it->second)) {
             if (vh.type == type)
                 return handle((PyObject *) it->second);
         }
@@ -636,7 +636,7 @@ public:
     /// native typeinfo, or when the native one wasn't able to produce a value.
     PYBIND11_NOINLINE bool try_load_foreign_module_local(handle src) {
         constexpr auto *local_key = PYBIND11_MODULE_LOCAL_ID;
-        const auto pytype = src.get_type();
+        const auto pytype = type::handle_of(src);
         if (!hasattr(pytype, local_key))
             return false;
 
@@ -1006,6 +1006,7 @@ template <typename CharT> using is_std_c
     std::is_same<CharT, wchar_t> /* std::wstring */
 >;
 
+
 template <typename T>
 struct type_caster<T, enable_if_t<std::is_arithmetic<T>::value && !is_std_char_type<T>::value>> {
     using _py_type_0 = conditional_t<sizeof(T) <= sizeof(long), long, long long>;
@@ -1034,12 +1035,12 @@ public:
                 : (py_type) PYBIND11_LONG_AS_LONGLONG(src.ptr());
         }
 
+        // Python API reported an error
         bool py_err = py_value == (py_type) -1 && PyErr_Occurred();
 
-        // Protect std::numeric_limits::min/max with parentheses
-        if (py_err || (std::is_integral<T>::value && sizeof(py_type) != sizeof(T) &&
-                       (py_value < (py_type) (std::numeric_limits<T>::min)() ||
-                        py_value > (py_type) (std::numeric_limits<T>::max)()))) {
+        // Check to see if the conversion is valid (integers should match exactly)
+        // Signed/unsigned checks happen elsewhere
+        if (py_err || (std::is_integral<T>::value && sizeof(py_type) != sizeof(T) && py_value != (py_type) (T) py_value)) {
             bool type_error = py_err && PyErr_ExceptionMatches(
 #if PY_VERSION_HEX < 0x03000000 && !defined(PYPY_VERSION)
                 PyExc_SystemError
@@ -1129,7 +1130,7 @@ public:
         }
 
         /* Check if this is a C++ type */
-        auto &bases = all_type_info((PyTypeObject *) h.get_type().ptr());
+        auto &bases = all_type_info((PyTypeObject *) type::handle_of(h).ptr());
         if (bases.size() == 1) { // Only allowing loading from a single-value type
             value = values_and_holders(reinterpret_cast<instance *>(h.ptr())).begin()->value_ptr();
             return true;
@@ -1243,7 +1244,7 @@ template <typename StringType, bool IsVi
             load_src.ptr(), UTF_N == 8 ? "utf-8" : UTF_N == 16 ? "utf-16" : "utf-32", nullptr));
         if (!utfNbytes) { PyErr_Clear(); return false; }
 
-        const CharT *buffer = reinterpret_cast<const CharT *>(PYBIND11_BYTES_AS_STRING(utfNbytes.ptr()));
+        const auto *buffer = reinterpret_cast<const CharT *>(PYBIND11_BYTES_AS_STRING(utfNbytes.ptr()));
         size_t length = (size_t) PYBIND11_BYTES_SIZE(utfNbytes.ptr()) / sizeof(CharT);
         if (UTF_N > 8) { buffer++; length--; } // Skip BOM for UTF-16/32
         value = StringType(buffer, length);
@@ -1257,7 +1258,7 @@ template <typename StringType, bool IsVi
 
     static handle cast(const StringType &src, return_value_policy /* policy */, handle /* parent */) {
         const char *buffer = reinterpret_cast<const char *>(src.data());
-        ssize_t nbytes = ssize_t(src.size() * sizeof(CharT));
+        auto nbytes = ssize_t(src.size() * sizeof(CharT));
         handle s = decode_utfN(buffer, nbytes);
         if (!s) throw error_already_set();
         return s;
@@ -1363,7 +1364,7 @@ public:
         // errors.  We also allow want to allow unicode characters U+0080 through U+00FF, as those
         // can fit into a single char value.
         if (StringCaster::UTF_N == 8 && str_len > 1 && str_len <= 4) {
-            unsigned char v0 = static_cast<unsigned char>(value[0]);
+            auto v0 = static_cast<unsigned char>(value[0]);
             size_t char0_bytes = !(v0 & 0x80) ? 1 : // low bits only: 0-127
                 (v0 & 0xE0) == 0xC0 ? 2 : // 0b110xxxxx - start of 2-byte sequence
                 (v0 & 0xF0) == 0xE0 ? 3 : // 0b1110xxxx - start of 3-byte sequence
@@ -1421,6 +1422,17 @@ public:
         return cast_impl(std::forward<T>(src), policy, parent, indices{});
     }
 
+    // copied from the PYBIND11_TYPE_CASTER macro
+    template <typename T>
+    static handle cast(T *src, return_value_policy policy, handle parent) {
+        if (!src) return none().release();
+        if (policy == return_value_policy::take_ownership) {
+            auto h = cast(std::move(*src), policy, parent); delete src; return h;
+        } else {
+            return cast(*src, policy, parent);
+        }
+    }
+
     static constexpr auto name = _("Tuple[") + concat(make_caster<Ts>::name...) + _("]");
 
     template <typename T> using cast_op_type = type;
@@ -1696,7 +1708,7 @@ template <typename T, typename SFINAE> t
         throw cast_error("Unable to cast Python instance to C++ type (compile in debug mode for details)");
 #else
         throw cast_error("Unable to cast Python instance of type " +
-            (std::string) str(handle.get_type()) + " to C++ type '" + type_id<T>() + "'");
+            (std::string) str(type::handle_of(handle)) + " to C++ type '" + type_id<T>() + "'");
 #endif
     }
     return conv;
@@ -1747,7 +1759,7 @@ detail::enable_if_t<!detail::move_never<
         throw cast_error("Unable to cast Python instance to C++ rvalue: instance has multiple references"
             " (compile in debug mode for details)");
 #else
-        throw cast_error("Unable to move from Python " + (std::string) str(obj.get_type()) +
+        throw cast_error("Unable to move from Python " + (std::string) str(type::handle_of(obj)) +
                 " instance to C++ " + type_id<T>() + " instance: instance has multiple references");
 #endif
 
@@ -1756,7 +1768,7 @@ detail::enable_if_t<!detail::move_never<
     return ret;
 }
 
-// Calling cast() on an rvalue calls pybind::cast with the object rvalue, which does:
+// Calling cast() on an rvalue calls pybind11::cast with the object rvalue, which does:
 // - If we have to move (because T has no copy constructor), do it.  This will fail if the moved
 //   object has multiple references, but trying to copy will fail to compile.
 // - If both movable and copyable, check ref count: if 1, move; otherwise copy
@@ -1785,16 +1797,16 @@ PYBIND11_NAMESPACE_BEGIN(detail)
 template <typename T, enable_if_t<!is_pyobject<T>::value, int>>
 object object_or_cast(T &&o) { return pybind11::cast(std::forward<T>(o)); }
 
-struct overload_unused {}; // Placeholder type for the unneeded (and dead code) static variable in the OVERLOAD_INT macro
-template <typename ret_type> using overload_caster_t = conditional_t<
-    cast_is_temporary_value_reference<ret_type>::value, make_caster<ret_type>, overload_unused>;
+struct override_unused {}; // Placeholder type for the unneeded (and dead code) static variable in the PYBIND11_OVERRIDE_OVERRIDE macro
+template <typename ret_type> using override_caster_t = conditional_t<
+    cast_is_temporary_value_reference<ret_type>::value, make_caster<ret_type>, override_unused>;
 
 // Trampoline use: for reference/pointer types to value-converted values, we do a value cast, then
 // store the result in the given variable.  For other types, this is a no-op.
 template <typename T> enable_if_t<cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&o, make_caster<T> &caster) {
     return cast_op<T>(load_type(caster, o));
 }
-template <typename T> enable_if_t<!cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&, overload_unused &) {
+template <typename T> enable_if_t<!cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&, override_unused &) {
     pybind11_fail("Internal error: cast_ref fallback invoked"); }
 
 // Trampoline use: Having a pybind11::cast with an invalid reference type is going to static_assert, even
@@ -1899,7 +1911,12 @@ public:
 /// \ingroup annotations
 /// Annotation indicating that all following arguments are keyword-only; the is the equivalent of an
 /// unnamed '*' argument (in Python 3)
-struct kwonly {};
+struct kw_only {};
+
+/// \ingroup annotations
+/// Annotation indicating that all previous arguments are positional-only; the is the equivalent of an
+/// unnamed '/' argument (in Python 3.8)
+struct pos_only {};
 
 template <typename T>
 arg_v arg::operator=(T &&value) const { return {std::move(*this), std::forward<T>(value)}; }
@@ -1912,7 +1929,7 @@ inline namespace literals {
     String literal version of `arg`
  \endrst */
 constexpr arg operator"" _a(const char *name, size_t) { return arg(name); }
-}
+} // namespace literals
 
 PYBIND11_NAMESPACE_BEGIN(detail)
 
@@ -2187,13 +2204,25 @@ object object_api<Derived>::call(Args &&
 
 PYBIND11_NAMESPACE_END(detail)
 
+
+template<typename T>
+handle type::handle_of() {
+   static_assert(
+      std::is_base_of<detail::type_caster_generic, detail::make_caster<T>>::value,
+      "py::type::of<T> only supports the case where T is a registered C++ types."
+    );
+
+    return detail::get_type_handle(typeid(T), true);
+}
+
+
 #define PYBIND11_MAKE_OPAQUE(...) \
     namespace pybind11 { namespace detail { \
         template<> class type_caster<__VA_ARGS__> : public type_caster_base<__VA_ARGS__> { }; \
     }}
 
 /// Lets you pass a type containing a `,` through a macro parameter without needing a separate
-/// typedef, e.g.: `PYBIND11_OVERLOAD(PYBIND11_TYPE(ReturnType<A, B>), PYBIND11_TYPE(Parent<C, D>), f, arg)`
+/// typedef, e.g.: `PYBIND11_OVERRIDE(PYBIND11_TYPE(ReturnType<A, B>), PYBIND11_TYPE(Parent<C, D>), f, arg)`
 #define PYBIND11_TYPE(...) __VA_ARGS__
 
 PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/chrono.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/chrono.h
@@ -33,9 +33,9 @@ PYBIND11_NAMESPACE_BEGIN(detail)
 template <typename type> class duration_caster {
 public:
     typedef typename type::rep rep;
-    typedef typename type::period period;
+    using period = typename type::period;
 
-    typedef std::chrono::duration<uint_fast32_t, std::ratio<86400>> days;
+    using days = std::chrono::duration<uint_fast32_t, std::ratio<86400>>;
 
     bool load(handle src, bool) {
         using namespace std::chrono;
@@ -98,7 +98,7 @@ public:
 // This is for casting times on the system clock into datetime.datetime instances
 template <typename Duration> class type_caster<std::chrono::time_point<std::chrono::system_clock, Duration>> {
 public:
-    typedef std::chrono::time_point<std::chrono::system_clock, Duration> type;
+    using type = std::chrono::time_point<std::chrono::system_clock, Duration>;
     bool load(handle src, bool) {
         using namespace std::chrono;
 
@@ -140,7 +140,7 @@ public:
         }
         else return false;
 
-        value = system_clock::from_time_t(std::mktime(&cal)) + msecs;
+        value = time_point_cast<Duration>(system_clock::from_time_t(std::mktime(&cal)) + msecs);
         return true;
     }
 
@@ -150,21 +150,28 @@ public:
         // Lazy initialise the PyDateTime import
         if (!PyDateTimeAPI) { PyDateTime_IMPORT; }
 
-        std::time_t tt = system_clock::to_time_t(time_point_cast<system_clock::duration>(src));
+        // Get out microseconds, and make sure they are positive, to avoid bug in eastern hemisphere time zones
+        // (cfr. https://github.com/pybind/pybind11/issues/2417)
+        using us_t = duration<int, std::micro>;
+        auto us = duration_cast<us_t>(src.time_since_epoch() % seconds(1));
+        if (us.count() < 0)
+            us += seconds(1);
+
+        // Subtract microseconds BEFORE `system_clock::to_time_t`, because:
+        // > If std::time_t has lower precision, it is implementation-defined whether the value is rounded or truncated.
+        // (https://en.cppreference.com/w/cpp/chrono/system_clock/to_time_t)
+        std::time_t tt = system_clock::to_time_t(time_point_cast<system_clock::duration>(src - us));
         // this function uses static memory so it's best to copy it out asap just in case
         // otherwise other code that is using localtime may break this (not just python code)
         std::tm localtime = *std::localtime(&tt);
 
-        // Declare these special duration types so the conversions happen with the correct primitive types (int)
-        using us_t = duration<int, std::micro>;
-
         return PyDateTime_FromDateAndTime(localtime.tm_year + 1900,
                                           localtime.tm_mon + 1,
                                           localtime.tm_mday,
                                           localtime.tm_hour,
                                           localtime.tm_min,
                                           localtime.tm_sec,
-                                          (duration_cast<us_t>(src.time_since_epoch() % seconds(1))).count());
+                                          us.count());
     }
     PYBIND11_TYPE_CASTER(type, _("datetime.datetime"));
 };
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/detail/class.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/detail/class.h
@@ -169,7 +169,7 @@ extern "C" inline PyObject *pybind11_met
     auto instance = reinterpret_cast<detail::instance *>(self);
 
     // Ensure that the base __init__ function(s) were called
-    for (auto vh : values_and_holders(instance)) {
+    for (const auto &vh : values_and_holders(instance)) {
         if (!vh.holder_constructed()) {
             PyErr_Format(PyExc_TypeError, "%.200s.__init__() must be called when overriding __init__",
                          vh.type->type->tp_name);
@@ -592,7 +592,7 @@ inline PyObject* make_new_python_type(co
 
     auto &internals = get_internals();
     auto bases = tuple(rec.bases);
-    auto base = (bases.size() == 0) ? internals.instance_base
+    auto base = (bases.empty()) ? internals.instance_base
                                     : bases[0].ptr();
 
     /* Danger zone: from now (and until PyType_Ready), make sure to
@@ -616,7 +616,7 @@ inline PyObject* make_new_python_type(co
     type->tp_doc = tp_doc;
     type->tp_base = type_incref((PyTypeObject *)base);
     type->tp_basicsize = static_cast<ssize_t>(sizeof(instance));
-    if (bases.size() > 0)
+    if (!bases.empty())
         type->tp_bases = bases.release().ptr();
 
     /* Don't inherit base __init__ */
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/detail/common.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/detail/common.h
@@ -9,6 +9,10 @@
 
 #pragma once
 
+#define PYBIND11_VERSION_MAJOR 2
+#define PYBIND11_VERSION_MINOR 6
+#define PYBIND11_VERSION_PATCH 0.dev1
+
 #define PYBIND11_NAMESPACE_BEGIN(name) namespace name {
 #define PYBIND11_NAMESPACE_END(name) }
 
@@ -96,10 +100,6 @@
 #  define PYBIND11_MAYBE_UNUSED __attribute__ ((__unused__))
 #endif
 
-#define PYBIND11_VERSION_MAJOR 2
-#define PYBIND11_VERSION_MINOR 5
-#define PYBIND11_VERSION_PATCH dev1
-
 /* Don't let Python.h #define (v)snprintf as macro because they are implemented
    properly in Visual Studio since 2015. */
 #if defined(_MSC_VER) && _MSC_VER >= 1900
@@ -154,6 +154,7 @@
 #include <vector>
 #include <string>
 #include <stdexcept>
+#include <exception>
 #include <unordered_set>
 #include <unordered_map>
 #include <memory>
@@ -501,8 +502,16 @@ template <bool... Bs> using select_indic
 template <bool B> using bool_constant = std::integral_constant<bool, B>;
 template <typename T> struct negation : bool_constant<!T::value> { };
 
+// PGI cannot detect operator delete with the "compatible" void_t impl, so
+// using the new one (C++14 defect, so generally works on newer compilers, even
+// if not in C++17 mode)
+#if defined(__PGIC__)
+template<typename... > using void_t = void;
+#else
 template <typename...> struct void_t_impl { using type = void; };
 template <typename... Ts> using void_t = typename void_t_impl<Ts...>::type;
+#endif
+
 
 /// Compile-time all/any/none of that check the boolean value of all template types
 #if defined(__cpp_fold_expressions) && !(defined(_MSC_VER) && (_MSC_VER < 1916))
@@ -528,17 +537,17 @@ template <class T, template<class> class
 
 /// Strip the class from a method type
 template <typename T> struct remove_class { };
-template <typename C, typename R, typename... A> struct remove_class<R (C::*)(A...)> { typedef R type(A...); };
-template <typename C, typename R, typename... A> struct remove_class<R (C::*)(A...) const> { typedef R type(A...); };
+template <typename C, typename R, typename... A> struct remove_class<R (C::*)(A...)> { using type = R (A...); };
+template <typename C, typename R, typename... A> struct remove_class<R (C::*)(A...) const> { using type = R (A...); };
 
 /// Helper template to strip away type modifiers
-template <typename T> struct intrinsic_type                       { typedef T type; };
-template <typename T> struct intrinsic_type<const T>              { typedef typename intrinsic_type<T>::type type; };
-template <typename T> struct intrinsic_type<T*>                   { typedef typename intrinsic_type<T>::type type; };
-template <typename T> struct intrinsic_type<T&>                   { typedef typename intrinsic_type<T>::type type; };
-template <typename T> struct intrinsic_type<T&&>                  { typedef typename intrinsic_type<T>::type type; };
-template <typename T, size_t N> struct intrinsic_type<const T[N]> { typedef typename intrinsic_type<T>::type type; };
-template <typename T, size_t N> struct intrinsic_type<T[N]>       { typedef typename intrinsic_type<T>::type type; };
+template <typename T> struct intrinsic_type                       { using type = T; };
+template <typename T> struct intrinsic_type<const T>              { using type = typename intrinsic_type<T>::type; };
+template <typename T> struct intrinsic_type<T*>                   { using type = typename intrinsic_type<T>::type; };
+template <typename T> struct intrinsic_type<T&>                   { using type = typename intrinsic_type<T>::type; };
+template <typename T> struct intrinsic_type<T&&>                  { using type = typename intrinsic_type<T>::type; };
+template <typename T, size_t N> struct intrinsic_type<const T[N]> { using type = typename intrinsic_type<T>::type; };
+template <typename T, size_t N> struct intrinsic_type<T[N]>       { using type = typename intrinsic_type<T>::type; };
 template <typename T> using intrinsic_t = typename intrinsic_type<T>::type;
 
 /// Helper type to replace 'void' in some expressions
@@ -752,7 +761,7 @@ struct nodelete { template <typename T>
 PYBIND11_NAMESPACE_BEGIN(detail)
 template <typename... Args>
 struct overload_cast_impl {
-    constexpr overload_cast_impl() {} // MSVC 2015 needs this
+    constexpr overload_cast_impl() {}; // NOLINT(modernize-use-equals-default):  MSVC 2015 needs this
 
     template <typename Return>
     constexpr auto operator()(Return (*pf)(Args...)) const noexcept
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/detail/init.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/detail/init.h
@@ -132,6 +132,7 @@ void construct(value_and_holder &v_h, Al
 template <typename Class>
 void construct(value_and_holder &v_h, Holder<Class> holder, bool need_alias) {
     auto *ptr = holder_helper<Holder<Class>>::get(holder);
+    no_nullptr(ptr);
     // If we need an alias, check that the held pointer is actually an alias instance
     if (Class::has_alias && need_alias && !is_alias<Class>(ptr))
         throw type_error("pybind11::init(): construction failed: returned holder-wrapped instance "
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/detail/internals.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/detail/internals.h
@@ -82,10 +82,10 @@ struct type_equal_to {
 template <typename value_type>
 using type_map = std::unordered_map<std::type_index, value_type, type_hash, type_equal_to>;
 
-struct overload_hash {
+struct override_hash {
     inline size_t operator()(const std::pair<const PyObject *, const char *>& v) const {
         size_t value = std::hash<const void *>()(v.first);
-        value ^= std::hash<const void *>()(v.second)  + 0x9e3779b9 + (value<<6) + (value>>2);
+        value ^= std::hash<const void *>()(v.second) + 0x9e3779b9 + (value<<6) + (value>>2);
         return value;
     }
 };
@@ -97,7 +97,7 @@ struct internals {
     type_map<type_info *> registered_types_cpp; // std::type_index -> pybind11's type information
     std::unordered_map<PyTypeObject *, std::vector<type_info *>> registered_types_py; // PyTypeObject* -> base type_info(s)
     std::unordered_multimap<const void *, instance*> registered_instances; // void * -> instance*
-    std::unordered_set<std::pair<const PyObject *, const char *>, overload_hash> inactive_overload_cache;
+    std::unordered_set<std::pair<const PyObject *, const char *>, override_hash> inactive_override_cache;
     type_map<std::vector<bool (*)(PyObject *, void *&)>> direct_conversions;
     std::unordered_map<const PyObject *, std::vector<PyObject *>> patients;
     std::forward_list<void (*) (std::exception_ptr)> registered_exception_translators;
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/eigen.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/eigen.h
@@ -553,7 +553,7 @@ struct type_caster<Type, enable_if_t<is_
         object matrix_type = sparse_module.attr(
             rowMajor ? "csr_matrix" : "csc_matrix");
 
-        if (!obj.get_type().is(matrix_type)) {
+        if (!type::handle_of(obj).is(matrix_type)) {
             try {
                 obj = matrix_type(obj);
             } catch (const error_already_set &) {
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/iostream.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/iostream.h
@@ -30,7 +30,7 @@ private:
     object pywrite;
     object pyflush;
 
-    int overflow(int c) {
+    int overflow(int c) override {
         if (!traits_type::eq_int_type(c, traits_type::eof())) {
             *pptr() = traits_type::to_char_type(c);
             pbump(1);
@@ -38,7 +38,10 @@ private:
         return sync() == 0 ? traits_type::not_eof(c) : traits_type::eof();
     }
 
-    int sync() {
+    // This function must be non-virtual to be called in a destructor. If the
+    // rare MSVC test failure shows up with this version, then this should be
+    // simplified to a fully qualified call.
+    int _sync() {
         if (pbase() != pptr()) {
             // This subtraction cannot be negative, so dropping the sign
             str line(pbase(), static_cast<size_t>(pptr() - pbase()));
@@ -54,6 +57,10 @@ private:
         return 0;
     }
 
+    int sync() override {
+        return _sync();
+    }
+
 public:
 
     pythonbuf(object pyostream, size_t buffer_size = 1024)
@@ -67,8 +74,8 @@ public:
     pythonbuf(pythonbuf&&) = default;
 
     /// Sync before destroy
-    ~pythonbuf() {
-        sync();
+    ~pythonbuf() override {
+        _sync();
     }
 };
 
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/numpy.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/numpy.h
@@ -222,7 +222,7 @@ private:
     };
 
     static npy_api lookup() {
-        module m = module::import("numpy.core.multiarray");
+        module_ m = module::import("numpy.core.multiarray");
         auto c = m.attr("_ARRAY_API");
 #if PY_MAJOR_VERSION >= 3
         void **api_ptr = (void **) PyCapsule_GetPointer(c.ptr(), NULL);
@@ -281,7 +281,7 @@ template <typename T> struct is_complex
 template <typename T> struct is_complex<std::complex<T>> : std::true_type { };
 
 template <typename T> struct array_info_scalar {
-    typedef T type;
+    using type = T;
     static constexpr bool is_array = false;
     static constexpr bool is_empty = false;
     static constexpr auto extents = _("");
@@ -550,7 +550,7 @@ public:
         forcecast = detail::npy_api::NPY_ARRAY_FORCECAST_
     };
 
-    array() : array({{0}}, static_cast<const double *>(nullptr)) {}
+    array() : array(0, static_cast<const double *>(nullptr)) {}
 
     using ShapeContainer = detail::any_container<ssize_t>;
     using StridesContainer = detail::any_container<ssize_t>;
@@ -611,8 +611,8 @@ public:
     template <typename T>
     explicit array(ssize_t count, const T *ptr, handle base = handle()) : array({count}, {}, ptr, base) { }
 
-    explicit array(const buffer_info &info)
-    : array(pybind11::dtype(info), info.shape, info.strides, info.ptr) { }
+    explicit array(const buffer_info &info, handle base = handle())
+    : array(pybind11::dtype(info), info.shape, info.strides, info.ptr, base) { }
 
     /// Array descriptor (dtype)
     pybind11::dtype dtype() const {
@@ -858,7 +858,7 @@ public:
         if (!m_ptr) throw error_already_set();
     }
 
-    explicit array_t(const buffer_info& info) : array(info) { }
+    explicit array_t(const buffer_info& info, handle base = handle()) : array(info, base) { }
 
     array_t(ShapeContainer shape, StridesContainer strides, const T *ptr = nullptr, handle base = handle())
         : array(std::move(shape), std::move(strides), ptr, base) { }
@@ -934,7 +934,8 @@ public:
     static bool check_(handle h) {
         const auto &api = detail::npy_api::get();
         return api.PyArray_Check_(h.ptr())
-               && api.PyArray_EquivTypes_(detail::array_proxy(h.ptr())->descr, dtype::of<T>().ptr());
+               && api.PyArray_EquivTypes_(detail::array_proxy(h.ptr())->descr, dtype::of<T>().ptr())
+               && detail::check_flags(h.ptr(), ExtraFlags & (array::c_style | array::f_style));
     }
 
 protected:
@@ -1295,7 +1296,7 @@ public:
         m_strides.back() = static_cast<value_type>(strides.back());
         for (size_type i = m_strides.size() - 1; i != 0; --i) {
             size_type j = i - 1;
-            value_type s = static_cast<value_type>(shape[i]);
+            auto s = static_cast<value_type>(shape[i]);
             m_strides[j] = strides[j] + m_strides[i] - strides[i] * s;
         }
     }
@@ -1483,7 +1484,14 @@ struct vectorize_arg {
 
 template <typename Func, typename Return, typename... Args>
 struct vectorize_helper {
+
+// NVCC for some reason breaks if NVectorized is private
+#ifdef __CUDACC__
+public:
+#else
 private:
+#endif
+
     static constexpr size_t N = sizeof...(Args);
     static constexpr size_t NVectorized = constexpr_sum(vectorize_arg<Args>::vectorize...);
     static_assert(NVectorized >= 1,
@@ -1531,7 +1539,7 @@ private:
         ssize_t nd = 0;
         std::vector<ssize_t> shape(0);
         auto trivial = broadcast(buffers, nd, shape);
-        size_t ndim = (size_t) nd;
+        auto ndim = (size_t) nd;
 
         size_t size = std::accumulate(shape.begin(), shape.end(), (size_t) 1, std::multiplies<size_t>());
 
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/pybind11.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/pybind11.h
@@ -55,7 +55,7 @@ PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESP
 /// Wraps an arbitrary C++ function/method/lambda function/.. into a callable Python object
 class cpp_function : public function {
 public:
-    cpp_function() { }
+    cpp_function() = default;
     cpp_function(std::nullptr_t) { }
 
     /// Construct a cpp_function from a vanilla function pointer
@@ -165,7 +165,7 @@ protected:
             /* Get a pointer to the capture object */
             auto data = (sizeof(capture) <= sizeof(call.func.data)
                          ? &call.func.data : call.func.data[0]);
-            capture *cap = const_cast<capture *>(reinterpret_cast<const capture *>(data));
+            auto *cap = const_cast<capture *>(reinterpret_cast<const capture *>(data));
 
             /* Override policy for rvalues -- usually to enforce rvp::move on an rvalue */
             return_value_policy policy = return_value_policy_override<Return>::policy(call.func.policy);
@@ -187,11 +187,13 @@ protected:
         process_attributes<Extra...>::init(extra..., rec);
 
         {
-            constexpr bool has_kwonly_args = any_of<std::is_same<kwonly, Extra>...>::value,
+            constexpr bool has_kw_only_args = any_of<std::is_same<kw_only, Extra>...>::value,
+                           has_pos_only_args = any_of<std::is_same<pos_only, Extra>...>::value,
                            has_args = any_of<std::is_same<args, Args>...>::value,
                            has_arg_annotations = any_of<is_keyword<Extra>...>::value;
-            static_assert(has_arg_annotations || !has_kwonly_args, "py::kwonly requires the use of argument annotations");
-            static_assert(!(has_args && has_kwonly_args), "py::kwonly cannot be combined with a py::args argument");
+            static_assert(has_arg_annotations || !has_kw_only_args, "py::kw_only requires the use of argument annotations");
+            static_assert(has_arg_annotations || !has_pos_only_args, "py::pos_only requires the use of argument annotations (for docstrings and aligning the annotations to the argument)");
+            static_assert(!(has_args && has_kw_only_args), "py::kw_only cannot be combined with a py::args argument");
         }
 
         /* Generate a readable signature describing the function's arguments and return value types */
@@ -228,7 +230,7 @@ protected:
             if (a.descr)
                 a.descr = strdup(a.descr);
             else if (a.value)
-                a.descr = strdup(a.value.attr("__repr__")().cast<std::string>().c_str());
+                a.descr = strdup(repr(a.value).cast<std::string>().c_str());
         }
 
         rec->is_constructor = !strcmp(rec->name, "__init__") || !strcmp(rec->name, "__setstate__");
@@ -257,7 +259,10 @@ protected:
                 // Write arg name for everything except *args and **kwargs.
                 if (*(pc + 1) == '*')
                     continue;
-
+                // Separator for keyword-only arguments, placed before the kw
+                // arguments start
+                if (rec->nargs_kw_only > 0 && arg_index + rec->nargs_kw_only == args)
+                    signature += "*, ";
                 if (arg_index < rec->args.size() && rec->args[arg_index].name) {
                     signature += rec->args[arg_index].name;
                 } else if (arg_index == 0 && rec->is_method) {
@@ -272,6 +277,10 @@ protected:
                     signature += " = ";
                     signature += rec->args[arg_index].descr;
                 }
+                // Separator for positional-only arguments (placed after the
+                // argument, rather than before like *
+                if (rec->nargs_pos_only > 0 && (arg_index + 1) == rec->nargs_pos_only)
+                    signature += ", /";
                 arg_index++;
             } else if (c == '%') {
                 const std::type_info *t = types[type_index++];
@@ -297,6 +306,7 @@ protected:
                 signature += c;
             }
         }
+
         if (arg_index != args || types[type_index] != nullptr)
             pybind11_fail("Internal error while parsing type signature (2)");
 
@@ -410,7 +420,7 @@ protected:
         }
 
         /* Install docstring */
-        PyCFunctionObject *func = (PyCFunctionObject *) m_ptr;
+        auto *func = (PyCFunctionObject *) m_ptr;
         if (func->m_ml->ml_doc)
             std::free(const_cast<char *>(func->m_ml->ml_doc));
         func->m_ml->ml_doc = strdup(signatures.c_str());
@@ -455,7 +465,7 @@ protected:
                               *it = overloads;
 
         /* Need to know how many arguments + keyword arguments there are to pick the right overload */
-        const size_t n_args_in = (size_t) PyTuple_GET_SIZE(args_in);
+        const auto n_args_in = (size_t) PyTuple_GET_SIZE(args_in);
 
         handle parent = n_args_in > 0 ? PyTuple_GET_ITEM(args_in, 0) : nullptr,
                result = PYBIND11_TRY_NEXT_OVERLOAD;
@@ -512,7 +522,7 @@ protected:
                 size_t num_args = func.nargs;    // Number of positional arguments that we need
                 if (func.has_args) --num_args;   // (but don't count py::args
                 if (func.has_kwargs) --num_args; //  or py::kwargs)
-                size_t pos_args = num_args - func.nargs_kwonly;
+                size_t pos_args = num_args - func.nargs_kw_only;
 
                 if (!func.has_args && n_args_in > pos_args)
                     continue; // Too many positional arguments for this overload
@@ -533,7 +543,7 @@ protected:
                         self_value_and_holder.type->dealloc(self_value_and_holder);
 
                     call.init_self = PyTuple_GET_ITEM(args_in, 0);
-                    call.args.push_back(reinterpret_cast<PyObject *>(&self_value_and_holder));
+                    call.args.emplace_back(reinterpret_cast<PyObject *>(&self_value_and_holder));
                     call.args_convert.push_back(false);
                     ++args_copied;
                 }
@@ -561,6 +571,26 @@ protected:
                 // We'll need to copy this if we steal some kwargs for defaults
                 dict kwargs = reinterpret_borrow<dict>(kwargs_in);
 
+                // 1.5. Fill in any missing pos_only args from defaults if they exist
+                if (args_copied < func.nargs_pos_only) {
+                    for (; args_copied < func.nargs_pos_only; ++args_copied) {
+                        const auto &arg = func.args[args_copied];
+                        handle value;
+
+                        if (arg.value) {
+                            value = arg.value;
+                        }
+                        if (value) {
+                            call.args.push_back(value);
+                            call.args_convert.push_back(arg.convert);
+                        } else
+                            break;
+                    }
+
+                    if (args_copied < func.nargs_pos_only)
+                        continue; // Not enough defaults to fill the positional arguments
+                }
+
                 // 2. Check kwargs and, failing that, defaults that may help complete the list
                 if (args_copied < num_args) {
                     bool copied_kwargs = false;
@@ -596,7 +626,7 @@ protected:
                 }
 
                 // 3. Check everything was consumed (unless we have a kwargs arg)
-                if (kwargs && kwargs.size() > 0 && !func.has_kwargs)
+                if (kwargs && !kwargs.empty() && !func.has_kwargs)
                     continue; // Unconsumed kwargs, but no py::kwargs argument to accept them
 
                 // 4a. If we have a py::args argument, create a new tuple with leftovers
@@ -776,18 +806,27 @@ protected:
             for (size_t ti = overloads->is_constructor ? 1 : 0; ti < args_.size(); ++ti) {
                 if (!some_args) some_args = true;
                 else msg += ", ";
-                msg += pybind11::repr(args_[ti]);
+                try {
+                    msg += pybind11::repr(args_[ti]);
+                } catch (const error_already_set&) {
+                    msg += "<repr raised Error>";
+                }
             }
             if (kwargs_in) {
                 auto kwargs = reinterpret_borrow<dict>(kwargs_in);
-                if (kwargs.size() > 0) {
+                if (!kwargs.empty()) {
                     if (some_args) msg += "; ";
                     msg += "kwargs: ";
                     bool first = true;
                     for (auto kwarg : kwargs) {
                         if (first) first = false;
                         else msg += ", ";
-                        msg += pybind11::str("{}={!r}").format(kwarg.first, kwarg.second);
+                        msg += pybind11::str("{}=").format(kwarg.first);
+                        try {
+                            msg += pybind11::repr(kwarg.second);
+                        } catch (const error_already_set&) {
+                            msg += "<repr raised Error>";
+                        }
                     }
                 }
             }
@@ -813,15 +852,15 @@ protected:
 };
 
 /// Wrapper for Python extension modules
-class module : public object {
+class module_ : public object {
 public:
-    PYBIND11_OBJECT_DEFAULT(module, object, PyModule_Check)
+    PYBIND11_OBJECT_DEFAULT(module_, object, PyModule_Check)
 
     /// Create a new top-level Python module with the given name and docstring
-    explicit module(const char *name, const char *doc = nullptr) {
+    explicit module_(const char *name, const char *doc = nullptr) {
         if (!options::show_user_defined_docstrings()) doc = nullptr;
 #if PY_MAJOR_VERSION >= 3
-        PyModuleDef *def = new PyModuleDef();
+        auto *def = new PyModuleDef();
         std::memset(def, 0, sizeof(PyModuleDef));
         def->m_name = name;
         def->m_doc = doc;
@@ -832,7 +871,7 @@ public:
         m_ptr = Py_InitModule3(name, nullptr, doc);
 #endif
         if (m_ptr == nullptr)
-            pybind11_fail("Internal error in module::module()");
+            pybind11_fail("Internal error in module_::module_()");
         inc_ref();
     }
 
@@ -842,7 +881,7 @@ public:
         details on the ``Extra&& ... extra`` argument, see section :ref:`extras`.
     \endrst */
     template <typename Func, typename... Extra>
-    module &def(const char *name_, Func &&f, const Extra& ... extra) {
+    module_ &def(const char *name_, Func &&f, const Extra& ... extra) {
         cpp_function func(std::forward<Func>(f), name(name_), scope(*this),
                           sibling(getattr(*this, name_, none())), extra...);
         // NB: allow overwriting here because cpp_function sets up a chain with the intention of
@@ -861,10 +900,10 @@ public:
             py::module m2 = m.def_submodule("sub", "A submodule of 'example'");
             py::module m3 = m2.def_submodule("subsub", "A submodule of 'example.sub'");
     \endrst */
-    module def_submodule(const char *name, const char *doc = nullptr) {
+    module_ def_submodule(const char *name, const char *doc = nullptr) {
         std::string full_name = std::string(PyModule_GetName(m_ptr))
             + std::string(".") + std::string(name);
-        auto result = reinterpret_borrow<module>(PyImport_AddModule(full_name.c_str()));
+        auto result = reinterpret_borrow<module_>(PyImport_AddModule(full_name.c_str()));
         if (doc && options::show_user_defined_docstrings())
             result.attr("__doc__") = pybind11::str(doc);
         attr(name) = result;
@@ -872,11 +911,11 @@ public:
     }
 
     /// Import and return a module or throws `error_already_set`.
-    static module import(const char *name) {
+    static module_ import(const char *name) {
         PyObject *obj = PyImport_ImportModule(name);
         if (!obj)
             throw error_already_set();
-        return reinterpret_steal<module>(obj);
+        return reinterpret_steal<module_>(obj);
     }
 
     /// Reload the module or throws `error_already_set`.
@@ -884,7 +923,7 @@ public:
         PyObject *obj = PyImport_ReloadModule(ptr());
         if (!obj)
             throw error_already_set();
-        *this = reinterpret_steal<module>(obj);
+        *this = reinterpret_steal<module_>(obj);
     }
 
     // Adds an object to the module using the given name.  Throws if an object with the given name
@@ -901,6 +940,8 @@ public:
     }
 };
 
+using module = module_;
+
 /// \ingroup python_builtins
 /// Return a dictionary representing the global variables in the current execution frame,
 /// or ``__main__.__dict__`` if there is no frame (usually when the interpreter is embedded).
@@ -981,7 +1022,7 @@ protected:
     void install_buffer_funcs(
             buffer_info *(*get_buffer)(PyObject *, void *),
             void *get_buffer_data) {
-        PyHeapTypeObject *type = (PyHeapTypeObject*) m_ptr;
+        auto *type = (PyHeapTypeObject*) m_ptr;
         auto tinfo = detail::get_type_info(&type->ht_type);
 
         if (!type->ht_type.tp_as_buffer)
@@ -1047,6 +1088,13 @@ inline void call_operator_delete(void *p
     #endif
 }
 
+inline void add_class_method(object& cls, const char *name_, const cpp_function &cf) {
+    cls.attr(cf.name()) = cf;
+    if (strcmp(name_, "__eq__") == 0 && !cls.attr("__dict__").contains("__hash__")) {
+      cls.attr("__hash__") = none();
+    }
+}
+
 PYBIND11_NAMESPACE_END(detail)
 
 /// Given a pointer to a member function, cast it to its `Derived` version.
@@ -1144,7 +1192,7 @@ public:
     class_ &def(const char *name_, Func&& f, const Extra&... extra) {
         cpp_function cf(method_adaptor<type>(std::forward<Func>(f)), name(name_), is_method(*this),
                         sibling(getattr(*this, name_, none())), extra...);
-        attr(cf.name()) = cf;
+        add_class_method(*this, name_, cf);
         return *this;
     }
 
@@ -1196,7 +1244,7 @@ public:
 
     template <typename Func> class_& def_buffer(Func &&func) {
         struct capture { Func func; };
-        capture *ptr = new capture { std::forward<Func>(func) };
+        auto *ptr = new capture { std::forward<Func>(func) };
         install_buffer_funcs([](PyObject *obj, void *ptr) -> buffer_info* {
             detail::make_caster<type> caster;
             if (!caster.load(obj, false))
@@ -1381,6 +1429,13 @@ private:
 
     /// Deallocates an instance; via holder, if constructed; otherwise via operator delete.
     static void dealloc(detail::value_and_holder &v_h) {
+        // We could be deallocating because we are cleaning up after a Python exception.
+        // If so, the Python error indicator will be set. We need to clear that before
+        // running the destructor, in case the destructor code calls more Python.
+        // If we don't, the Python API will exit with an exception, and pybind11 will
+        // throw error_already_set from the C++ destructor which is forbidden and triggers
+        // std::terminate().
+        error_scope scope;
         if (v_h.holder_constructed()) {
             v_h.holder<holder_type>().~holder_type();
             v_h.set_holder_constructed(false);
@@ -1436,7 +1491,7 @@ struct enum_base {
 
         m_base.attr("__repr__") = cpp_function(
             [](handle arg) -> str {
-                handle type = arg.get_type();
+                handle type = type::handle_of(arg);
                 object type_name = type.attr("__name__");
                 dict entries = type.attr("__entries");
                 for (const auto &kv : entries) {
@@ -1450,7 +1505,7 @@ struct enum_base {
 
         m_base.attr("name") = property(cpp_function(
             [](handle arg) -> str {
-                dict entries = arg.get_type().attr("__entries");
+                dict entries = type::handle_of(arg).attr("__entries");
                 for (const auto &kv : entries) {
                     if (handle(kv.second[int_(0)]).equal(arg))
                         return pybind11::str(kv.first);
@@ -1489,7 +1544,7 @@ struct enum_base {
         #define PYBIND11_ENUM_OP_STRICT(op, expr, strict_behavior)                     \
             m_base.attr(op) = cpp_function(                                            \
                 [](object a, object b) {                                               \
-                    if (!a.get_type().is(b.get_type()))                                \
+                    if (!type::handle_of(a).is(type::handle_of(b)))                    \
                         strict_behavior;                                               \
                     return expr;                                                       \
                 },                                                                     \
@@ -1736,7 +1791,7 @@ template <return_value_policy Policy = r
           typename KeyType = decltype((*std::declval<Iterator>()).first),
           typename... Extra>
 iterator make_key_iterator(Iterator first, Sentinel last, Extra &&... extra) {
-    typedef detail::iterator_state<Iterator, Sentinel, true, Policy> state;
+    using state = detail::iterator_state<Iterator, Sentinel, true, Policy>;
 
     if (!detail::get_type_info(typeid(state), false)) {
         class_<state>(handle(), "iterator", pybind11::module_local())
@@ -1815,10 +1870,10 @@ template <typename type>
 class exception : public object {
 public:
     exception() = default;
-    exception(handle scope, const char *name, PyObject *base = PyExc_Exception) {
+    exception(handle scope, const char *name, handle base = PyExc_Exception) {
         std::string full_name = scope.attr("__name__").cast<std::string>() +
                                 std::string(".") + name;
-        m_ptr = PyErr_NewException(const_cast<char *>(full_name.c_str()), base, NULL);
+        m_ptr = PyErr_NewException(const_cast<char *>(full_name.c_str()), base.ptr(), NULL);
         if (hasattr(scope, name))
             pybind11_fail("Error during initialization: multiple incompatible "
                           "definitions with name \"" + std::string(name) + "\"");
@@ -1848,7 +1903,7 @@ PYBIND11_NAMESPACE_END(detail)
 template <typename CppException>
 exception<CppException> &register_exception(handle scope,
                                             const char *name,
-                                            PyObject *base = PyExc_Exception) {
+                                            handle base = PyExc_Exception) {
     auto &ex = detail::get_exception_object<CppException>();
     if (!ex) ex = exception<CppException>(scope, name, base);
 
@@ -2057,21 +2112,22 @@ error_already_set::~error_already_set()
     }
 }
 
-inline function get_type_overload(const void *this_ptr, const detail::type_info *this_type, const char *name)  {
-    handle self = detail::get_object_handle(this_ptr, this_type);
+PYBIND11_NAMESPACE_BEGIN(detail)
+inline function get_type_override(const void *this_ptr, const type_info *this_type, const char *name)  {
+    handle self = get_object_handle(this_ptr, this_type);
     if (!self)
         return function();
-    handle type = self.get_type();
+    handle type = type::handle_of(self);
     auto key = std::make_pair(type.ptr(), name);
 
-    /* Cache functions that aren't overloaded in Python to avoid
+    /* Cache functions that aren't overridden in Python to avoid
        many costly Python dictionary lookups below */
-    auto &cache = detail::get_internals().inactive_overload_cache;
+    auto &cache = get_internals().inactive_override_cache;
     if (cache.find(key) != cache.end())
         return function();
 
-    function overload = getattr(self, name, function());
-    if (overload.is_cpp_function()) {
+    function override = getattr(self, name, function());
+    if (override.is_cpp_function()) {
         cache.insert(key);
         return function();
     }
@@ -2111,34 +2167,36 @@ inline function get_type_overload(const
     Py_DECREF(result);
 #endif
 
-    return overload;
+    return override;
 }
+PYBIND11_NAMESPACE_END(detail)
 
 /** \rst
   Try to retrieve a python method by the provided name from the instance pointed to by the this_ptr.
 
-  :this_ptr: The pointer to the object the overload should be retrieved for. This should be the first
-                   non-trampoline class encountered in the inheritance chain.
-  :name: The name of the overloaded Python method to retrieve.
+  :this_ptr: The pointer to the object the overriden method should be retrieved for. This should be
+             the first non-trampoline class encountered in the inheritance chain.
+  :name: The name of the overridden Python method to retrieve.
   :return: The Python method by this name from the object or an empty function wrapper.
  \endrst */
-template <class T> function get_overload(const T *this_ptr, const char *name) {
+template <class T> function get_override(const T *this_ptr, const char *name) {
     auto tinfo = detail::get_type_info(typeid(T));
-    return tinfo ? get_type_overload(this_ptr, tinfo, name) : function();
+    return tinfo ? detail::get_type_override(this_ptr, tinfo, name) : function();
 }
 
-#define PYBIND11_OVERLOAD_INT(ret_type, cname, name, ...) { \
+#define PYBIND11_OVERRIDE_IMPL(ret_type, cname, name, ...) \
+    do { \
         pybind11::gil_scoped_acquire gil; \
-        pybind11::function overload = pybind11::get_overload(static_cast<const cname *>(this), name); \
-        if (overload) { \
-            auto o = overload(__VA_ARGS__); \
+        pybind11::function override = pybind11::get_override(static_cast<const cname *>(this), name); \
+        if (override) { \
+            auto o = override(__VA_ARGS__); \
             if (pybind11::detail::cast_is_temporary_value_reference<ret_type>::value) { \
-                static pybind11::detail::overload_caster_t<ret_type> caster; \
+                static pybind11::detail::override_caster_t<ret_type> caster; \
                 return pybind11::detail::cast_ref<ret_type>(std::move(o), caster); \
             } \
             else return pybind11::detail::cast_safe<ret_type>(std::move(o)); \
         } \
-    }
+    } while (false)
 
 /** \rst
     Macro to populate the virtual method in the trampoline class. This macro tries to look up a method named 'fn'
@@ -2149,7 +2207,7 @@ template <class T> function get_overload
     .. code-block:: cpp
 
       std::string toString() override {
-        PYBIND11_OVERLOAD_NAME(
+        PYBIND11_OVERRIDE_NAME(
             std::string, // Return type (ret_type)
             Animal,      // Parent class (cname)
             "__str__",   // Name of method in Python (name)
@@ -2157,17 +2215,21 @@ template <class T> function get_overload
         );
       }
 \endrst */
-#define PYBIND11_OVERLOAD_NAME(ret_type, cname, name, fn, ...) \
-    PYBIND11_OVERLOAD_INT(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__) \
-    return cname::fn(__VA_ARGS__)
+#define PYBIND11_OVERRIDE_NAME(ret_type, cname, name, fn, ...) \
+    do { \
+        PYBIND11_OVERRIDE_IMPL(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__); \
+        return cname::fn(__VA_ARGS__); \
+    } while (false)
 
 /** \rst
-    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERLOAD_NAME`, except that it
-    throws if no overload can be found.
+    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERRIDE_NAME`, except that it
+    throws if no override can be found.
 \endrst */
-#define PYBIND11_OVERLOAD_PURE_NAME(ret_type, cname, name, fn, ...) \
-    PYBIND11_OVERLOAD_INT(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__) \
-    pybind11::pybind11_fail("Tried to call pure virtual function \"" PYBIND11_STRINGIFY(cname) "::" name "\"");
+#define PYBIND11_OVERRIDE_PURE_NAME(ret_type, cname, name, fn, ...) \
+    do { \
+        PYBIND11_OVERRIDE_IMPL(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__); \
+        pybind11::pybind11_fail("Tried to call pure virtual function \"" PYBIND11_STRINGIFY(cname) "::" name "\""); \
+    } while (false)
 
 /** \rst
     Macro to populate the virtual method in the trampoline class. This macro tries to look up the method
@@ -2184,7 +2246,7 @@ template <class T> function get_overload
 
           // Trampoline (need one for each virtual function)
           std::string go(int n_times) override {
-              PYBIND11_OVERLOAD_PURE(
+              PYBIND11_OVERRIDE_PURE(
                   std::string, // Return type (ret_type)
                   Animal,      // Parent class (cname)
                   go,          // Name of function in C++ (must match Python name) (fn)
@@ -2193,15 +2255,39 @@ template <class T> function get_overload
           }
       };
 \endrst */
-#define PYBIND11_OVERLOAD(ret_type, cname, fn, ...) \
-    PYBIND11_OVERLOAD_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
+#define PYBIND11_OVERRIDE(ret_type, cname, fn, ...) \
+    PYBIND11_OVERRIDE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
 
 /** \rst
-    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERLOAD`, except that it throws
-    if no overload can be found.
+    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERRIDE`, except that it throws
+    if no override can be found.
 \endrst */
+#define PYBIND11_OVERRIDE_PURE(ret_type, cname, fn, ...) \
+    PYBIND11_OVERRIDE_PURE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
+
+
+// Deprecated versions
+
+PYBIND11_DEPRECATED("get_type_overload has been deprecated")
+inline function get_type_overload(const void *this_ptr, const detail::type_info *this_type, const char *name) {
+    return detail::get_type_override(this_ptr, this_type, name);
+}
+
+template <class T>
+inline function get_overload(const T *this_ptr, const char *name) {
+    return get_override(this_ptr, name);
+}
+
+#define PYBIND11_OVERLOAD_INT(ret_type, cname, name, ...) \
+    PYBIND11_OVERRIDE_IMPL(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__)
+#define PYBIND11_OVERLOAD_NAME(ret_type, cname, name, fn, ...) \
+    PYBIND11_OVERRIDE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, fn, __VA_ARGS__)
+#define PYBIND11_OVERLOAD_PURE_NAME(ret_type, cname, name, fn, ...) \
+    PYBIND11_OVERRIDE_PURE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, fn, __VA_ARGS__);
+#define PYBIND11_OVERLOAD(ret_type, cname, fn, ...) \
+    PYBIND11_OVERRIDE(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), fn, __VA_ARGS__)
 #define PYBIND11_OVERLOAD_PURE(ret_type, cname, fn, ...) \
-    PYBIND11_OVERLOAD_PURE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
+    PYBIND11_OVERRIDE_PURE(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), fn, __VA_ARGS__);
 
 PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
 
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/pytypes.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/pytypes.h
@@ -19,6 +19,7 @@ PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESP
 /* A few forward declarations */
 class handle; class object;
 class str; class iterator;
+class type;
 struct arg; struct arg_v;
 
 PYBIND11_NAMESPACE_BEGIN(detail)
@@ -34,7 +35,7 @@ namespace accessor_policies {
     struct sequence_item;
     struct list_item;
     struct tuple_item;
-}
+} // namespace accessor_policies
 using obj_attr_accessor = accessor<accessor_policies::obj_attr>;
 using str_attr_accessor = accessor<accessor_policies::str_attr>;
 using item_accessor = accessor<accessor_policies::generic_item>;
@@ -151,7 +152,8 @@ public:
 
     /// Return the object's current reference count
     int ref_count() const { return static_cast<int>(Py_REFCNT(derived().ptr())); }
-    /// Return a handle to the Python type object underlying the instance
+
+    PYBIND11_DEPRECATED("Call py::type::handle_of(h) or py::type::of(h) instead of h.get_type()")
     handle get_type() const;
 
 private:
@@ -240,7 +242,7 @@ public:
     ~object() { dec_ref(); }
 
     /** \rst
-        Resets the internal pointer to ``nullptr`` without without decreasing the
+        Resets the internal pointer to ``nullptr`` without decreasing the
         object's reference count. The function returns a raw handle to the original
         Python object.
     \endrst */
@@ -330,13 +332,27 @@ public:
     error_already_set(const error_already_set &) = default;
     error_already_set(error_already_set &&) = default;
 
-    inline ~error_already_set();
+    inline ~error_already_set() override;
 
     /// Give the currently-held error back to Python, if any.  If there is currently a Python error
     /// already set it is cleared first.  After this call, the current object no longer stores the
     /// error variables (but the `.what()` string is still available).
     void restore() { PyErr_Restore(m_type.release().ptr(), m_value.release().ptr(), m_trace.release().ptr()); }
 
+    /// If it is impossible to raise the currently-held error, such as in destructor, we can write
+    /// it out using Python's unraisable hook (sys.unraisablehook). The error context should be
+    /// some object whose repr() helps identify the location of the error. Python already knows the
+    /// type and value of the error, so there is no need to repeat that. For example, __func__ could
+    /// be helpful. After this call, the current object no longer stores the error variables,
+    /// and neither does Python.
+    void discard_as_unraisable(object err_context) {
+        restore();
+        PyErr_WriteUnraisable(err_context.ptr());
+    }
+    void discard_as_unraisable(const char *err_context) {
+        discard_as_unraisable(reinterpret_steal<object>(PYBIND11_FROM_STRING(err_context)));
+    }
+
     // Does nothing; provided for backwards compatibility.
     PYBIND11_DEPRECATED("Use of error_already_set.clear() is deprecated")
     void clear() {}
@@ -370,7 +386,7 @@ bool isinstance(handle obj) { return T::
 template <typename T, detail::enable_if_t<!std::is_base_of<object, T>::value, int> = 0>
 bool isinstance(handle obj) { return detail::isinstance_generic(obj, typeid(T)); }
 
-template <> inline bool isinstance<handle>(handle obj) = delete;
+template <> inline bool isinstance<handle>(handle) = delete;
 template <> inline bool isinstance<object>(handle obj) { return obj.ptr() != nullptr; }
 
 /// \ingroup python_builtins
@@ -736,9 +752,7 @@ inline bool PyIterable_Check(PyObject *o
 }
 
 inline bool PyNone_Check(PyObject *o) { return o == Py_None; }
-#if PY_MAJOR_VERSION >= 3
 inline bool PyEllipsis_Check(PyObject *o) { return o == Py_Ellipsis; }
-#endif
 
 inline bool PyUnicode_Check_Permissive(PyObject *o) { return PyUnicode_Check(o) || PYBIND11_BYTES_CHECK(o); }
 
@@ -784,7 +798,9 @@ PYBIND11_NAMESPACE_END(detail)
         Name(handle h, stolen_t) : Parent(h, stolen_t{}) { } \
         PYBIND11_DEPRECATED("Use py::isinstance<py::python_type>(obj) instead") \
         bool check() const { return m_ptr != nullptr && (bool) CheckFun(m_ptr); } \
-        static bool check_(handle h) { return h.ptr() != nullptr && CheckFun(h.ptr()); }
+        static bool check_(handle h) { return h.ptr() != nullptr && CheckFun(h.ptr()); } \
+        template <typename Policy_> \
+        Name(const ::pybind11::detail::accessor<Policy_> &a) : Name(object(a)) { }
 
 #define PYBIND11_OBJECT_CVT(Name, Parent, CheckFun, ConvertFun) \
     PYBIND11_OBJECT_COMMON(Name, Parent, CheckFun) \
@@ -794,9 +810,7 @@ PYBIND11_NAMESPACE_END(detail)
     { if (!m_ptr) throw error_already_set(); } \
     Name(object &&o) \
     : Parent(check_(o) ? o.release().ptr() : ConvertFun(o.ptr()), stolen_t{}) \
-    { if (!m_ptr) throw error_already_set(); } \
-    template <typename Policy_> \
-    Name(const ::pybind11::detail::accessor<Policy_> &a) : Name(object(a)) { }
+    { if (!m_ptr) throw error_already_set(); }
 
 #define PYBIND11_OBJECT(Name, Parent, CheckFun) \
     PYBIND11_OBJECT_COMMON(Name, Parent, CheckFun) \
@@ -878,6 +892,32 @@ private:
     object value = {};
 };
 
+
+
+class type : public object {
+public:
+    PYBIND11_OBJECT(type, object, PyType_Check)
+
+    /// Return a type handle from a handle or an object
+    static handle handle_of(handle h) { return handle((PyObject*) Py_TYPE(h.ptr())); }
+
+    /// Return a type object from a handle or an object
+    static type of(handle h) { return type(type::handle_of(h), borrowed_t{}); }
+
+    // Defined in pybind11/cast.h
+    /// Convert C++ type to handle if previously registered. Does not convert
+    /// standard types, like int, float. etc. yet.
+    /// See https://github.com/pybind/pybind11/issues/2486
+    template<typename T>
+    static handle handle_of();
+
+    /// Convert C++ type to type if previously registered. Does not convert
+    /// standard types, like int, float. etc. yet.
+    /// See https://github.com/pybind/pybind11/issues/2486
+    template<typename T>
+    static type of() {return type(type::handle_of<T>(), borrowed_t{}); }
+};
+
 class iterable : public object {
 public:
     PYBIND11_OBJECT_DEFAULT(iterable, object, detail::PyIterable_Check)
@@ -908,7 +948,7 @@ public:
         Return a string representation of the object. This is analogous to
         the ``str()`` function in Python.
     \endrst */
-    explicit str(handle h) : object(raw_str(h.ptr()), stolen_t{}) { }
+    explicit str(handle h) : object(raw_str(h.ptr()), stolen_t{}) { if (!m_ptr) throw error_already_set(); }
 
     operator std::string() const {
         object temp = *this;
@@ -933,8 +973,8 @@ private:
     /// Return string representation -- always returns a new reference, even if already a str
     static PyObject *raw_str(PyObject *op) {
         PyObject *str_value = PyObject_Str(op);
-        if (!str_value) throw error_already_set();
 #if PY_MAJOR_VERSION < 3
+        if (!str_value) throw error_already_set();
         PyObject *unicode = PyUnicode_FromEncodedObject(str_value, "utf-8", nullptr);
         Py_XDECREF(str_value); str_value = unicode;
 #endif
@@ -948,7 +988,7 @@ inline namespace literals {
     String literal version of `str`
  \endrst */
 inline str operator"" _s(const char *s, size_t size) { return {s, size}; }
-}
+} // namespace literals
 
 /// \addtogroup pytypes
 /// @{
@@ -1020,13 +1060,11 @@ public:
     none() : object(Py_None, borrowed_t{}) { }
 };
 
-#if PY_MAJOR_VERSION >= 3
 class ellipsis : public object {
 public:
     PYBIND11_OBJECT(ellipsis, object, detail::PyEllipsis_Check)
     ellipsis() : object(Py_Ellipsis, borrowed_t{}) { }
 };
-#endif
 
 class bool_ : public object {
 public:
@@ -1325,7 +1363,7 @@ public:
     buffer_info request(bool writable = false) const {
         int flags = PyBUF_STRIDES | PyBUF_FORMAT;
         if (writable) flags |= PyBUF_WRITABLE;
-        Py_buffer *view = new Py_buffer();
+        auto *view = new Py_buffer();
         if (PyObject_GetBuffer(m_ptr, view, flags) != 0) {
             delete view;
             throw error_already_set();
@@ -1542,7 +1580,8 @@ template <typename D>
 str_attr_accessor object_api<D>::doc() const { return attr("__doc__"); }
 
 template <typename D>
-handle object_api<D>::get_type() const { return (PyObject *) Py_TYPE(derived().ptr()); }
+PYBIND11_DEPRECATED("Use py::type::of(h) instead of h.get_type()")
+handle object_api<D>::get_type() const { return type::handle_of(*this); }
 
 template <typename D>
 bool object_api<D>::rich_compare(object_api const &other, int value) const {
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/stl.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/stl.h
@@ -289,7 +289,7 @@ template<typename T> struct optional_cas
     PYBIND11_TYPE_CASTER(T, _("Optional[") + value_conv::name + _("]"));
 };
 
-#if PYBIND11_HAS_OPTIONAL
+#if defined(PYBIND11_HAS_OPTIONAL)
 template<typename T> struct type_caster<std::optional<T>>
     : public optional_caster<std::optional<T>> {};
 
@@ -297,7 +297,7 @@ template<> struct type_caster<std::nullo
     : public void_caster<std::nullopt_t> {};
 #endif
 
-#if PYBIND11_HAS_EXP_OPTIONAL
+#if defined(PYBIND11_HAS_EXP_OPTIONAL)
 template<typename T> struct type_caster<std::experimental::optional<T>>
     : public optional_caster<std::experimental::optional<T>> {};
 
@@ -369,7 +369,7 @@ struct variant_caster<V<Ts...>> {
     PYBIND11_TYPE_CASTER(Type, _("Union[") + detail::concat(make_caster<Ts>::name...) + _("]"));
 };
 
-#if PYBIND11_HAS_VARIANT
+#if defined(PYBIND11_HAS_VARIANT)
 template <typename... Ts>
 struct type_caster<std::variant<Ts...>> : variant_caster<std::variant<Ts...>> { };
 #endif
--- gtsam-4.1.0.orig/wrap/pybind11/include/pybind11/stl_bind.h
+++ gtsam-4.1.0/wrap/pybind11/include/pybind11/stl_bind.h
@@ -223,7 +223,7 @@ void vector_modifiers(enable_if_t<is_cop
             if (!slice.compute(v.size(), &start, &stop, &step, &slicelength))
                 throw error_already_set();
 
-            Vector *seq = new Vector();
+            auto *seq = new Vector();
             seq->reserve((size_t) slicelength);
 
             for (size_t i=0; i<slicelength; ++i) {
@@ -397,14 +397,19 @@ vector_buffer(Class_& cl) {
         if (!detail::compare_buffer_info<T>::compare(info) || (ssize_t) sizeof(T) != info.itemsize)
             throw type_error("Format mismatch (Python: " + info.format + " C++: " + format_descriptor<T>::format() + ")");
 
-        auto vec = std::unique_ptr<Vector>(new Vector());
-        vec->reserve((size_t) info.shape[0]);
         T *p = static_cast<T*>(info.ptr);
         ssize_t step = info.strides[0] / static_cast<ssize_t>(sizeof(T));
         T *end = p + info.shape[0] * step;
-        for (; p != end; p += step)
-            vec->push_back(*p);
-        return vec.release();
+        if (step == 1) {
+            return Vector(p, end);
+        }
+        else {
+            Vector vec;
+            vec.reserve((size_t) info.shape[0]);
+            for (; p != end; p += step)
+                vec.push_back(*p);
+            return vec;
+        }
     }));
 
     return;
--- gtsam-4.1.0.orig/wrap/pybind11/pybind11/__init__.py
+++ gtsam-4.1.0/wrap/pybind11/pybind11/__init__.py
@@ -1,13 +1,12 @@
 # -*- coding: utf-8 -*-
-from ._version import version_info, __version__  # noqa: F401 imported but unused
 
+from ._version import version_info, __version__
+from .commands import get_include, get_cmake_dir
 
-def get_include(user=False):
-    import os
-    d = os.path.dirname(__file__)
-    if os.path.exists(os.path.join(d, "include")):
-        # Package is installed
-        return os.path.join(d, "include")
-    else:
-        # Package is from a source directory
-        return os.path.join(os.path.dirname(d), "include")
+
+__all__ = (
+    "version_info",
+    "__version__",
+    "get_include",
+    "get_cmake_dir",
+)
--- gtsam-4.1.0.orig/wrap/pybind11/pybind11/__main__.py
+++ gtsam-4.1.0/wrap/pybind11/pybind11/__main__.py
@@ -5,13 +5,15 @@ import argparse
 import sys
 import sysconfig
 
-from . import get_include
+from .commands import get_include, get_cmake_dir
 
 
 def print_includes():
-    dirs = [sysconfig.get_path('include'),
-            sysconfig.get_path('platinclude'),
-            get_include()]
+    dirs = [
+        sysconfig.get_path("include"),
+        sysconfig.get_path("platinclude"),
+        get_include(),
+    ]
 
     # Make unique but preserve order
     unique_dirs = []
@@ -19,19 +21,29 @@ def print_includes():
         if d not in unique_dirs:
             unique_dirs.append(d)
 
-    print(' '.join('-I' + d for d in unique_dirs))
+    print(" ".join("-I" + d for d in unique_dirs))
 
 
 def main():
-    parser = argparse.ArgumentParser(prog='python -m pybind11')
-    parser.add_argument('--includes', action='store_true',
-                        help='Include flags for both pybind11 and Python headers.')
+    parser = argparse.ArgumentParser()
+    parser.add_argument(
+        "--includes",
+        action="store_true",
+        help="Include flags for both pybind11 and Python headers.",
+    )
+    parser.add_argument(
+        "--cmakedir",
+        action="store_true",
+        help="Print the CMake module directory, ideal for setting -Dpybind11_ROOT in CMake.",
+    )
     args = parser.parse_args()
     if not sys.argv[1:]:
         parser.print_help()
     if args.includes:
         print_includes()
+    if args.cmakedir:
+        print(get_cmake_dir())
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     main()
--- gtsam-4.1.0.orig/wrap/pybind11/pybind11/_version.py
+++ gtsam-4.1.0/wrap/pybind11/pybind11/_version.py
@@ -1,3 +1,12 @@
 # -*- coding: utf-8 -*-
-version_info = (2, 5, 'dev1')
-__version__ = '.'.join(map(str, version_info))
+
+
+def _to_int(s):
+    try:
+        return int(s)
+    except ValueError:
+        return s
+
+
+__version__ = "2.6.0.dev1"
+version_info = tuple(_to_int(s) for s in __version__.split("."))
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/pybind11/commands.py
@@ -0,0 +1,20 @@
+# -*- coding: utf-8 -*-
+import os
+
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+
+
+def get_include(user=False):
+    installed_path = os.path.join(DIR, "include")
+    source_path = os.path.join(os.path.dirname(DIR), "include")
+    return installed_path if os.path.exists(installed_path) else source_path
+
+
+def get_cmake_dir():
+    cmake_installed_path = os.path.join(DIR, "share", "cmake", "pybind11")
+    if os.path.exists(cmake_installed_path):
+        return cmake_installed_path
+    else:
+        msg = "pybind11 not installed, installation required to access the CMake files"
+        raise ImportError(msg)
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/pybind11/setup_helpers.py
@@ -0,0 +1,270 @@
+# -*- coding: utf-8 -*-
+
+"""
+This module provides helpers for C++11+ projects using pybind11.
+
+LICENSE:
+
+Copyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+   list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+   this list of conditions and the following disclaimer in the documentation
+   and/or other materials provided with the distribution.
+
+3. Neither the name of the copyright holder nor the names of its contributors
+   may be used to endorse or promote products derived from this software
+   without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+"""
+
+import contextlib
+import os
+import shutil
+import sys
+import tempfile
+import threading
+import warnings
+
+try:
+    from setuptools.command.build_ext import build_ext as _build_ext
+    from setuptools import Extension as _Extension
+except ImportError:
+    from distutils.command.build_ext import build_ext as _build_ext
+    from distutils.extension import Extension as _Extension
+
+import distutils.errors
+
+
+WIN = sys.platform.startswith("win32")
+PY2 = sys.version_info[0] < 3
+MACOS = sys.platform.startswith("darwin")
+STD_TMPL = "/std:c++{}" if WIN else "-std=c++{}"
+
+
+# It is recommended to use PEP 518 builds if using this module. However, this
+# file explicitly supports being copied into a user's project directory
+# standalone, and pulling pybind11 with the deprecated setup_requires feature.
+# If you copy the file, remember to add it to your MANIFEST.in, and add the current
+# directory into your path if it sits beside your setup.py.
+
+
+class Pybind11Extension(_Extension):
+    """
+    Build a C++11+ Extension module with pybind11. This automatically adds the
+    recommended flags when you init the extension and assumes C++ sources - you
+    can further modify the options yourself.
+
+    The customizations are:
+
+    * ``/EHsc`` and ``/bigobj`` on Windows
+    * ``stdlib=libc++`` on macOS
+    * ``visibility=hidden`` and ``-g0`` on Unix
+
+    Finally, you can set ``cxx_std`` via constructor or afterwords to enable
+    flags for C++ std, and a few extra helper flags related to the C++ standard
+    level. It is _highly_ recommended you either set this, or use the provided
+    ``build_ext``, which will search for the highest supported extension for
+    you if the ``cxx_std`` property is not set. Do not set the ``cxx_std``
+    property more than once, as flags are added when you set it. Set the
+    property to None to disable the addition of C++ standard flags.
+
+    If you want to add pybind11 headers manually, for example for an exact
+    git checkout, then set ``include_pybind11=False``.
+
+    Warning: do not use property-based access to the instance on Python 2 -
+    this is an ugly old-style class due to Distutils.
+    """
+
+    def _add_cflags(self, *flags):
+        for flag in flags:
+            if flag not in self.extra_compile_args:
+                self.extra_compile_args.append(flag)
+
+    def _add_lflags(self, *flags):
+        for flag in flags:
+            if flag not in self.extra_compile_args:
+                self.extra_link_args.append(flag)
+
+    def __init__(self, *args, **kwargs):
+
+        self._cxx_level = 0
+        cxx_std = kwargs.pop("cxx_std", 0)
+
+        if "language" not in kwargs:
+            kwargs["language"] = "c++"
+
+        include_pybind11 = kwargs.pop("include_pybind11", True)
+
+        # Can't use super here because distutils has old-style classes in
+        # Python 2!
+        _Extension.__init__(self, *args, **kwargs)
+
+        # Include the installed package pybind11 headers
+        if include_pybind11:
+            # If using setup_requires, this fails the first time - that's okay
+            try:
+                import pybind11
+
+                pyinc = pybind11.get_include()
+
+                if pyinc not in self.include_dirs:
+                    self.include_dirs.append(pyinc)
+            except ImportError:
+                pass
+
+        # Have to use the accessor manually to support Python 2 distutils
+        Pybind11Extension.cxx_std.__set__(self, cxx_std)
+
+        if WIN:
+            self._add_cflags("/EHsc", "/bigobj")
+        else:
+            self._add_cflags("-fvisibility=hidden", "-g0")
+            if MACOS:
+                self._add_cflags("-stdlib=libc++")
+                self._add_lflags("-stdlib=libc++")
+
+    @property
+    def cxx_std(self):
+        """
+        The CXX standard level. If set, will add the required flags. If left
+        at 0, it will trigger an automatic search when pybind11's build_ext
+        is used. If None, will have no effect.  Besides just the flags, this
+        may add a register warning/error fix for Python 2 or macos-min 10.9
+        or 10.14.
+        """
+        return self._cxx_level
+
+    @cxx_std.setter
+    def cxx_std(self, level):
+
+        if self._cxx_level:
+            warnings.warn("You cannot safely change the cxx_level after setting it!")
+
+        # MSVC 2015 Update 3 and later only have 14 (and later 17) modes
+        if WIN and level == 11:
+            level = 14
+
+        self._cxx_level = level
+
+        if not level:
+            return
+
+        self.extra_compile_args.append(STD_TMPL.format(level))
+
+        if MACOS and "MACOSX_DEPLOYMENT_TARGET" not in os.environ:
+            # C++17 requires a higher min version of macOS
+            macosx_min = "-mmacosx-version-min=" + ("10.9" if level < 17 else "10.14")
+            self.extra_compile_args.append(macosx_min)
+            self.extra_link_args.append(macosx_min)
+
+        if PY2:
+            if level >= 17:
+                self.extra_compile_args.append("/wd503" if WIN else "-Wno-register")
+            elif not WIN and level >= 14:
+                self.extra_compile_args.append("-Wno-deprecated-register")
+
+
+# Just in case someone clever tries to multithread
+tmp_chdir_lock = threading.Lock()
+cpp_cache_lock = threading.Lock()
+
+
+@contextlib.contextmanager
+def tmp_chdir():
+    "Prepare and enter a temporary directory, cleanup when done"
+
+    # Threadsafe
+    with tmp_chdir_lock:
+        olddir = os.getcwd()
+        try:
+            tmpdir = tempfile.mkdtemp()
+            os.chdir(tmpdir)
+            yield tmpdir
+        finally:
+            os.chdir(olddir)
+            shutil.rmtree(tmpdir)
+
+
+# cf http://bugs.python.org/issue26689
+def has_flag(compiler, flag):
+    """
+    Return the flag if a flag name is supported on the
+    specified compiler, otherwise None (can be used as a boolean).
+    If multiple flags are passed, return the first that matches.
+    """
+
+    with tmp_chdir():
+        fname = "flagcheck.cpp"
+        with open(fname, "w") as f:
+            f.write("int main (int argc, char **argv) { return 0; }")
+
+        try:
+            compiler.compile([fname], extra_postargs=[flag])
+        except distutils.errors.CompileError:
+            return False
+        return True
+
+
+# Every call will cache the result
+cpp_flag_cache = None
+
+
+def auto_cpp_level(compiler):
+    """
+    Return the max supported C++ std level (17, 14, or 11).
+    """
+
+    global cpp_flag_cache
+
+    # If this has been previously calculated with the same args, return that
+    with cpp_cache_lock:
+        if cpp_flag_cache:
+            return cpp_flag_cache
+
+    levels = [17, 14] + ([] if WIN else [11])
+
+    for level in levels:
+        if has_flag(compiler, STD_TMPL.format(level)):
+            with cpp_cache_lock:
+                cpp_flag_cache = level
+            return level
+
+    msg = "Unsupported compiler -- at least C++11 support is needed!"
+    raise RuntimeError(msg)
+
+
+class build_ext(_build_ext):  # noqa: N801
+    """
+    Customized build_ext that allows an auto-search for the highest supported
+    C++ level for Pybind11Extension.
+    """
+
+    def build_extensions(self):
+        """
+        Build extensions, injecting C++ std for Pybind11Extension if needed.
+        """
+
+        for ext in self.extensions:
+            if hasattr(ext, "_cxx_level") and ext._cxx_level == 0:
+                # Python 2 syntax - old-style distutils class
+                ext.__class__.cxx_std.__set__(ext, auto_cpp_level(self.compiler))
+
+        # Python 2 doesn't allow super here, since distutils uses old-style
+        # classes!
+        _build_ext.build_extensions(self)
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/pyproject.toml
@@ -0,0 +1,3 @@
+[build-system]
+requires = ["setuptools", "wheel", "cmake==3.18.0", "ninja"]
+build-backend = "setuptools.build_meta"
--- gtsam-4.1.0.orig/wrap/pybind11/setup.cfg
+++ gtsam-4.1.0/wrap/pybind11/setup.cfg
@@ -1,6 +1,58 @@
+[metadata]
+long_description = file: README.md
+long_description_content_type = text/markdown
+description = Seamless operability between C++11 and Python
+author = Wenzel Jakob
+author_email = "wenzel.jakob@epfl.ch"
+url = "https://github.com/pybind/pybind11"
+license = BSD
+
+classifiers =
+    Development Status :: 5 - Production/Stable
+    Intended Audience :: Developers
+    Topic :: Software Development :: Libraries :: Python Modules
+    Topic :: Utilities
+    Programming Language :: C++
+    Programming Language :: Python :: 2.7
+    Programming Language :: Python :: 3
+    Programming Language :: Python :: 3.5
+    Programming Language :: Python :: 3.6
+    Programming Language :: Python :: 3.7
+    Programming Language :: Python :: 3.8
+    License :: OSI Approved :: BSD License
+    Programming Language :: Python :: Implementation :: PyPy
+    Programming Language :: Python :: Implementation :: CPython
+    Programming Language :: C++
+    Topic :: Software Development :: Libraries :: Python Modules
+
+keywords =
+    C++11
+    Python bindings
+
+[options]
+python_requires = >=2.7, !=3.0, !=3.1, !=3.2, !=3.3, !=3.4
+zip_safe = False
+
 [bdist_wheel]
 universal=1
 
+[check-manifest]
+ignore =
+    tests/**
+    docs/**
+    tools/**
+    include/**
+    .appveyor.yml
+    .cmake-format.yaml
+    .gitmodules
+    .pre-commit-config.yaml
+    .readthedocs.yml
+    .clang-tidy
+    pybind11/include/**
+    pybind11/share/**
+    CMakeLists.txt
+
+
 [flake8]
 max-line-length = 99
 show_source = True
@@ -10,3 +62,5 @@ ignore =
     E201, E241, W504,
     # camelcase 'cPickle' imported as lowercase 'pickle'
     N813
+    # Black conflict
+    W503, E203
--- gtsam-4.1.0.orig/wrap/pybind11/setup.py
+++ gtsam-4.1.0/wrap/pybind11/setup.py
@@ -3,128 +3,113 @@
 
 # Setup script for PyPI; use CMakeFile.txt to build extension modules
 
-from setuptools import setup
-from distutils.command.install_headers import install_headers
-from distutils.command.build_py import build_py
-from pybind11 import __version__
+import contextlib
 import os
-
-package_data = [
-    'include/pybind11/detail/class.h',
-    'include/pybind11/detail/common.h',
-    'include/pybind11/detail/descr.h',
-    'include/pybind11/detail/init.h',
-    'include/pybind11/detail/internals.h',
-    'include/pybind11/detail/typeid.h',
-    'include/pybind11/attr.h',
-    'include/pybind11/buffer_info.h',
-    'include/pybind11/cast.h',
-    'include/pybind11/chrono.h',
-    'include/pybind11/common.h',
-    'include/pybind11/complex.h',
-    'include/pybind11/eigen.h',
-    'include/pybind11/embed.h',
-    'include/pybind11/eval.h',
-    'include/pybind11/functional.h',
-    'include/pybind11/iostream.h',
-    'include/pybind11/numpy.h',
-    'include/pybind11/operators.h',
-    'include/pybind11/options.h',
-    'include/pybind11/pybind11.h',
-    'include/pybind11/pytypes.h',
-    'include/pybind11/stl.h',
-    'include/pybind11/stl_bind.h',
-]
-
-# Prevent installation of pybind11 headers by setting
-# PYBIND11_USE_CMAKE.
-if os.environ.get('PYBIND11_USE_CMAKE'):
-    headers = []
-else:
-    headers = package_data
-
-
-class InstallHeaders(install_headers):
-    """Use custom header installer because the default one flattens subdirectories"""
-    def run(self):
-        if not self.distribution.headers:
-            return
-
-        for header in self.distribution.headers:
-            subdir = os.path.dirname(os.path.relpath(header, 'include/pybind11'))
-            install_dir = os.path.join(self.install_dir, subdir)
-            self.mkpath(install_dir)
-
-            (out, _) = self.copy_file(header, install_dir)
-            self.outfiles.append(out)
-
-
-# Install the headers inside the package as well
-class BuildPy(build_py):
-    def build_package_data(self):
-        build_py.build_package_data(self)
-        for header in package_data:
-            target = os.path.join(self.build_lib, 'pybind11', header)
-            self.mkpath(os.path.dirname(target))
-            self.copy_file(header, target, preserve_mode=False)
-
-    def get_outputs(self, include_bytecode=1):
-        outputs = build_py.get_outputs(self, include_bytecode=include_bytecode)
-        for header in package_data:
-            target = os.path.join(self.build_lib, 'pybind11', header)
-            outputs.append(target)
-        return outputs
-
-
-setup(
-    name='pybind11',
-    version=__version__,
-    description='Seamless operability between C++11 and Python',
-    author='Wenzel Jakob',
-    author_email='wenzel.jakob@epfl.ch',
-    url='https://github.com/pybind/pybind11',
-    download_url='https://github.com/pybind/pybind11/tarball/v' + __version__,
-    packages=['pybind11'],
-    license='BSD',
-    headers=headers,
-    zip_safe=False,
-    cmdclass=dict(install_headers=InstallHeaders, build_py=BuildPy),
-    classifiers=[
-        'Development Status :: 5 - Production/Stable',
-        'Intended Audience :: Developers',
-        'Topic :: Software Development :: Libraries :: Python Modules',
-        'Topic :: Utilities',
-        'Programming Language :: C++',
-        'Programming Language :: Python :: 2.7',
-        'Programming Language :: Python :: 3',
-        'Programming Language :: Python :: 3.2',
-        'Programming Language :: Python :: 3.3',
-        'Programming Language :: Python :: 3.4',
-        'Programming Language :: Python :: 3.5',
-        'Programming Language :: Python :: 3.6',
-        'License :: OSI Approved :: BSD License'
-    ],
-    keywords='C++11, Python bindings',
-    long_description="""pybind11 is a lightweight header-only library that
-exposes C++ types in Python and vice versa, mainly to create Python bindings of
-existing C++ code. Its goals and syntax are similar to the excellent
-Boost.Python by David Abrahams: to minimize boilerplate code in traditional
-extension modules by inferring type information using compile-time
-introspection.
-
-The main issue with Boost.Python-and the reason for creating such a similar
-project-is Boost. Boost is an enormously large and complex suite of utility
-libraries that works with almost every C++ compiler in existence. This
-compatibility has its cost: arcane template tricks and workarounds are
-necessary to support the oldest and buggiest of compiler specimens. Now that
-C++11-compatible compilers are widely available, this heavy machinery has
-become an excessively large and unnecessary dependency.
-
-Think of this library as a tiny self-contained version of Boost.Python with
-everything stripped away that isn't relevant for binding generation. Without
-comments, the core header files only require ~4K lines of code and depend on
-Python (2.7 or 3.x, or PyPy2.7 >= 5.7) and the C++ standard library. This
-compact implementation was possible thanks to some of the new C++11 language
-features (specifically: tuples, lambda functions and variadic templates). Since
-its creation, this library has grown beyond Boost.Python in many ways, leading
-to dramatically simpler binding code in many common situations.""")
+import re
+import shutil
+import string
+import subprocess
+import sys
+import tempfile
+
+import setuptools.command.sdist
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+VERSION_REGEX = re.compile(
+    r"^\s*#\s*define\s+PYBIND11_VERSION_([A-Z]+)\s+(.*)$", re.MULTILINE
+)
+
+# PYBIND11_GLOBAL_SDIST will build a different sdist, with the python-headers
+# files, and the sys.prefix files (CMake and headers).
+
+global_sdist = os.environ.get("PYBIND11_GLOBAL_SDIST", False)
+
+setup_py = "tools/setup_global.py.in" if global_sdist else "tools/setup_main.py.in"
+extra_cmd = 'cmdclass["sdist"] = SDist\n'
+
+to_src = (
+    ("pyproject.toml", "tools/pyproject.toml"),
+    ("setup.py", setup_py),
+)
+
+# Read the listed version
+with open("pybind11/_version.py") as f:
+    code = compile(f.read(), "pybind11/_version.py", "exec")
+    loc = {}
+    exec(code, loc)
+    version = loc["__version__"]
+
+# Verify that the version matches the one in C++
+with open("include/pybind11/detail/common.h") as f:
+    matches = dict(VERSION_REGEX.findall(f.read()))
+cpp_version = "{MAJOR}.{MINOR}.{PATCH}".format(**matches)
+if version != cpp_version:
+    msg = "Python version {} does not match C++ version {}!".format(
+        version, cpp_version
+    )
+    raise RuntimeError(msg)
+
+
+def get_and_replace(filename, binary=False, **opts):
+    with open(filename, "rb" if binary else "r") as f:
+        contents = f.read()
+    # Replacement has to be done on text in Python 3 (both work in Python 2)
+    if binary:
+        return string.Template(contents.decode()).substitute(opts).encode()
+    else:
+        return string.Template(contents).substitute(opts)
+
+
+# Use our input files instead when making the SDist (and anything that depends
+# on it, like a wheel)
+class SDist(setuptools.command.sdist.sdist):
+    def make_release_tree(self, base_dir, files):
+        setuptools.command.sdist.sdist.make_release_tree(self, base_dir, files)
+
+        for to, src in to_src:
+            txt = get_and_replace(src, binary=True, version=version, extra_cmd="")
+
+            dest = os.path.join(base_dir, to)
+
+            # This is normally linked, so unlink before writing!
+            os.unlink(dest)
+            with open(dest, "wb") as f:
+                f.write(txt)
+
+
+# Backport from Python 3
+@contextlib.contextmanager
+def TemporaryDirectory():  # noqa: N802
+    "Prepare a temporary directory, cleanup when done"
+    try:
+        tmpdir = tempfile.mkdtemp()
+        yield tmpdir
+    finally:
+        shutil.rmtree(tmpdir)
+
+
+# Remove the CMake install directory when done
+@contextlib.contextmanager
+def remove_output(*sources):
+    try:
+        yield
+    finally:
+        for src in sources:
+            shutil.rmtree(src)
+
+
+with remove_output("pybind11/include", "pybind11/share"):
+    # Generate the files if they are not present.
+    with TemporaryDirectory() as tmpdir:
+        cmd = ["cmake", "-S", ".", "-B", tmpdir] + [
+            "-DCMAKE_INSTALL_PREFIX=pybind11",
+            "-DBUILD_TESTING=OFF",
+            "-DPYBIND11_NOPYTHON=ON",
+        ]
+        cmake_opts = dict(cwd=DIR, stdout=sys.stdout, stderr=sys.stderr)
+        subprocess.check_call(cmd, **cmake_opts)
+        subprocess.check_call(["cmake", "--install", tmpdir], **cmake_opts)
+
+    txt = get_and_replace(setup_py, version=version, extra_cmd=extra_cmd)
+    code = compile(txt, setup_py, "exec")
+    exec(code, {"SDist": SDist})
--- gtsam-4.1.0.orig/wrap/pybind11/tests/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/CMakeLists.txt
@@ -5,80 +5,150 @@
 # All rights reserved. Use of this source code is governed by a
 # BSD-style license that can be found in the LICENSE file.
 
-cmake_minimum_required(VERSION 2.8.12)
+cmake_minimum_required(VERSION 3.4)
 
-option(PYBIND11_WERROR  "Report all warnings as errors"  OFF)
-set(PYBIND11_TEST_OVERRIDE "" CACHE STRING "Tests from ;-separated list of *.cpp files will be built instead of all tests")
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
+
+# Only needed for CMake < 3.5 support
+include(CMakeParseArguments)
+
+# Filter out items; print an optional message if any items filtered
+#
+# Usage:
+#   pybind11_filter_tests(LISTNAME file1.cpp file2.cpp ... MESSAGE "")
+#
+macro(PYBIND11_FILTER_TESTS LISTNAME)
+  cmake_parse_arguments(ARG "" "MESSAGE" "" ${ARGN})
+  set(PYBIND11_FILTER_TESTS_FOUND OFF)
+  foreach(filename IN LISTS ARG_UNPARSED_ARGUMENTS)
+    list(FIND ${LISTNAME} ${filename} _FILE_FOUND)
+    if(_FILE_FOUND GREATER -1)
+      list(REMOVE_AT ${LISTNAME} ${_FILE_FOUND})
+      set(PYBIND11_FILTER_TESTS_FOUND ON)
+    endif()
+  endforeach()
+  if(PYBIND11_FILTER_TESTS_FOUND AND ARG_MESSAGE)
+    message(STATUS "${ARG_MESSAGE}")
+  endif()
+endmacro()
+
+# New Python support
+if(DEFINED Python_EXECUTABLE)
+  set(PYTHON_EXECUTABLE "${Python_EXECUTABLE}")
+  set(PYTHON_VERSION "${Python_VERSION}")
+endif()
+
+# There's no harm in including a project in a project
+project(pybind11_tests CXX)
 
-if (CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_SOURCE_DIR)
-    # We're being loaded directly, i.e. not via add_subdirectory, so make this
-    # work as its own project and load the pybind11Config to get the tools we need
-    project(pybind11_tests CXX)
+# Access FindCatch and more
+list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_LIST_DIR}/../tools")
 
-    find_package(pybind11 REQUIRED CONFIG)
+option(PYBIND11_WERROR "Report all warnings as errors" OFF)
+option(DOWNLOAD_EIGEN "Download EIGEN (requires CMake 3.11+)" OFF)
+option(PYBIND11_CUDA_TESTS "Enable building CUDA tests (requires CMake 3.12+)" OFF)
+set(PYBIND11_TEST_OVERRIDE
+    ""
+    CACHE STRING "Tests from ;-separated list of *.cpp files will be built instead of all tests")
+set(PYBIND11_TEST_FILTER
+    ""
+    CACHE STRING "Tests from ;-separated list of *.cpp files will be removed from all tests")
+
+if(CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_SOURCE_DIR)
+  # We're being loaded directly, i.e. not via add_subdirectory, so make this
+  # work as its own project and load the pybind11Config to get the tools we need
+  find_package(pybind11 REQUIRED CONFIG)
 endif()
 
 if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES)
   message(STATUS "Setting tests build type to MinSizeRel as none was specified")
-  set(CMAKE_BUILD_TYPE MinSizeRel CACHE STRING "Choose the type of build." FORCE)
-  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS "Debug" "Release"
-    "MinSizeRel" "RelWithDebInfo")
+  set(CMAKE_BUILD_TYPE
+      MinSizeRel
+      CACHE STRING "Choose the type of build." FORCE)
+  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS "Debug" "Release" "MinSizeRel"
+                                               "RelWithDebInfo")
+endif()
+
+if(PYBIND11_CUDA_TESTS)
+  enable_language(CUDA)
+  if(DEFINED CMAKE_CXX_STANDARD)
+    set(CMAKE_CUDA_STANDARD ${CMAKE_CXX_STANDARD})
+  endif()
+  set(CMAKE_CUDA_STANDARD_REQUIRED ON)
 endif()
 
 # Full set of test files (you can override these; see below)
 set(PYBIND11_TEST_FILES
-  test_async.cpp
-  test_buffers.cpp
-  test_builtin_casters.cpp
-  test_call_policies.cpp
-  test_callbacks.cpp
-  test_chrono.cpp
-  test_class.cpp
-  test_constants_and_functions.cpp
-  test_copy_move.cpp
-  test_custom_type_casters.cpp
-  test_docstring_options.cpp
-  test_eigen.cpp
-  test_enum.cpp
-  test_eval.cpp
-  test_exceptions.cpp
-  test_factory_constructors.cpp
-  test_gil_scoped.cpp
-  test_iostream.cpp
-  test_kwargs_and_defaults.cpp
-  test_local_bindings.cpp
-  test_methods_and_attributes.cpp
-  test_modules.cpp
-  test_multiple_inheritance.cpp
-  test_numpy_array.cpp
-  test_numpy_dtypes.cpp
-  test_numpy_vectorize.cpp
-  test_opaque_types.cpp
-  test_operator_overloading.cpp
-  test_pickling.cpp
-  test_pytypes.cpp
-  test_sequences_and_iterators.cpp
-  test_smart_ptr.cpp
-  test_stl.cpp
-  test_stl_binders.cpp
-  test_tagbased_polymorphic.cpp
-  test_union.cpp
-  test_virtual_functions.cpp
-)
+    test_async.cpp
+    test_buffers.cpp
+    test_builtin_casters.cpp
+    test_call_policies.cpp
+    test_callbacks.cpp
+    test_chrono.cpp
+    test_class.cpp
+    test_constants_and_functions.cpp
+    test_copy_move.cpp
+    test_custom_type_casters.cpp
+    test_docstring_options.cpp
+    test_eigen.cpp
+    test_enum.cpp
+    test_eval.cpp
+    test_exceptions.cpp
+    test_factory_constructors.cpp
+    test_gil_scoped.cpp
+    test_iostream.cpp
+    test_kwargs_and_defaults.cpp
+    test_local_bindings.cpp
+    test_methods_and_attributes.cpp
+    test_modules.cpp
+    test_multiple_inheritance.cpp
+    test_numpy_array.cpp
+    test_numpy_dtypes.cpp
+    test_numpy_vectorize.cpp
+    test_opaque_types.cpp
+    test_operator_overloading.cpp
+    test_pickling.cpp
+    test_pytypes.cpp
+    test_sequences_and_iterators.cpp
+    test_smart_ptr.cpp
+    test_stl.cpp
+    test_stl_binders.cpp
+    test_tagbased_polymorphic.cpp
+    test_union.cpp
+    test_virtual_functions.cpp)
 
 # Invoking cmake with something like:
-#     cmake -DPYBIND11_TEST_OVERRIDE="test_callbacks.cpp;test_picking.cpp" ..
+#     cmake -DPYBIND11_TEST_OVERRIDE="test_callbacks.cpp;test_pickling.cpp" ..
 # lets you override the tests that get compiled and run.  You can restore to all tests with:
 #     cmake -DPYBIND11_TEST_OVERRIDE= ..
-if (PYBIND11_TEST_OVERRIDE)
+if(PYBIND11_TEST_OVERRIDE)
   set(PYBIND11_TEST_FILES ${PYBIND11_TEST_OVERRIDE})
 endif()
 
-# Skip test_async for Python < 3.5
-list(FIND PYBIND11_TEST_FILES test_async.cpp PYBIND11_TEST_FILES_ASYNC_I)
-if((PYBIND11_TEST_FILES_ASYNC_I GREATER -1) AND ("${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR}" VERSION_LESS 3.5))
-  message(STATUS "Skipping test_async because Python version ${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR} < 3.5")
-  list(REMOVE_AT PYBIND11_TEST_FILES ${PYBIND11_TEST_FILES_ASYNC_I})
+# You can also filter tests:
+if(PYBIND11_TEST_FILTER)
+  pybind11_filter_tests(PYBIND11_TEST_FILES ${PYBIND11_TEST_FILTER})
+endif()
+
+if(PYTHON_VERSION VERSION_LESS 3.5)
+  pybind11_filter_tests(PYBIND11_TEST_FILES test_async.cpp MESSAGE
+                        "Skipping test_async on Python 2")
+endif()
+
+# Skip tests for CUDA check:
+# /pybind11/tests/test_constants_and_functions.cpp(125):
+#   error: incompatible exception specifications
+if(PYBIND11_CUDA_TESTS)
+  pybind11_filter_tests(
+    PYBIND11_TEST_FILES test_constants_and_functions.cpp MESSAGE
+    "Skipping test_constants_and_functions due to incompatible exception specifications")
 endif()
 
 string(REPLACE ".cpp" ".py" PYBIND11_PYTEST_FILES "${PYBIND11_TEST_FILES}")
@@ -86,16 +156,10 @@ string(REPLACE ".cpp" ".py" PYBIND11_PYT
 # Contains the set of test files that require pybind11_cross_module_tests to be
 # built; if none of these are built (i.e. because TEST_OVERRIDE is used and
 # doesn't include them) the second module doesn't get built.
-set(PYBIND11_CROSS_MODULE_TESTS
-  test_exceptions.py
-  test_local_bindings.py
-  test_stl.py
-  test_stl_binders.py
-)
-
-set(PYBIND11_CROSS_MODULE_GIL_TESTS
-  test_gil_scoped.py
-)
+set(PYBIND11_CROSS_MODULE_TESTS test_exceptions.py test_local_bindings.py test_stl.py
+                                test_stl_binders.py)
+
+set(PYBIND11_CROSS_MODULE_GIL_TESTS test_gil_scoped.py)
 
 # Check if Eigen is available; if not, remove from PYBIND11_TEST_FILES (but
 # keep it in PYBIND11_PYTEST_FILES, so that we get the "eigen is not installed"
@@ -105,21 +169,45 @@ if(PYBIND11_TEST_FILES_EIGEN_I GREATER -
   # Try loading via newer Eigen's Eigen3Config first (bypassing tools/FindEigen3.cmake).
   # Eigen 3.3.1+ exports a cmake 3.0+ target for handling dependency requirements, but also
   # produces a fatal error if loaded from a pre-3.0 cmake.
-  if (NOT CMAKE_VERSION VERSION_LESS 3.0)
+  if(DOWNLOAD_EIGEN)
+    if(CMAKE_VERSION VERSION_LESS 3.11)
+      message(FATAL_ERROR "CMake 3.11+ required when using DOWNLOAD_EIGEN")
+    endif()
+
+    set(EIGEN3_VERSION_STRING "3.3.7")
+
+    include(FetchContent)
+    FetchContent_Declare(
+      eigen
+      GIT_REPOSITORY https://gitlab.com/libeigen/eigen.git
+      GIT_TAG ${EIGEN3_VERSION_STRING})
+
+    FetchContent_GetProperties(eigen)
+    if(NOT eigen_POPULATED)
+      message(STATUS "Downloading Eigen")
+      FetchContent_Populate(eigen)
+    endif()
+
+    set(EIGEN3_INCLUDE_DIR ${eigen_SOURCE_DIR})
+    set(EIGEN3_FOUND TRUE)
+
+  else()
     find_package(Eigen3 3.2.7 QUIET CONFIG)
-    if (EIGEN3_FOUND)
-      if (EIGEN3_VERSION_STRING AND NOT EIGEN3_VERSION_STRING VERSION_LESS 3.3.1)
-        set(PYBIND11_EIGEN_VIA_TARGET 1)
-      endif()
+
+    if(NOT EIGEN3_FOUND)
+      # Couldn't load via target, so fall back to allowing module mode finding, which will pick up
+      # tools/FindEigen3.cmake
+      find_package(Eigen3 3.2.7 QUIET)
     endif()
   endif()
-  if (NOT EIGEN3_FOUND)
-    # Couldn't load via target, so fall back to allowing module mode finding, which will pick up
-    # tools/FindEigen3.cmake
-    find_package(Eigen3 3.2.7 QUIET)
-  endif()
 
   if(EIGEN3_FOUND)
+    if(NOT TARGET Eigen3::Eigen)
+      add_library(Eigen3::Eigen IMPORTED INTERFACE)
+      set_property(TARGET Eigen3::Eigen PROPERTY INTERFACE_INCLUDE_DIRECTORIES
+                                                 "${EIGEN3_INCLUDE_DIR}")
+    endif()
+
     # Eigen 3.3.1+ cmake sets EIGEN3_VERSION_STRING (and hard codes the version when installed
     # rather than looking it up in the cmake script); older versions, and the
     # tools/FindEigen3.cmake, set EIGEN3_VERSION instead.
@@ -129,28 +217,56 @@ if(PYBIND11_TEST_FILES_EIGEN_I GREATER -
     message(STATUS "Building tests with Eigen v${EIGEN3_VERSION}")
   else()
     list(REMOVE_AT PYBIND11_TEST_FILES ${PYBIND11_TEST_FILES_EIGEN_I})
-    message(STATUS "Building tests WITHOUT Eigen")
+    message(STATUS "Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download")
   endif()
 endif()
 
 # Optional dependency for some tests (boost::variant is only supported with version >= 1.56)
 find_package(Boost 1.56)
 
+if(Boost_FOUND)
+  if(NOT TARGET Boost::headers)
+    if(TARGET Boost::boost)
+      # Classic FindBoost
+      add_library(Boost::headers ALIAS Boost::boost)
+    else()
+      # Very old FindBoost, or newer Boost than CMake in older CMakes
+      add_library(Boost::headers IMPORTED INTERFACE)
+      set_property(TARGET Boost::headers PROPERTY INTERFACE_INCLUDE_DIRECTORIES
+                                                  ${Boost_INCLUDE_DIRS})
+    endif()
+  endif()
+endif()
+
 # Compile with compiler warnings turned on
 function(pybind11_enable_warnings target_name)
   if(MSVC)
     target_compile_options(${target_name} PRIVATE /W4)
-  elseif(CMAKE_CXX_COMPILER_ID MATCHES "(GNU|Intel|Clang)")
-      target_compile_options(${target_name} PRIVATE -Wall -Wextra -Wconversion -Wcast-qual -Wdeprecated)
+  elseif(CMAKE_CXX_COMPILER_ID MATCHES "(GNU|Intel|Clang)" AND NOT PYBIND11_CUDA_TESTS)
+    target_compile_options(${target_name} PRIVATE -Wall -Wextra -Wconversion -Wcast-qual
+                                                  -Wdeprecated -Wundef)
   endif()
 
   if(PYBIND11_WERROR)
     if(MSVC)
       target_compile_options(${target_name} PRIVATE /WX)
+    elseif(PYBIND11_CUDA_TESTS)
+      target_compile_options(${target_name} PRIVATE "SHELL:-Werror all-warnings")
     elseif(CMAKE_CXX_COMPILER_ID MATCHES "(GNU|Intel|Clang)")
       target_compile_options(${target_name} PRIVATE -Werror)
     endif()
   endif()
+
+  # Needs to be readded since the ordering requires these to be after the ones above
+  if(CMAKE_CXX_STANDARD
+     AND CMAKE_CXX_COMPILER_ID MATCHES "Clang"
+     AND PYTHON_VERSION VERSION_LESS 3.0)
+    if(CMAKE_CXX_STANDARD LESS 17)
+      target_compile_options(${target_name} PUBLIC -Wno-deprecated-register)
+    else()
+      target_compile_options(${target_name} PUBLIC -Wno-register)
+    endif()
+  endif()
 endfunction()
 
 set(test_targets pybind11_tests)
@@ -158,7 +274,7 @@ set(test_targets pybind11_tests)
 # Build pybind11_cross_module_tests if any test_whatever.py are being built that require it
 foreach(t ${PYBIND11_CROSS_MODULE_TESTS})
   list(FIND PYBIND11_PYTEST_FILES ${t} i)
-  if (i GREATER -1)
+  if(i GREATER -1)
     list(APPEND test_targets pybind11_cross_module_tests)
     break()
   endif()
@@ -166,78 +282,118 @@ endforeach()
 
 foreach(t ${PYBIND11_CROSS_MODULE_GIL_TESTS})
   list(FIND PYBIND11_PYTEST_FILES ${t} i)
-  if (i GREATER -1)
+  if(i GREATER -1)
     list(APPEND test_targets cross_module_gil_utils)
     break()
   endif()
 endforeach()
 
-set(testdir ${CMAKE_CURRENT_SOURCE_DIR})
+# Support CUDA testing by forcing the target file to compile with NVCC
+if(PYBIND11_CUDA_TESTS)
+  set_property(SOURCE ${PYBIND11_TEST_FILES} PROPERTY LANGUAGE CUDA)
+endif()
+
 foreach(target ${test_targets})
   set(test_files ${PYBIND11_TEST_FILES})
-  if(NOT target STREQUAL "pybind11_tests")
+  if(NOT "${target}" STREQUAL "pybind11_tests")
     set(test_files "")
   endif()
 
+  # Support CUDA testing by forcing the target file to compile with NVCC
+  if(PYBIND11_CUDA_TESTS)
+    set_property(SOURCE ${target}.cpp PROPERTY LANGUAGE CUDA)
+  endif()
+
   # Create the binding library
   pybind11_add_module(${target} THIN_LTO ${target}.cpp ${test_files} ${PYBIND11_HEADERS})
   pybind11_enable_warnings(${target})
 
+  if(NOT CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_CURRENT_BINARY_DIR)
+    get_property(
+      suffix
+      TARGET ${target}
+      PROPERTY SUFFIX)
+    set(source_output "${CMAKE_CURRENT_SOURCE_DIR}/${target}${suffix}")
+    if(suffix AND EXISTS "${source_output}")
+      message(WARNING "Output file also in source directory; "
+                      "please remove to avoid confusion: ${source_output}")
+    endif()
+  endif()
+
   if(MSVC)
     target_compile_options(${target} PRIVATE /utf-8)
   endif()
 
   if(EIGEN3_FOUND)
-    if (PYBIND11_EIGEN_VIA_TARGET)
-      target_link_libraries(${target} PRIVATE Eigen3::Eigen)
-    else()
-      target_include_directories(${target} PRIVATE ${EIGEN3_INCLUDE_DIR})
-    endif()
+    target_link_libraries(${target} PRIVATE Eigen3::Eigen)
     target_compile_definitions(${target} PRIVATE -DPYBIND11_TEST_EIGEN)
   endif()
 
   if(Boost_FOUND)
-    target_include_directories(${target} PRIVATE ${Boost_INCLUDE_DIRS})
+    target_link_libraries(${target} PRIVATE Boost::headers)
     target_compile_definitions(${target} PRIVATE -DPYBIND11_TEST_BOOST)
   endif()
 
   # Always write the output file directly into the 'tests' directory (even on MSVC)
   if(NOT CMAKE_LIBRARY_OUTPUT_DIRECTORY)
-    set_target_properties(${target} PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${testdir})
+    set_target_properties(${target} PROPERTIES LIBRARY_OUTPUT_DIRECTORY
+                                               "${CMAKE_CURRENT_BINARY_DIR}")
     foreach(config ${CMAKE_CONFIGURATION_TYPES})
       string(TOUPPER ${config} config)
-      set_target_properties(${target} PROPERTIES LIBRARY_OUTPUT_DIRECTORY_${config} ${testdir})
+      set_target_properties(${target} PROPERTIES LIBRARY_OUTPUT_DIRECTORY_${config}
+                                                 "${CMAKE_CURRENT_BINARY_DIR}")
     endforeach()
   endif()
 endforeach()
 
-# Make sure pytest is found or produce a fatal error
+# Make sure pytest is found or produce a warning
 if(NOT PYBIND11_PYTEST_FOUND)
-  execute_process(COMMAND ${PYTHON_EXECUTABLE} -c "import pytest; print(pytest.__version__)"
-                  RESULT_VARIABLE pytest_not_found OUTPUT_VARIABLE pytest_version ERROR_QUIET)
+  execute_process(
+    COMMAND ${PYTHON_EXECUTABLE} -c "import pytest; print(pytest.__version__)"
+    RESULT_VARIABLE pytest_not_found
+    OUTPUT_VARIABLE pytest_version
+    ERROR_QUIET)
   if(pytest_not_found)
-    message(FATAL_ERROR "Running the tests requires pytest. Please install it manually"
-                        " (try: ${PYTHON_EXECUTABLE} -m pip install pytest)")
-  elseif(pytest_version VERSION_LESS 3.0)
-    message(FATAL_ERROR "Running the tests requires pytest >= 3.0. Found: ${pytest_version}"
-                        "Please update it (try: ${PYTHON_EXECUTABLE} -m pip install -U pytest)")
+    message(WARNING "Running the tests requires pytest. Please install it manually"
+                    " (try: ${PYTHON_EXECUTABLE} -m pip install pytest)")
+  elseif(pytest_version VERSION_LESS 3.1)
+    message(WARNING "Running the tests requires pytest >= 3.1. Found: ${pytest_version}"
+                    "Please update it (try: ${PYTHON_EXECUTABLE} -m pip install -U pytest)")
+  else()
+    set(PYBIND11_PYTEST_FOUND
+        TRUE
+        CACHE INTERNAL "")
   endif()
-  set(PYBIND11_PYTEST_FOUND TRUE CACHE INTERNAL "")
 endif()
 
-if(CMAKE_VERSION VERSION_LESS 3.2)
-  set(PYBIND11_USES_TERMINAL "")
-else()
-  set(PYBIND11_USES_TERMINAL "USES_TERMINAL")
+if(NOT CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_CURRENT_BINARY_DIR)
+  # This is not used later in the build, so it's okay to regenerate each time.
+  configure_file("${CMAKE_CURRENT_SOURCE_DIR}/pytest.ini" "${CMAKE_CURRENT_BINARY_DIR}/pytest.ini"
+                 COPYONLY)
+  file(APPEND "${CMAKE_CURRENT_BINARY_DIR}/pytest.ini"
+       "\ntestpaths = \"${CMAKE_CURRENT_SOURCE_DIR}\"")
+
 endif()
 
+# cmake 3.12 added list(transform <list> prepend
+# but we can't use it yet
+string(REPLACE "test_" "${CMAKE_CURRENT_BINARY_DIR}/test_" PYBIND11_BINARY_TEST_FILES
+               "${PYBIND11_PYTEST_FILES}")
+
 # A single command to compile and run the tests
-add_custom_target(pytest COMMAND ${PYTHON_EXECUTABLE} -m pytest ${PYBIND11_PYTEST_FILES}
-                  DEPENDS ${test_targets} WORKING_DIRECTORY ${testdir} ${PYBIND11_USES_TERMINAL})
+add_custom_target(
+  pytest
+  COMMAND ${PYTHON_EXECUTABLE} -m pytest ${PYBIND11_BINARY_PYTEST_FILES}
+  DEPENDS ${test_targets}
+  WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
+  USES_TERMINAL)
 
 if(PYBIND11_TEST_OVERRIDE)
-  add_custom_command(TARGET pytest POST_BUILD
-    COMMAND ${CMAKE_COMMAND} -E echo "Note: not all tests run: -DPYBIND11_TEST_OVERRIDE is in effect")
+  add_custom_command(
+    TARGET pytest
+    POST_BUILD
+    COMMAND ${CMAKE_COMMAND} -E echo
+            "Note: not all tests run: -DPYBIND11_TEST_OVERRIDE is in effect")
 endif()
 
 # Add a check target to run all the tests, starting with pytest (we add dependencies to this below)
@@ -245,17 +401,23 @@ add_custom_target(check DEPENDS pytest)
 
 # The remaining tests only apply when being built as part of the pybind11 project, but not if the
 # tests are being built independently.
-if (NOT PROJECT_NAME STREQUAL "pybind11")
+if(CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_SOURCE_DIR)
   return()
 endif()
 
 # Add a post-build comment to show the primary test suite .so size and, if a previous size, compare it:
-add_custom_command(TARGET pybind11_tests POST_BUILD
-  COMMAND ${PYTHON_EXECUTABLE} ${PROJECT_SOURCE_DIR}/tools/libsize.py
-  $<TARGET_FILE:pybind11_tests> ${CMAKE_CURRENT_BINARY_DIR}/sosize-$<TARGET_FILE_NAME:pybind11_tests>.txt)
-
-# Test embedding the interpreter. Provides the `cpptest` target.
-add_subdirectory(test_embed)
+add_custom_command(
+  TARGET pybind11_tests
+  POST_BUILD
+  COMMAND
+    ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/../tools/libsize.py
+    $<TARGET_FILE:pybind11_tests>
+    ${CMAKE_CURRENT_BINARY_DIR}/sosize-$<TARGET_FILE_NAME:pybind11_tests>.txt)
+
+if(NOT PYBIND11_CUDA_TESTS)
+  # Test embedding the interpreter. Provides the `cpptest` target.
+  add_subdirectory(test_embed)
 
-# Test CMake build using functions and targets from subdirectory or installed location
-add_subdirectory(test_cmake_build)
+  # Test CMake build using functions and targets from subdirectory or installed location
+  add_subdirectory(test_cmake_build)
+endif()
--- gtsam-4.1.0.orig/wrap/pybind11/tests/conftest.py
+++ gtsam-4.1.0/wrap/pybind11/tests/conftest.py
@@ -5,22 +5,26 @@ Extends output capture as needed by pybi
 Adds docstring and exceptions message sanitizers: ignore Python 2 vs 3 differences.
 """
 
-import pytest
-import textwrap
-import difflib
-import re
-import sys
 import contextlib
-import platform
+import difflib
 import gc
+import re
+import textwrap
+
+import pytest
+
+import env
+
+# Early diagnostic for failed imports
+import pybind11_tests  # noqa: F401
 
 _unicode_marker = re.compile(r'u(\'[^\']*\')')
 _long_marker = re.compile(r'([0-9])L')
 _hexadecimal = re.compile(r'0x[0-9a-fA-F]+')
 
-# test_async.py requires support for async and await
+# Avoid collecting Python3 only files
 collect_ignore = []
-if sys.version_info[:2] < (3, 5):
+if env.PY2:
     collect_ignore.append("test_async.py")
 
 
@@ -192,59 +196,5 @@ def gc_collect():
 
 
 def pytest_configure():
-    """Add import suppression and test requirements to `pytest` namespace"""
-    try:
-        import numpy as np
-    except ImportError:
-        np = None
-    try:
-        import scipy
-    except ImportError:
-        scipy = None
-    try:
-        from pybind11_tests.eigen import have_eigen
-    except ImportError:
-        have_eigen = False
-    pypy = platform.python_implementation() == "PyPy"
-
-    skipif = pytest.mark.skipif
     pytest.suppress = suppress
-    pytest.requires_numpy = skipif(not np, reason="numpy is not installed")
-    pytest.requires_scipy = skipif(not np, reason="scipy is not installed")
-    pytest.requires_eigen_and_numpy = skipif(not have_eigen or not np,
-                                             reason="eigen and/or numpy are not installed")
-    pytest.requires_eigen_and_scipy = skipif(
-        not have_eigen or not scipy, reason="eigen and/or scipy are not installed")
-    pytest.unsupported_on_pypy = skipif(pypy, reason="unsupported on PyPy")
-    pytest.bug_in_pypy = pytest.mark.xfail(pypy, reason="bug in PyPy")
-    pytest.unsupported_on_pypy3 = skipif(pypy and sys.version_info.major >= 3,
-                                         reason="unsupported on PyPy3")
-    pytest.unsupported_on_pypy_lt_6 = skipif(pypy and sys.pypy_version_info[0] < 6,
-                                             reason="unsupported on PyPy<6")
-    pytest.unsupported_on_py2 = skipif(sys.version_info.major < 3,
-                                       reason="unsupported on Python 2.x")
     pytest.gc_collect = gc_collect
-
-
-def _test_import_pybind11():
-    """Early diagnostic for test module initialization errors
-
-    When there is an error during initialization, the first import will report the
-    real error while all subsequent imports will report nonsense. This import test
-    is done early (in the pytest configuration file, before any tests) in order to
-    avoid the noise of having all tests fail with identical error messages.
-
-    Any possible exception is caught here and reported manually *without* the stack
-    trace. This further reduces noise since the trace would only show pytest internals
-    which are not useful for debugging pybind11 module issues.
-    """
-    # noinspection PyBroadException
-    try:
-        import pybind11_tests  # noqa: F401 imported but unused
-    except Exception as e:
-        print("Failed to import pybind11_tests from pytest:")
-        print("  {}: {}".format(type(e).__name__, e))
-        sys.exit(1)
-
-
-_test_import_pybind11()
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tests/env.py
@@ -0,0 +1,14 @@
+# -*- coding: utf-8 -*-
+import platform
+import sys
+
+LINUX = sys.platform.startswith("linux")
+MACOS = sys.platform.startswith("darwin")
+WIN = sys.platform.startswith("win32") or sys.platform.startswith("cygwin")
+
+CPYTHON = platform.python_implementation() == "CPython"
+PYPY = platform.python_implementation() == "PyPy"
+
+PY2 = sys.version_info.major == 2
+
+PY = sys.version_info
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tests/extra_python_package/test_files.py
@@ -0,0 +1,259 @@
+# -*- coding: utf-8 -*-
+import contextlib
+import os
+import string
+import subprocess
+import sys
+import tarfile
+import zipfile
+
+# These tests must be run explicitly
+# They require CMake 3.15+ (--install)
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+MAIN_DIR = os.path.dirname(os.path.dirname(DIR))
+
+
+main_headers = {
+    "include/pybind11/attr.h",
+    "include/pybind11/buffer_info.h",
+    "include/pybind11/cast.h",
+    "include/pybind11/chrono.h",
+    "include/pybind11/common.h",
+    "include/pybind11/complex.h",
+    "include/pybind11/eigen.h",
+    "include/pybind11/embed.h",
+    "include/pybind11/eval.h",
+    "include/pybind11/functional.h",
+    "include/pybind11/iostream.h",
+    "include/pybind11/numpy.h",
+    "include/pybind11/operators.h",
+    "include/pybind11/options.h",
+    "include/pybind11/pybind11.h",
+    "include/pybind11/pytypes.h",
+    "include/pybind11/stl.h",
+    "include/pybind11/stl_bind.h",
+}
+
+detail_headers = {
+    "include/pybind11/detail/class.h",
+    "include/pybind11/detail/common.h",
+    "include/pybind11/detail/descr.h",
+    "include/pybind11/detail/init.h",
+    "include/pybind11/detail/internals.h",
+    "include/pybind11/detail/typeid.h",
+}
+
+cmake_files = {
+    "share/cmake/pybind11/FindPythonLibsNew.cmake",
+    "share/cmake/pybind11/pybind11Common.cmake",
+    "share/cmake/pybind11/pybind11Config.cmake",
+    "share/cmake/pybind11/pybind11ConfigVersion.cmake",
+    "share/cmake/pybind11/pybind11NewTools.cmake",
+    "share/cmake/pybind11/pybind11Targets.cmake",
+    "share/cmake/pybind11/pybind11Tools.cmake",
+}
+
+py_files = {
+    "__init__.py",
+    "__main__.py",
+    "_version.py",
+    "commands.py",
+    "setup_helpers.py",
+}
+
+headers = main_headers | detail_headers
+src_files = headers | cmake_files
+all_files = src_files | py_files
+
+
+sdist_files = {
+    "pybind11",
+    "pybind11/include",
+    "pybind11/include/pybind11",
+    "pybind11/include/pybind11/detail",
+    "pybind11/share",
+    "pybind11/share/cmake",
+    "pybind11/share/cmake/pybind11",
+    "pyproject.toml",
+    "setup.cfg",
+    "setup.py",
+    "LICENSE",
+    "MANIFEST.in",
+    "README.md",
+    "PKG-INFO",
+}
+
+local_sdist_files = {
+    ".egg-info",
+    ".egg-info/PKG-INFO",
+    ".egg-info/SOURCES.txt",
+    ".egg-info/dependency_links.txt",
+    ".egg-info/not-zip-safe",
+    ".egg-info/top_level.txt",
+}
+
+
+def test_build_sdist(monkeypatch, tmpdir):
+
+    monkeypatch.chdir(MAIN_DIR)
+
+    out = subprocess.check_output(
+        [
+            sys.executable,
+            "setup.py",
+            "sdist",
+            "--formats=tar",
+            "--dist-dir",
+            str(tmpdir),
+        ]
+    )
+    if hasattr(out, "decode"):
+        out = out.decode()
+
+    (sdist,) = tmpdir.visit("*.tar")
+
+    with tarfile.open(str(sdist)) as tar:
+        start = tar.getnames()[0] + "/"
+        version = start[9:-1]
+        simpler = set(n.split("/", 1)[-1] for n in tar.getnames()[1:])
+
+        with contextlib.closing(
+            tar.extractfile(tar.getmember(start + "setup.py"))
+        ) as f:
+            setup_py = f.read()
+
+        with contextlib.closing(
+            tar.extractfile(tar.getmember(start + "pyproject.toml"))
+        ) as f:
+            pyproject_toml = f.read()
+
+    files = set("pybind11/{}".format(n) for n in all_files)
+    files |= sdist_files
+    files |= set("pybind11{}".format(n) for n in local_sdist_files)
+    files.add("pybind11.egg-info/entry_points.txt")
+    files.add("pybind11.egg-info/requires.txt")
+    assert simpler == files
+
+    with open(os.path.join(MAIN_DIR, "tools", "setup_main.py.in"), "rb") as f:
+        contents = (
+            string.Template(f.read().decode())
+            .substitute(version=version, extra_cmd="")
+            .encode()
+        )
+        assert setup_py == contents
+
+    with open(os.path.join(MAIN_DIR, "tools", "pyproject.toml"), "rb") as f:
+        contents = f.read()
+        assert pyproject_toml == contents
+
+
+def test_build_global_dist(monkeypatch, tmpdir):
+
+    monkeypatch.chdir(MAIN_DIR)
+    monkeypatch.setenv("PYBIND11_GLOBAL_SDIST", "1")
+
+    out = subprocess.check_output(
+        [
+            sys.executable,
+            "setup.py",
+            "sdist",
+            "--formats=tar",
+            "--dist-dir",
+            str(tmpdir),
+        ]
+    )
+    if hasattr(out, "decode"):
+        out = out.decode()
+
+    (sdist,) = tmpdir.visit("*.tar")
+
+    with tarfile.open(str(sdist)) as tar:
+        start = tar.getnames()[0] + "/"
+        version = start[16:-1]
+        simpler = set(n.split("/", 1)[-1] for n in tar.getnames()[1:])
+
+        with contextlib.closing(
+            tar.extractfile(tar.getmember(start + "setup.py"))
+        ) as f:
+            setup_py = f.read()
+
+        with contextlib.closing(
+            tar.extractfile(tar.getmember(start + "pyproject.toml"))
+        ) as f:
+            pyproject_toml = f.read()
+
+    files = set("pybind11/{}".format(n) for n in all_files)
+    files |= sdist_files
+    files |= set("pybind11_global{}".format(n) for n in local_sdist_files)
+    assert simpler == files
+
+    with open(os.path.join(MAIN_DIR, "tools", "setup_global.py.in"), "rb") as f:
+        contents = (
+            string.Template(f.read().decode())
+            .substitute(version=version, extra_cmd="")
+            .encode()
+        )
+        assert setup_py == contents
+
+    with open(os.path.join(MAIN_DIR, "tools", "pyproject.toml"), "rb") as f:
+        contents = f.read()
+        assert pyproject_toml == contents
+
+
+def tests_build_wheel(monkeypatch, tmpdir):
+    monkeypatch.chdir(MAIN_DIR)
+
+    subprocess.check_output(
+        [sys.executable, "-m", "pip", "wheel", ".", "-w", str(tmpdir)]
+    )
+
+    (wheel,) = tmpdir.visit("*.whl")
+
+    files = set("pybind11/{}".format(n) for n in all_files)
+    files |= {
+        "dist-info/LICENSE",
+        "dist-info/METADATA",
+        "dist-info/RECORD",
+        "dist-info/WHEEL",
+        "dist-info/entry_points.txt",
+        "dist-info/top_level.txt",
+    }
+
+    with zipfile.ZipFile(str(wheel)) as z:
+        names = z.namelist()
+
+    trimmed = set(n for n in names if "dist-info" not in n)
+    trimmed |= set(
+        "dist-info/{}".format(n.split("/", 1)[-1]) for n in names if "dist-info" in n
+    )
+    assert files == trimmed
+
+
+def tests_build_global_wheel(monkeypatch, tmpdir):
+    monkeypatch.chdir(MAIN_DIR)
+    monkeypatch.setenv("PYBIND11_GLOBAL_SDIST", "1")
+
+    subprocess.check_output(
+        [sys.executable, "-m", "pip", "wheel", ".", "-w", str(tmpdir)]
+    )
+
+    (wheel,) = tmpdir.visit("*.whl")
+
+    files = set("data/data/{}".format(n) for n in src_files)
+    files |= set("data/headers/{}".format(n[8:]) for n in headers)
+    files |= {
+        "dist-info/LICENSE",
+        "dist-info/METADATA",
+        "dist-info/WHEEL",
+        "dist-info/top_level.txt",
+        "dist-info/RECORD",
+    }
+
+    with zipfile.ZipFile(str(wheel)) as z:
+        names = z.namelist()
+
+    beginning = names[0].split("/", 1)[0].rsplit(".", 1)[0]
+    trimmed = set(n[len(beginning) + 1 :] for n in names)
+
+    assert files == trimmed
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tests/extra_setuptools/test_setuphelper.py
@@ -0,0 +1,95 @@
+# -*- coding: utf-8 -*-
+import os
+import sys
+import subprocess
+from textwrap import dedent
+
+import pytest
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+MAIN_DIR = os.path.dirname(os.path.dirname(DIR))
+
+
+@pytest.mark.parametrize("std", [11, 0])
+def test_simple_setup_py(monkeypatch, tmpdir, std):
+    monkeypatch.chdir(tmpdir)
+    monkeypatch.syspath_prepend(MAIN_DIR)
+
+    (tmpdir / "setup.py").write_text(
+        dedent(
+            u"""\
+            import sys
+            sys.path.append({MAIN_DIR!r})
+
+            from setuptools import setup, Extension
+            from pybind11.setup_helpers import build_ext, Pybind11Extension
+
+            std = {std}
+
+            ext_modules = [
+                Pybind11Extension(
+                    "simple_setup",
+                    sorted(["main.cpp"]),
+                    cxx_std=std,
+                ),
+            ]
+
+            cmdclass = dict()
+            if std == 0:
+                cmdclass["build_ext"] = build_ext
+
+
+            setup(
+                name="simple_setup_package",
+                cmdclass=cmdclass,
+                ext_modules=ext_modules,
+            )
+            """
+        ).format(MAIN_DIR=MAIN_DIR, std=std),
+        encoding="ascii",
+    )
+
+    (tmpdir / "main.cpp").write_text(
+        dedent(
+            u"""\
+            #include <pybind11/pybind11.h>
+
+            int f(int x) {
+                return x * 3;
+            }
+            PYBIND11_MODULE(simple_setup, m) {
+                m.def("f", &f);
+            }
+            """
+        ),
+        encoding="ascii",
+    )
+
+    subprocess.check_call(
+        [sys.executable, "setup.py", "build_ext", "--inplace"],
+        stdout=sys.stdout,
+        stderr=sys.stderr,
+    )
+
+    # Debug helper printout, normally hidden
+    for item in tmpdir.listdir():
+        print(item.basename)
+
+    assert (
+        len([f for f in tmpdir.listdir() if f.basename.startswith("simple_setup")]) == 1
+    )
+    assert len(list(tmpdir.listdir())) == 4  # two files + output + build_dir
+
+    (tmpdir / "test.py").write_text(
+        dedent(
+            u"""\
+            import simple_setup
+            assert simple_setup.f(3) == 9
+            """
+        ),
+        encoding="ascii",
+    )
+
+    subprocess.check_call(
+        [sys.executable, "test.py"], stdout=sys.stdout, stderr=sys.stderr
+    )
--- gtsam-4.1.0.orig/wrap/pybind11/tests/local_bindings.h
+++ gtsam-4.1.0/wrap/pybind11/tests/local_bindings.h
@@ -58,7 +58,7 @@ public:
     std::string name_;
     const std::string &name() { return name_; }
 };
-}
+} // namespace pets
 
 struct MixGL { int i; MixGL(int i) : i{i} {} };
 struct MixGL2 { int i; MixGL2(int i) : i{i} {} };
--- gtsam-4.1.0.orig/wrap/pybind11/tests/pybind11_tests.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/pybind11_tests.cpp
@@ -32,11 +32,11 @@ std::list<std::function<void(py::module
 }
 
 test_initializer::test_initializer(Initializer init) {
-    initializers().push_back(init);
+    initializers().emplace_back(init);
 }
 
 test_initializer::test_initializer(const char *submodule_name, Initializer init) {
-    initializers().push_back([=](py::module &parent) {
+    initializers().emplace_back([=](py::module &parent) {
         auto m = parent.def_submodule(submodule_name);
         init(m);
     });
@@ -88,6 +88,4 @@ PYBIND11_MODULE(pybind11_tests, m) {
 
     for (const auto &initializer : initializers())
         initializer(m);
-
-    if (!py::hasattr(m, "have_eigen")) m.attr("have_eigen") = false;
 }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/pytest.ini
+++ gtsam-4.1.0/wrap/pybind11/tests/pytest.ini
@@ -1,11 +1,14 @@
 [pytest]
-minversion = 3.0
-norecursedirs = test_cmake_build test_embed
+minversion = 3.1
+norecursedirs = test_* extra_*
+xfail_strict = True
 addopts =
     # show summary of skipped tests
     -rs
     # capture only Python print and C++ py::print, but not C output (low-level Python errors)
     --capture=sys
+    # enable all warnings
+    -Wa
 filterwarnings =
     # make warnings into errors but ignore certain third-party extension issues
     error
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tests/requirements.txt
@@ -0,0 +1,8 @@
+--extra-index-url https://antocuni.github.io/pypy-wheels/manylinux2010/
+numpy==1.16.6; python_version<"3.6"
+numpy==1.18.0; platform_python_implementation=="PyPy" and sys_platform=="darwin" and python_version>="3.6"
+numpy==1.19.1; (platform_python_implementation!="PyPy" or sys_platform!="darwin") and python_version>="3.6" and python_version<"3.9"
+pytest==4.6.9; python_version<"3.5"
+pytest==5.4.3; python_version>="3.5"
+scipy==1.2.3; (platform_python_implementation!="PyPy" or sys_platform!="darwin") and python_version<"3.6"
+scipy==1.5.2; (platform_python_implementation!="PyPy" or sys_platform!="darwin") and python_version>="3.6" and python_version<"3.9"
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_async.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_async.py
@@ -1,7 +1,8 @@
 # -*- coding: utf-8 -*-
-import asyncio
 import pytest
-from pybind11_tests import async_module as m
+
+asyncio = pytest.importorskip("asyncio")
+m = pytest.importorskip("pybind11_tests.async_module")
 
 
 @pytest.fixture
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_buffers.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_buffers.py
@@ -1,19 +1,15 @@
 # -*- coding: utf-8 -*-
 import io
 import struct
-import sys
 
 import pytest
 
+import env  # noqa: F401
+
 from pybind11_tests import buffers as m
 from pybind11_tests import ConstructorStats
 
-PY3 = sys.version_info[0] >= 3
-
-pytestmark = pytest.requires_numpy
-
-with pytest.suppress(ImportError):
-    import numpy as np
+np = pytest.importorskip("numpy")
 
 
 def test_from_python():
@@ -39,9 +35,7 @@ def test_from_python():
     assert cstats.move_assignments == 0
 
 
-# PyPy: Memory leak in the "np.array(m, copy=False)" call
-# https://bitbucket.org/pypy/pypy/issues/2444
-@pytest.unsupported_on_pypy
+# https://foss.heptapod.net/pypy/pypy/-/issues/2444
 def test_to_python():
     mat = m.Matrix(5, 4)
     assert memoryview(mat).shape == (5, 4)
@@ -76,7 +70,6 @@ def test_to_python():
     assert cstats.move_assignments == 0
 
 
-@pytest.unsupported_on_pypy
 def test_inherited_protocol():
     """SquareMatrix is derived from Matrix and inherits the buffer protocol"""
 
@@ -85,7 +78,6 @@ def test_inherited_protocol():
     assert np.asarray(matrix).shape == (5, 5)
 
 
-@pytest.unsupported_on_pypy
 def test_pointer_to_member_fn():
     for cls in [m.Buffer, m.ConstBuffer, m.DerivedBuffer]:
         buf = cls()
@@ -94,19 +86,17 @@ def test_pointer_to_member_fn():
         assert value == 0x12345678
 
 
-@pytest.unsupported_on_pypy
 def test_readonly_buffer():
     buf = m.BufferReadOnly(0x64)
     view = memoryview(buf)
-    assert view[0] == 0x64 if PY3 else b'd'
+    assert view[0] == b'd' if env.PY2 else 0x64
     assert view.readonly
 
 
-@pytest.unsupported_on_pypy
 def test_selective_readonly_buffer():
     buf = m.BufferReadOnlySelect()
 
-    memoryview(buf)[0] = 0x64 if PY3 else b'd'
+    memoryview(buf)[0] = b'd' if env.PY2 else 0x64
     assert buf.value == 0x64
 
     io.BytesIO(b'A').readinto(buf)
@@ -114,6 +104,6 @@ def test_selective_readonly_buffer():
 
     buf.readonly = True
     with pytest.raises(TypeError):
-        memoryview(buf)[0] = 0 if PY3 else b'\0'
+        memoryview(buf)[0] = b'\0' if env.PY2 else 0
     with pytest.raises(TypeError):
         io.BytesIO(b'1').readinto(buf)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_builtin_casters.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_builtin_casters.cpp
@@ -117,12 +117,16 @@ TEST_SUBMODULE(builtin_casters, m) {
         return std::make_pair(RValueCaster{}, std::make_tuple(RValueCaster{}, std::make_pair(RValueCaster{}, RValueCaster{}))); });
     m.def("lvalue_nested", []() -> const decltype(lvnested) & { return lvnested; });
 
+    static std::pair<int, std::string> int_string_pair{2, "items"};
+    m.def("int_string_pair", []() { return &int_string_pair; });
+
     // test_builtins_cast_return_none
     m.def("return_none_string", []() -> std::string * { return nullptr; });
     m.def("return_none_char",   []() -> const char *  { return nullptr; });
     m.def("return_none_bool",   []() -> bool *        { return nullptr; });
     m.def("return_none_int",    []() -> int *         { return nullptr; });
     m.def("return_none_float",  []() -> float *       { return nullptr; });
+    m.def("return_none_pair",   []() -> std::pair<int,int> * { return nullptr; });
 
     // test_none_deferred
     m.def("defer_none_cstring", [](char *) { return false; });
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_builtin_casters.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_builtin_casters.py
@@ -1,6 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
 
+import env  # noqa: F401
+
 from pybind11_tests import builtin_casters as m
 from pybind11_tests import UserType, IncType
 
@@ -115,13 +117,16 @@ def test_bytes_to_string():
     """Tests the ability to pass bytes to C++ string-accepting functions.  Note that this is
     one-way: the only way to return bytes to Python is via the pybind11::bytes class."""
     # Issue #816
-    import sys
-    byte = bytes if sys.version_info[0] < 3 else str
 
-    assert m.strlen(byte("hi")) == 2
-    assert m.string_length(byte("world")) == 5
-    assert m.string_length(byte("a\x00b")) == 3
-    assert m.strlen(byte("a\x00b")) == 1  # C-string limitation
+    def to_bytes(s):
+        b = s if env.PY2 else s.encode("utf8")
+        assert isinstance(b, bytes)
+        return b
+
+    assert m.strlen(to_bytes("hi")) == 2
+    assert m.string_length(to_bytes("world")) == 5
+    assert m.string_length(to_bytes("a\x00b")) == 3
+    assert m.strlen(to_bytes("a\x00b")) == 1  # C-string limitation
 
     # passing in a utf8 encoded string should work
     assert m.string_length(u'💩'.encode("utf8")) == 4
@@ -187,12 +192,11 @@ def test_string_view(capture):
 
 def test_integer_casting():
     """Issue #929 - out-of-range integer values shouldn't be accepted"""
-    import sys
     assert m.i32_str(-1) == "-1"
     assert m.i64_str(-1) == "-1"
     assert m.i32_str(2000000000) == "2000000000"
     assert m.u32_str(2000000000) == "2000000000"
-    if sys.version_info < (3,):
+    if env.PY2:
         assert m.i32_str(long(-1)) == "-1"  # noqa: F821 undefined name 'long'
         assert m.i64_str(long(-1)) == "-1"  # noqa: F821 undefined name 'long'
         assert m.i64_str(long(-999999999999)) == "-999999999999"  # noqa: F821 undefined name
@@ -214,7 +218,7 @@ def test_integer_casting():
         m.i32_str(3000000000)
     assert "incompatible function arguments" in str(excinfo.value)
 
-    if sys.version_info < (3,):
+    if env.PY2:
         with pytest.raises(TypeError) as excinfo:
             m.u32_str(long(-1))  # noqa: F821 undefined name 'long'
         assert "incompatible function arguments" in str(excinfo.value)
@@ -250,6 +254,8 @@ def test_tuple(doc):
     assert m.rvalue_nested() == ("rvalue", ("rvalue", ("rvalue", "rvalue")))
     assert m.lvalue_nested() == ("lvalue", ("lvalue", ("lvalue", "lvalue")))
 
+    assert m.int_string_pair() == (2, "items")
+
 
 def test_builtins_cast_return_none():
     """Casters produced with PYBIND11_TYPE_CASTER() should convert nullptr to None"""
@@ -258,6 +264,7 @@ def test_builtins_cast_return_none():
     assert m.return_none_bool() is None
     assert m.return_none_int() is None
     assert m.return_none_float() is None
+    assert m.return_none_pair() is None
 
 
 def test_none_deferred():
@@ -352,9 +359,9 @@ def test_bool_caster():
     assert convert(A(False)) is False
 
 
-@pytest.requires_numpy
 def test_numpy_bool():
-    import numpy as np
+    np = pytest.importorskip("numpy")
+
     convert, noconvert = m.bool_passthrough, m.bool_passthrough_noconvert
 
     def cant_convert(v):
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_call_policies.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_call_policies.cpp
@@ -46,6 +46,7 @@ TEST_SUBMODULE(call_policies, m) {
     class Parent {
     public:
         Parent() { py::print("Allocating parent."); }
+        Parent(const Parent& parent) = default;
         ~Parent() { py::print("Releasing parent."); }
         void addChild(Child *) { }
         Child *returnChild() { return new Child(); }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_call_policies.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_call_policies.py
@@ -1,9 +1,13 @@
 # -*- coding: utf-8 -*-
 import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import call_policies as m
 from pybind11_tests import ConstructorStats
 
 
+@pytest.mark.xfail("env.PYPY", reason="sometimes comes out 1 off on PyPy", strict=False)
 def test_keep_alive_argument(capture):
     n_inst = ConstructorStats.detail_reg_inst()
     with capture:
@@ -70,8 +74,8 @@ def test_keep_alive_return_value(capture
     """
 
 
-# https://bitbucket.org/pypy/pypy/issues/2447
-@pytest.unsupported_on_pypy
+# https://foss.heptapod.net/pypy/pypy/-/issues/2447
+@pytest.mark.xfail("env.PYPY", reason="_PyObject_GetDictPtr is unimplemented")
 def test_alive_gc(capture):
     n_inst = ConstructorStats.detail_reg_inst()
     p = m.ParentGC()
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_chrono.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_chrono.cpp
@@ -10,6 +10,25 @@
 
 #include "pybind11_tests.h"
 #include <pybind11/chrono.h>
+#include <chrono>
+
+struct different_resolutions {
+    using time_point_h = std::chrono::time_point<
+        std::chrono::system_clock, std::chrono::hours>;
+    using time_point_m = std::chrono::time_point<
+        std::chrono::system_clock, std::chrono::minutes>;
+    using time_point_s = std::chrono::time_point<
+        std::chrono::system_clock, std::chrono::seconds>;
+    using time_point_ms = std::chrono::time_point<
+        std::chrono::system_clock, std::chrono::milliseconds>;
+    using time_point_us = std::chrono::time_point<
+        std::chrono::system_clock, std::chrono::microseconds>;
+    time_point_h timestamp_h;
+    time_point_m timestamp_m;
+    time_point_s timestamp_s;
+    time_point_ms timestamp_ms;
+    time_point_us timestamp_us;
+};
 
 TEST_SUBMODULE(chrono, m) {
     using system_time = std::chrono::system_clock::time_point;
@@ -52,4 +71,14 @@ TEST_SUBMODULE(chrono, m) {
     m.def("test_nano_timepoint", [](timestamp start, timespan delta) -> timestamp {
         return start + delta;
     });
+
+    // Test different resolutions
+    py::class_<different_resolutions>(m, "different_resolutions")
+        .def(py::init<>())
+        .def_readwrite("timestamp_h", &different_resolutions::timestamp_h)
+        .def_readwrite("timestamp_m", &different_resolutions::timestamp_m)
+        .def_readwrite("timestamp_s", &different_resolutions::timestamp_s)
+        .def_readwrite("timestamp_ms", &different_resolutions::timestamp_ms)
+        .def_readwrite("timestamp_us", &different_resolutions::timestamp_us)
+        ;
 }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_chrono.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_chrono.py
@@ -1,11 +1,15 @@
 # -*- coding: utf-8 -*-
 from pybind11_tests import chrono as m
 import datetime
+import pytest
+
+import env  # noqa: F401
 
 
 def test_chrono_system_clock():
 
     # Get the time from both c++ and datetime
+    date0 = datetime.datetime.today()
     date1 = m.test_chrono1()
     date2 = datetime.datetime.today()
 
@@ -13,16 +17,15 @@ def test_chrono_system_clock():
     assert isinstance(date1, datetime.datetime)
 
     # The numbers should vary by a very small amount (time it took to execute)
+    diff_python = abs(date2 - date0)
     diff = abs(date1 - date2)
 
-    # There should never be a days/seconds difference
+    # There should never be a days difference
     assert diff.days == 0
-    assert diff.seconds == 0
 
-    # We test that no more than about 0.5 seconds passes here
-    # This makes sure that the dates created are very close to the same
-    # but if the testing system is incredibly overloaded this should still pass
-    assert diff.microseconds < 500000
+    # Since datetime.datetime.today() calls time.time(), and on some platforms
+    # that has 1 second accuracy, we compare this way
+    assert diff.seconds <= diff_python.seconds
 
 
 def test_chrono_system_clock_roundtrip():
@@ -72,8 +75,30 @@ def test_chrono_system_clock_roundtrip_d
     assert time2.microsecond == 0
 
 
-def test_chrono_system_clock_roundtrip_time():
-    time1 = datetime.datetime.today().time()
+SKIP_TZ_ENV_ON_WIN = pytest.mark.skipif(
+    "env.WIN", reason="TZ environment variable only supported on POSIX"
+)
+
+
+@pytest.mark.parametrize("time1", [
+    datetime.datetime.today().time(),
+    datetime.time(0, 0, 0),
+    datetime.time(0, 0, 0, 1),
+    datetime.time(0, 28, 45, 109827),
+    datetime.time(0, 59, 59, 999999),
+    datetime.time(1, 0, 0),
+    datetime.time(5, 59, 59, 0),
+    datetime.time(5, 59, 59, 1),
+])
+@pytest.mark.parametrize("tz", [
+    None,
+    pytest.param("Europe/Brussels", marks=SKIP_TZ_ENV_ON_WIN),
+    pytest.param("Asia/Pyongyang", marks=SKIP_TZ_ENV_ON_WIN),
+    pytest.param("America/New_York", marks=SKIP_TZ_ENV_ON_WIN),
+])
+def test_chrono_system_clock_roundtrip_time(time1, tz, monkeypatch):
+    if tz is not None:
+        monkeypatch.setenv("TZ", "/usr/share/zoneinfo/{}".format(tz))
 
     # Roundtrip the time
     datetime2 = m.test_chrono2(time1)
@@ -175,3 +200,13 @@ def test_nano_timepoint():
     time = datetime.datetime.now()
     time1 = m.test_nano_timepoint(time, datetime.timedelta(seconds=60))
     assert(time1 == time + datetime.timedelta(seconds=60))
+
+
+def test_chrono_different_resolutions():
+    resolutions = m.different_resolutions()
+    time = datetime.datetime.now()
+    resolutions.timestamp_h = time
+    resolutions.timestamp_m = time
+    resolutions.timestamp_s = time
+    resolutions.timestamp_ms = time
+    resolutions.timestamp_us = time
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_class.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_class.cpp
@@ -103,7 +103,7 @@ TEST_SUBMODULE(class_, m) {
         BaseClass() = default;
         BaseClass(const BaseClass &) = default;
         BaseClass(BaseClass &&) = default;
-        virtual ~BaseClass() {}
+        virtual ~BaseClass() = default;
     };
     struct DerivedClass1 : BaseClass { };
     struct DerivedClass2 : BaseClass { };
@@ -134,6 +134,32 @@ TEST_SUBMODULE(class_, m) {
         );
     });
 
+    struct Invalid {};
+
+    // test_type
+    m.def("check_type", [](int category) {
+        // Currently not supported (via a fail at compile time)
+        // See https://github.com/pybind/pybind11/issues/2486
+        // if (category == 2)
+        //     return py::type::of<int>();
+        if (category == 1)
+            return py::type::of<DerivedClass1>();
+        else
+            return py::type::of<Invalid>();
+    });
+
+    m.def("get_type_of", [](py::object ob) {
+        return py::type::of(ob);
+    });
+
+    m.def("as_type", [](py::object ob) {
+        auto tp = py::type(ob);
+        if (py::isinstance<py::type>(ob))
+            return tp;
+        else
+            throw std::runtime_error("Invalid type");
+    });
+
     // test_mismatched_holder
     struct MismatchBase1 { };
     struct MismatchDerived1 : MismatchBase1 { };
@@ -227,6 +253,8 @@ TEST_SUBMODULE(class_, m) {
         static void *operator new(size_t s, void *ptr) { py::print("C placement-new", s); return ptr; }
         static void operator delete(void *p, size_t s) { py::print("C delete", s); return ::operator delete(p); }
         virtual ~AliasedHasOpNewDelSize() = default;
+        AliasedHasOpNewDelSize() = default;
+        AliasedHasOpNewDelSize(const AliasedHasOpNewDelSize&) = delete;
     };
     struct PyAliasedHasOpNewDelSize : AliasedHasOpNewDelSize {
         PyAliasedHasOpNewDelSize() = default;
@@ -277,6 +305,8 @@ TEST_SUBMODULE(class_, m) {
     class ProtectedB {
     public:
         virtual ~ProtectedB() = default;
+        ProtectedB() = default;
+        ProtectedB(const ProtectedB &) = delete;
 
     protected:
         virtual int foo() const { return value; }
@@ -287,7 +317,7 @@ TEST_SUBMODULE(class_, m) {
 
     class TrampolineB : public ProtectedB {
     public:
-        int foo() const override { PYBIND11_OVERLOAD(int, ProtectedB, foo, ); }
+        int foo() const override { PYBIND11_OVERRIDE(int, ProtectedB, foo, ); }
     };
 
     class PublicistB : public ProtectedB {
@@ -323,7 +353,7 @@ TEST_SUBMODULE(class_, m) {
     // test_reentrant_implicit_conversion_failure
     // #1035: issue with runaway reentrant implicit conversion
     struct BogusImplicitConversion {
-        BogusImplicitConversion(const BogusImplicitConversion &) { }
+        BogusImplicitConversion(const BogusImplicitConversion &) = default;
     };
 
     py::class_<BogusImplicitConversion>(m, "BogusImplicitConversion")
@@ -375,19 +405,34 @@ TEST_SUBMODULE(class_, m) {
     // test_non_final_final
     struct IsNonFinalFinal {};
     py::class_<IsNonFinalFinal>(m, "IsNonFinalFinal", py::is_final());
+
+    struct PyPrintDestructor {
+        PyPrintDestructor() = default;
+        ~PyPrintDestructor() {
+            py::print("Print from destructor");
+        }
+        void throw_something() { throw std::runtime_error("error"); }
+    };
+    py::class_<PyPrintDestructor>(m, "PyPrintDestructor")
+        .def(py::init<>())
+        .def("throw_something", &PyPrintDestructor::throw_something);
 }
 
-template <int N> class BreaksBase { public: virtual ~BreaksBase() = default; };
+template <int N> class BreaksBase { public:
+    virtual ~BreaksBase() = default;
+    BreaksBase() = default;
+    BreaksBase(const BreaksBase&) = delete;
+};
 template <int N> class BreaksTramp : public BreaksBase<N> {};
 // These should all compile just fine:
-typedef py::class_<BreaksBase<1>, std::unique_ptr<BreaksBase<1>>, BreaksTramp<1>> DoesntBreak1;
-typedef py::class_<BreaksBase<2>, BreaksTramp<2>, std::unique_ptr<BreaksBase<2>>> DoesntBreak2;
-typedef py::class_<BreaksBase<3>, std::unique_ptr<BreaksBase<3>>> DoesntBreak3;
-typedef py::class_<BreaksBase<4>, BreaksTramp<4>> DoesntBreak4;
-typedef py::class_<BreaksBase<5>> DoesntBreak5;
-typedef py::class_<BreaksBase<6>, std::shared_ptr<BreaksBase<6>>, BreaksTramp<6>> DoesntBreak6;
-typedef py::class_<BreaksBase<7>, BreaksTramp<7>, std::shared_ptr<BreaksBase<7>>> DoesntBreak7;
-typedef py::class_<BreaksBase<8>, std::shared_ptr<BreaksBase<8>>> DoesntBreak8;
+using DoesntBreak1 = py::class_<BreaksBase<1>, std::unique_ptr<BreaksBase<1>>, BreaksTramp<1>>;
+using DoesntBreak2 = py::class_<BreaksBase<2>, BreaksTramp<2>, std::unique_ptr<BreaksBase<2>>>;
+using DoesntBreak3 = py::class_<BreaksBase<3>, std::unique_ptr<BreaksBase<3>>>;
+using DoesntBreak4 = py::class_<BreaksBase<4>, BreaksTramp<4>>;
+using DoesntBreak5 = py::class_<BreaksBase<5>>;
+using DoesntBreak6 = py::class_<BreaksBase<6>, std::shared_ptr<BreaksBase<6>>, BreaksTramp<6>>;
+using DoesntBreak7 = py::class_<BreaksBase<7>, BreaksTramp<7>, std::shared_ptr<BreaksBase<7>>>;
+using DoesntBreak8 = py::class_<BreaksBase<8>, std::shared_ptr<BreaksBase<8>>>;
 #define CHECK_BASE(N) static_assert(std::is_same<typename DoesntBreak##N::type, BreaksBase<N>>::value, \
         "DoesntBreak" #N " has wrong type!")
 CHECK_BASE(1); CHECK_BASE(2); CHECK_BASE(3); CHECK_BASE(4); CHECK_BASE(5); CHECK_BASE(6); CHECK_BASE(7); CHECK_BASE(8);
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_class.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_class.py
@@ -1,6 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
 
+import env  # noqa: F401
+
 from pybind11_tests import class_ as m
 from pybind11_tests import UserType, ConstructorStats
 
@@ -24,6 +26,40 @@ def test_instance(msg):
     assert cstats.alive() == 0
 
 
+def test_type():
+    assert m.check_type(1) == m.DerivedClass1
+    with pytest.raises(RuntimeError) as execinfo:
+        m.check_type(0)
+
+    assert 'pybind11::detail::get_type_info: unable to find type info' in str(execinfo.value)
+    assert 'Invalid' in str(execinfo.value)
+
+    # Currently not supported
+    # See https://github.com/pybind/pybind11/issues/2486
+    # assert m.check_type(2) == int
+
+
+def test_type_of_py():
+    assert m.get_type_of(1) == int
+    assert m.get_type_of(m.DerivedClass1()) == m.DerivedClass1
+    assert m.get_type_of(int) == type
+
+
+def test_type_of_py_nodelete():
+    # If the above test deleted the class, this will segfault
+    assert m.get_type_of(m.DerivedClass1()) == m.DerivedClass1
+
+
+def test_as_type_py():
+    assert m.as_type(int) == int
+
+    with pytest.raises(RuntimeError):
+        assert m.as_type(1) == int
+
+    with pytest.raises(RuntimeError):
+        assert m.as_type(m.DerivedClass1()) == m.DerivedClass1
+
+
 def test_docstrings(doc):
     assert doc(UserType) == "A `py::class_` type for testing"
     assert UserType.__name__ == "UserType"
@@ -261,7 +297,7 @@ def test_brace_initialization():
     assert b.vec == [123, 456]
 
 
-@pytest.unsupported_on_pypy
+@pytest.mark.xfail("env.PYPY")
 def test_class_refcount():
     """Instances must correctly increase/decrease the reference count of their types (#1029)"""
     from sys import getrefcount
@@ -307,8 +343,8 @@ def test_aligned():
         assert p % 1024 == 0
 
 
-# https://bitbucket.org/pypy/pypy/issues/2742
-@pytest.unsupported_on_pypy
+# https://foss.heptapod.net/pypy/pypy/-/issues/2742
+@pytest.mark.xfail("env.PYPY")
 def test_final():
     with pytest.raises(TypeError) as exc_info:
         class PyFinalChild(m.IsFinal):
@@ -316,10 +352,16 @@ def test_final():
     assert str(exc_info.value).endswith("is not an acceptable base type")
 
 
-# https://bitbucket.org/pypy/pypy/issues/2742
-@pytest.unsupported_on_pypy
+# https://foss.heptapod.net/pypy/pypy/-/issues/2742
+@pytest.mark.xfail("env.PYPY")
 def test_non_final_final():
     with pytest.raises(TypeError) as exc_info:
         class PyNonFinalFinalChild(m.IsNonFinalFinal):
             pass
     assert str(exc_info.value).endswith("is not an acceptable base type")
+
+
+# https://github.com/pybind/pybind11/issues/1878
+def test_exception_rvalue_abort():
+    with pytest.raises(RuntimeError):
+        m.PyPrintDestructor().throw_something()
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/CMakeLists.txt
@@ -1,56 +1,77 @@
-add_custom_target(test_cmake_build)
+# Built-in in CMake 3.5+
+include(CMakeParseArguments)
 
-if(CMAKE_VERSION VERSION_LESS 3.1)
-  # 3.0 needed for interface library for subdirectory_target/installed_target
-  # 3.1 needed for cmake -E env for testing
-  return()
-endif()
+add_custom_target(test_cmake_build)
 
-include(CMakeParseArguments)
 function(pybind11_add_build_test name)
   cmake_parse_arguments(ARG "INSTALL" "" "" ${ARGN})
 
-  set(build_options "-DCMAKE_PREFIX_PATH=${PROJECT_BINARY_DIR}/mock_install"
-                    "-DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}"
-                    "-DPYTHON_EXECUTABLE:FILEPATH=${PYTHON_EXECUTABLE}"
-                    "-DPYBIND11_CPP_STANDARD=${PYBIND11_CPP_STANDARD}")
+  set(build_options "-DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}")
+
+  if(PYBIND11_FINDPYTHON)
+    list(APPEND build_options "-DPYBIND11_FINDPYTHON=${PYBIND11_FINDPYTHON}")
+
+    if(DEFINED Python_ROOT_DIR)
+      list(APPEND build_options "-DPython_ROOT_DIR=${Python_ROOT_DIR}")
+    endif()
+
+    list(APPEND build_options "-DPython_EXECUTABLE=${Python_EXECUTABLE}")
+  else()
+    list(APPEND build_options "-DPYTHON_EXECUTABLE=${PYTHON_EXECUTABLE}")
+  endif()
+
+  if(DEFINED CMAKE_CXX_STANDARD)
+    list(APPEND build_options "-DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD}")
+  endif()
+
   if(NOT ARG_INSTALL)
-    list(APPEND build_options "-DPYBIND11_PROJECT_DIR=${PROJECT_SOURCE_DIR}")
+    list(APPEND build_options "-DPYBIND11_PROJECT_DIR=${pybind11_SOURCE_DIR}")
+  else()
+    list(APPEND build_options "-DCMAKE_PREFIX_PATH=${pybind11_BINARY_DIR}/mock_install")
   endif()
 
-  add_custom_target(test_${name} ${CMAKE_CTEST_COMMAND}
-    --quiet --output-log ${name}.log
-    --build-and-test "${CMAKE_CURRENT_SOURCE_DIR}/${name}"
-                     "${CMAKE_CURRENT_BINARY_DIR}/${name}"
-    --build-config Release
+  add_custom_target(
+    test_build_${name}
+    ${CMAKE_CTEST_COMMAND}
+    --build-and-test
+    "${CMAKE_CURRENT_SOURCE_DIR}/${name}"
+    "${CMAKE_CURRENT_BINARY_DIR}/${name}"
+    --build-config
+    Release
     --build-noclean
-    --build-generator ${CMAKE_GENERATOR}
-    $<$<BOOL:${CMAKE_GENERATOR_PLATFORM}>:--build-generator-platform> ${CMAKE_GENERATOR_PLATFORM}
-    --build-makeprogram ${CMAKE_MAKE_PROGRAM}
-    --build-target check
-    --build-options ${build_options}
-  )
+    --build-generator
+    ${CMAKE_GENERATOR}
+    $<$<BOOL:${CMAKE_GENERATOR_PLATFORM}>:--build-generator-platform>
+    ${CMAKE_GENERATOR_PLATFORM}
+    --build-makeprogram
+    ${CMAKE_MAKE_PROGRAM}
+    --build-target
+    check_${name}
+    --build-options
+    ${build_options})
   if(ARG_INSTALL)
-    add_dependencies(test_${name} mock_install)
+    add_dependencies(test_build_${name} mock_install)
   endif()
-  add_dependencies(test_cmake_build test_${name})
+  add_dependencies(test_cmake_build test_build_${name})
 endfunction()
 
 pybind11_add_build_test(subdirectory_function)
 pybind11_add_build_test(subdirectory_target)
-if(NOT ${PYTHON_MODULE_EXTENSION} MATCHES "pypy")
+if("${PYTHON_MODULE_EXTENSION}" MATCHES "pypy" OR "${Python_INTERPRETER_ID}" STREQUAL "PyPy")
+  message(STATUS "Skipping embed test on PyPy")
+else()
   pybind11_add_build_test(subdirectory_embed)
 endif()
 
 if(PYBIND11_INSTALL)
-  add_custom_target(mock_install ${CMAKE_COMMAND}
-    "-DCMAKE_INSTALL_PREFIX=${PROJECT_BINARY_DIR}/mock_install"
-    -P "${PROJECT_BINARY_DIR}/cmake_install.cmake"
-  )
+  add_custom_target(
+    mock_install ${CMAKE_COMMAND} "-DCMAKE_INSTALL_PREFIX=${pybind11_BINARY_DIR}/mock_install" -P
+                 "${pybind11_BINARY_DIR}/cmake_install.cmake")
 
   pybind11_add_build_test(installed_function INSTALL)
   pybind11_add_build_test(installed_target INSTALL)
-  if(NOT ${PYTHON_MODULE_EXTENSION} MATCHES "pypy")
+  if(NOT ("${PYTHON_MODULE_EXTENSION}" MATCHES "pypy" OR "${Python_INTERPRETER_ID}" STREQUAL "PyPy"
+         ))
     pybind11_add_build_test(installed_embed INSTALL)
   endif()
 endif()
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/installed_embed/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/installed_embed/CMakeLists.txt
@@ -1,15 +1,26 @@
-cmake_minimum_required(VERSION 3.0)
+cmake_minimum_required(VERSION 3.4)
+
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
+
 project(test_installed_embed CXX)
 
-set(CMAKE_MODULE_PATH "")
 find_package(pybind11 CONFIG REQUIRED)
 message(STATUS "Found pybind11 v${pybind11_VERSION}: ${pybind11_INCLUDE_DIRS}")
 
-add_executable(test_cmake_build ../embed.cpp)
-target_link_libraries(test_cmake_build PRIVATE pybind11::embed)
+add_executable(test_installed_embed ../embed.cpp)
+target_link_libraries(test_installed_embed PRIVATE pybind11::embed)
+set_target_properties(test_installed_embed PROPERTIES OUTPUT_NAME test_cmake_build)
 
 # Do not treat includes from IMPORTED target as SYSTEM (Python headers in pybind11::embed).
 # This may be needed to resolve header conflicts, e.g. between Python release and debug headers.
-set_target_properties(test_cmake_build PROPERTIES NO_SYSTEM_FROM_IMPORTED ON)
+set_target_properties(test_installed_embed PROPERTIES NO_SYSTEM_FROM_IMPORTED ON)
 
-add_custom_target(check $<TARGET_FILE:test_cmake_build> ${PROJECT_SOURCE_DIR}/../test.py)
+add_custom_target(check_installed_embed $<TARGET_FILE:test_installed_embed>
+                                        ${PROJECT_SOURCE_DIR}/../test.py)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/installed_function/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/installed_function/CMakeLists.txt
@@ -1,12 +1,38 @@
-cmake_minimum_required(VERSION 2.8.12)
+cmake_minimum_required(VERSION 3.4)
 project(test_installed_module CXX)
 
-set(CMAKE_MODULE_PATH "")
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
+
+project(test_installed_function CXX)
 
 find_package(pybind11 CONFIG REQUIRED)
-message(STATUS "Found pybind11 v${pybind11_VERSION}: ${pybind11_INCLUDE_DIRS}")
+message(
+  STATUS "Found pybind11 v${pybind11_VERSION} ${pybind11_VERSION_TYPE}: ${pybind11_INCLUDE_DIRS}")
+
+pybind11_add_module(test_installed_function SHARED NO_EXTRAS ../main.cpp)
+set_target_properties(test_installed_function PROPERTIES OUTPUT_NAME test_cmake_build)
 
-pybind11_add_module(test_cmake_build SHARED NO_EXTRAS ../main.cpp)
+if(DEFINED Python_EXECUTABLE)
+  set(_Python_EXECUTABLE "${Python_EXECUTABLE}")
+elseif(DEFINED PYTHON_EXECUTABLE)
+  set(_Python_EXECUTABLE "${PYTHON_EXECUTABLE}")
+else()
+  message(FATAL_ERROR "No Python executable defined (should not be possible at this stage)")
+endif()
 
-add_custom_target(check ${CMAKE_COMMAND} -E env PYTHONPATH=$<TARGET_FILE_DIR:test_cmake_build>
-                  ${PYTHON_EXECUTABLE} ${PROJECT_SOURCE_DIR}/../test.py ${PROJECT_NAME})
+add_custom_target(
+  check_installed_function
+  ${CMAKE_COMMAND}
+  -E
+  env
+  PYTHONPATH=$<TARGET_FILE_DIR:test_installed_function>
+  ${_Python_EXECUTABLE}
+  ${PROJECT_SOURCE_DIR}/../test.py
+  ${PROJECT_NAME})
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/installed_target/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/installed_target/CMakeLists.txt
@@ -1,22 +1,45 @@
-cmake_minimum_required(VERSION 3.0)
-project(test_installed_target CXX)
+cmake_minimum_required(VERSION 3.4)
+
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
 
-set(CMAKE_MODULE_PATH "")
+project(test_installed_target CXX)
 
 find_package(pybind11 CONFIG REQUIRED)
 message(STATUS "Found pybind11 v${pybind11_VERSION}: ${pybind11_INCLUDE_DIRS}")
 
-add_library(test_cmake_build MODULE ../main.cpp)
+add_library(test_installed_target MODULE ../main.cpp)
 
-target_link_libraries(test_cmake_build PRIVATE pybind11::module)
+target_link_libraries(test_installed_target PRIVATE pybind11::module)
+set_target_properties(test_installed_target PROPERTIES OUTPUT_NAME test_cmake_build)
 
-# make sure result is, for example, test_installed_target.so, not libtest_installed_target.dylib
-set_target_properties(test_cmake_build PROPERTIES PREFIX "${PYTHON_MODULE_PREFIX}"
-                                                  SUFFIX "${PYTHON_MODULE_EXTENSION}")
+# Make sure result is, for example, test_installed_target.so, not libtest_installed_target.dylib
+pybind11_extension(test_installed_target)
 
 # Do not treat includes from IMPORTED target as SYSTEM (Python headers in pybind11::module).
 # This may be needed to resolve header conflicts, e.g. between Python release and debug headers.
-set_target_properties(test_cmake_build PROPERTIES NO_SYSTEM_FROM_IMPORTED ON)
+set_target_properties(test_installed_target PROPERTIES NO_SYSTEM_FROM_IMPORTED ON)
 
-add_custom_target(check ${CMAKE_COMMAND} -E env PYTHONPATH=$<TARGET_FILE_DIR:test_cmake_build>
-                  ${PYTHON_EXECUTABLE} ${PROJECT_SOURCE_DIR}/../test.py ${PROJECT_NAME})
+if(DEFINED Python_EXECUTABLE)
+  set(_Python_EXECUTABLE "${Python_EXECUTABLE}")
+elseif(DEFINED PYTHON_EXECUTABLE)
+  set(_Python_EXECUTABLE "${PYTHON_EXECUTABLE}")
+else()
+  message(FATAL_ERROR "No Python executable defined (should not be possible at this stage)")
+endif()
+
+add_custom_target(
+  check_installed_target
+  ${CMAKE_COMMAND}
+  -E
+  env
+  PYTHONPATH=$<TARGET_FILE_DIR:test_installed_target>
+  ${_Python_EXECUTABLE}
+  ${PROJECT_SOURCE_DIR}/../test.py
+  ${PROJECT_NAME})
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/subdirectory_embed/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/subdirectory_embed/CMakeLists.txt
@@ -1,25 +1,39 @@
-cmake_minimum_required(VERSION 3.0)
+cmake_minimum_required(VERSION 3.4)
+
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
+
 project(test_subdirectory_embed CXX)
 
-set(PYBIND11_INSTALL ON CACHE BOOL "")
+set(PYBIND11_INSTALL
+    ON
+    CACHE BOOL "")
 set(PYBIND11_EXPORT_NAME test_export)
 
 add_subdirectory(${PYBIND11_PROJECT_DIR} pybind11)
 
 # Test basic target functionality
-add_executable(test_cmake_build ../embed.cpp)
-target_link_libraries(test_cmake_build PRIVATE pybind11::embed)
+add_executable(test_subdirectory_embed ../embed.cpp)
+target_link_libraries(test_subdirectory_embed PRIVATE pybind11::embed)
+set_target_properties(test_subdirectory_embed PROPERTIES OUTPUT_NAME test_cmake_build)
 
-add_custom_target(check $<TARGET_FILE:test_cmake_build> ${PROJECT_SOURCE_DIR}/../test.py)
+add_custom_target(check_subdirectory_embed $<TARGET_FILE:test_subdirectory_embed>
+                                           ${PROJECT_SOURCE_DIR}/../test.py)
 
 # Test custom export group -- PYBIND11_EXPORT_NAME
 add_library(test_embed_lib ../embed.cpp)
 target_link_libraries(test_embed_lib PRIVATE pybind11::embed)
 
-install(TARGETS test_embed_lib
-        EXPORT  test_export
-        ARCHIVE DESTINATION bin
-        LIBRARY DESTINATION lib
-        RUNTIME DESTINATION lib)
-install(EXPORT      test_export
-        DESTINATION lib/cmake/test_export/test_export-Targets.cmake)
+install(
+  TARGETS test_embed_lib
+  EXPORT test_export
+  ARCHIVE DESTINATION bin
+  LIBRARY DESTINATION lib
+  RUNTIME DESTINATION lib)
+install(EXPORT test_export DESTINATION lib/cmake/test_export/test_export-Targets.cmake)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/subdirectory_function/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/subdirectory_function/CMakeLists.txt
@@ -1,8 +1,34 @@
-cmake_minimum_required(VERSION 2.8.12)
-project(test_subdirectory_module CXX)
+cmake_minimum_required(VERSION 3.4)
 
-add_subdirectory(${PYBIND11_PROJECT_DIR} pybind11)
-pybind11_add_module(test_cmake_build THIN_LTO ../main.cpp)
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
 
-add_custom_target(check ${CMAKE_COMMAND} -E env PYTHONPATH=$<TARGET_FILE_DIR:test_cmake_build>
-                  ${PYTHON_EXECUTABLE} ${PROJECT_SOURCE_DIR}/../test.py ${PROJECT_NAME})
+project(test_subdirectory_function CXX)
+
+add_subdirectory("${PYBIND11_PROJECT_DIR}" pybind11)
+pybind11_add_module(test_subdirectory_function ../main.cpp)
+set_target_properties(test_subdirectory_function PROPERTIES OUTPUT_NAME test_cmake_build)
+
+if(DEFINED Python_EXECUTABLE)
+  set(_Python_EXECUTABLE "${Python_EXECUTABLE}")
+elseif(DEFINED PYTHON_EXECUTABLE)
+  set(_Python_EXECUTABLE "${PYTHON_EXECUTABLE}")
+else()
+  message(FATAL_ERROR "No Python executable defined (should not be possible at this stage)")
+endif()
+
+add_custom_target(
+  check_subdirectory_function
+  ${CMAKE_COMMAND}
+  -E
+  env
+  PYTHONPATH=$<TARGET_FILE_DIR:test_subdirectory_function>
+  ${_Python_EXECUTABLE}
+  ${PROJECT_SOURCE_DIR}/../test.py
+  ${PROJECT_NAME})
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_cmake_build/subdirectory_target/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_cmake_build/subdirectory_target/CMakeLists.txt
@@ -1,15 +1,40 @@
-cmake_minimum_required(VERSION 3.0)
+cmake_minimum_required(VERSION 3.4)
+
+# The `cmake_minimum_required(VERSION 3.4...3.18)` syntax does not work with
+# some versions of VS that have a patched CMake 3.11. This forces us to emulate
+# the behavior using the following workaround:
+if(${CMAKE_VERSION} VERSION_LESS 3.18)
+  cmake_policy(VERSION ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION})
+else()
+  cmake_policy(VERSION 3.18)
+endif()
+
 project(test_subdirectory_target CXX)
 
 add_subdirectory(${PYBIND11_PROJECT_DIR} pybind11)
 
-add_library(test_cmake_build MODULE ../main.cpp)
+add_library(test_subdirectory_target MODULE ../main.cpp)
+set_target_properties(test_subdirectory_target PROPERTIES OUTPUT_NAME test_cmake_build)
+
+target_link_libraries(test_subdirectory_target PRIVATE pybind11::module)
 
-target_link_libraries(test_cmake_build PRIVATE pybind11::module)
+# Make sure result is, for example, test_installed_target.so, not libtest_installed_target.dylib
+pybind11_extension(test_subdirectory_target)
 
-# make sure result is, for example, test_installed_target.so, not libtest_installed_target.dylib
-set_target_properties(test_cmake_build PROPERTIES PREFIX "${PYTHON_MODULE_PREFIX}"
-                                                  SUFFIX "${PYTHON_MODULE_EXTENSION}")
+if(DEFINED Python_EXECUTABLE)
+  set(_Python_EXECUTABLE "${Python_EXECUTABLE}")
+elseif(DEFINED PYTHON_EXECUTABLE)
+  set(_Python_EXECUTABLE "${PYTHON_EXECUTABLE}")
+else()
+  message(FATAL_ERROR "No Python executable defined (should not be possible at this stage)")
+endif()
 
-add_custom_target(check ${CMAKE_COMMAND} -E env PYTHONPATH=$<TARGET_FILE_DIR:test_cmake_build>
-                  ${PYTHON_EXECUTABLE} ${PROJECT_SOURCE_DIR}/../test.py ${PROJECT_NAME})
+add_custom_target(
+  check_subdirectory_target
+  ${CMAKE_COMMAND}
+  -E
+  env
+  PYTHONPATH=$<TARGET_FILE_DIR:test_subdirectory_target>
+  ${_Python_EXECUTABLE}
+  ${PROJECT_SOURCE_DIR}/../test.py
+  ${PROJECT_NAME})
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_constants_and_functions.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_constants_and_functions.cpp
@@ -74,7 +74,7 @@ struct C {
 #  pragma GCC diagnostic pop
 #endif
 };
-}
+} // namespace test_exc_sp
 
 
 TEST_SUBMODULE(constants_and_functions, m) {
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_constants_and_functions.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_constants_and_functions.py
@@ -1,5 +1,7 @@
 # -*- coding: utf-8 -*-
-from pybind11_tests import constants_and_functions as m
+import pytest
+
+m = pytest.importorskip("pybind11_tests.constants_and_functions")
 
 
 def test_constants():
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_copy_move.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_copy_move.cpp
@@ -19,14 +19,14 @@ struct empty {
 };
 
 struct lacking_copy_ctor : public empty<lacking_copy_ctor> {
-    lacking_copy_ctor() {}
+    lacking_copy_ctor() = default;
     lacking_copy_ctor(const lacking_copy_ctor& other) = delete;
 };
 
 template <> lacking_copy_ctor empty<lacking_copy_ctor>::instance_ = {};
 
 struct lacking_move_ctor : public empty<lacking_move_ctor> {
-    lacking_move_ctor() {}
+    lacking_move_ctor() = default;
     lacking_move_ctor(const lacking_move_ctor& other) = delete;
     lacking_move_ctor(lacking_move_ctor&& other) = delete;
 };
@@ -175,14 +175,20 @@ TEST_SUBMODULE(copy_move_policies, m) {
     m.attr("has_optional") = false;
 #endif
 
-    // #70 compilation issue if operator new is not public
+    // #70 compilation issue if operator new is not public - simple body added
+    // but not needed on most compilers; MSVC and nvcc don't like a local
+    // struct not having a method defined when declared, since it can not be
+    // added later.
     struct PrivateOpNew {
         int value = 1;
     private:
-#if defined(_MSC_VER)
-#  pragma warning(disable: 4822) // warning C4822: local class member function does not have a body
-#endif
-        void *operator new(size_t bytes);
+        void *operator new(size_t bytes) {
+            void *ptr = std::malloc(bytes);
+            if (ptr)
+                return ptr;
+            else
+                throw std::bad_alloc{};
+        }
     };
     py::class_<PrivateOpNew>(m, "PrivateOpNew").def_readonly("value", &PrivateOpNew::value);
     m.def("private_op_new_value", []() { return PrivateOpNew(); });
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_custom_type_casters.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_custom_type_casters.cpp
@@ -58,7 +58,8 @@ public:
         return py::none().release();
     }
 };
-}}
+} // namespace detail
+} // namespace pybind11
 
 // test_custom_caster_destruction
 class DestructionTester {
@@ -79,7 +80,8 @@ template <> struct type_caster<Destructi
         return py::bool_(true).release();
     }
 };
-}}
+} // namespace detail
+} // namespace pybind11
 
 TEST_SUBMODULE(custom_type_casters, m) {
     // test_custom_type_casters
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_eigen.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_eigen.cpp
@@ -87,8 +87,6 @@ TEST_SUBMODULE(eigen, m) {
     using SparseMatrixR = Eigen::SparseMatrix<float, Eigen::RowMajor>;
     using SparseMatrixC = Eigen::SparseMatrix<float>;
 
-    m.attr("have_eigen") = true;
-
     // various tests
     m.def("double_col", [](const Eigen::VectorXf &x) -> Eigen::VectorXf { return 2.0f * x; });
     m.def("double_row", [](const Eigen::RowVectorXf &x) -> Eigen::RowVectorXf { return 2.0f * x; });
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_eigen.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_eigen.py
@@ -2,17 +2,15 @@
 import pytest
 from pybind11_tests import ConstructorStats
 
-pytestmark = pytest.requires_eigen_and_numpy
+np = pytest.importorskip("numpy")
+m = pytest.importorskip("pybind11_tests.eigen")
 
-with pytest.suppress(ImportError):
-    from pybind11_tests import eigen as m
-    import numpy as np
-
-    ref = np.array([[ 0.,  3,  0,  0,  0, 11],
-                    [22,  0,  0,  0, 17, 11],
-                    [ 7,  5,  0,  1,  0, 11],
-                    [ 0,  0,  0,  0,  0, 11],
-                    [ 0,  0, 14,  0,  8, 11]])
+
+ref = np.array([[ 0.,  3,  0,  0,  0, 11],
+                [22,  0,  0,  0, 17, 11],
+                [ 7,  5,  0,  1,  0, 11],
+                [ 0,  0,  0,  0,  0, 11],
+                [ 0,  0, 14,  0,  8, 11]])
 
 
 def assert_equal_ref(mat):
@@ -646,8 +644,8 @@ def test_named_arguments():
     assert str(excinfo.value) == 'Nonconformable matrices!'
 
 
-@pytest.requires_eigen_and_scipy
 def test_sparse():
+    pytest.importorskip("scipy")
     assert_sparse_equal_ref(m.sparse_r())
     assert_sparse_equal_ref(m.sparse_c())
     assert_sparse_equal_ref(m.sparse_copy_r(m.sparse_r()))
@@ -656,8 +654,8 @@ def test_sparse():
     assert_sparse_equal_ref(m.sparse_copy_c(m.sparse_r()))
 
 
-@pytest.requires_eigen_and_scipy
 def test_sparse_signature(doc):
+    pytest.importorskip("scipy")
     assert doc(m.sparse_copy_r) == """
         sparse_copy_r(arg0: scipy.sparse.csr_matrix[numpy.float32]) -> scipy.sparse.csr_matrix[numpy.float32]
     """  # noqa: E501 line too long
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_embed/CMakeLists.txt
+++ gtsam-4.1.0/wrap/pybind11/tests/test_embed/CMakeLists.txt
@@ -1,41 +1,43 @@
-if(${PYTHON_MODULE_EXTENSION} MATCHES "pypy")
-  add_custom_target(cpptest)  # Dummy target on PyPy. Embedding is not supported.
+if("${PYTHON_MODULE_EXTENSION}" MATCHES "pypy" OR "${Python_INTERPRETER_ID}" STREQUAL "PyPy")
+  add_custom_target(cpptest) # Dummy target on PyPy. Embedding is not supported.
   set(_suppress_unused_variable_warning "${DOWNLOAD_CATCH}")
   return()
 endif()
 
-find_package(Catch 1.9.3)
+find_package(Catch 2.13.0)
+
 if(CATCH_FOUND)
   message(STATUS "Building interpreter tests using Catch v${CATCH_VERSION}")
 else()
   message(STATUS "Catch not detected. Interpreter tests will be skipped. Install Catch headers"
-                 " manually or use `cmake -DDOWNLOAD_CATCH=1` to fetch them automatically.")
+                 " manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.")
   return()
 endif()
 
-add_executable(test_embed
-  catch.cpp
-  test_interpreter.cpp
-)
-target_include_directories(test_embed PRIVATE ${CATCH_INCLUDE_DIR})
+find_package(Threads REQUIRED)
+
+add_executable(test_embed catch.cpp test_interpreter.cpp)
 pybind11_enable_warnings(test_embed)
 
-if(NOT CMAKE_VERSION VERSION_LESS 3.0)
-  target_link_libraries(test_embed PRIVATE pybind11::embed)
-else()
-  target_include_directories(test_embed PRIVATE ${PYBIND11_INCLUDE_DIR} ${PYTHON_INCLUDE_DIRS})
-  target_compile_options(test_embed PRIVATE ${PYBIND11_CPP_STANDARD})
-  target_link_libraries(test_embed PRIVATE ${PYTHON_LIBRARIES})
-endif()
+target_link_libraries(test_embed PRIVATE pybind11::embed Catch2::Catch2 Threads::Threads)
 
-find_package(Threads REQUIRED)
-target_link_libraries(test_embed PUBLIC ${CMAKE_THREAD_LIBS_INIT})
+if(NOT CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_CURRENT_BINARY_DIR)
+  file(COPY test_interpreter.py DESTINATION "${CMAKE_CURRENT_BINARY_DIR}")
+endif()
 
-add_custom_target(cpptest COMMAND $<TARGET_FILE:test_embed>
-                  WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR})
+add_custom_target(
+  cpptest
+  COMMAND "$<TARGET_FILE:test_embed>"
+  WORKING_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}")
 
 pybind11_add_module(external_module THIN_LTO external_module.cpp)
-set_target_properties(external_module PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR})
+set_target_properties(external_module PROPERTIES LIBRARY_OUTPUT_DIRECTORY
+                                                 "${CMAKE_CURRENT_BINARY_DIR}")
+foreach(config ${CMAKE_CONFIGURATION_TYPES})
+  string(TOUPPER ${config} config)
+  set_target_properties(external_module PROPERTIES LIBRARY_OUTPUT_DIRECTORY_${config}
+                                                   "${CMAKE_CURRENT_BINARY_DIR}")
+endforeach()
 add_dependencies(cpptest external_module)
 
 add_dependencies(check cpptest)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_embed/test_interpreter.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_embed/test_interpreter.cpp
@@ -30,7 +30,7 @@ private:
 class PyWidget final : public Widget {
     using Widget::Widget;
 
-    int the_answer() const override { PYBIND11_OVERLOAD_PURE(int, Widget, the_answer); }
+    int the_answer() const override { PYBIND11_OVERRIDE_PURE(int, Widget, the_answer); }
 };
 
 PYBIND11_EMBEDDED_MODULE(widget_module, m) {
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_eval.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_eval.py
@@ -1,6 +1,10 @@
 # -*- coding: utf-8 -*-
 import os
+
 import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import eval_ as m
 
 
@@ -15,7 +19,7 @@ def test_evals(capture):
     assert m.test_eval_failure()
 
 
-@pytest.unsupported_on_pypy3
+@pytest.mark.xfail("env.PYPY and not env.PY2", raises=RuntimeError)
 def test_eval_file():
     filename = os.path.join(os.path.dirname(__file__), "test_eval_call.py")
     assert m.test_eval_file(filename)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_exceptions.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_exceptions.cpp
@@ -13,7 +13,7 @@
 class MyException : public std::exception {
 public:
     explicit MyException(const char * m) : message{m} {}
-    virtual const char * what() const noexcept override {return message.c_str();}
+    const char * what() const noexcept override {return message.c_str();}
 private:
     std::string message = "";
 };
@@ -22,7 +22,7 @@ private:
 class MyException2 : public std::exception {
 public:
     explicit MyException2(const char * m) : message{m} {}
-    virtual const char * what() const noexcept override {return message.c_str();}
+    const char * what() const noexcept override {return message.c_str();}
 private:
     std::string message = "";
 };
@@ -41,7 +41,7 @@ private:
 class MyException4 : public std::exception {
 public:
     explicit MyException4(const char * m) : message{m} {}
-    virtual const char * what() const noexcept override {return message.c_str();}
+    const char * what() const noexcept override {return message.c_str();}
 private:
     std::string message = "";
 };
@@ -65,6 +65,25 @@ struct PythonCallInDestructor {
     py::dict d;
 };
 
+
+
+struct PythonAlreadySetInDestructor {
+    PythonAlreadySetInDestructor(const py::str &s) : s(s) {}
+    ~PythonAlreadySetInDestructor() {
+        py::dict foo;
+        try {
+            // Assign to a py::object to force read access of nonexistent dict entry
+            py::object o = foo["bar"];
+        }
+        catch (py::error_already_set& ex) {
+            ex.discard_as_unraisable(s);
+        }
+    }
+
+    py::str s;
+};
+
+
 TEST_SUBMODULE(exceptions, m) {
     m.def("throw_std_exception", []() {
         throw std::runtime_error("This exception was intentionally thrown.");
@@ -183,6 +202,11 @@ TEST_SUBMODULE(exceptions, m) {
         return false;
     });
 
+    m.def("python_alreadyset_in_destructor", [](py::str s) {
+        PythonAlreadySetInDestructor alreadyset_in_destructor(s);
+        return true;
+    });
+
     // test_nested_throws
     m.def("try_catch", [m](py::object exc_type, py::function f, py::args args) {
         try { f(*args); }
@@ -194,4 +218,7 @@ TEST_SUBMODULE(exceptions, m) {
         }
     });
 
+    // Test repr that cannot be displayed
+    m.def("simple_bool_passthrough", [](bool x) {return x;});
+
 }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_exceptions.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_exceptions.py
@@ -1,4 +1,6 @@
 # -*- coding: utf-8 -*-
+import sys
+
 import pytest
 
 from pybind11_tests import exceptions as m
@@ -48,6 +50,33 @@ def test_python_call_in_catch():
     assert d["good"] is True
 
 
+def test_python_alreadyset_in_destructor(monkeypatch, capsys):
+    hooked = False
+    triggered = [False]  # mutable, so Python 2.7 closure can modify it
+
+    if hasattr(sys, 'unraisablehook'):  # Python 3.8+
+        hooked = True
+        default_hook = sys.unraisablehook
+
+        def hook(unraisable_hook_args):
+            exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
+            if obj == 'already_set demo':
+                triggered[0] = True
+            default_hook(unraisable_hook_args)
+            return
+
+        # Use monkeypatch so pytest can apply and remove the patch as appropriate
+        monkeypatch.setattr(sys, 'unraisablehook', hook)
+
+    assert m.python_alreadyset_in_destructor('already_set demo') is True
+    if hooked:
+        assert triggered[0] is True
+
+    _, captured_stderr = capsys.readouterr()
+    # Error message is different in Python 2 and 3, check for words that appear in both
+    assert 'ignored' in captured_stderr and 'already_set demo' in captured_stderr
+
+
 def test_exception_matches():
     assert m.exception_matches()
     assert m.exception_matches_base()
@@ -149,3 +178,14 @@ def test_nested_throws(capture):
     with pytest.raises(m.MyException5) as excinfo:
         m.try_catch(m.MyException, pycatch, m.MyException, m.throws5)
     assert str(excinfo.value) == "this is a helper-defined translated exception"
+
+
+# This can often happen if you wrap a pybind11 class in a Python wrapper
+def test_invalid_repr():
+
+    class MyRepr(object):
+        def __repr__(self):
+            raise AttributeError("Example error")
+
+    with pytest.raises(TypeError):
+        m.simple_bool_passthrough(MyRepr())
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_factory_constructors.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_factory_constructors.cpp
@@ -11,6 +11,7 @@
 #include "pybind11_tests.h"
 #include "constructor_stats.h"
 #include <cmath>
+#include <new>
 
 // Classes for testing python construction via C++ factory function:
 // Not publicly constructible, copyable, or movable:
@@ -57,13 +58,13 @@ class TestFactory4 : public TestFactory3
 public:
     TestFactory4() : TestFactory3() { print_default_created(this); }
     TestFactory4(int v) : TestFactory3(v) { print_created(this, v); }
-    virtual ~TestFactory4() { print_destroyed(this); }
+    ~TestFactory4() override { print_destroyed(this); }
 };
 // Another class for an invalid downcast test
 class TestFactory5 : public TestFactory3 {
 public:
     TestFactory5(int i) : TestFactory3(i) { print_created(this, i); }
-    virtual ~TestFactory5() { print_destroyed(this); }
+    ~TestFactory5() override { print_destroyed(this); }
 };
 
 class TestFactory6 {
@@ -87,8 +88,8 @@ public:
     PyTF6(PyTF6 &&f) : TestFactory6(std::move(f)) { print_move_created(this); }
     PyTF6(const PyTF6 &f) : TestFactory6(f) { print_copy_created(this); }
     PyTF6(std::string s) : TestFactory6((int) s.size()) { alias = true; print_created(this, s); }
-    virtual ~PyTF6() { print_destroyed(this); }
-    int get() override { PYBIND11_OVERLOAD(int, TestFactory6, get, /*no args*/); }
+    ~PyTF6() override { print_destroyed(this); }
+    int get() override { PYBIND11_OVERRIDE(int, TestFactory6, get, /*no args*/); }
 };
 
 class TestFactory7 {
@@ -108,8 +109,8 @@ public:
     PyTF7(int i) : TestFactory7(i) { alias = true; print_created(this, i); }
     PyTF7(PyTF7 &&f) : TestFactory7(std::move(f)) { print_move_created(this); }
     PyTF7(const PyTF7 &f) : TestFactory7(f) { print_copy_created(this); }
-    virtual ~PyTF7() { print_destroyed(this); }
-    int get() override { PYBIND11_OVERLOAD(int, TestFactory7, get, /*no args*/); }
+    ~PyTF7() override { print_destroyed(this); }
+    int get() override { PYBIND11_OVERRIDE(int, TestFactory7, get, /*no args*/); }
 };
 
 
@@ -154,6 +155,8 @@ TEST_SUBMODULE(factory_constructors, m)
     MAKE_TAG_TYPE(TF4);
     MAKE_TAG_TYPE(TF5);
     MAKE_TAG_TYPE(null_ptr);
+    MAKE_TAG_TYPE(null_unique_ptr);
+    MAKE_TAG_TYPE(null_shared_ptr);
     MAKE_TAG_TYPE(base);
     MAKE_TAG_TYPE(invalid_base);
     MAKE_TAG_TYPE(alias);
@@ -194,6 +197,8 @@ TEST_SUBMODULE(factory_constructors, m)
 
         // Returns nullptr:
         .def(py::init([](null_ptr_tag) { return (TestFactory3 *) nullptr; }))
+        .def(py::init([](null_unique_ptr_tag) { return std::unique_ptr<TestFactory3>(); }))
+        .def(py::init([](null_shared_ptr_tag) { return std::shared_ptr<TestFactory3>(); }))
 
         .def_readwrite("value", &TestFactory3::value)
         ;
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_factory_constructors.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_factory_constructors.py
@@ -2,6 +2,8 @@
 import pytest
 import re
 
+import env  # noqa: F401
+
 from pybind11_tests import factory_constructors as m
 from pybind11_tests.factory_constructors import tag
 from pybind11_tests import ConstructorStats
@@ -39,9 +41,12 @@ def test_init_factory_basic():
     z3 = m.TestFactory3("bye")
     assert z3.value == "bye"
 
-    with pytest.raises(TypeError) as excinfo:
-        m.TestFactory3(tag.null_ptr)
-    assert str(excinfo.value) == "pybind11::init(): factory function returned nullptr"
+    for null_ptr_kind in [tag.null_ptr,
+                          tag.null_unique_ptr,
+                          tag.null_shared_ptr]:
+        with pytest.raises(TypeError) as excinfo:
+            m.TestFactory3(null_ptr_kind)
+        assert str(excinfo.value) == "pybind11::init(): factory function returned nullptr"
 
     assert [i.alive() for i in cstats] == [3, 3, 3]
     assert ConstructorStats.detail_reg_inst() == n_inst + 9
@@ -331,10 +336,10 @@ def strip_comments(s):
     return re.sub(r'\s+#.*', '', s)
 
 
-def test_reallocations(capture, msg):
+def test_reallocation_a(capture, msg):
     """When the constructor is overloaded, previous overloads can require a preallocated value.
     This test makes sure that such preallocated values only happen when they might be necessary,
-    and that they are deallocated properly"""
+    and that they are deallocated properly."""
 
     pytest.gc_collect()
 
@@ -348,6 +353,9 @@ def test_reallocations(capture, msg):
         ~NoisyAlloc()
         noisy delete
     """
+
+
+def test_reallocation_b(capture, msg):
     with capture:
         create_and_destroy(1.5)
     assert msg(capture) == strip_comments("""
@@ -360,6 +368,8 @@ def test_reallocations(capture, msg):
         noisy delete   # operator delete
     """)
 
+
+def test_reallocation_c(capture, msg):
     with capture:
         create_and_destroy(2, 3)
     assert msg(capture) == strip_comments("""
@@ -370,6 +380,8 @@ def test_reallocations(capture, msg):
         noisy delete   # operator delete
     """)
 
+
+def test_reallocation_d(capture, msg):
     with capture:
         create_and_destroy(2.5, 3)
     assert msg(capture) == strip_comments("""
@@ -381,6 +393,8 @@ def test_reallocations(capture, msg):
         noisy delete   # operator delete
     """)
 
+
+def test_reallocation_e(capture, msg):
     with capture:
         create_and_destroy(3.5, 4.5)
     assert msg(capture) == strip_comments("""
@@ -392,6 +406,8 @@ def test_reallocations(capture, msg):
         noisy delete   # operator delete
     """)
 
+
+def test_reallocation_f(capture, msg):
     with capture:
         create_and_destroy(4, 0.5)
     assert msg(capture) == strip_comments("""
@@ -404,6 +420,8 @@ def test_reallocations(capture, msg):
         noisy delete   # operator delete
     """)
 
+
+def test_reallocation_g(capture, msg):
     with capture:
         create_and_destroy(5, "hi")
     assert msg(capture) == strip_comments("""
@@ -418,7 +436,7 @@ def test_reallocations(capture, msg):
     """)
 
 
-@pytest.unsupported_on_py2
+@pytest.mark.skipif("env.PY2")
 def test_invalid_self():
     """Tests invocation of the pybind-registered base class with an invalid `self` argument.  You
     can only actually do this on Python 3: Python 2 raises an exception itself if you try."""
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_gil_scoped.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_gil_scoped.cpp
@@ -13,17 +13,19 @@
 
 class VirtClass  {
 public:
-    virtual ~VirtClass() {}
+    virtual ~VirtClass() = default;
+    VirtClass() = default;
+    VirtClass(const VirtClass&) = delete;
     virtual void virtual_func() {}
     virtual void pure_virtual_func() = 0;
 };
 
 class PyVirtClass : public VirtClass {
     void virtual_func() override {
-        PYBIND11_OVERLOAD(void, VirtClass, virtual_func,);
+        PYBIND11_OVERRIDE(void, VirtClass, virtual_func,);
     }
     void pure_virtual_func() override {
-        PYBIND11_OVERLOAD_PURE(void, VirtClass, pure_virtual_func,);
+        PYBIND11_OVERRIDE_PURE(void, VirtClass, pure_virtual_func,);
     }
 };
 
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_gil_scoped.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_gil_scoped.py
@@ -1,6 +1,11 @@
 # -*- coding: utf-8 -*-
 import multiprocessing
 import threading
+
+import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import gil_scoped as m
 
 
@@ -49,6 +54,8 @@ def _python_to_cpp_to_python_from_thread
         thread.join()
 
 
+# TODO: FIXME, sometimes returns -11 instead of 0
+@pytest.mark.xfail("env.PY > (3,8) and env.MACOS", strict=False)
 def test_python_to_cpp_to_python_from_thread():
     """Makes sure there is no GIL deadlock when running in a thread.
 
@@ -57,6 +64,8 @@ def test_python_to_cpp_to_python_from_th
     assert _run_in_process(_python_to_cpp_to_python_from_threads, 1) == 0
 
 
+# TODO: FIXME
+@pytest.mark.xfail("env.PY > (3,8) and env.MACOS", strict=False)
 def test_python_to_cpp_to_python_from_thread_multiple_parallel():
     """Makes sure there is no GIL deadlock when running in a thread multiple times in parallel.
 
@@ -65,6 +74,8 @@ def test_python_to_cpp_to_python_from_th
     assert _run_in_process(_python_to_cpp_to_python_from_threads, 8, parallel=True) == 0
 
 
+# TODO: FIXME
+@pytest.mark.xfail("env.PY > (3,8) and env.MACOS", strict=False)
 def test_python_to_cpp_to_python_from_thread_multiple_sequential():
     """Makes sure there is no GIL deadlock when running in a thread multiple times sequentially.
 
@@ -73,6 +84,8 @@ def test_python_to_cpp_to_python_from_th
     assert _run_in_process(_python_to_cpp_to_python_from_threads, 8, parallel=False) == 0
 
 
+# TODO: FIXME
+@pytest.mark.xfail("env.PY > (3,8) and env.MACOS", strict=False)
 def test_python_to_cpp_to_python_from_process():
     """Makes sure there is no GIL deadlock when using processes.
 
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_kwargs_and_defaults.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_kwargs_and_defaults.cpp
@@ -95,32 +95,48 @@ TEST_SUBMODULE(kwargs_and_defaults, m) {
 //    m.def("bad_args7", [](py::kwargs, py::kwargs) {});
 
     // test_keyword_only_args
-    m.def("kwonly_all", [](int i, int j) { return py::make_tuple(i, j); },
-            py::kwonly(), py::arg("i"), py::arg("j"));
-    m.def("kwonly_some", [](int i, int j, int k) { return py::make_tuple(i, j, k); },
-            py::arg(), py::kwonly(), py::arg("j"), py::arg("k"));
-    m.def("kwonly_with_defaults", [](int i, int j, int k, int z) { return py::make_tuple(i, j, k, z); },
-            py::arg() = 3, "j"_a = 4, py::kwonly(), "k"_a = 5, "z"_a);
-    m.def("kwonly_mixed", [](int i, int j) { return py::make_tuple(i, j); },
-            "i"_a, py::kwonly(), "j"_a);
-    m.def("kwonly_plus_more", [](int i, int j, int k, py::kwargs kwargs) {
+    m.def("kw_only_all", [](int i, int j) { return py::make_tuple(i, j); },
+            py::kw_only(), py::arg("i"), py::arg("j"));
+    m.def("kw_only_some", [](int i, int j, int k) { return py::make_tuple(i, j, k); },
+            py::arg(), py::kw_only(), py::arg("j"), py::arg("k"));
+    m.def("kw_only_with_defaults", [](int i, int j, int k, int z) { return py::make_tuple(i, j, k, z); },
+            py::arg() = 3, "j"_a = 4, py::kw_only(), "k"_a = 5, "z"_a);
+    m.def("kw_only_mixed", [](int i, int j) { return py::make_tuple(i, j); },
+            "i"_a, py::kw_only(), "j"_a);
+    m.def("kw_only_plus_more", [](int i, int j, int k, py::kwargs kwargs) {
             return py::make_tuple(i, j, k, kwargs); },
-            py::arg() /* positional */, py::arg("j") = -1 /* both */, py::kwonly(), py::arg("k") /* kw-only */);
+            py::arg() /* positional */, py::arg("j") = -1 /* both */, py::kw_only(), py::arg("k") /* kw-only */);
 
-    m.def("register_invalid_kwonly", [](py::module m) {
-        m.def("bad_kwonly", [](int i, int j) { return py::make_tuple(i, j); },
-                py::kwonly(), py::arg() /* invalid unnamed argument */, "j"_a);
+    m.def("register_invalid_kw_only", [](py::module m) {
+        m.def("bad_kw_only", [](int i, int j) { return py::make_tuple(i, j); },
+                py::kw_only(), py::arg() /* invalid unnamed argument */, "j"_a);
     });
 
+    // test_positional_only_args
+    m.def("pos_only_all", [](int i, int j) { return py::make_tuple(i, j); },
+            py::arg("i"), py::arg("j"), py::pos_only());
+    m.def("pos_only_mix", [](int i, int j) { return py::make_tuple(i, j); },
+            py::arg("i"), py::pos_only(), py::arg("j"));
+    m.def("pos_kw_only_mix", [](int i, int j, int k) { return py::make_tuple(i, j, k); },
+            py::arg("i"), py::pos_only(), py::arg("j"), py::kw_only(), py::arg("k"));
+    m.def("pos_only_def_mix", [](int i, int j, int k) { return py::make_tuple(i, j, k); },
+            py::arg("i"), py::arg("j") = 2, py::pos_only(), py::arg("k") = 3);
+
+
     // These should fail to compile:
-    // argument annotations are required when using kwonly
-//    m.def("bad_kwonly1", [](int) {}, py::kwonly());
-    // can't specify both `py::kwonly` and a `py::args` argument
-//    m.def("bad_kwonly2", [](int i, py::args) {}, py::kwonly(), "i"_a);
+    // argument annotations are required when using kw_only
+//    m.def("bad_kw_only1", [](int) {}, py::kw_only());
+    // can't specify both `py::kw_only` and a `py::args` argument
+//    m.def("bad_kw_only2", [](int i, py::args) {}, py::kw_only(), "i"_a);
 
     // test_function_signatures (along with most of the above)
     struct KWClass { void foo(int, float) {} };
     py::class_<KWClass>(m, "KWClass")
         .def("foo0", &KWClass::foo)
         .def("foo1", &KWClass::foo, "x"_a, "y"_a);
+
+    // Make sure a class (not an instance) can be used as a default argument.
+    // The return value doesn't matter, only that the module is importable.
+    m.def("class_default_argument", [](py::object a) { return py::repr(a); },
+        "a"_a = py::module::import("decimal").attr("Decimal"));
 }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_kwargs_and_defaults.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_kwargs_and_defaults.py
@@ -1,5 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import kwargs_and_defaults as m
 
 
@@ -109,43 +112,92 @@ def test_mixed_args_and_kwargs(msg):
 
 
 def test_keyword_only_args(msg):
-    assert m.kwonly_all(i=1, j=2) == (1, 2)
-    assert m.kwonly_all(j=1, i=2) == (2, 1)
+    assert m.kw_only_all(i=1, j=2) == (1, 2)
+    assert m.kw_only_all(j=1, i=2) == (2, 1)
 
     with pytest.raises(TypeError) as excinfo:
-        assert m.kwonly_all(i=1) == (1,)
+        assert m.kw_only_all(i=1) == (1,)
     assert "incompatible function arguments" in str(excinfo.value)
 
     with pytest.raises(TypeError) as excinfo:
-        assert m.kwonly_all(1, 2) == (1, 2)
+        assert m.kw_only_all(1, 2) == (1, 2)
     assert "incompatible function arguments" in str(excinfo.value)
 
-    assert m.kwonly_some(1, k=3, j=2) == (1, 2, 3)
+    assert m.kw_only_some(1, k=3, j=2) == (1, 2, 3)
 
-    assert m.kwonly_with_defaults(z=8) == (3, 4, 5, 8)
-    assert m.kwonly_with_defaults(2, z=8) == (2, 4, 5, 8)
-    assert m.kwonly_with_defaults(2, j=7, k=8, z=9) == (2, 7, 8, 9)
-    assert m.kwonly_with_defaults(2, 7, z=9, k=8) == (2, 7, 8, 9)
+    assert m.kw_only_with_defaults(z=8) == (3, 4, 5, 8)
+    assert m.kw_only_with_defaults(2, z=8) == (2, 4, 5, 8)
+    assert m.kw_only_with_defaults(2, j=7, k=8, z=9) == (2, 7, 8, 9)
+    assert m.kw_only_with_defaults(2, 7, z=9, k=8) == (2, 7, 8, 9)
 
-    assert m.kwonly_mixed(1, j=2) == (1, 2)
-    assert m.kwonly_mixed(j=2, i=3) == (3, 2)
-    assert m.kwonly_mixed(i=2, j=3) == (2, 3)
+    assert m.kw_only_mixed(1, j=2) == (1, 2)
+    assert m.kw_only_mixed(j=2, i=3) == (3, 2)
+    assert m.kw_only_mixed(i=2, j=3) == (2, 3)
 
-    assert m.kwonly_plus_more(4, 5, k=6, extra=7) == (4, 5, 6, {'extra': 7})
-    assert m.kwonly_plus_more(3, k=5, j=4, extra=6) == (3, 4, 5, {'extra': 6})
-    assert m.kwonly_plus_more(2, k=3, extra=4) == (2, -1, 3, {'extra': 4})
+    assert m.kw_only_plus_more(4, 5, k=6, extra=7) == (4, 5, 6, {'extra': 7})
+    assert m.kw_only_plus_more(3, k=5, j=4, extra=6) == (3, 4, 5, {'extra': 6})
+    assert m.kw_only_plus_more(2, k=3, extra=4) == (2, -1, 3, {'extra': 4})
 
     with pytest.raises(TypeError) as excinfo:
-        assert m.kwonly_mixed(i=1) == (1,)
+        assert m.kw_only_mixed(i=1) == (1,)
     assert "incompatible function arguments" in str(excinfo.value)
 
     with pytest.raises(RuntimeError) as excinfo:
-        m.register_invalid_kwonly(m)
+        m.register_invalid_kw_only(m)
     assert msg(excinfo.value) == """
-        arg(): cannot specify an unnamed argument after an kwonly() annotation
+        arg(): cannot specify an unnamed argument after an kw_only() annotation
     """
 
 
+def test_positional_only_args(msg):
+    assert m.pos_only_all(1, 2) == (1, 2)
+    assert m.pos_only_all(2, 1) == (2, 1)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_all(i=1, j=2)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.pos_only_mix(1, 2) == (1, 2)
+    assert m.pos_only_mix(2, j=1) == (2, 1)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_mix(i=1, j=2)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.pos_kw_only_mix(1, 2, k=3) == (1, 2, 3)
+    assert m.pos_kw_only_mix(1, j=2, k=3) == (1, 2, 3)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_kw_only_mix(i=1, j=2, k=3)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_kw_only_mix(1, 2, 3)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_def_mix()
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.pos_only_def_mix(1) == (1, 2, 3)
+    assert m.pos_only_def_mix(1, 4) == (1, 4, 3)
+    assert m.pos_only_def_mix(1, 4, 7) == (1, 4, 7)
+    assert m.pos_only_def_mix(1, 4, k=7) == (1, 4, 7)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_def_mix(1, j=4)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_signatures():
+    assert "kw_only_all(*, i: int, j: int) -> tuple\n" == m.kw_only_all.__doc__
+    assert "kw_only_mixed(i: int, *, j: int) -> tuple\n" == m.kw_only_mixed.__doc__
+    assert "pos_only_all(i: int, j: int, /) -> tuple\n" == m.pos_only_all.__doc__
+    assert "pos_only_mix(i: int, /, j: int) -> tuple\n" == m.pos_only_mix.__doc__
+    assert "pos_kw_only_mix(i: int, /, j: int, *, k: int) -> tuple\n" == m.pos_kw_only_mix.__doc__
+
+
+@pytest.mark.xfail("env.PYPY and env.PY2", reason="PyPy2 doesn't double count")
 def test_args_refcount():
     """Issue/PR #1216 - py::args elements get double-inc_ref()ed when combined with regular
     arguments"""
@@ -184,3 +236,5 @@ def test_args_refcount():
     # tuple without having to inc_ref the individual elements, but here we can't, hence the extra
     # refs.
     assert m.mixed_args_refcount(myval, myval, myval) == (exp3 + 3, exp3 + 3, exp3 + 3)
+
+    assert m.class_default_argument() == "<class 'decimal.Decimal'>"
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_local_bindings.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_local_bindings.py
@@ -1,6 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
 
+import env  # noqa: F401
+
 from pybind11_tests import local_bindings as m
 
 
@@ -153,7 +155,7 @@ def test_internal_locals_differ():
     assert m.local_cpp_types_addr() != cm.local_cpp_types_addr()
 
 
-@pytest.bug_in_pypy
+@pytest.mark.xfail("env.PYPY")
 def test_stl_caster_vs_stl_bind(msg):
     """One module uses a generic vector caster from `<pybind11/stl.h>` while the other
     exports `std::vector<int>` via `py:bind_vector` and `py::module_local`"""
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_methods_and_attributes.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_methods_and_attributes.cpp
@@ -289,6 +289,7 @@ TEST_SUBMODULE(methods_and_attributes, m
     class DynamicClass {
     public:
         DynamicClass() { print_default_created(this); }
+        DynamicClass(const DynamicClass&) = delete;
         ~DynamicClass() { print_destroyed(this); }
     };
     py::class_<DynamicClass>(m, "DynamicClass", py::dynamic_attr())
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_methods_and_attributes.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_methods_and_attributes.py
@@ -1,5 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import methods_and_attributes as m
 from pybind11_tests import ConstructorStats
 
@@ -257,8 +260,8 @@ def test_property_rvalue_policy():
     assert os.value == 1
 
 
-# https://bitbucket.org/pypy/pypy/issues/2447
-@pytest.unsupported_on_pypy
+# https://foss.heptapod.net/pypy/pypy/-/issues/2447
+@pytest.mark.xfail("env.PYPY")
 def test_dynamic_attributes():
     instance = m.DynamicClass()
     assert not hasattr(instance, "foo")
@@ -299,8 +302,8 @@ def test_dynamic_attributes():
         assert cstats.alive() == 0
 
 
-# https://bitbucket.org/pypy/pypy/issues/2447
-@pytest.unsupported_on_pypy
+# https://foss.heptapod.net/pypy/pypy/-/issues/2447
+@pytest.mark.xfail("env.PYPY")
 def test_cyclic_gc():
     # One object references itself
     instance = m.DynamicClass()
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_multiple_inheritance.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_multiple_inheritance.py
@@ -1,5 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import ConstructorStats
 from pybind11_tests import multiple_inheritance as m
 
@@ -11,7 +14,8 @@ def test_multiple_inheritance_cpp():
     assert mt.bar() == 4
 
 
-@pytest.bug_in_pypy
+@pytest.mark.skipif("env.PYPY and env.PY2")
+@pytest.mark.xfail("env.PYPY and not env.PY2")
 def test_multiple_inheritance_mix1():
     class Base1:
         def __init__(self, i):
@@ -32,7 +36,6 @@ def test_multiple_inheritance_mix1():
 
 
 def test_multiple_inheritance_mix2():
-
     class Base2:
         def __init__(self, i):
             self.i = i
@@ -51,7 +54,8 @@ def test_multiple_inheritance_mix2():
     assert mt.bar() == 4
 
 
-@pytest.bug_in_pypy
+@pytest.mark.skipif("env.PYPY and env.PY2")
+@pytest.mark.xfail("env.PYPY and not env.PY2")
 def test_multiple_inheritance_python():
 
     class MI1(m.Base1, m.Base2):
@@ -256,7 +260,7 @@ def test_mi_static_properties():
         assert d.static_value == 0
 
 
-@pytest.unsupported_on_pypy_lt_6
+# Requires PyPy 6+
 def test_mi_dynamic_attributes():
     """Mixing bases with and without dynamic attribute support"""
 
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_numpy_array.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_numpy_array.cpp
@@ -212,7 +212,7 @@ TEST_SUBMODULE(numpy_array, sm) {
         .def(py::init<>())
         .def("numpy_view", [](py::object &obj) {
             py::print("ArrayClass::numpy_view()");
-            ArrayClass &a = obj.cast<ArrayClass&>();
+            auto &a = obj.cast<ArrayClass&>();
             return py::array_t<int>({2}, {4}, a.data, obj);
         }
     );
@@ -362,7 +362,7 @@ TEST_SUBMODULE(numpy_array, sm) {
     // test_array_resize
     // reshape array to 2D without changing size
     sm.def("array_reshape2", [](py::array_t<double> a) {
-        const ssize_t dim_sz = (ssize_t)std::sqrt(a.size());
+        const auto dim_sz = (ssize_t)std::sqrt(a.size());
         if (dim_sz * dim_sz != a.size())
             throw std::domain_error("array_reshape2: input array total size is not a squared integer");
         a.resize({dim_sz, dim_sz});
@@ -382,9 +382,45 @@ TEST_SUBMODULE(numpy_array, sm) {
         return a;
     });
 
-#if PY_MAJOR_VERSION >= 3
-        sm.def("index_using_ellipsis", [](py::array a) {
-            return a[py::make_tuple(0, py::ellipsis(), 0)];
-        });
-#endif
+    sm.def("index_using_ellipsis", [](py::array a) {
+        return a[py::make_tuple(0, py::ellipsis(), 0)];
+    });
+
+    // test_argument_conversions
+    sm.def("accept_double",
+           [](py::array_t<double, 0>) {},
+           py::arg("a"));
+    sm.def("accept_double_forcecast",
+           [](py::array_t<double, py::array::forcecast>) {},
+           py::arg("a"));
+    sm.def("accept_double_c_style",
+           [](py::array_t<double, py::array::c_style>) {},
+           py::arg("a"));
+    sm.def("accept_double_c_style_forcecast",
+           [](py::array_t<double, py::array::forcecast | py::array::c_style>) {},
+           py::arg("a"));
+    sm.def("accept_double_f_style",
+           [](py::array_t<double, py::array::f_style>) {},
+           py::arg("a"));
+    sm.def("accept_double_f_style_forcecast",
+           [](py::array_t<double, py::array::forcecast | py::array::f_style>) {},
+           py::arg("a"));
+    sm.def("accept_double_noconvert",
+           [](py::array_t<double, 0>) {},
+           py::arg("a").noconvert());
+    sm.def("accept_double_forcecast_noconvert",
+           [](py::array_t<double, py::array::forcecast>) {},
+           py::arg("a").noconvert());
+    sm.def("accept_double_c_style_noconvert",
+           [](py::array_t<double, py::array::c_style>) {},
+           py::arg("a").noconvert());
+    sm.def("accept_double_c_style_forcecast_noconvert",
+           [](py::array_t<double, py::array::forcecast | py::array::c_style>) {},
+           py::arg("a").noconvert());
+    sm.def("accept_double_f_style_noconvert",
+           [](py::array_t<double, py::array::f_style>) {},
+           py::arg("a").noconvert());
+    sm.def("accept_double_f_style_forcecast_noconvert",
+           [](py::array_t<double, py::array::forcecast | py::array::f_style>) {},
+           py::arg("a").noconvert());
 }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_numpy_array.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_numpy_array.py
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 import pytest
-from pybind11_tests import numpy_array as m
 
-pytestmark = pytest.requires_numpy
+import env  # noqa: F401
+
+from pybind11_tests import numpy_array as m
 
-with pytest.suppress(ImportError):
-    import numpy as np
+np = pytest.importorskip("numpy")
 
 
 def test_dtypes():
@@ -243,7 +243,6 @@ def test_numpy_view(capture):
     """
 
 
-@pytest.unsupported_on_pypy
 def test_cast_numpy_int64_to_uint64():
     m.function_taking_uint64(123)
     m.function_taking_uint64(np.uint64(123))
@@ -424,20 +423,65 @@ def test_array_resize(msg):
     assert(b.shape == (8, 8))
 
 
-@pytest.unsupported_on_pypy
+@pytest.mark.xfail("env.PYPY")
 def test_array_create_and_resize(msg):
     a = m.create_and_resize(2)
     assert(a.size == 4)
     assert(np.all(a == 42.))
 
 
-@pytest.unsupported_on_py2
 def test_index_using_ellipsis():
     a = m.index_using_ellipsis(np.zeros((5, 6, 7)))
     assert a.shape == (6,)
 
 
-@pytest.unsupported_on_pypy
+@pytest.mark.parametrize("forcecast", [False, True])
+@pytest.mark.parametrize("contiguity", [None, 'C', 'F'])
+@pytest.mark.parametrize("noconvert", [False, True])
+@pytest.mark.filterwarnings(
+    "ignore:Casting complex values to real discards the imaginary part:numpy.ComplexWarning"
+)
+def test_argument_conversions(forcecast, contiguity, noconvert):
+    function_name = "accept_double"
+    if contiguity == 'C':
+        function_name += "_c_style"
+    elif contiguity == 'F':
+        function_name += "_f_style"
+    if forcecast:
+        function_name += "_forcecast"
+    if noconvert:
+        function_name += "_noconvert"
+    function = getattr(m, function_name)
+
+    for dtype in [np.dtype('float32'), np.dtype('float64'), np.dtype('complex128')]:
+        for order in ['C', 'F']:
+            for shape in [(2, 2), (1, 3, 1, 1), (1, 1, 1), (0,)]:
+                if not noconvert:
+                    # If noconvert is not passed, only complex128 needs to be truncated and
+                    # "cannot be safely obtained". So without `forcecast`, the argument shouldn't
+                    # be accepted.
+                    should_raise = dtype.name == 'complex128' and not forcecast
+                else:
+                    # If noconvert is passed, only float64 and the matching order is accepted.
+                    # If at most one dimension has a size greater than 1, the array is also
+                    # trivially contiguous.
+                    trivially_contiguous = sum(1 for d in shape if d > 1) <= 1
+                    should_raise = (
+                        dtype.name != 'float64' or
+                        (contiguity is not None and
+                         contiguity != order and
+                         not trivially_contiguous)
+                    )
+
+                array = np.zeros(shape, dtype=dtype, order=order)
+                if not should_raise:
+                    function(array)
+                else:
+                    with pytest.raises(TypeError, match="incompatible function arguments"):
+                        function(array)
+
+
+@pytest.mark.xfail("env.PYPY")
 def test_dtype_refcount_leak():
     from sys import getrefcount
     dtype = np.dtype(np.float_)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_numpy_dtypes.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_numpy_dtypes.py
@@ -1,12 +1,13 @@
 # -*- coding: utf-8 -*-
 import re
+
 import pytest
-from pybind11_tests import numpy_dtypes as m
 
-pytestmark = pytest.requires_numpy
+import env  # noqa: F401
+
+from pybind11_tests import numpy_dtypes as m
 
-with pytest.suppress(ImportError):
-    import numpy as np
+np = pytest.importorskip("numpy")
 
 
 @pytest.fixture(scope='module')
@@ -294,7 +295,7 @@ def test_register_dtype():
     assert 'dtype is already registered' in str(excinfo.value)
 
 
-@pytest.unsupported_on_pypy
+@pytest.mark.xfail("env.PYPY")
 def test_str_leak():
     from sys import getrefcount
     fmt = "f4"
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_numpy_vectorize.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_numpy_vectorize.cpp
@@ -37,7 +37,7 @@ TEST_SUBMODULE(numpy_vectorize, m) {
     ));
 
     // test_type_selection
-    // Numpy function which only accepts specific data types
+    // NumPy function which only accepts specific data types
     m.def("selective_func", [](py::array_t<int, py::array::c_style>) { return "Int branch taken."; });
     m.def("selective_func", [](py::array_t<float, py::array::c_style>) { return "Float branch taken."; });
     m.def("selective_func", [](py::array_t<std::complex<float>, py::array::c_style>) { return "Complex float branch taken."; });
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_numpy_vectorize.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_numpy_vectorize.py
@@ -2,10 +2,7 @@
 import pytest
 from pybind11_tests import numpy_vectorize as m
 
-pytestmark = pytest.requires_numpy
-
-with pytest.suppress(ImportError):
-    import numpy as np
+np = pytest.importorskip("numpy")
 
 
 def test_vectorize(capture):
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_opaque_types.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_opaque_types.cpp
@@ -60,7 +60,7 @@ TEST_SUBMODULE(opaque_types, m) {
     m.def("get_null_str_value", [](char *ptr) { return reinterpret_cast<std::intptr_t>(ptr); });
 
     m.def("return_unique_ptr", []() -> std::unique_ptr<StringList> {
-        StringList *result = new StringList();
+        auto *result = new StringList();
         result->push_back("some value");
         return std::unique_ptr<StringList>(result);
     });
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_operator_overloading.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_operator_overloading.cpp
@@ -73,7 +73,7 @@ namespace std {
         // Not a good hash function, but easy to test
         size_t operator()(const Vector2 &) { return 4; }
     };
-}
+} // namespace std
 
 // Not a good abs function, but easy to test.
 std::string abs(const Vector2&) {
@@ -88,11 +88,11 @@ std::string abs(const Vector2&) {
   // Here, we suppress the warning using `#pragma diagnostic`.
   // Taken from: https://github.com/RobotLocomotion/drake/commit/aaf84b46
   // TODO(eric): This could be resolved using a function / functor (e.g. `py::self()`).
-  #if (__APPLE__) && (__clang__)
+  #if defined(__APPLE__) && defined(__clang__)
     #if (__clang_major__ >= 10) && (__clang_minor__ >= 0) && (__clang_patchlevel__ >= 1)
       #pragma GCC diagnostic ignored "-Wself-assign-overloaded"
     #endif
-  #elif (__clang__)
+  #elif defined(__clang__)
     #if (__clang_major__ >= 7)
       #pragma GCC diagnostic ignored "-Wself-assign-overloaded"
     #endif
@@ -187,6 +187,38 @@ TEST_SUBMODULE(operators, m) {
         .def(py::self *= int())
         .def_readwrite("b", &NestC::b);
     m.def("get_NestC", [](const NestC &c) { return c.value; });
+
+
+    // test_overriding_eq_reset_hash
+    // #2191 Overriding __eq__ should set __hash__ to None
+    struct Comparable {
+        int value;
+        bool operator==(const Comparable& rhs) const {return value == rhs.value;}
+    };
+
+    struct Hashable : Comparable {
+        explicit Hashable(int value): Comparable{value}{};
+        size_t hash() const { return static_cast<size_t>(value); }
+    };
+
+    struct Hashable2 : Hashable {
+        using Hashable::Hashable;
+    };
+
+    py::class_<Comparable>(m, "Comparable")
+        .def(py::init<int>())
+        .def(py::self == py::self);
+
+    py::class_<Hashable>(m, "Hashable")
+        .def(py::init<int>())
+        .def(py::self == py::self)
+        .def("__hash__", &Hashable::hash);
+
+    // define __hash__ before __eq__
+    py::class_<Hashable2>(m, "Hashable2")
+        .def("__hash__", &Hashable::hash)
+        .def(py::init<int>())
+        .def(py::self == py::self);
 }
 
 #ifndef _MSC_VER
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_operator_overloading.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_operator_overloading.py
@@ -127,3 +127,19 @@ def test_nested():
     assert abase.value == 42
     del abase, b
     pytest.gc_collect()
+
+
+def test_overriding_eq_reset_hash():
+
+    assert m.Comparable(15) is not m.Comparable(15)
+    assert m.Comparable(15) == m.Comparable(15)
+
+    with pytest.raises(TypeError):
+        hash(m.Comparable(15))  # TypeError: unhashable type: 'm.Comparable'
+
+    for hashable in (m.Hashable, m.Hashable2):
+        assert hashable(15) is not hashable(15)
+        assert hashable(15) == hashable(15)
+
+        assert hash(hashable(15)) == 15
+        assert hash(hashable(15)) == hash(hashable(15))
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_pickling.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_pickling.py
@@ -1,5 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
+
+import env  # noqa: F401
+
 from pybind11_tests import pickling as m
 
 try:
@@ -22,7 +25,7 @@ def test_roundtrip(cls_name):
     assert p2.extra2() == p.extra2()
 
 
-@pytest.unsupported_on_pypy
+@pytest.mark.xfail("env.PYPY")
 @pytest.mark.parametrize("cls_name", ["PickleableWithDict", "PickleableWithDictNew"])
 def test_roundtrip_with_dict(cls_name):
     cls = getattr(m, cls_name)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_pytypes.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_pytypes.cpp
@@ -80,6 +80,7 @@ TEST_SUBMODULE(pytypes, m) {
     m.def("str_from_bytes", []() { return py::str(py::bytes("boo", 3)); });
     m.def("str_from_object", [](const py::object& obj) { return py::str(obj); });
     m.def("repr_from_object", [](const py::object& obj) { return py::repr(obj); });
+    m.def("str_from_handle", [](py::handle h) { return py::str(h); });
 
     m.def("str_format", []() {
         auto s1 = "{} + {} = {}"_s.format(1, 2, 3);
@@ -197,6 +198,7 @@ TEST_SUBMODULE(pytypes, m) {
     // test_constructors
     m.def("default_constructors", []() {
         return py::dict(
+            "bytes"_a=py::bytes(),
             "str"_a=py::str(),
             "bool"_a=py::bool_(),
             "int"_a=py::int_(),
@@ -210,6 +212,7 @@ TEST_SUBMODULE(pytypes, m) {
 
     m.def("converting_constructors", [](py::dict d) {
         return py::dict(
+            "bytes"_a=py::bytes(d["bytes"]),
             "str"_a=py::str(d["str"]),
             "bool"_a=py::bool_(d["bool"]),
             "int"_a=py::int_(d["int"]),
@@ -225,6 +228,7 @@ TEST_SUBMODULE(pytypes, m) {
     m.def("cast_functions", [](py::dict d) {
         // When converting between Python types, obj.cast<T>() should be the same as T(obj)
         return py::dict(
+            "bytes"_a=d["bytes"].cast<py::bytes>(),
             "str"_a=d["str"].cast<py::str>(),
             "bool"_a=d["bool"].cast<py::bool_>(),
             "int"_a=d["int"].cast<py::int_>(),
@@ -237,6 +241,8 @@ TEST_SUBMODULE(pytypes, m) {
         );
     });
 
+    m.def("convert_to_pybind11_str", [](py::object o) { return py::str(o); });
+
     m.def("get_implicit_casting", []() {
         py::dict d;
         d["char*_i1"] = "abc";
@@ -319,6 +325,16 @@ TEST_SUBMODULE(pytypes, m) {
         return a[py::slice(0, -1, 2)];
     });
 
+    // See #2361
+    m.def("issue2361_str_implicit_copy_none", []() {
+        py::str is_this_none = py::none();
+        return is_this_none;
+    });
+    m.def("issue2361_dict_implicit_copy_none", []() {
+        py::dict is_this_none = py::none();
+        return is_this_none;
+    });
+
     m.def("test_memoryview_object", [](py::buffer b) {
         return py::memoryview(b);
     });
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_pytypes.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_pytypes.py
@@ -3,6 +3,8 @@ from __future__ import division
 import pytest
 import sys
 
+import env  # noqa: F401
+
 from pybind11_tests import pytypes as m
 from pybind11_tests import debug_enabled
 
@@ -102,18 +104,30 @@ def test_str(doc):
 
     assert m.str_from_object(A()) == "this is a str"
     assert m.repr_from_object(A()) == "this is a repr"
+    assert m.str_from_handle(A()) == "this is a str"
 
     s1, s2 = m.str_format()
     assert s1 == "1 + 2 = 3"
     assert s1 == s2
 
+    malformed_utf8 = b"\x80"
+    assert m.str_from_object(malformed_utf8) is malformed_utf8  # To be fixed; see #2380
+    if env.PY2:
+        # with pytest.raises(UnicodeDecodeError):
+        #     m.str_from_object(malformed_utf8)
+        with pytest.raises(UnicodeDecodeError):
+            m.str_from_handle(malformed_utf8)
+    else:
+        # assert m.str_from_object(malformed_utf8) == "b'\\x80'"
+        assert m.str_from_handle(malformed_utf8) == "b'\\x80'"
+
 
 def test_bytes(doc):
     assert m.bytes_from_string().decode() == "foo"
     assert m.bytes_from_str().decode() == "bar"
 
     assert doc(m.bytes_from_str) == "bytes_from_str() -> {}".format(
-        "bytes" if sys.version_info[0] == 3 else "str"
+        "str" if env.PY2 else "bytes"
     )
 
 
@@ -188,11 +202,17 @@ def test_accessors():
 
 def test_constructors():
     """C++ default and converting constructors are equivalent to type calls in Python"""
-    types = [str, bool, int, float, tuple, list, dict, set]
+    types = [bytes, str, bool, int, float, tuple, list, dict, set]
     expected = {t.__name__: t() for t in types}
+    if env.PY2:
+        # Note that bytes.__name__ == 'str' in Python 2.
+        # pybind11::str is unicode even under Python 2.
+        expected["bytes"] = bytes()
+        expected["str"] = unicode()  # noqa: F821
     assert m.default_constructors() == expected
 
     data = {
+        bytes: b'41',  # Currently no supported or working conversions.
         str: 42,
         bool: "Not empty",
         int: "42",
@@ -205,6 +225,11 @@ def test_constructors():
     }
     inputs = {k.__name__: v for k, v in data.items()}
     expected = {k.__name__: k(v) for k, v in data.items()}
+    if env.PY2:  # Similar to the above. See comments above.
+        inputs["bytes"] = b'41'
+        inputs["str"] = 42
+        expected["bytes"] = b'41'
+        expected["str"] = u"42"
 
     assert m.converting_constructors(inputs) == expected
     assert m.cast_functions(inputs) == expected
@@ -220,6 +245,38 @@ def test_constructors():
         assert noconv2[k] is expected[k]
 
 
+def test_pybind11_str_raw_str():
+    # specifically to exercise pybind11::str::raw_str
+    cvt = m.convert_to_pybind11_str
+    assert cvt(u"Str") == u"Str"
+    assert cvt(b'Bytes') == u"Bytes" if env.PY2 else "b'Bytes'"
+    assert cvt(None) == u"None"
+    assert cvt(False) == u"False"
+    assert cvt(True) == u"True"
+    assert cvt(42) == u"42"
+    assert cvt(2**65) == u"36893488147419103232"
+    assert cvt(-1.50) == u"-1.5"
+    assert cvt(()) == u"()"
+    assert cvt((18,)) == u"(18,)"
+    assert cvt([]) == u"[]"
+    assert cvt([28]) == u"[28]"
+    assert cvt({}) == u"{}"
+    assert cvt({3: 4}) == u"{3: 4}"
+    assert cvt(set()) == u"set([])" if env.PY2 else "set()"
+    assert cvt({3, 3}) == u"set([3])" if env.PY2 else "{3}"
+
+    valid_orig = u"Ǳ"
+    valid_utf8 = valid_orig.encode("utf-8")
+    valid_cvt = cvt(valid_utf8)
+    assert type(valid_cvt) == bytes  # Probably surprising.
+    assert valid_cvt == b'\xc7\xb1'
+
+    malformed_utf8 = b'\x80'
+    malformed_cvt = cvt(malformed_utf8)
+    assert type(malformed_cvt) == bytes  # Probably surprising.
+    assert malformed_cvt == b'\x80'
+
+
 def test_implicit_casting():
     """Tests implicit casting when assigning or appending to dicts and lists."""
     z = m.get_implicit_casting()
@@ -281,6 +338,14 @@ def test_list_slicing():
     assert li[::2] == m.test_list_slicing(li)
 
 
+def test_issue2361():
+    # See issue #2361
+    assert m.issue2361_str_implicit_copy_none() == "None"
+    with pytest.raises(TypeError) as excinfo:
+        assert m.issue2361_dict_implicit_copy_none()
+    assert "'NoneType' object is not iterable" in str(excinfo.value)
+
+
 @pytest.mark.parametrize('method, args, fmt, expected_view', [
     (m.test_memoryview_object, (b'red',), 'B', b'red'),
     (m.test_memoryview_buffer_info, (b'green',), 'B', b'green'),
@@ -292,7 +357,7 @@ def test_memoryview(method, args, fmt, e
     view = method(*args)
     assert isinstance(view, memoryview)
     assert view.format == fmt
-    if isinstance(expected_view, bytes) or sys.version_info[0] >= 3:
+    if isinstance(expected_view, bytes) or not env.PY2:
         view_as_list = list(view)
     else:
         # Using max to pick non-zero byte (big-endian vs little-endian).
@@ -300,9 +365,7 @@ def test_memoryview(method, args, fmt, e
     assert view_as_list == list(expected_view)
 
 
-@pytest.mark.skipif(
-    not hasattr(sys, 'getrefcount'),
-    reason='getrefcount is not available')
+@pytest.mark.xfail("env.PYPY", reason="getrefcount is not available")
 @pytest.mark.parametrize('method', [
     m.test_memoryview_object,
     m.test_memoryview_buffer_info,
@@ -320,9 +383,10 @@ def test_memoryview_from_buffer_empty_sh
     view = m.test_memoryview_from_buffer_empty_shape()
     assert isinstance(view, memoryview)
     assert view.format == 'B'
-    if sys.version_info.major < 3:
+    if env.PY2:
         # Python 2 behavior is weird, but Python 3 (the future) is fine.
-        assert bytes(view).startswith(b'<memory at ')
+        # PyPy3 has <memoryview, while CPython 2 has <memory
+        assert bytes(view).startswith(b'<memory')
     else:
         assert bytes(view) == b''
 
@@ -333,14 +397,14 @@ def test_test_memoryview_from_buffer_inv
 
 
 def test_test_memoryview_from_buffer_nullptr():
-    if sys.version_info.major < 3:
+    if env.PY2:
         m.test_memoryview_from_buffer_nullptr()
     else:
         with pytest.raises(ValueError):
             m.test_memoryview_from_buffer_nullptr()
 
 
-@pytest.mark.skipif(sys.version_info.major < 3, reason='API not available')
+@pytest.mark.skipif("env.PY2")
 def test_memoryview_from_memory():
     view = m.test_memoryview_from_memory()
     assert isinstance(view, memoryview)
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_sequences_and_iterators.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_sequences_and_iterators.cpp
@@ -13,6 +13,8 @@
 #include <pybind11/operators.h>
 #include <pybind11/stl.h>
 
+#include <algorithm>
+
 template<typename T>
 class NonZeroIterator {
     const T* ptr_;
@@ -198,7 +200,7 @@ TEST_SUBMODULE(sequences_and_iterators,
             size_t start, stop, step, slicelength;
             if (!slice.compute(s.size(), &start, &stop, &step, &slicelength))
                 throw py::error_already_set();
-            Sequence *seq = new Sequence(slicelength);
+            auto *seq = new Sequence(slicelength);
             for (size_t i = 0; i < slicelength; ++i) {
                 (*seq)[i] = s[start]; start += step;
             }
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_smart_ptr.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_smart_ptr.cpp
@@ -27,7 +27,8 @@ namespace pybind11 { namespace detail {
     struct holder_helper<ref<T>> {
         static const T *get(const ref<T> &p) { return p.get_ptr(); }
     };
-}}
+} // namespace detail
+} // namespace pybind11
 
 // The following is not required anymore for std::shared_ptr, but it should compile without error:
 PYBIND11_DECLARE_HOLDER_TYPE(T, std::shared_ptr<T>);
@@ -97,9 +98,9 @@ TEST_SUBMODULE(smart_ptr, m) {
     class MyObject1 : public Object {
     public:
         MyObject1(int value) : value(value) { print_created(this, toString()); }
-        std::string toString() const { return "MyObject1[" + std::to_string(value) + "]"; }
+        std::string toString() const override { return "MyObject1[" + std::to_string(value) + "]"; }
     protected:
-        virtual ~MyObject1() { print_destroyed(this); }
+        ~MyObject1() override { print_destroyed(this); }
     private:
         int value;
     };
@@ -207,7 +208,7 @@ TEST_SUBMODULE(smart_ptr, m) {
     class MyObject4b : public MyObject4a {
     public:
         MyObject4b(int i) : MyObject4a(i) { print_created(this); }
-        ~MyObject4b() { print_destroyed(this); }
+        ~MyObject4b() override { print_destroyed(this); }
     };
     py::class_<MyObject4b, MyObject4a>(m, "MyObject4b")
         .def(py::init<int>());
@@ -338,7 +339,9 @@ TEST_SUBMODULE(smart_ptr, m) {
     // test_shared_ptr_gc
     // #187: issue involving std::shared_ptr<> return value policy & garbage collection
     struct ElementBase {
-        virtual ~ElementBase() { } /* Force creation of virtual table */
+        virtual ~ElementBase() = default; /* Force creation of virtual table */
+        ElementBase() = default;
+        ElementBase(const ElementBase&) = delete;
     };
     py::class_<ElementBase, std::shared_ptr<ElementBase>>(m, "ElementBase");
 
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_smart_ptr.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_smart_ptr.py
@@ -1,7 +1,8 @@
 # -*- coding: utf-8 -*-
 import pytest
-from pybind11_tests import smart_ptr as m
-from pybind11_tests import ConstructorStats
+
+m = pytest.importorskip("pybind11_tests.smart_ptr")
+from pybind11_tests import ConstructorStats  # noqa: E402
 
 
 def test_smart_ptr(capture):
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_stl.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_stl.cpp
@@ -15,7 +15,7 @@
 #include <string>
 
 // Test with `std::variant` in C++17 mode, or with `boost::variant` in C++11/14
-#if PYBIND11_HAS_VARIANT
+#if defined(PYBIND11_HAS_VARIANT)
 using std::variant;
 #elif defined(PYBIND11_TEST_BOOST) && (!defined(_MSC_VER) || _MSC_VER >= 1910)
 #  include <boost/variant.hpp>
@@ -47,7 +47,7 @@ struct TplCtorClass {
 namespace std {
     template <>
     struct hash<TplCtorClass> { size_t operator()(const TplCtorClass &) const { return 0; } };
-}
+} // namespace std
 
 
 template <template <typename> class OptionalImpl, typename T>
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_stl_binders.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_stl_binders.py
@@ -1,10 +1,9 @@
 # -*- coding: utf-8 -*-
 import pytest
-import sys
-from pybind11_tests import stl_binders as m
 
-with pytest.suppress(ImportError):
-    import numpy as np
+import env  # noqa: F401
+
+from pybind11_tests import stl_binders as m
 
 
 def test_vector_int():
@@ -69,15 +68,14 @@ def test_vector_int():
     assert len(v_int2) == 0
 
 
-# related to the PyPy's buffer protocol.
-@pytest.unsupported_on_pypy
+# Older PyPy's failed here, related to the PyPy's buffer protocol.
 def test_vector_buffer():
     b = bytearray([1, 2, 3, 4])
     v = m.VectorUChar(b)
     assert v[1] == 2
     v[2] = 5
     mv = memoryview(v)  # We expose the buffer interface
-    if sys.version_info.major > 2:
+    if not env.PY2:
         assert mv[2] == 5
         mv[2] = 6
     else:
@@ -85,14 +83,18 @@ def test_vector_buffer():
         mv[2] = '\x06'
     assert v[2] == 6
 
+    if not env.PY2:
+        mv = memoryview(b)
+        v = m.VectorUChar(mv[::2])
+        assert v[1] == 3
+
     with pytest.raises(RuntimeError) as excinfo:
         m.create_undeclstruct()  # Undeclared struct contents, no buffer interface
     assert "NumPy type info missing for " in str(excinfo.value)
 
 
-@pytest.unsupported_on_pypy
-@pytest.requires_numpy
 def test_vector_buffer_numpy():
+    np = pytest.importorskip("numpy")
     a = np.array([1, 2, 3, 4], dtype=np.int32)
     with pytest.raises(TypeError):
         m.VectorInt(a)
@@ -119,6 +121,10 @@ def test_vector_buffer_numpy():
                                                    ('y', 'float64'), ('z', 'bool')], align=True)))
     assert len(v) == 3
 
+    b = np.array([1, 2, 3, 4], dtype=np.uint8)
+    v = m.VectorUChar(b[::2])
+    assert v[1] == 3
+
 
 def test_vector_bool():
     import pybind11_cross_module_tests as cm
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_tagbased_polymorphic.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_tagbased_polymorphic.cpp
@@ -117,7 +117,7 @@ namespace pybind11 {
         static const void *get(const itype *src, const std::type_info*& type)
         { type = src ? Animal::type_of_kind(src->kind) : nullptr; return src; }
     };
-}
+} // namespace pybind11
 
 TEST_SUBMODULE(tagbased_polymorphic, m) {
     py::class_<Animal>(m, "Animal")
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_virtual_functions.cpp
+++ gtsam-4.1.0/wrap/pybind11/tests/test_virtual_functions.cpp
@@ -47,7 +47,7 @@ public:
 
     int run(int value) override {
         /* Generate wrapping code that enables native function overloading */
-        PYBIND11_OVERLOAD(
+        PYBIND11_OVERRIDE(
             int,         /* Return type */
             ExampleVirt, /* Parent class */
             run,         /* Name of function */
@@ -56,7 +56,7 @@ public:
     }
 
     bool run_bool() override {
-        PYBIND11_OVERLOAD_PURE(
+        PYBIND11_OVERRIDE_PURE(
             bool,         /* Return type */
             ExampleVirt,  /* Parent class */
             run_bool,     /* Name of function */
@@ -66,7 +66,7 @@ public:
     }
 
     void pure_virtual() override {
-        PYBIND11_OVERLOAD_PURE(
+        PYBIND11_OVERRIDE_PURE(
             void,         /* Return type */
             ExampleVirt,  /* Parent class */
             pure_virtual, /* Name of function */
@@ -78,7 +78,7 @@ public:
     // We can return reference types for compatibility with C++ virtual interfaces that do so, but
     // note they have some significant limitations (see the documentation).
     const std::string &get_string1() override {
-        PYBIND11_OVERLOAD(
+        PYBIND11_OVERRIDE(
             const std::string &, /* Return type */
             ExampleVirt,         /* Parent class */
             get_string1,         /* Name of function */
@@ -87,7 +87,7 @@ public:
     }
 
     const std::string *get_string2() override {
-        PYBIND11_OVERLOAD(
+        PYBIND11_OVERRIDE(
             const std::string *, /* Return type */
             ExampleVirt,         /* Parent class */
             get_string2,         /* Name of function */
@@ -129,7 +129,9 @@ private:
 
 class NCVirt {
 public:
-    virtual ~NCVirt() { }
+    virtual ~NCVirt() = default;
+    NCVirt() = default;
+    NCVirt(const NCVirt&) = delete;
     virtual NonCopyable get_noncopyable(int a, int b) { return NonCopyable(a, b); }
     virtual Movable get_movable(int a, int b) = 0;
 
@@ -137,13 +139,13 @@ public:
     std::string print_movable(int a, int b) { return get_movable(a, b).get_value(); }
 };
 class NCVirtTrampoline : public NCVirt {
-#if !defined(__INTEL_COMPILER)
+#if !defined(__INTEL_COMPILER) && !defined(__CUDACC__) && !defined(__PGIC__)
     NonCopyable get_noncopyable(int a, int b) override {
-        PYBIND11_OVERLOAD(NonCopyable, NCVirt, get_noncopyable, a, b);
+        PYBIND11_OVERRIDE(NonCopyable, NCVirt, get_noncopyable, a, b);
     }
 #endif
     Movable get_movable(int a, int b) override {
-        PYBIND11_OVERLOAD_PURE(Movable, NCVirt, get_movable, a, b);
+        PYBIND11_OVERRIDE_PURE(Movable, NCVirt, get_movable, a, b);
     }
 };
 
@@ -151,11 +153,13 @@ struct Base {
     /* for some reason MSVC2015 can't compile this if the function is pure virtual */
     virtual std::string dispatch() const { return {}; };
     virtual ~Base() = default;
+    Base() = default;
+    Base(const Base&) = delete;
 };
 
 struct DispatchIssue : Base {
-    virtual std::string dispatch() const {
-        PYBIND11_OVERLOAD_PURE(std::string, Base, dispatch, /* no arguments */);
+    std::string dispatch() const override {
+        PYBIND11_OVERRIDE_PURE(std::string, Base, dispatch, /* no arguments */);
     }
 };
 
@@ -201,7 +205,7 @@ TEST_SUBMODULE(virtual_functions, m) {
         .def(py::init<int, int>());
 
     // test_move_support
-#if !defined(__INTEL_COMPILER)
+#if !defined(__INTEL_COMPILER) && !defined(__CUDACC__) && !defined(__PGIC__)
     py::class_<NCVirt, NCVirtTrampoline>(m, "NCVirt")
         .def(py::init<>())
         .def("get_noncopyable", &NCVirt::get_noncopyable)
@@ -221,19 +225,22 @@ TEST_SUBMODULE(virtual_functions, m) {
     // don't invoke Python dispatch classes by default when instantiating C++ classes
     // that were not extended on the Python side
     struct A {
-        virtual ~A() {}
+        A() = default;
+        A(const A&) = delete;
+        virtual ~A() = default;
         virtual void f() { py::print("A.f()"); }
     };
 
     struct PyA : A {
         PyA() { py::print("PyA.PyA()"); }
-        ~PyA() { py::print("PyA.~PyA()"); }
+        PyA(const PyA&) = delete;
+        ~PyA() override { py::print("PyA.~PyA()"); }
 
         void f() override {
             py::print("PyA.f()");
             // This convolution just gives a `void`, but tests that PYBIND11_TYPE() works to protect
             // a type containing a ,
-            PYBIND11_OVERLOAD(PYBIND11_TYPE(typename std::enable_if<true, void>::type), A, f);
+            PYBIND11_OVERRIDE(PYBIND11_TYPE(typename std::enable_if<true, void>::type), A, f);
         }
     };
 
@@ -246,16 +253,19 @@ TEST_SUBMODULE(virtual_functions, m) {
     // test_alias_delay_initialization2
     // ... unless we explicitly request it, as in this example:
     struct A2 {
-        virtual ~A2() {}
+        A2() = default;
+        A2(const A2&) = delete;
+        virtual ~A2() = default;
         virtual void f() { py::print("A2.f()"); }
     };
 
     struct PyA2 : A2 {
         PyA2() { py::print("PyA2.PyA2()"); }
-        ~PyA2() { py::print("PyA2.~PyA2()"); }
+        PyA2(const PyA2&) = delete;
+        ~PyA2() override { py::print("PyA2.~PyA2()"); }
         void f() override {
             py::print("PyA2.f()");
-            PYBIND11_OVERLOAD(void, A2, f);
+            PYBIND11_OVERRIDE(void, A2, f);
         }
     };
 
@@ -282,6 +292,8 @@ TEST_SUBMODULE(virtual_functions, m) {
         std::string v;
         A a;
         explicit OverrideTest(const std::string &v) : v{v} {}
+        OverrideTest() = default;
+        OverrideTest(const OverrideTest&) = delete;
         virtual std::string str_value() { return v; }
         virtual std::string &str_ref() { return v; }
         virtual A A_value() { return a; }
@@ -292,19 +304,19 @@ TEST_SUBMODULE(virtual_functions, m) {
     class PyOverrideTest : public OverrideTest {
     public:
         using OverrideTest::OverrideTest;
-        std::string str_value() override { PYBIND11_OVERLOAD(std::string, OverrideTest, str_value); }
+        std::string str_value() override { PYBIND11_OVERRIDE(std::string, OverrideTest, str_value); }
         // Not allowed (uncommenting should hit a static_assert failure): we can't get a reference
         // to a python numeric value, since we only copy values in the numeric type caster:
-//      std::string &str_ref() override { PYBIND11_OVERLOAD(std::string &, OverrideTest, str_ref); }
+//      std::string &str_ref() override { PYBIND11_OVERRIDE(std::string &, OverrideTest, str_ref); }
         // But we can work around it like this:
     private:
         std::string _tmp;
-        std::string str_ref_helper() { PYBIND11_OVERLOAD(std::string, OverrideTest, str_ref); }
+        std::string str_ref_helper() { PYBIND11_OVERRIDE(std::string, OverrideTest, str_ref); }
     public:
         std::string &str_ref() override { return _tmp = str_ref_helper(); }
 
-        A A_value() override { PYBIND11_OVERLOAD(A, OverrideTest, A_value); }
-        A &A_ref() override { PYBIND11_OVERLOAD(A &, OverrideTest, A_ref); }
+        A A_value() override { PYBIND11_OVERRIDE(A, OverrideTest, A_value); }
+        A &A_ref() override { PYBIND11_OVERRIDE(A &, OverrideTest, A_ref); }
     };
 
     py::class_<OverrideTest::A>(m, "OverrideTest_A")
@@ -339,6 +351,8 @@ public: \
         return say_something(1) + " " + std::to_string(unlucky_number()); \
     }
 A_METHODS
+    A_Repeat() = default;
+    A_Repeat(const A_Repeat&) = delete;
     virtual ~A_Repeat() = default;
 };
 class B_Repeat : public A_Repeat {
@@ -364,7 +378,12 @@ D_METHODS
 };
 
 // Base classes for templated inheritance trampolines.  Identical to the repeat-everything version:
-class A_Tpl { A_METHODS; virtual ~A_Tpl() = default; };
+class A_Tpl {
+    A_METHODS;
+    A_Tpl() = default;
+    A_Tpl(const A_Tpl&) = delete;
+    virtual ~A_Tpl() = default;
+};
 class B_Tpl : public A_Tpl { B_METHODS };
 class C_Tpl : public B_Tpl { C_METHODS };
 class D_Tpl : public C_Tpl { D_METHODS };
@@ -374,29 +393,29 @@ class D_Tpl : public C_Tpl { D_METHODS }
 class PyA_Repeat : public A_Repeat {
 public:
     using A_Repeat::A_Repeat;
-    int unlucky_number() override { PYBIND11_OVERLOAD_PURE(int, A_Repeat, unlucky_number, ); }
-    std::string say_something(unsigned times) override { PYBIND11_OVERLOAD(std::string, A_Repeat, say_something, times); }
+    int unlucky_number() override { PYBIND11_OVERRIDE_PURE(int, A_Repeat, unlucky_number, ); }
+    std::string say_something(unsigned times) override { PYBIND11_OVERRIDE(std::string, A_Repeat, say_something, times); }
 };
 class PyB_Repeat : public B_Repeat {
 public:
     using B_Repeat::B_Repeat;
-    int unlucky_number() override { PYBIND11_OVERLOAD(int, B_Repeat, unlucky_number, ); }
-    std::string say_something(unsigned times) override { PYBIND11_OVERLOAD(std::string, B_Repeat, say_something, times); }
-    double lucky_number() override { PYBIND11_OVERLOAD(double, B_Repeat, lucky_number, ); }
+    int unlucky_number() override { PYBIND11_OVERRIDE(int, B_Repeat, unlucky_number, ); }
+    std::string say_something(unsigned times) override { PYBIND11_OVERRIDE(std::string, B_Repeat, say_something, times); }
+    double lucky_number() override { PYBIND11_OVERRIDE(double, B_Repeat, lucky_number, ); }
 };
 class PyC_Repeat : public C_Repeat {
 public:
     using C_Repeat::C_Repeat;
-    int unlucky_number() override { PYBIND11_OVERLOAD(int, C_Repeat, unlucky_number, ); }
-    std::string say_something(unsigned times) override { PYBIND11_OVERLOAD(std::string, C_Repeat, say_something, times); }
-    double lucky_number() override { PYBIND11_OVERLOAD(double, C_Repeat, lucky_number, ); }
+    int unlucky_number() override { PYBIND11_OVERRIDE(int, C_Repeat, unlucky_number, ); }
+    std::string say_something(unsigned times) override { PYBIND11_OVERRIDE(std::string, C_Repeat, say_something, times); }
+    double lucky_number() override { PYBIND11_OVERRIDE(double, C_Repeat, lucky_number, ); }
 };
 class PyD_Repeat : public D_Repeat {
 public:
     using D_Repeat::D_Repeat;
-    int unlucky_number() override { PYBIND11_OVERLOAD(int, D_Repeat, unlucky_number, ); }
-    std::string say_something(unsigned times) override { PYBIND11_OVERLOAD(std::string, D_Repeat, say_something, times); }
-    double lucky_number() override { PYBIND11_OVERLOAD(double, D_Repeat, lucky_number, ); }
+    int unlucky_number() override { PYBIND11_OVERRIDE(int, D_Repeat, unlucky_number, ); }
+    std::string say_something(unsigned times) override { PYBIND11_OVERRIDE(std::string, D_Repeat, say_something, times); }
+    double lucky_number() override { PYBIND11_OVERRIDE(double, D_Repeat, lucky_number, ); }
 };
 
 // Inheritance approach 2: templated trampoline classes.
@@ -417,15 +436,15 @@ template <class Base = A_Tpl>
 class PyA_Tpl : public Base {
 public:
     using Base::Base; // Inherit constructors
-    int unlucky_number() override { PYBIND11_OVERLOAD_PURE(int, Base, unlucky_number, ); }
-    std::string say_something(unsigned times) override { PYBIND11_OVERLOAD(std::string, Base, say_something, times); }
+    int unlucky_number() override { PYBIND11_OVERRIDE_PURE(int, Base, unlucky_number, ); }
+    std::string say_something(unsigned times) override { PYBIND11_OVERRIDE(std::string, Base, say_something, times); }
 };
 template <class Base = B_Tpl>
 class PyB_Tpl : public PyA_Tpl<Base> {
 public:
     using PyA_Tpl<Base>::PyA_Tpl; // Inherit constructors (via PyA_Tpl's inherited constructors)
-    int unlucky_number() override { PYBIND11_OVERLOAD(int, Base, unlucky_number, ); }
-    double lucky_number() override { PYBIND11_OVERLOAD(double, Base, lucky_number, ); }
+    int unlucky_number() override { PYBIND11_OVERRIDE(int, Base, unlucky_number, ); }
+    double lucky_number() override { PYBIND11_OVERRIDE(double, Base, lucky_number, ); }
 };
 // Since C_Tpl and D_Tpl don't declare any new virtual methods, we don't actually need these (we can
 // use PyB_Tpl<C_Tpl> and PyB_Tpl<D_Tpl> for the trampoline classes instead):
--- gtsam-4.1.0.orig/wrap/pybind11/tests/test_virtual_functions.py
+++ gtsam-4.1.0/wrap/pybind11/tests/test_virtual_functions.py
@@ -1,8 +1,10 @@
 # -*- coding: utf-8 -*-
 import pytest
 
-from pybind11_tests import virtual_functions as m
-from pybind11_tests import ConstructorStats
+import env  # noqa: F401
+
+m = pytest.importorskip("pybind11_tests.virtual_functions")
+from pybind11_tests import ConstructorStats  # noqa: E402
 
 
 def test_override(capture, msg):
@@ -160,7 +162,7 @@ def test_alias_delay_initialization2(cap
 
 # PyPy: Reference count > 1 causes call with noncopyable instance
 # to fail in ncv1.print_nc()
-@pytest.unsupported_on_pypy
+@pytest.mark.xfail("env.PYPY")
 @pytest.mark.skipif(not hasattr(m, "NCVirt"), reason="NCVirt test broken on ICPC")
 def test_move_support():
     class NCVirtExt(m.NCVirt):
--- gtsam-4.1.0.orig/wrap/pybind11/tools/FindCatch.cmake
+++ gtsam-4.1.0/wrap/pybind11/tools/FindCatch.cmake
@@ -19,9 +19,14 @@ endif()
 
 # Extract the version number from catch.hpp
 function(_get_catch_version)
-  file(STRINGS "${CATCH_INCLUDE_DIR}/catch.hpp" version_line REGEX "Catch v.*" LIMIT_COUNT 1)
+  file(
+    STRINGS "${CATCH_INCLUDE_DIR}/catch.hpp" version_line
+    REGEX "Catch v.*"
+    LIMIT_COUNT 1)
   if(version_line MATCHES "Catch v([0-9]+)\\.([0-9]+)\\.([0-9]+)")
-    set(CATCH_VERSION "${CMAKE_MATCH_1}.${CMAKE_MATCH_2}.${CMAKE_MATCH_3}" PARENT_SCOPE)
+    set(CATCH_VERSION
+        "${CMAKE_MATCH_1}.${CMAKE_MATCH_2}.${CMAKE_MATCH_3}"
+        PARENT_SCOPE)
   endif()
 endfunction()
 
@@ -34,11 +39,16 @@ function(_download_catch version destina
   if(error)
     message(FATAL_ERROR "Could not download ${url}")
   endif()
-  set(CATCH_INCLUDE_DIR "${destination_dir}" CACHE INTERNAL "")
+  set(CATCH_INCLUDE_DIR
+      "${destination_dir}"
+      CACHE INTERNAL "")
 endfunction()
 
 # Look for catch locally
-find_path(CATCH_INCLUDE_DIR NAMES catch.hpp PATH_SUFFIXES catch)
+find_path(
+  CATCH_INCLUDE_DIR
+  NAMES catch.hpp
+  PATH_SUFFIXES catch2)
 if(CATCH_INCLUDE_DIR)
   _get_catch_version()
 endif()
@@ -54,4 +64,7 @@ if(NOT CATCH_VERSION OR CATCH_VERSION VE
   endif()
 endif()
 
+add_library(Catch2::Catch2 IMPORTED INTERFACE)
+set_property(TARGET Catch2::Catch2 PROPERTY INTERFACE_INCLUDE_DIRECTORIES "${CATCH_INCLUDE_DIR}")
+
 set(CATCH_FOUND TRUE)
--- gtsam-4.1.0.orig/wrap/pybind11/tools/FindEigen3.cmake
+++ gtsam-4.1.0/wrap/pybind11/tools/FindEigen3.cmake
@@ -26,17 +26,21 @@ if(NOT Eigen3_FIND_VERSION)
     set(Eigen3_FIND_VERSION_PATCH 0)
   endif(NOT Eigen3_FIND_VERSION_PATCH)
 
-  set(Eigen3_FIND_VERSION "${Eigen3_FIND_VERSION_MAJOR}.${Eigen3_FIND_VERSION_MINOR}.${Eigen3_FIND_VERSION_PATCH}")
+  set(Eigen3_FIND_VERSION
+      "${Eigen3_FIND_VERSION_MAJOR}.${Eigen3_FIND_VERSION_MINOR}.${Eigen3_FIND_VERSION_PATCH}")
 endif(NOT Eigen3_FIND_VERSION)
 
 macro(_eigen3_check_version)
   file(READ "${EIGEN3_INCLUDE_DIR}/Eigen/src/Core/util/Macros.h" _eigen3_version_header)
 
-  string(REGEX MATCH "define[ \t]+EIGEN_WORLD_VERSION[ \t]+([0-9]+)" _eigen3_world_version_match "${_eigen3_version_header}")
+  string(REGEX MATCH "define[ \t]+EIGEN_WORLD_VERSION[ \t]+([0-9]+)" _eigen3_world_version_match
+               "${_eigen3_version_header}")
   set(EIGEN3_WORLD_VERSION "${CMAKE_MATCH_1}")
-  string(REGEX MATCH "define[ \t]+EIGEN_MAJOR_VERSION[ \t]+([0-9]+)" _eigen3_major_version_match "${_eigen3_version_header}")
+  string(REGEX MATCH "define[ \t]+EIGEN_MAJOR_VERSION[ \t]+([0-9]+)" _eigen3_major_version_match
+               "${_eigen3_version_header}")
   set(EIGEN3_MAJOR_VERSION "${CMAKE_MATCH_1}")
-  string(REGEX MATCH "define[ \t]+EIGEN_MINOR_VERSION[ \t]+([0-9]+)" _eigen3_minor_version_match "${_eigen3_version_header}")
+  string(REGEX MATCH "define[ \t]+EIGEN_MINOR_VERSION[ \t]+([0-9]+)" _eigen3_minor_version_match
+               "${_eigen3_version_header}")
   set(EIGEN3_MINOR_VERSION "${CMAKE_MATCH_1}")
 
   set(EIGEN3_VERSION ${EIGEN3_WORLD_VERSION}.${EIGEN3_MAJOR_VERSION}.${EIGEN3_MINOR_VERSION})
@@ -53,20 +57,19 @@ macro(_eigen3_check_version)
   endif(NOT EIGEN3_VERSION_OK)
 endmacro(_eigen3_check_version)
 
-if (EIGEN3_INCLUDE_DIR)
+if(EIGEN3_INCLUDE_DIR)
 
   # in cache already
   _eigen3_check_version()
   set(EIGEN3_FOUND ${EIGEN3_VERSION_OK})
 
-else (EIGEN3_INCLUDE_DIR)
+else(EIGEN3_INCLUDE_DIR)
 
-  find_path(EIGEN3_INCLUDE_DIR NAMES signature_of_eigen3_matrix_library
-      PATHS
-      ${CMAKE_INSTALL_PREFIX}/include
-      ${KDE4_INCLUDE_DIR}
-      PATH_SUFFIXES eigen3 eigen
-    )
+  find_path(
+    EIGEN3_INCLUDE_DIR
+    NAMES signature_of_eigen3_matrix_library
+    PATHS ${CMAKE_INSTALL_PREFIX}/include ${KDE4_INCLUDE_DIR}
+    PATH_SUFFIXES eigen3 eigen)
 
   if(EIGEN3_INCLUDE_DIR)
     _eigen3_check_version()
--- gtsam-4.1.0.orig/wrap/pybind11/tools/FindPythonLibsNew.cmake
+++ gtsam-4.1.0/wrap/pybind11/tools/FindPythonLibsNew.cmake
@@ -52,33 +52,65 @@
 
 # Checking for the extension makes sure that `LibsNew` was found and not just `Libs`.
 if(PYTHONLIBS_FOUND AND PYTHON_MODULE_EXTENSION)
-    return()
+  return()
 endif()
 
-# Use the Python interpreter to find the libs.
-if(NOT PythonLibsNew_FIND_VERSION)
-    set(PythonLibsNew_FIND_VERSION "")
+if(PythonLibsNew_FIND_QUIETLY)
+  set(_pythonlibs_quiet QUIET)
 endif()
+
 if(PythonLibsNew_FIND_REQUIRED)
-    find_package(PythonInterp ${PythonLibsNew_FIND_VERSION} REQUIRED)
-else()
-    find_package(PythonInterp ${PythonLibsNew_FIND_VERSION})
+  set(_pythonlibs_required REQUIRED)
+endif()
+
+# Check to see if the `python` command is present and from a virtual
+# environment, conda, or GHA activation - if it is, try to use that.
+
+if(NOT DEFINED PYTHON_EXECUTABLE)
+  if(DEFINED ENV{VIRTUAL_ENV})
+    find_program(
+      PYTHON_EXECUTABLE python
+      PATHS "$ENV{VIRTUAL_ENV}" "$ENV{VIRTUAL_ENV}/bin"
+      NO_DEFAULT_PATH)
+  elseif(DEFINED ENV{CONDA_PREFIX})
+    find_program(
+      PYTHON_EXECUTABLE python
+      PATHS "$ENV{CONDA_PREFIX}" "$ENV{CONDA_PREFIX}/bin"
+      NO_DEFAULT_PATH)
+  elseif(DEFINED ENV{pythonLocation})
+    find_program(
+      PYTHON_EXECUTABLE python
+      PATHS "$ENV{pythonLocation}" "$ENV{pythonLocation}/bin"
+      NO_DEFAULT_PATH)
+  endif()
+  if(NOT PYTHON_EXECUTABLE)
+    unset(PYTHON_EXECUTABLE)
+  endif()
+endif()
+
+# Use the Python interpreter to find the libs.
+if(NOT PythonLibsNew_FIND_VERSION)
+  set(PythonLibsNew_FIND_VERSION "")
 endif()
 
+find_package(PythonInterp ${PythonLibsNew_FIND_VERSION} ${_pythonlibs_required}
+             ${_pythonlibs_quiet})
+
 if(NOT PYTHONINTERP_FOUND)
-    set(PYTHONLIBS_FOUND FALSE)
-    set(PythonLibsNew_FOUND FALSE)
-    return()
+  set(PYTHONLIBS_FOUND FALSE)
+  set(PythonLibsNew_FOUND FALSE)
+  return()
 endif()
 
-# According to http://stackoverflow.com/questions/646518/python-how-to-detect-debug-interpreter
+# According to https://stackoverflow.com/questions/646518/python-how-to-detect-debug-interpreter
 # testing whether sys has the gettotalrefcount function is a reliable, cross-platform
 # way to detect a CPython debug interpreter.
 #
 # The library suffix is from the config var LDVERSION sometimes, otherwise
 # VERSION. VERSION will typically be like "2.7" on unix, and "27" on windows.
-execute_process(COMMAND "${PYTHON_EXECUTABLE}" "-c"
-    "from distutils import sysconfig as s;import sys;import struct;
+execute_process(
+  COMMAND
+    "${PYTHON_EXECUTABLE}" "-c" "from distutils import sysconfig as s;import sys;import struct;
 print('.'.join(str(v) for v in sys.version_info));
 print(sys.prefix);
 print(s.get_python_inc(plat_specific=True));
@@ -90,23 +122,22 @@ print(s.get_config_var('LDVERSION') or s
 print(s.get_config_var('LIBDIR') or '');
 print(s.get_config_var('MULTIARCH') or '');
 "
-    RESULT_VARIABLE _PYTHON_SUCCESS
-    OUTPUT_VARIABLE _PYTHON_VALUES
-    ERROR_VARIABLE _PYTHON_ERROR_VALUE)
+  RESULT_VARIABLE _PYTHON_SUCCESS
+  OUTPUT_VARIABLE _PYTHON_VALUES
+  ERROR_VARIABLE _PYTHON_ERROR_VALUE)
 
 if(NOT _PYTHON_SUCCESS MATCHES 0)
-    if(PythonLibsNew_FIND_REQUIRED)
-        message(FATAL_ERROR
-            "Python config failure:\n${_PYTHON_ERROR_VALUE}")
-    endif()
-    set(PYTHONLIBS_FOUND FALSE)
-    set(PythonLibsNew_FOUND FALSE)
-    return()
+  if(PythonLibsNew_FIND_REQUIRED)
+    message(FATAL_ERROR "Python config failure:\n${_PYTHON_ERROR_VALUE}")
+  endif()
+  set(PYTHONLIBS_FOUND FALSE)
+  set(PythonLibsNew_FOUND FALSE)
+  return()
 endif()
 
 # Convert the process output into a list
 if(WIN32)
-    string(REGEX REPLACE "\\\\" "/" _PYTHON_VALUES ${_PYTHON_VALUES})
+  string(REGEX REPLACE "\\\\" "/" _PYTHON_VALUES ${_PYTHON_VALUES})
 endif()
 string(REGEX REPLACE ";" "\\\\;" _PYTHON_VALUES ${_PYTHON_VALUES})
 string(REGEX REPLACE "\n" ";" _PYTHON_VALUES ${_PYTHON_VALUES})
@@ -124,16 +155,15 @@ list(GET _PYTHON_VALUES 9 PYTHON_MULTIAR
 # Make sure the Python has the same pointer-size as the chosen compiler
 # Skip if CMAKE_SIZEOF_VOID_P is not defined
 if(CMAKE_SIZEOF_VOID_P AND (NOT "${PYTHON_SIZEOF_VOID_P}" STREQUAL "${CMAKE_SIZEOF_VOID_P}"))
-    if(PythonLibsNew_FIND_REQUIRED)
-        math(EXPR _PYTHON_BITS "${PYTHON_SIZEOF_VOID_P} * 8")
-        math(EXPR _CMAKE_BITS "${CMAKE_SIZEOF_VOID_P} * 8")
-        message(FATAL_ERROR
-            "Python config failure: Python is ${_PYTHON_BITS}-bit, "
-            "chosen compiler is  ${_CMAKE_BITS}-bit")
-    endif()
-    set(PYTHONLIBS_FOUND FALSE)
-    set(PythonLibsNew_FOUND FALSE)
-    return()
+  if(PythonLibsNew_FIND_REQUIRED)
+    math(EXPR _PYTHON_BITS "${PYTHON_SIZEOF_VOID_P} * 8")
+    math(EXPR _CMAKE_BITS "${CMAKE_SIZEOF_VOID_P} * 8")
+    message(FATAL_ERROR "Python config failure: Python is ${_PYTHON_BITS}-bit, "
+                        "chosen compiler is  ${_CMAKE_BITS}-bit")
+  endif()
+  set(PYTHONLIBS_FOUND FALSE)
+  set(PythonLibsNew_FOUND FALSE)
+  return()
 endif()
 
 # The built-in FindPython didn't always give the version numbers
@@ -141,6 +171,7 @@ string(REGEX REPLACE "\\." ";" _PYTHON_V
 list(GET _PYTHON_VERSION_LIST 0 PYTHON_VERSION_MAJOR)
 list(GET _PYTHON_VERSION_LIST 1 PYTHON_VERSION_MINOR)
 list(GET _PYTHON_VERSION_LIST 2 PYTHON_VERSION_PATCH)
+set(PYTHON_VERSION "${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR}.${PYTHON_VERSION_PATCH}")
 
 # Make sure all directory separators are '/'
 string(REGEX REPLACE "\\\\" "/" PYTHON_PREFIX "${PYTHON_PREFIX}")
@@ -148,79 +179,77 @@ string(REGEX REPLACE "\\\\" "/" PYTHON_I
 string(REGEX REPLACE "\\\\" "/" PYTHON_SITE_PACKAGES "${PYTHON_SITE_PACKAGES}")
 
 if(CMAKE_HOST_WIN32)
-    set(PYTHON_LIBRARY
-        "${PYTHON_PREFIX}/libs/python${PYTHON_LIBRARY_SUFFIX}.lib")
-
-    # when run in a venv, PYTHON_PREFIX points to it. But the libraries remain in the
-    # original python installation. They may be found relative to PYTHON_INCLUDE_DIR.
-    if(NOT EXISTS "${PYTHON_LIBRARY}")
-        get_filename_component(_PYTHON_ROOT ${PYTHON_INCLUDE_DIR} DIRECTORY)
-        set(PYTHON_LIBRARY
-            "${_PYTHON_ROOT}/libs/python${PYTHON_LIBRARY_SUFFIX}.lib")
-    endif()
-
-    # if we are in MSYS & MINGW, and we didn't find windows python lib, look for system python lib
-    if(DEFINED ENV{MSYSTEM} AND MINGW AND NOT EXISTS "${PYTHON_LIBRARY}")
-        if(PYTHON_MULTIARCH)
-            set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
-        else()
-            set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
-        endif()
-        unset(PYTHON_LIBRARY)
-        find_library(PYTHON_LIBRARY
-            NAMES "python${PYTHON_LIBRARY_SUFFIX}"
-            PATHS ${_PYTHON_LIBS_SEARCH}
-            NO_DEFAULT_PATH)
-    endif()
+  set(PYTHON_LIBRARY "${PYTHON_PREFIX}/libs/python${PYTHON_LIBRARY_SUFFIX}.lib")
 
-    # raise an error if the python libs are still not found.
-    if(NOT EXISTS "${PYTHON_LIBRARY}")
-        message(FATAL_ERROR "Python libraries not found")
-    endif()
-
-else()
+  # when run in a venv, PYTHON_PREFIX points to it. But the libraries remain in the
+  # original python installation. They may be found relative to PYTHON_INCLUDE_DIR.
+  if(NOT EXISTS "${PYTHON_LIBRARY}")
+    get_filename_component(_PYTHON_ROOT ${PYTHON_INCLUDE_DIR} DIRECTORY)
+    set(PYTHON_LIBRARY "${_PYTHON_ROOT}/libs/python${PYTHON_LIBRARY_SUFFIX}.lib")
+  endif()
+
+  # if we are in MSYS & MINGW, and we didn't find windows python lib, look for system python lib
+  if(DEFINED ENV{MSYSTEM}
+     AND MINGW
+     AND NOT EXISTS "${PYTHON_LIBRARY}")
     if(PYTHON_MULTIARCH)
-        set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
+      set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
     else()
-        set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
-    endif()
-    #message(STATUS "Searching for Python libs in ${_PYTHON_LIBS_SEARCH}")
-    # Probably this needs to be more involved. It would be nice if the config
-    # information the python interpreter itself gave us were more complete.
-    find_library(PYTHON_LIBRARY
-        NAMES "python${PYTHON_LIBRARY_SUFFIX}"
-        PATHS ${_PYTHON_LIBS_SEARCH}
-        NO_DEFAULT_PATH)
-
-    # If all else fails, just set the name/version and let the linker figure out the path.
-    if(NOT PYTHON_LIBRARY)
-        set(PYTHON_LIBRARY python${PYTHON_LIBRARY_SUFFIX})
+      set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
     endif()
+    unset(PYTHON_LIBRARY)
+    find_library(
+      PYTHON_LIBRARY
+      NAMES "python${PYTHON_LIBRARY_SUFFIX}"
+      PATHS ${_PYTHON_LIBS_SEARCH}
+      NO_DEFAULT_PATH)
+  endif()
+
+  # raise an error if the python libs are still not found.
+  if(NOT EXISTS "${PYTHON_LIBRARY}")
+    message(FATAL_ERROR "Python libraries not found")
+  endif()
+
+else()
+  if(PYTHON_MULTIARCH)
+    set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
+  else()
+    set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
+  endif()
+  #message(STATUS "Searching for Python libs in ${_PYTHON_LIBS_SEARCH}")
+  # Probably this needs to be more involved. It would be nice if the config
+  # information the python interpreter itself gave us were more complete.
+  find_library(
+    PYTHON_LIBRARY
+    NAMES "python${PYTHON_LIBRARY_SUFFIX}"
+    PATHS ${_PYTHON_LIBS_SEARCH}
+    NO_DEFAULT_PATH)
+
+  # If all else fails, just set the name/version and let the linker figure out the path.
+  if(NOT PYTHON_LIBRARY)
+    set(PYTHON_LIBRARY python${PYTHON_LIBRARY_SUFFIX})
+  endif()
 endif()
 
-MARK_AS_ADVANCED(
-  PYTHON_LIBRARY
-  PYTHON_INCLUDE_DIR
-)
+mark_as_advanced(PYTHON_LIBRARY PYTHON_INCLUDE_DIR)
 
 # We use PYTHON_INCLUDE_DIR, PYTHON_LIBRARY and PYTHON_DEBUG_LIBRARY for the
 # cache entries because they are meant to specify the location of a single
 # library. We now set the variables listed by the documentation for this
 # module.
-SET(PYTHON_INCLUDE_DIRS "${PYTHON_INCLUDE_DIR}")
-SET(PYTHON_LIBRARIES "${PYTHON_LIBRARY}")
+set(PYTHON_INCLUDE_DIRS "${PYTHON_INCLUDE_DIR}")
+set(PYTHON_LIBRARIES "${PYTHON_LIBRARY}")
 if(NOT PYTHON_DEBUG_LIBRARY)
-    SET(PYTHON_DEBUG_LIBRARY "")
+  set(PYTHON_DEBUG_LIBRARY "")
 endif()
-SET(PYTHON_DEBUG_LIBRARIES "${PYTHON_DEBUG_LIBRARY}")
+set(PYTHON_DEBUG_LIBRARIES "${PYTHON_DEBUG_LIBRARY}")
 
-find_package_message(PYTHON
-    "Found PythonLibs: ${PYTHON_LIBRARY}"
-    "${PYTHON_EXECUTABLE}${PYTHON_VERSION_STRING}")
+find_package_message(PYTHON "Found PythonLibs: ${PYTHON_LIBRARY}"
+                     "${PYTHON_EXECUTABLE}${PYTHON_VERSION_STRING}")
 
 set(PYTHONLIBS_FOUND TRUE)
 set(PythonLibsNew_FOUND TRUE)
 
 if(NOT PYTHON_MODULE_PREFIX)
-    SET(PYTHON_MODULE_PREFIX "")
+  set(PYTHON_MODULE_PREFIX "")
 endif()
--- gtsam-4.1.0.orig/wrap/pybind11/tools/check-style.sh
+++ gtsam-4.1.0/wrap/pybind11/tools/check-style.sh
@@ -4,45 +4,19 @@
 #
 # This script currently checks for
 #
-# 1. use of tabs instead of spaces
-# 2. MSDOS-style CRLF endings
-# 3. trailing spaces
-# 4. missing space between keyword and parenthesis, e.g.: for(, if(, while(
-# 5. Missing space between right parenthesis and brace, e.g. 'for (...){'
-# 6. opening brace on its own line. It should always be on the same line as the
+# 1. missing space between keyword and parenthesis, e.g.: for(, if(, while(
+# 2. Missing space between right parenthesis and brace, e.g. 'for (...){'
+# 3. opening brace on its own line. It should always be on the same line as the
 #    if/while/for/do statement.
 #
-# Invoke as: tools/check-style.sh
+# Invoke as: tools/check-style.sh <filenames>
 #
 
 check_style_errors=0
 IFS=$'\n'
 
-found="$( GREP_COLORS='mt=41' GREP_COLOR='41' grep $'\t' include tests/*.{cpp,py,h} docs/*.rst -rn --color=always )"
-if [ -n "$found" ]; then
-    # The mt=41 sets a red background for matched tabs:
-    echo -e '\033[31;01mError: found tab characters in the following files:\033[0m'
-    check_style_errors=1
-    echo "$found" | sed -e 's/^/    /'
-fi
-
-
-found="$( grep -IUlr $'\r' include tests/*.{cpp,py,h} docs/*.rst --color=always )"
-if [ -n "$found" ]; then
-    echo -e '\033[31;01mError: found CRLF characters in the following files:\033[0m'
-    check_style_errors=1
-    echo "$found" | sed -e 's/^/    /'
-fi
-
-found="$(GREP_COLORS='mt=41' GREP_COLOR='41' grep '[[:blank:]]\+$' include tests/*.{cpp,py,h} docs/*.rst -rn --color=always )"
-if [ -n "$found" ]; then
-    # The mt=41 sets a red background for matched trailing spaces
-    echo -e '\033[31;01mError: found trailing spaces in the following files:\033[0m'
-    check_style_errors=1
-    echo "$found" | sed -e 's/^/    /'
-fi
 
-found="$(grep '\<\(if\|for\|while\|catch\)(\|){' include tests/*.{cpp,h} -rn --color=always)"
+found="$(grep '\<\(if\|for\|while\|catch\)(\|){' $@ -rn --color=always)"
 if [ -n "$found" ]; then
     echo -e '\033[31;01mError: found the following coding style problems:\033[0m'
     check_style_errors=1
@@ -60,7 +34,7 @@ last && /^\s*{/ {
     last=""
 }
 { last = /(if|for|while|catch|switch)\s*\(.*\)\s*$/ ? $0 : "" }
-' $(find include -type f) tests/*.{cpp,h} docs/*.rst)"
+' $(find include -type f) $@)"
 if [ -n "$found" ]; then
     check_style_errors=1
     echo -e '\033[31;01mError: braces should occur on the same line as the if/while/.. statement. Found issues in the following files:\033[0m'
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tools/cmake_uninstall.cmake.in
@@ -0,0 +1,23 @@
+# Source: https://gitlab.kitware.com/cmake/community/-/wikis/FAQ#can-i-do-make-uninstall-with-cmake
+
+if(NOT EXISTS "@CMAKE_BINARY_DIR@/install_manifest.txt")
+  message(FATAL_ERROR "Cannot find install manifest: @CMAKE_BINARY_DIR@/install_manifest.txt")
+endif()
+
+file(READ "@CMAKE_BINARY_DIR@/install_manifest.txt" files)
+string(REGEX REPLACE "\n" ";" files "${files}")
+foreach(file ${files})
+  message(STATUS "Uninstalling $ENV{DESTDIR}${file}")
+  if(IS_SYMLINK "$ENV{DESTDIR}${file}" OR EXISTS "$ENV{DESTDIR}${file}")
+    exec_program(
+      "@CMAKE_COMMAND@" ARGS
+      "-E remove \"$ENV{DESTDIR}${file}\""
+      OUTPUT_VARIABLE rm_out
+      RETURN_VALUE rm_retval)
+    if(NOT "${rm_retval}" STREQUAL 0)
+      message(FATAL_ERROR "Problem when removing $ENV{DESTDIR}${file}")
+    endif()
+  else(IS_SYMLINK "$ENV{DESTDIR}${file}" OR EXISTS "$ENV{DESTDIR}${file}")
+    message(STATUS "File $ENV{DESTDIR}${file} does not exist.")
+  endif()
+endforeach()
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tools/pybind11Common.cmake
@@ -0,0 +1,314 @@
+#[======================================================[.rst
+
+Adds the following targets::
+
+    pybind11::pybind11 - link to headers and pybind11
+    pybind11::module - Adds module links
+    pybind11::embed - Adds embed links
+    pybind11::lto - Link time optimizations (manual selection)
+    pybind11::thin_lto - Link time optimizations (manual selection)
+    pybind11::python_link_helper - Adds link to Python libraries
+    pybind11::python2_no_register - Avoid warning/error with Python 2 + C++14/7
+    pybind11::windows_extras - MSVC bigobj and mp for building multithreaded
+    pybind11::opt_size - avoid optimizations that increase code size
+
+Adds the following functions::
+
+    pybind11_strip(target) - strip target after building on linux/macOS
+
+
+#]======================================================]
+
+# CMake 3.10 has an include_guard command, but we can't use that yet
+if(TARGET pybind11::lto)
+  return()
+endif()
+
+# If we are in subdirectory mode, all IMPORTED targets must be GLOBAL. If we
+# are in CONFIG mode, they should be "normal" targets instead.
+# In CMake 3.11+ you can promote a target to global after you create it,
+# which might be simpler than this check.
+get_property(
+  is_config
+  TARGET pybind11::headers
+  PROPERTY IMPORTED)
+if(NOT is_config)
+  set(optional_global GLOBAL)
+endif()
+
+# --------------------- Shared targets ----------------------------
+
+# Build an interface library target:
+add_library(pybind11::pybind11 IMPORTED INTERFACE ${optional_global})
+set_property(
+  TARGET pybind11::pybind11
+  APPEND
+  PROPERTY INTERFACE_LINK_LIBRARIES pybind11::headers)
+
+# Build a module target:
+add_library(pybind11::module IMPORTED INTERFACE ${optional_global})
+set_property(
+  TARGET pybind11::module
+  APPEND
+  PROPERTY INTERFACE_LINK_LIBRARIES pybind11::pybind11)
+
+# Build an embed library target:
+add_library(pybind11::embed IMPORTED INTERFACE ${optional_global})
+set_property(
+  TARGET pybind11::embed
+  APPEND
+  PROPERTY INTERFACE_LINK_LIBRARIES pybind11::pybind11)
+
+# ----------------------- no register ----------------------
+
+# Workaround for Python 2.7 and C++17 (C++14 as a warning) incompatibility
+# This adds the flags -Wno-register and -Wno-deprecated-register if the compiler
+# is Clang 3.9+ or AppleClang and the compile language is CXX, or /wd5033 for MSVC (all languages,
+# since MSVC didn't recognize COMPILE_LANGUAGE until CMake 3.11+).
+
+add_library(pybind11::python2_no_register INTERFACE IMPORTED ${optional_global})
+set(clang_4plus
+    "$<AND:$<CXX_COMPILER_ID:Clang>,$<NOT:$<VERSION_LESS:$<CXX_COMPILER_VERSION>,3.9>>>")
+set(no_register "$<OR:${clang_4plus},$<CXX_COMPILER_ID:AppleClang>>")
+
+if(MSVC AND CMAKE_VERSION VERSION_LESS 3.11)
+  set(cxx_no_register "${no_register}")
+else()
+  set(cxx_no_register "$<AND:$<COMPILE_LANGUAGE:CXX>,${no_register}>")
+endif()
+
+set(msvc "$<CXX_COMPILER_ID:MSVC>")
+
+set_property(
+  TARGET pybind11::python2_no_register
+  PROPERTY INTERFACE_COMPILE_OPTIONS
+           "$<${cxx_no_register}:-Wno-register;-Wno-deprecated-register>" "$<${msvc}:/wd5033>")
+
+# --------------------------- link helper ---------------------------
+
+add_library(pybind11::python_link_helper IMPORTED INTERFACE ${optional_global})
+
+if(CMAKE_VERSION VERSION_LESS 3.13)
+  # In CMake 3.11+, you can set INTERFACE properties via the normal methods, and
+  # this would be simpler.
+  set_property(
+    TARGET pybind11::python_link_helper
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES "$<$<PLATFORM_ID:Darwin>:-undefined dynamic_lookup>")
+else()
+  # link_options was added in 3.13+
+  # This is safer, because you are ensured the deduplication pass in CMake will not consider
+  # these separate and remove one but not the other.
+  set_property(
+    TARGET pybind11::python_link_helper
+    APPEND
+    PROPERTY INTERFACE_LINK_OPTIONS "$<$<PLATFORM_ID:Darwin>:LINKER:-undefined,dynamic_lookup>")
+endif()
+
+# ------------------------ Windows extras -------------------------
+
+add_library(pybind11::windows_extras IMPORTED INTERFACE ${optional_global})
+
+if(MSVC)
+  # /MP enables multithreaded builds (relevant when there are many files), /bigobj is
+  # needed for bigger binding projects due to the limit to 64k addressable sections
+  set_property(
+    TARGET pybind11::windows_extras
+    APPEND
+    PROPERTY INTERFACE_COMPILE_OPTIONS /bigobj)
+
+  if(CMAKE_VERSION VERSION_LESS 3.11)
+    set_property(
+      TARGET pybind11::windows_extras
+      APPEND
+      PROPERTY INTERFACE_COMPILE_OPTIONS $<$<NOT:$<CONFIG:Debug>>:/MP>)
+  else()
+    # Only set these options for C++ files.  This is important so that, for
+    # instance, projects that include other types of source files like CUDA
+    # .cu files don't get these options propagated to nvcc since that would
+    # cause the build to fail.
+    set_property(
+      TARGET pybind11::windows_extras
+      APPEND
+      PROPERTY INTERFACE_COMPILE_OPTIONS $<$<NOT:$<CONFIG:Debug>>:$<$<COMPILE_LANGUAGE:CXX>:/MP>>)
+  endif()
+endif()
+
+# ----------------------- Optimize binary size --------------------------
+
+add_library(pybind11::opt_size IMPORTED INTERFACE ${optional_global})
+
+if(MSVC)
+  set(PYBIND11_OPT_SIZE /Os)
+else()
+  set(PYBIND11_OPT_SIZE -Os)
+endif()
+
+set_property(
+  TARGET pybind11::opt_size
+  APPEND
+  PROPERTY INTERFACE_COMPILE_OPTIONS $<$<CONFIG:Release>:${PYBIND11_OPT_SIZE}>
+           $<$<CONFIG:MinSizeRel>:${PYBIND11_OPT_SIZE}>
+           $<$<CONFIG:RelWithDebInfo>:${PYBIND11_OPT_SIZE}>)
+
+# ----------------------- Legacy option --------------------------
+
+# Warn or error if old variable name used
+if(PYBIND11_CPP_STANDARD)
+  string(REGEX MATCH [[..$]] VAL "${PYBIND11_CPP_STANDARD}")
+  if(CMAKE_CXX_STANDARD)
+    if(NOT CMAKE_CXX_STANDARD STREQUAL VAL)
+      message(WARNING "CMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} does not match "
+                      "PYBIND11_CPP_STANDARD=${PYBIND11_CPP_STANDARD}, "
+                      "please remove PYBIND11_CPP_STANDARD from your cache")
+    endif()
+  else()
+    set(supported_standards 11 14 17 20)
+    if("${VAL}" IN_LIST supported_standards)
+      message(WARNING "USE -DCMAKE_CXX_STANDARD=${VAL} instead of PYBIND11_CPP_STANDARD")
+      set(CMAKE_CXX_STANDARD
+          ${VAL}
+          CACHE STRING "From PYBIND11_CPP_STANDARD")
+    else()
+      message(FATAL_ERROR "PYBIND11_CPP_STANDARD should be replaced with CMAKE_CXX_STANDARD "
+                          "(last two chars: ${VAL} not understood as a valid CXX std)")
+    endif()
+  endif()
+endif()
+
+# --------------------- Python specifics -------------------------
+
+# Check to see which Python mode we are in, new, old, or no python
+if(PYBIND11_NOPYTHON)
+  set(_pybind11_nopython ON)
+elseif(
+  PYBIND11_FINDPYTHON
+  OR Python_FOUND
+  OR Python2_FOUND
+  OR Python3_FOUND)
+  # New mode
+  include("${CMAKE_CURRENT_LIST_DIR}/pybind11NewTools.cmake")
+
+else()
+
+  # Classic mode
+  include("${CMAKE_CURRENT_LIST_DIR}/pybind11Tools.cmake")
+
+endif()
+
+# --------------------- LTO -------------------------------
+
+include(CheckCXXCompilerFlag)
+
+# Checks whether the given CXX/linker flags can compile and link a cxx file.
+# cxxflags and linkerflags are lists of flags to use.  The result variable is a
+# unique variable name for each set of flags: the compilation result will be
+# cached base on the result variable.  If the flags work, sets them in
+# cxxflags_out/linkerflags_out internal cache variables (in addition to
+# ${result}).
+function(_pybind11_return_if_cxx_and_linker_flags_work result cxxflags linkerflags cxxflags_out
+         linkerflags_out)
+  set(CMAKE_REQUIRED_LIBRARIES ${linkerflags})
+  check_cxx_compiler_flag("${cxxflags}" ${result})
+  if(${result})
+    set(${cxxflags_out}
+        "${cxxflags}"
+        PARENT_SCOPE)
+    set(${linkerflags_out}
+        "${linkerflags}"
+        PARENT_SCOPE)
+  endif()
+endfunction()
+
+function(_pybind11_generate_lto target prefer_thin_lto)
+  if(CMAKE_CXX_COMPILER_ID MATCHES "GNU|Clang")
+    set(cxx_append "")
+    set(linker_append "")
+    if(CMAKE_CXX_COMPILER_ID MATCHES "Clang" AND NOT APPLE)
+      # Clang Gold plugin does not support -Os; append -O3 to MinSizeRel builds to override it
+      set(linker_append ";$<$<CONFIG:MinSizeRel>:-O3>")
+    elseif(CMAKE_CXX_COMPILER_ID MATCHES "GNU")
+      set(cxx_append ";-fno-fat-lto-objects")
+    endif()
+
+    if(CMAKE_CXX_COMPILER_ID MATCHES "Clang" AND prefer_thin_lto)
+      _pybind11_return_if_cxx_and_linker_flags_work(
+        HAS_FLTO_THIN "-flto=thin${cxx_append}" "-flto=thin${linker_append}"
+        PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
+    endif()
+
+    if(NOT HAS_FLTO_THIN)
+      _pybind11_return_if_cxx_and_linker_flags_work(
+        HAS_FLTO "-flto${cxx_append}" "-flto${linker_append}" PYBIND11_LTO_CXX_FLAGS
+        PYBIND11_LTO_LINKER_FLAGS)
+    endif()
+  elseif(CMAKE_CXX_COMPILER_ID MATCHES "Intel")
+    # Intel equivalent to LTO is called IPO
+    _pybind11_return_if_cxx_and_linker_flags_work(HAS_INTEL_IPO "-ipo" "-ipo"
+                                                  PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
+  elseif(MSVC)
+    # cmake only interprets libraries as linker flags when they start with a - (otherwise it
+    # converts /LTCG to \LTCG as if it was a Windows path).  Luckily MSVC supports passing flags
+    # with - instead of /, even if it is a bit non-standard:
+    _pybind11_return_if_cxx_and_linker_flags_work(HAS_MSVC_GL_LTCG "/GL" "-LTCG"
+                                                  PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
+  endif()
+
+  # Enable LTO flags if found, except for Debug builds
+  if(PYBIND11_LTO_CXX_FLAGS)
+    set(not_debug "$<NOT:$<CONFIG:Debug>>")
+    set(cxx_lang "$<COMPILE_LANGUAGE:CXX>")
+    if(MSVC AND CMAKE_VERSION VERSION_LESS 3.11)
+      set(genex "${not_debug}")
+    else()
+      set(genex "$<AND:${not_debug},${cxx_lang}>")
+    endif()
+    set_property(
+      TARGET ${target}
+      APPEND
+      PROPERTY INTERFACE_COMPILE_OPTIONS "$<${genex}:${PYBIND11_LTO_CXX_FLAGS}>")
+    if(CMAKE_PROJECT_NAME STREQUAL "pybind11")
+      message(STATUS "${target} enabled")
+    endif()
+  else()
+    if(CMAKE_PROJECT_NAME STREQUAL "pybind11")
+      message(STATUS "${target} disabled (not supported by the compiler and/or linker)")
+    endif()
+  endif()
+
+  if(PYBIND11_LTO_LINKER_FLAGS)
+    if(CMAKE_VERSION VERSION_LESS 3.11)
+      set_property(
+        TARGET ${target}
+        APPEND
+        PROPERTY INTERFACE_LINK_LIBRARIES "$<${not_debug}:${PYBIND11_LTO_LINKER_FLAGS}>")
+    else()
+      set_property(
+        TARGET ${target}
+        APPEND
+        PROPERTY INTERFACE_LINK_OPTIONS "$<${not_debug}:${PYBIND11_LTO_LINKER_FLAGS}>")
+    endif()
+  endif()
+endfunction()
+
+add_library(pybind11::lto IMPORTED INTERFACE ${optional_global})
+_pybind11_generate_lto(pybind11::lto FALSE)
+
+add_library(pybind11::thin_lto IMPORTED INTERFACE ${optional_global})
+_pybind11_generate_lto(pybind11::thin_lto TRUE)
+
+# ---------------------- pybind11_strip -----------------------------
+
+function(pybind11_strip target_name)
+  # Strip unnecessary sections of the binary on Linux/macOS
+  if(CMAKE_STRIP)
+    if(APPLE)
+      set(x_opt -x)
+    endif()
+
+    add_custom_command(
+      TARGET ${target_name}
+      POST_BUILD
+      COMMAND ${CMAKE_STRIP} ${x_opt} $<TARGET_FILE:${target_name}>)
+  endif()
+endfunction()
--- gtsam-4.1.0.orig/wrap/pybind11/tools/pybind11Config.cmake.in
+++ gtsam-4.1.0/wrap/pybind11/tools/pybind11Config.cmake.in
@@ -1,104 +1,145 @@
-# pybind11Config.cmake
-# --------------------
-#
-# PYBIND11 cmake module.
-# This module sets the following variables in your project::
-#
-#   pybind11_FOUND - true if pybind11 and all required components found on the system
-#   pybind11_VERSION - pybind11 version in format Major.Minor.Release
-#   pybind11_INCLUDE_DIRS - Directories where pybind11 and python headers are located.
-#   pybind11_INCLUDE_DIR - Directory where pybind11 headers are located.
-#   pybind11_DEFINITIONS - Definitions necessary to use pybind11, namely USING_pybind11.
-#   pybind11_LIBRARIES - compile flags and python libraries (as needed) to link against.
-#   pybind11_LIBRARY - empty.
-#   CMAKE_MODULE_PATH - appends location of accompanying FindPythonLibsNew.cmake and
-#                       pybind11Tools.cmake modules.
-#
-#
-# Available components: None
-#
-#
-# Exported targets::
-#
-# If pybind11 is found, this module defines the following :prop_tgt:`IMPORTED`
-# interface library targets::
-#
-#   pybind11::module - for extension modules
-#   pybind11::embed - for embedding the Python interpreter
-#
-# Python headers, libraries (as needed by platform), and the C++ standard
-# are attached to the target. Set PythonLibsNew variables to influence
-# python detection and CMAKE_CXX_STANDARD (11 or 14) to influence standard
-# setting. ::
-#
-#   find_package(pybind11 CONFIG REQUIRED)
-#   message(STATUS "Found pybind11 v${pybind11_VERSION}: ${pybind11_INCLUDE_DIRS}")
-#
-#   # Create an extension module
-#   add_library(mylib MODULE main.cpp)
-#   target_link_libraries(mylib pybind11::module)
-#
-#   # Or embed the Python interpreter into an executable
-#   add_executable(myexe main.cpp)
-#   target_link_libraries(myexe pybind11::embed)
-#
-# Suggested usage::
-#
-# find_package with version info is not recommended except for release versions. ::
-#
-#   find_package(pybind11 CONFIG)
-#   find_package(pybind11 2.0 EXACT CONFIG REQUIRED)
-#
-#
-# The following variables can be set to guide the search for this package::
-#
-#   pybind11_DIR - CMake variable, set to directory containing this Config file
-#   CMAKE_PREFIX_PATH - CMake variable, set to root directory of this package
-#   PATH - environment variable, set to bin directory of this package
-#   CMAKE_DISABLE_FIND_PACKAGE_pybind11 - CMake variable, disables
-#     find_package(pybind11) when not REQUIRED, perhaps to force internal build
+#[=============================================================================[.rst
 
-@PACKAGE_INIT@
+pybind11Config.cmake
+--------------------
+
+PYBIND11 cmake module.
+This module sets the following variables in your project::
+
+  pybind11_FOUND - true if pybind11 and all required components found on the system
+  pybind11_VERSION - pybind11 version in format Major.Minor.Release
+  pybind11_VERSION_TYPE - pybind11 version type (dev, release)
+  pybind11_INCLUDE_DIRS - Directories where pybind11 and python headers are located.
+  pybind11_INCLUDE_DIR - Directory where pybind11 headers are located.
+  pybind11_DEFINITIONS - Definitions necessary to use pybind11, namely USING_pybind11.
+  pybind11_LIBRARIES - compile flags and python libraries (as needed) to link against.
+  pybind11_LIBRARY - empty.
+
+
+Available components: None
+
+
+Exported targets::
+
+If pybind11 is found, this module defines the following :prop_tgt:`IMPORTED`
+interface library targets::
+
+  pybind11::module - for extension modules
+  pybind11::embed - for embedding the Python interpreter
+
+Python headers, libraries (as needed by platform), and the C++ standard
+are attached to the target.
+
+Advanced targets are also supplied - these are primary for users building
+complex applications, and they are available in all modes::
+
+  pybind11::headers - Just the pybind11 headers and minimum compile requirements
+  pybind11::pybind11 - Python headers too
+  pybind11::python_link_helper - Just the "linking" part of pybind11:module, for CMake < 3.15
+  pybind11::python2_no_register - Quiets the warning/error when mixing C++14+ and Python 2, also included in pybind11::module
+  pybind11::thin_lto - An alternative to INTERPROCEDURAL_OPTIMIZATION
+  pybind11::lto - An alternative to INTERPROCEDURAL_OPTIMIZATION (also avoids thin LTO on clang)
+  pybind11::windows_extras - Adds bigobj and mp for MSVC
+
+Modes::
+
+There are two modes provided; classic, which is built on the old Python
+discovery packages in CMake, or the new FindPython mode, which uses FindPython
+from 3.12+ forward (3.15+ _highly_ recommended).
+
+New FindPython mode::
+
+To activate this mode, either call ``find_package(Python COMPONENTS Interpreter Development)``
+before finding this package, or set the ``PYBIND11_FINDPYTHON`` variable to ON. In this mode,
+you can either use the basic targets, or use the FindPython tools::
+
+  find_package(Python COMPONENTS Interpreter Development)
+  find_package(pybind11 CONFIG)
+
+  # pybind11 method:
+  pybind11_add_module(MyModule1 src1.cpp)
 
-set(PN pybind11)
+  # Python method:
+  Python_add_library(MyModule2 src2.cpp)
+  target_link_libraries(MyModule2 pybind11::headers)
+  set_target_properties(MyModule2 PROPERTIES
+                                  INTERPROCEDURAL_OPTIMIZATION ON
+                                  CXX__VISIBILITY_PRESET ON
+                                  VISIBLITY_INLINES_HIDDEN ON)
 
-# location of pybind11/pybind11.h
-set(${PN}_INCLUDE_DIR "${PACKAGE_PREFIX_DIR}/@CMAKE_INSTALL_INCLUDEDIR@")
+If you build targets yourself, you may be interested in stripping the output
+for reduced size; this is the one other feature that the helper function gives you.
 
-set(${PN}_LIBRARY "")
-set(${PN}_DEFINITIONS USING_${PN})
+Classic mode::
 
-check_required_components(${PN})
-
-# make detectable the FindPythonLibsNew.cmake module
-list(APPEND CMAKE_MODULE_PATH ${CMAKE_CURRENT_LIST_DIR})
-
-include(pybind11Tools)
-
-if(NOT (CMAKE_VERSION VERSION_LESS 3.0))
-#-----------------------------------------------------------------------------
-# Don't include targets if this file is being picked up by another
-# project which has already built this as a subproject
-#-----------------------------------------------------------------------------
-if(NOT TARGET ${PN}::pybind11)
-    include("${CMAKE_CURRENT_LIST_DIR}/${PN}Targets.cmake")
-
-    find_package(PythonLibsNew ${PYBIND11_PYTHON_VERSION} MODULE REQUIRED)
-    set_property(TARGET ${PN}::pybind11 APPEND PROPERTY INTERFACE_INCLUDE_DIRECTORIES ${PYTHON_INCLUDE_DIRS})
-    set_property(TARGET ${PN}::embed APPEND PROPERTY INTERFACE_LINK_LIBRARIES ${PYTHON_LIBRARIES})
-    if(WIN32 OR CYGWIN)
-      set_property(TARGET ${PN}::module APPEND PROPERTY INTERFACE_LINK_LIBRARIES ${PYTHON_LIBRARIES})
-    endif()
-
-    if(CMAKE_VERSION VERSION_LESS 3.3)
-      set_property(TARGET ${PN}::pybind11 APPEND PROPERTY INTERFACE_COMPILE_OPTIONS "${PYBIND11_CPP_STANDARD}")
-    else()
-      set_property(TARGET ${PN}::pybind11 APPEND PROPERTY INTERFACE_COMPILE_OPTIONS $<$<COMPILE_LANGUAGE:CXX>:${PYBIND11_CPP_STANDARD}>)
-    endif()
-
-    get_property(_iid TARGET ${PN}::pybind11 PROPERTY INTERFACE_INCLUDE_DIRECTORIES)
-    get_property(_ill TARGET ${PN}::module PROPERTY INTERFACE_LINK_LIBRARIES)
-    set(${PN}_INCLUDE_DIRS ${_iid})
-    set(${PN}_LIBRARIES ${_ico} ${_ill})
+Set PythonLibsNew variables to influence python detection and
+CMAKE_CXX_STANDARD to influence standard setting. ::
+
+  find_package(pybind11 CONFIG REQUIRED)
+
+  # Create an extension module
+  add_library(mylib MODULE main.cpp)
+  target_link_libraries(mylib PUBLIC pybind11::module)
+
+  # Or embed the Python interpreter into an executable
+  add_executable(myexe main.cpp)
+  target_link_libraries(myexe PUBLIC pybind11::embed)
+
+Suggested usage::
+
+find_package with version info is not recommended except for release versions. ::
+
+  find_package(pybind11 CONFIG)
+  find_package(pybind11 2.0 EXACT CONFIG REQUIRED)
+
+
+The following variables can be set to guide the search for this package::
+
+  pybind11_DIR - CMake variable, set to directory containing this Config file
+  CMAKE_PREFIX_PATH - CMake variable, set to root directory of this package
+  PATH - environment variable, set to bin directory of this package
+  CMAKE_DISABLE_FIND_PACKAGE_pybind11 - CMake variable, disables
+    find_package(pybind11) when not REQUIRED, perhaps to force internal build
+
+Helper functions::
+
+  pybind11_add_module(...) - Add a library and setup all helpers
+  pybind11_strip(target) - Strip a target after building it (linux/macOS)
+  pybind11_extension(target) - Injects the Python extension name
+
+See ``pybind11Tools.cmake`` or ``pybind11NewTools.cmake`` for details on
+``pybind11_add_module``.
+
+#]=============================================================================]
+@PACKAGE_INIT@
+
+# Location of pybind11/pybind11.h
+set(pybind11_INCLUDE_DIR "${PACKAGE_PREFIX_DIR}/@CMAKE_INSTALL_INCLUDEDIR@")
+
+set(pybind11_LIBRARY "")
+set(pybind11_DEFINITIONS USING_pybind11)
+set(pybind11_VERSION_TYPE "@pybind11_VERSION_TYPE@")
+
+check_required_components(pybind11)
+
+if(TARGET pybind11::python_link_helper)
+  # This has already been setup elsewhere, such as with a previous call or
+  # add_subdirectory
+  return()
 endif()
+
+include("${CMAKE_CURRENT_LIST_DIR}/pybind11Targets.cmake")
+
+# Easier to use / remember
+add_library(pybind11::headers IMPORTED INTERFACE)
+set_target_properties(pybind11::headers PROPERTIES INTERFACE_LINK_LIBRARIES
+                                                   pybind11::pybind11_headers)
+
+include("${CMAKE_CURRENT_LIST_DIR}/pybind11Common.cmake")
+
+if(NOT pybind11_FIND_QUIETLY)
+  message(
+    STATUS
+      "Found pybind11: ${pybind11_INCLUDE_DIR} (found version \"${pybind11_VERSION}\" ${pybind11_VERSION_TYPE})"
+  )
 endif()
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tools/pybind11NewTools.cmake
@@ -0,0 +1,217 @@
+# tools/pybind11NewTools.cmake -- Build system for the pybind11 modules
+#
+# Copyright (c) 2020 Wenzel Jakob <wenzel@inf.ethz.ch> and Henry Schreiner
+#
+# All rights reserved. Use of this source code is governed by a
+# BSD-style license that can be found in the LICENSE file.
+
+get_property(
+  is_config
+  TARGET pybind11::headers
+  PROPERTY IMPORTED)
+
+if(pybind11_FIND_QUIETLY)
+  set(_pybind11_quiet QUIET)
+endif()
+
+if(CMAKE_VERSION VERSION_LESS 3.12)
+  message(FATAL_ERROR "You cannot use the new FindPython module with CMake < 3.12")
+endif()
+
+if(NOT Python_FOUND
+   AND NOT Python3_FOUND
+   AND NOT Python2_FOUND)
+  if(NOT DEFINED Python_FIND_IMPLEMENTATIONS)
+    set(Python_FIND_IMPLEMENTATIONS CPython PyPy)
+  endif()
+
+  # GitHub Actions like activation
+  if(NOT DEFINED Python_ROOT_DIR AND DEFINED ENV{pythonLocation})
+    set(Python_ROOT_DIR "$ENV{pythonLocation}")
+  endif()
+
+  find_package(Python REQUIRED COMPONENTS Interpreter Development ${_pybind11_quiet})
+
+  # If we are in submodule mode, export the Python targets to global targets.
+  # If this behavior is not desired, FindPython _before_ pybind11.
+  if(NOT is_config)
+    set_property(TARGET Python::Python PROPERTY IMPORTED_GLOBAL TRUE)
+    set_property(TARGET Python::Interpreter PROPERTY IMPORTED_GLOBAL TRUE)
+    if(TARGET Python::Module)
+      set_property(TARGET Python::Module PROPERTY IMPORTED_GLOBAL TRUE)
+    endif()
+  endif()
+endif()
+
+if(Python_FOUND)
+  set(_Python
+      Python
+      CACHE INTERNAL "" FORCE)
+elseif(Python3_FOUND AND NOT Python2_FOUND)
+  set(_Python
+      Python3
+      CACHE INTERNAL "" FORCE)
+elseif(Python2_FOUND AND NOT Python3_FOUND)
+  set(_Python
+      Python2
+      CACHE INTERNAL "" FORCE)
+else()
+  message(AUTHOR_WARNING "Python2 and Python3 both present, pybind11 in "
+                         "PYBIND11_NOPYTHON mode (manually activate to silence warning)")
+  set(_pybind11_nopython ON)
+  return()
+endif()
+
+if(PYBIND11_MASTER_PROJECT)
+  if(${_Python}_INTERPRETER_ID MATCHES "PyPy")
+    message(STATUS "PyPy ${${_Python}_PyPy_VERSION} (Py ${${_Python}_VERSION})")
+  else()
+    message(STATUS "${_Python} ${${_Python}_VERSION}")
+  endif()
+endif()
+
+# Debug check - see https://stackoverflow.com/questions/646518/python-how-to-detect-debug-Interpreter
+execute_process(
+  COMMAND "${${_Python}_EXECUTABLE}" "-c" "import sys; sys.exit(hasattr(sys, 'gettotalrefcount'))"
+  RESULT_VARIABLE PYTHON_IS_DEBUG)
+
+# Get the suffix - SO is deprecated, should use EXT_SUFFIX, but this is
+# required for PyPy3 (as of 7.3.1)
+execute_process(
+  COMMAND "${${_Python}_EXECUTABLE}" "-c"
+          "from distutils import sysconfig; print(sysconfig.get_config_var('SO'))"
+  OUTPUT_VARIABLE _PYTHON_MODULE_EXTENSION
+  ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE)
+
+# This needs to be available for the pybind11_extension function
+set(PYTHON_MODULE_EXTENSION
+    "${_PYTHON_MODULE_EXTENSION}"
+    CACHE INTERNAL "")
+
+# Python debug libraries expose slightly different objects before 3.8
+# https://docs.python.org/3.6/c-api/intro.html#debugging-builds
+# https://stackoverflow.com/questions/39161202/how-to-work-around-missing-pymodule-create2-in-amd64-win-python35-d-lib
+if(PYTHON_IS_DEBUG)
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_COMPILE_DEFINITIONS Py_DEBUG)
+endif()
+
+# Check on every access - since Python2 and Python3 could have been used - do nothing in that case.
+
+if(DEFINED ${_Python}_INCLUDE_DIRS)
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_INCLUDE_DIRECTORIES $<BUILD_INTERFACE:${${_Python}_INCLUDE_DIRS}>)
+endif()
+
+if(DEFINED ${_Python}_VERSION AND ${_Python}_VERSION VERSION_LESS 3)
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES pybind11::python2_no_register)
+endif()
+
+# In CMake 3.18+, you can find these separately, so include an if
+if(TARGET ${_Python}::${_Python})
+  set_property(
+    TARGET pybind11::embed
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES ${_Python}::${_Python})
+endif()
+
+# CMake 3.15+ has this
+if(TARGET ${_Python}::Module)
+  set_property(
+    TARGET pybind11::module
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES ${_Python}::Module)
+else()
+  set_property(
+    TARGET pybind11::module
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES pybind11::python_link_helper)
+endif()
+
+# WITHOUT_SOABI and WITH_SOABI will disable the custom extension handling used by pybind11.
+# WITH_SOABI is passed on to python_add_library.
+function(pybind11_add_module target_name)
+  cmake_parse_arguments(PARSE_ARGV 1 ARG
+                        "STATIC;SHARED;MODULE;THIN_LTO;OPT_SIZE;NO_EXTRAS;WITHOUT_SOABI" "" "")
+
+  if(ARG_ADD_LIBRARY_STATIC)
+    set(type STATIC)
+  elseif(ARG_ADD_LIBRARY_SHARED)
+    set(type SHARED)
+  else()
+    set(type MODULE)
+  endif()
+
+  if("${_Python}" STREQUAL "Python")
+    python_add_library(${target_name} ${type} ${ARG_UNPARSED_ARGUMENTS})
+  elseif("${_Python}" STREQUAL "Python3")
+    python3_add_library(${target_name} ${type} ${ARG_UNPARSED_ARGUMENTS})
+  elseif("${_Python}" STREQUAL "Python2")
+    python2_add_library(${target_name} ${type} ${ARG_UNPARSED_ARGUMENTS})
+  else()
+    message(FATAL_ERROR "Cannot detect FindPython version: ${_Python}")
+  endif()
+
+  target_link_libraries(${target_name} PRIVATE pybind11::headers)
+
+  if(type STREQUAL "MODULE")
+    target_link_libraries(${target_name} PRIVATE pybind11::module)
+  else()
+    target_link_libraries(${target_name} PRIVATE pybind11::embed)
+  endif()
+
+  if(MSVC)
+    target_link_libraries(${target_name} PRIVATE pybind11::windows_extras)
+  endif()
+
+  if(DEFINED ${_Python}_VERSION AND ${_Python}_VERSION VERSION_LESS 3)
+    target_link_libraries(${target_name} PRIVATE pybind11::python2_no_register)
+  endif()
+
+  set_target_properties(${target_name} PROPERTIES CXX_VISIBILITY_PRESET "hidden"
+                                                  CUDA_VISIBILITY_PRESET "hidden")
+
+  # If we don't pass a WITH_SOABI or WITHOUT_SOABI, use our own default handling of extensions
+  if("${type}" STREQUAL "MODULE" AND (NOT ARG_WITHOUT_SOABI OR NOT "WITH_SOABI" IN_LIST
+                                                               ARG_UNPARSED_ARGUMENTS))
+    pybind11_extension(${target_name})
+  endif()
+
+  if(ARG_NO_EXTRAS)
+    return()
+  endif()
+
+  if(NOT DEFINED CMAKE_INTERPROCEDURAL_OPTIMIZATION)
+    if(ARG_THIN_LTO)
+      target_link_libraries(${target_name} PRIVATE pybind11::thin_lto)
+    else()
+      target_link_libraries(${target_name} PRIVATE pybind11::lto)
+    endif()
+  endif()
+
+  if(NOT MSVC AND NOT ${CMAKE_BUILD_TYPE} MATCHES Debug|RelWithDebInfo)
+    # Strip unnecessary sections of the binary on Linux/macOS
+    pybind11_strip(${target_name})
+  endif()
+
+  if(MSVC)
+    target_link_libraries(${target_name} PRIVATE pybind11::windows_extras)
+  endif()
+
+  if(ARG_OPT_SIZE)
+    target_link_libraries(${target_name} PRIVATE pybind11::opt_size)
+  endif()
+endfunction()
+
+function(pybind11_extension name)
+  # The extension is precomputed
+  set_target_properties(${name} PROPERTIES PREFIX "" SUFFIX "${PYTHON_MODULE_EXTENSION}")
+
+endfunction()
--- gtsam-4.1.0.orig/wrap/pybind11/tools/pybind11Tools.cmake
+++ gtsam-4.1.0/wrap/pybind11/tools/pybind11Tools.cmake
@@ -1,135 +1,133 @@
 # tools/pybind11Tools.cmake -- Build system for the pybind11 modules
 #
-# Copyright (c) 2015 Wenzel Jakob <wenzel@inf.ethz.ch>
+# Copyright (c) 2020 Wenzel Jakob <wenzel.jakob@epfl.ch>
 #
 # All rights reserved. Use of this source code is governed by a
 # BSD-style license that can be found in the LICENSE file.
 
-cmake_minimum_required(VERSION 2.8.12)
+# Built-in in CMake 3.5+
+include(CMakeParseArguments)
 
-# Add a CMake parameter for choosing a desired Python version
-if(NOT PYBIND11_PYTHON_VERSION)
-  set(PYBIND11_PYTHON_VERSION "" CACHE STRING "Python version to use for compiling modules")
+if(pybind11_FIND_QUIETLY)
+  set(_pybind11_quiet QUIET)
 endif()
 
-set(Python_ADDITIONAL_VERSIONS 3.9 3.8 3.7 3.6 3.5 3.4)
-find_package(PythonLibsNew ${PYBIND11_PYTHON_VERSION} REQUIRED)
-
-include(CheckCXXCompilerFlag)
-include(CMakeParseArguments)
-
-# Use the language standards abstraction if CMake supports it with the current compiler
-if(NOT CMAKE_VERSION VERSION_LESS 3.1)
-  if(NOT CMAKE_CXX_STANDARD)
-    if(CMAKE_CXX14_STANDARD_COMPILE_OPTION)
-      set(CMAKE_CXX_STANDARD 14)
-    elseif(CMAKE_CXX11_STANDARD_COMPILE_OPTION)
-      set(CMAKE_CXX_STANDARD 11)
-    endif()
-  endif()
-  if(CMAKE_CXX_STANDARD)
-    set(CMAKE_CXX_EXTENSIONS OFF)
-    set(CMAKE_CXX_STANDARD_REQUIRED ON)
-  endif()
+# If this is the first run, PYTHON_VERSION can stand in for PYBIND11_PYTHON_VERSION
+if(NOT DEFINED PYBIND11_PYTHON_VERSION AND DEFINED PYTHON_VERSION)
+  message(WARNING "Set PYBIND11_PYTHON_VERSION to search for a specific version, not "
+                  "PYTHON_VERSION (which is an output). Assuming that is what you "
+                  "meant to do and continuing anyway.")
+  set(PYBIND11_PYTHON_VERSION
+      "${PYTHON_VERSION}"
+      CACHE STRING "Python version to use for compiling modules")
+  unset(PYTHON_VERSION)
+  unset(PYTHON_VERSION CACHE)
+else()
+  # If this is set as a normal variable, promote it, otherwise, make an empty cache variable.
+  set(PYBIND11_PYTHON_VERSION
+      "${PYBIND11_PYTHON_VERSION}"
+      CACHE STRING "Python version to use for compiling modules")
 endif()
 
-# Fall back to heuristics
-if(NOT PYBIND11_CPP_STANDARD AND NOT CMAKE_CXX_STANDARD)
-  if(MSVC)
-    set(PYBIND11_CPP_STANDARD /std:c++14)
-  else()
-    check_cxx_compiler_flag("-std=c++14" HAS_CPP14_FLAG)
-    if(HAS_CPP14_FLAG)
-      set(PYBIND11_CPP_STANDARD -std=c++14)
-    else()
-      check_cxx_compiler_flag("-std=c++11" HAS_CPP11_FLAG)
-      if(HAS_CPP11_FLAG)
-        set(PYBIND11_CPP_STANDARD -std=c++11)
-      endif()
+# A user can set versions manually too
+set(Python_ADDITIONAL_VERSIONS
+    "3.9;3.8;3.7;3.6;3.5;3.4"
+    CACHE INTERNAL "")
+
+list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_LIST_DIR}")
+find_package(PythonLibsNew ${PYBIND11_PYTHON_VERSION} MODULE REQUIRED ${_pybind11_quiet})
+list(REMOVE_AT CMAKE_MODULE_PATH -1)
+
+# Cache variables so pybind11_add_module can be used in parent projects
+set(PYTHON_INCLUDE_DIRS
+    ${PYTHON_INCLUDE_DIRS}
+    CACHE INTERNAL "")
+set(PYTHON_LIBRARIES
+    ${PYTHON_LIBRARIES}
+    CACHE INTERNAL "")
+set(PYTHON_MODULE_PREFIX
+    ${PYTHON_MODULE_PREFIX}
+    CACHE INTERNAL "")
+set(PYTHON_MODULE_EXTENSION
+    ${PYTHON_MODULE_EXTENSION}
+    CACHE INTERNAL "")
+set(PYTHON_VERSION_MAJOR
+    ${PYTHON_VERSION_MAJOR}
+    CACHE INTERNAL "")
+set(PYTHON_VERSION_MINOR
+    ${PYTHON_VERSION_MINOR}
+    CACHE INTERNAL "")
+set(PYTHON_VERSION
+    ${PYTHON_VERSION}
+    CACHE INTERNAL "")
+set(PYTHON_IS_DEBUG
+    "${PYTHON_IS_DEBUG}"
+    CACHE INTERNAL "")
+
+if(PYBIND11_MASTER_PROJECT)
+  if(PYTHON_MODULE_EXTENSION MATCHES "pypy")
+    if(NOT DEFINED PYPY_VERSION)
+      execute_process(
+        COMMAND ${PYTHON_EXECUTABLE} -c
+                [=[import sys; print(".".join(map(str, sys.pypy_version_info[:3])))]=]
+        OUTPUT_VARIABLE pypy_version)
+      set(PYPY_VERSION
+          ${pypy_version}
+          CACHE INTERNAL "")
     endif()
+    message(STATUS "PYPY ${PYPY_VERSION} (Py ${PYTHON_VERSION})")
+  else()
+    message(STATUS "PYTHON ${PYTHON_VERSION}")
   endif()
-
-  if(NOT PYBIND11_CPP_STANDARD)
-    message(FATAL_ERROR "Unsupported compiler -- pybind11 requires C++11 support!")
-  endif()
-  set(PYBIND11_CPP_STANDARD ${PYBIND11_CPP_STANDARD} CACHE STRING
-      "C++ standard flag, e.g. -std=c++11, -std=c++14, /std:c++14.  Defaults to C++14 mode." FORCE)
 endif()
 
-# Checks whether the given CXX/linker flags can compile and link a cxx file.  cxxflags and
-# linkerflags are lists of flags to use.  The result variable is a unique variable name for each set
-# of flags: the compilation result will be cached base on the result variable.  If the flags work,
-# sets them in cxxflags_out/linkerflags_out internal cache variables (in addition to ${result}).
-function(_pybind11_return_if_cxx_and_linker_flags_work result cxxflags linkerflags cxxflags_out linkerflags_out)
-  set(CMAKE_REQUIRED_LIBRARIES ${linkerflags})
-  check_cxx_compiler_flag("${cxxflags}" ${result})
-  if (${result})
-    set(${cxxflags_out} "${cxxflags}" CACHE INTERNAL "" FORCE)
-    set(${linkerflags_out} "${linkerflags}" CACHE INTERNAL "" FORCE)
-  endif()
-endfunction()
+# Only add Python for build - must be added during the import for config since it has to be re-discovered.
+set_property(
+  TARGET pybind11::pybind11
+  APPEND
+  PROPERTY INTERFACE_INCLUDE_DIRECTORIES $<BUILD_INTERFACE:${PYTHON_INCLUDE_DIRS}>)
+
+# Python debug libraries expose slightly different objects before 3.8
+# https://docs.python.org/3.6/c-api/intro.html#debugging-builds
+# https://stackoverflow.com/questions/39161202/how-to-work-around-missing-pymodule-create2-in-amd64-win-python35-d-lib
+if(PYTHON_IS_DEBUG)
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_COMPILE_DEFINITIONS Py_DEBUG)
+endif()
 
-# Internal: find the appropriate link time optimization flags for this compiler
-function(_pybind11_add_lto_flags target_name prefer_thin_lto)
-  if (NOT DEFINED PYBIND11_LTO_CXX_FLAGS)
-    set(PYBIND11_LTO_CXX_FLAGS "" CACHE INTERNAL "")
-    set(PYBIND11_LTO_LINKER_FLAGS "" CACHE INTERNAL "")
-
-    if(CMAKE_CXX_COMPILER_ID MATCHES "GNU|Clang")
-      set(cxx_append "")
-      set(linker_append "")
-      if (CMAKE_CXX_COMPILER_ID MATCHES "Clang" AND NOT APPLE)
-        # Clang Gold plugin does not support -Os; append -O3 to MinSizeRel builds to override it
-        set(linker_append ";$<$<CONFIG:MinSizeRel>:-O3>")
-      elseif(CMAKE_CXX_COMPILER_ID MATCHES "GNU")
-        set(cxx_append ";-fno-fat-lto-objects")
-      endif()
-
-      if (CMAKE_CXX_COMPILER_ID MATCHES "Clang" AND prefer_thin_lto)
-        _pybind11_return_if_cxx_and_linker_flags_work(HAS_FLTO_THIN
-          "-flto=thin${cxx_append}" "-flto=thin${linker_append}"
-          PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-      endif()
-
-      if (NOT HAS_FLTO_THIN)
-        _pybind11_return_if_cxx_and_linker_flags_work(HAS_FLTO
-          "-flto${cxx_append}" "-flto${linker_append}"
-          PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-      endif()
-    elseif (CMAKE_CXX_COMPILER_ID MATCHES "Intel")
-      # Intel equivalent to LTO is called IPO
-      _pybind11_return_if_cxx_and_linker_flags_work(HAS_INTEL_IPO
-      "-ipo" "-ipo" PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-    elseif(MSVC)
-      # cmake only interprets libraries as linker flags when they start with a - (otherwise it
-      # converts /LTCG to \LTCG as if it was a Windows path).  Luckily MSVC supports passing flags
-      # with - instead of /, even if it is a bit non-standard:
-      _pybind11_return_if_cxx_and_linker_flags_work(HAS_MSVC_GL_LTCG
-        "/GL" "-LTCG" PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-    endif()
+set_property(
+  TARGET pybind11::module
+  APPEND
+  PROPERTY
+    INTERFACE_LINK_LIBRARIES pybind11::python_link_helper
+    "$<$<OR:$<PLATFORM_ID:Windows>,$<PLATFORM_ID:Cygwin>>:$<BUILD_INTERFACE:${PYTHON_LIBRARIES}>>")
+
+if(PYTHON_VERSION VERSION_LESS 3)
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES pybind11::python2_no_register)
+endif()
 
-    if (PYBIND11_LTO_CXX_FLAGS)
-      message(STATUS "LTO enabled")
-    else()
-      message(STATUS "LTO disabled (not supported by the compiler and/or linker)")
-    endif()
-  endif()
+set_property(
+  TARGET pybind11::embed
+  APPEND
+  PROPERTY INTERFACE_LINK_LIBRARIES pybind11::pybind11 $<BUILD_INTERFACE:${PYTHON_LIBRARIES}>)
 
-  # Enable LTO flags if found, except for Debug builds
-  if (PYBIND11_LTO_CXX_FLAGS)
-    target_compile_options(${target_name} PRIVATE "$<$<NOT:$<CONFIG:Debug>>:${PYBIND11_LTO_CXX_FLAGS}>")
-  endif()
-  if (PYBIND11_LTO_LINKER_FLAGS)
-    target_link_libraries(${target_name} PRIVATE "$<$<NOT:$<CONFIG:Debug>>:${PYBIND11_LTO_LINKER_FLAGS}>")
-  endif()
+function(pybind11_extension name)
+  # The prefix and extension are provided by FindPythonLibsNew.cmake
+  set_target_properties(${name} PROPERTIES PREFIX "${PYTHON_MODULE_PREFIX}"
+                                           SUFFIX "${PYTHON_MODULE_EXTENSION}")
 endfunction()
 
 # Build a Python extension module:
 # pybind11_add_module(<name> [MODULE | SHARED] [EXCLUDE_FROM_ALL]
-#                     [NO_EXTRAS] [SYSTEM] [THIN_LTO] source1 [source2 ...])
+#                     [NO_EXTRAS] [THIN_LTO] [OPT_SIZE] source1 [source2 ...])
 #
 function(pybind11_add_module target_name)
-  set(options MODULE SHARED EXCLUDE_FROM_ALL NO_EXTRAS SYSTEM THIN_LTO)
+  set(options "MODULE;SHARED;EXCLUDE_FROM_ALL;NO_EXTRAS;SYSTEM;THIN_LTO;OPT_SIZE")
   cmake_parse_arguments(ARG "${options}" "" "" ${ARGN})
 
   if(ARG_MODULE AND ARG_SHARED)
@@ -148,113 +146,46 @@ function(pybind11_add_module target_name
 
   add_library(${target_name} ${lib_type} ${exclude_from_all} ${ARG_UNPARSED_ARGUMENTS})
 
-  if(ARG_SYSTEM)
-    set(inc_isystem SYSTEM)
-  else()
-    set(inc_isystem "")
-  endif()
+  target_link_libraries(${target_name} PRIVATE pybind11::module)
 
-  set(PYBIND11_INCLUDE_DIR_SELECTED "")
-  if(PYBIND11_INCLUDE_DIR)
-    # from project CMakeLists.txt
-    set(PYBIND11_INCLUDE_DIR_SELECTED ${PYBIND11_INCLUDE_DIR})
-  elseif(pybind11_INCLUDE_DIR)
-    # from pybind11Config
-    set(PYBIND11_INCLUDE_DIR_SELECTED ${pybind11_INCLUDE_DIR})
-  else()
-    message(FATAL "No pybind11_INCLUDE_DIR available. Use "
-      "find_package(pybind11) before calling pybind11_add_module.")
+  if(ARG_SYSTEM)
+    message(
+      STATUS
+        "Warning: this does not have an effect - use NO_SYSTEM_FROM_IMPORTED if using imported targets"
+    )
   endif()
 
-  target_include_directories(${target_name} ${inc_isystem}
-    PRIVATE ${PYBIND11_INCLUDE_DIR_SELECTED}
-    PRIVATE ${PYTHON_INCLUDE_DIRS})
-
-  # Python debug libraries expose slightly different objects
-  # https://docs.python.org/3.6/c-api/intro.html#debugging-builds
-  # https://stackoverflow.com/questions/39161202/how-to-work-around-missing-pymodule-create2-in-amd64-win-python35-d-lib
-  if(PYTHON_IS_DEBUG)
-    target_compile_definitions(${target_name} PRIVATE Py_DEBUG)
-  endif()
-
-  # The prefix and extension are provided by FindPythonLibsNew.cmake
-  set_target_properties(${target_name} PROPERTIES PREFIX "${PYTHON_MODULE_PREFIX}")
-  set_target_properties(${target_name} PROPERTIES SUFFIX "${PYTHON_MODULE_EXTENSION}")
+  pybind11_extension(${target_name})
 
   # -fvisibility=hidden is required to allow multiple modules compiled against
   # different pybind versions to work properly, and for some features (e.g.
   # py::module_local).  We force it on everything inside the `pybind11`
   # namespace; also turning it on for a pybind module compilation here avoids
   # potential warnings or issues from having mixed hidden/non-hidden types.
-  set_target_properties(${target_name} PROPERTIES CXX_VISIBILITY_PRESET "hidden")
-  set_target_properties(${target_name} PROPERTIES CUDA_VISIBILITY_PRESET "hidden")
+  set_target_properties(${target_name} PROPERTIES CXX_VISIBILITY_PRESET "hidden"
+                                                  CUDA_VISIBILITY_PRESET "hidden")
 
-  if(WIN32 OR CYGWIN)
-    # Link against the Python shared library on Windows
-    target_link_libraries(${target_name} PRIVATE ${PYTHON_LIBRARIES})
-  elseif(APPLE)
-    # It's quite common to have multiple copies of the same Python version
-    # installed on one's system. E.g.: one copy from the OS and another copy
-    # that's statically linked into an application like Blender or Maya.
-    # If we link our plugin library against the OS Python here and import it
-    # into Blender or Maya later on, this will cause segfaults when multiple
-    # conflicting Python instances are active at the same time (even when they
-    # are of the same version).
-
-    # Windows is not affected by this issue since it handles DLL imports
-    # differently. The solution for Linux and Mac OS is simple: we just don't
-    # link against the Python library. The resulting shared library will have
-    # missing symbols, but that's perfectly fine -- they will be resolved at
-    # import time.
-
-    target_link_libraries(${target_name} PRIVATE "-undefined dynamic_lookup")
-
-    if(ARG_SHARED)
-      # Suppress CMake >= 3.0 warning for shared libraries
-      set_target_properties(${target_name} PROPERTIES MACOSX_RPATH ON)
-    endif()
+  if(ARG_NO_EXTRAS)
+    return()
   endif()
 
-  # Make sure C++11/14 are enabled
-  if(PYBIND11_CPP_STANDARD)
-    if(CMAKE_VERSION VERSION_LESS 3.3)
-      target_compile_options(${target_name} PUBLIC ${PYBIND11_CPP_STANDARD})
+  if(NOT DEFINED CMAKE_INTERPROCEDURAL_OPTIMIZATION)
+    if(ARG_THIN_LTO)
+      target_link_libraries(${target_name} PRIVATE pybind11::thin_lto)
     else()
-      target_compile_options(${target_name} PUBLIC $<$<COMPILE_LANGUAGE:CXX>:${PYBIND11_CPP_STANDARD}>)
+      target_link_libraries(${target_name} PRIVATE pybind11::lto)
     endif()
   endif()
 
-  if(ARG_NO_EXTRAS)
-    return()
+  if(NOT MSVC AND NOT ${CMAKE_BUILD_TYPE} MATCHES Debug|RelWithDebInfo)
+    pybind11_strip(${target_name})
   endif()
 
-  _pybind11_add_lto_flags(${target_name} ${ARG_THIN_LTO})
-
-  if (NOT MSVC AND NOT ${CMAKE_BUILD_TYPE} MATCHES Debug|RelWithDebInfo)
-    # Strip unnecessary sections of the binary on Linux/Mac OS
-    if(CMAKE_STRIP)
-      if(APPLE)
-        add_custom_command(TARGET ${target_name} POST_BUILD
-                           COMMAND ${CMAKE_STRIP} -x $<TARGET_FILE:${target_name}>)
-      else()
-        add_custom_command(TARGET ${target_name} POST_BUILD
-                           COMMAND ${CMAKE_STRIP} $<TARGET_FILE:${target_name}>)
-      endif()
-    endif()
+  if(MSVC)
+    target_link_libraries(${target_name} PRIVATE pybind11::windows_extras)
   endif()
 
-  if(MSVC)
-    # /MP enables multithreaded builds (relevant when there are many files), /bigobj is
-    # needed for bigger binding projects due to the limit to 64k addressable sections
-    target_compile_options(${target_name} PRIVATE /bigobj)
-    if(CMAKE_VERSION VERSION_LESS 3.11)
-      target_compile_options(${target_name} PRIVATE $<$<NOT:$<CONFIG:Debug>>:/MP>)
-    else()
-      # Only set these options for C++ files.  This is important so that, for
-      # instance, projects that include other types of source files like CUDA
-      # .cu files don't get these options propagated to nvcc since that would
-      # cause the build to fail.
-      target_compile_options(${target_name} PRIVATE $<$<NOT:$<CONFIG:Debug>>:$<$<COMPILE_LANGUAGE:CXX>:/MP>>)
-    endif()
+  if(ARG_OPT_SIZE)
+    target_link_libraries(${target_name} PRIVATE pybind11::opt_size)
   endif()
 endfunction()
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tools/pyproject.toml
@@ -0,0 +1,3 @@
+[build-system]
+requires = ["setuptools", "wheel"]
+build-backend = "setuptools.build_meta"
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tools/setup_global.py.in
@@ -0,0 +1,53 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+# Setup script for pybind11-global (in the sdist or in tools/setup_global.py in the repository)
+# This package is targeted for easy use from CMake.
+
+import contextlib
+import glob
+import os
+import re
+import shutil
+import subprocess
+import sys
+import tempfile
+
+# Setuptools has to be before distutils
+from setuptools import setup
+
+from distutils.command.install_headers import install_headers
+
+class InstallHeadersNested(install_headers):
+    def run(self):
+        headers = self.distribution.headers or []
+        for header in headers:
+            # Remove pybind11/include/
+            short_header = header.split("/", 2)[-1]
+
+            dst = os.path.join(self.install_dir, os.path.dirname(short_header))
+            self.mkpath(dst)
+            (out, _) = self.copy_file(header, dst)
+            self.outfiles.append(out)
+
+
+main_headers = glob.glob("pybind11/include/pybind11/*.h")
+detail_headers = glob.glob("pybind11/include/pybind11/detail/*.h")
+cmake_files = glob.glob("pybind11/share/cmake/pybind11/*.cmake")
+headers = main_headers + detail_headers
+
+cmdclass = {"install_headers": InstallHeadersNested}
+$extra_cmd
+
+setup(
+    name="pybind11_global",
+    version="$version",
+    packages=[],
+    headers=headers,
+    data_files=[
+        ("share/cmake/pybind11", cmake_files),
+        ("include/pybind11", main_headers),
+        ("include/pybind11/detail", detail_headers),
+    ],
+    cmdclass=cmdclass,
+)
--- /dev/null
+++ gtsam-4.1.0/wrap/pybind11/tools/setup_main.py.in
@@ -0,0 +1,35 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+# Setup script (in the sdist or in tools/setup_main.py in the repository)
+
+from setuptools import setup
+
+cmdclass = {}
+$extra_cmd
+
+setup(
+    name="pybind11",
+    version="$version",
+    download_url='https://github.com/pybind/pybind11/tarball/v$version',
+    packages=[
+        "pybind11",
+        "pybind11.include.pybind11",
+        "pybind11.include.pybind11.detail",
+        "pybind11.share.cmake.pybind11",
+    ],
+    package_data={
+        "pybind11.include.pybind11": ["*.h"],
+        "pybind11.include.pybind11.detail": ["*.h"],
+        "pybind11.share.cmake.pybind11": ["*.cmake"],
+    },
+    extras_require={
+        "global": ["pybind11_global==$version"]
+        },
+    entry_points={
+        "console_scripts": [
+             "pybind11-config = pybind11.__main__:main",
+        ]
+    },
+    cmdclass=cmdclass
+)
--- gtsam-4.1.0.orig/wrap/pybind_wrapper.py
+++ gtsam-4.1.0/wrap/pybind_wrapper.py
@@ -69,13 +69,13 @@ class PybindWrapper(object):
             return textwrap.dedent('''
                     .def("serialize",
                         []({class_inst} self){{
-                            return gtsam::serialize(self);
+                            return gtsam::serialize(*self);
                         }}
                     )
                     .def("deserialize",
                         []({class_inst} self, string serialized){{
-                            return gtsam::deserialize(serialized, self);
-                        }})
+                            gtsam::deserialize(serialized, *self);
+                        }}, py::arg("serialized"))
                     '''.format(class_inst=cpp_class + '*'))
 
         is_method = isinstance(method, instantiator.InstantiatedMethod)
--- gtsam-4.1.0.orig/wrap/tests/expected-python/geometry_pybind.cpp
+++ gtsam-4.1.0/wrap/tests/expected-python/geometry_pybind.cpp
@@ -40,13 +40,13 @@ PYBIND11_MODULE(geometry_py, m_) {
         .def("vectorConfusion",[](gtsam::Point2* self){return self->vectorConfusion();})
 .def("serialize",
     [](gtsam::Point2* self){
-        return gtsam::serialize(self);
+        return gtsam::serialize(*self);
     }
 )
 .def("deserialize",
     [](gtsam::Point2* self, string serialized){
-        return gtsam::deserialize(serialized, self);
-    })
+        gtsam::deserialize(serialized, *self);
+    }, py::arg("serialized"))
 ;
 
     py::class_<gtsam::Point3, std::shared_ptr<gtsam::Point3>>(m_gtsam, "Point3")
@@ -54,13 +54,13 @@ PYBIND11_MODULE(geometry_py, m_) {
         .def("norm",[](gtsam::Point3* self){return self->norm();})
 .def("serialize",
     [](gtsam::Point3* self){
-        return gtsam::serialize(self);
+        return gtsam::serialize(*self);
     }
 )
 .def("deserialize",
     [](gtsam::Point3* self, string serialized){
-        return gtsam::deserialize(serialized, self);
-    })
+        gtsam::deserialize(serialized, *self);
+    }, py::arg("serialized"))
 
         .def_static("staticFunction",[](){return gtsam::Point3::staticFunction();})
         .def_static("StaticFunctionRet",[]( double z){return gtsam::Point3::StaticFunctionRet(z);}, py::arg("z"));
